[{"URL": "https://www.semanticscholar.org/paper/Nucleus-segmentation-across-imaging-experiments%3A-Caicedo-Goodman/0b5b33b7ea1dc12f3e9252ac1852170a6a6775bf", "ID": "0b5b33b7ea1dc12f3e9252ac1852170a6a6775bf", "Title": "Nucleus segmentation across imaging experiments: the 2018 Data Science Bowl", "Abstract": "The 2018 Data Science Bowl attracted 3,891 teams worldwide to make the first attempt to build a segmentation method that could be applied to any two-dimensional light microscopy image of stained nuclei across experiments, with no human interaction. Segmenting the nuclei of cells in microscopy images is often the first step in the quantitative analysis of imaging data for biological and biomedical applications. Many bioimage analysis tools can segment nuclei in images but need to be selected and configured for every experiment. The 2018 Data Science Bowl attracted 3,891 teams worldwide to make the first attempt to build a segmentation method that could be applied to any two-dimensional light microscopy image of stained nuclei across experiments, with no human interaction. Top participants in the challenge succeeded in this task, developing deep-learning-based models that identified cell nuclei across many image types and experimental conditions without the need to manually adjust segmentation parameters. This represents an important step toward configuration-free bioimage analysis software tools. The 2018 Data Science Bowl challenged competitors to develop an accurate tool for segmenting stained nuclei from diverse light microscopy images. The winners deployed innovative deep-learning strategies to realize configuration-free segmentation.", "PublicationYear": "2019", "Authors": ["Juan C. Caicedo", "Allen Goodman", "Kyle W. Karhohs", "Beth A. Cimini", "Jeanelle Ackerman", "Marzieh Haghighi", "Cherkeng Heng", "Tim Becker", "Minh Doan", "Claire McQuin", "Mohammad Hossein Rohban", "Shantanu Singh", "Anne E Carpenter"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["c89bfd998b0a6c656010b629814ab0cad3cff72e", "a1af04fa0a581a9f134a734363b1786ab2c355b7", "e1b3ad532f9346d51578c32dc6b070c9744a8d88", "505e72b8d60e987e89b93fdd98859b857ca94207", "713e881b5c3134debf934026edf6f0ba3cb42c3c", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "68f30bd22817a17adc837eb285e51c9628f00e8d", "31a27c6500b6652d7ecc055c9b08457ad90128c1", "cee3035635eafa1c412934419d7563fdb06d73ae", "48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852"], "ReferenceCount": 53, "CitationCount": 427}, {"URL": "https://www.semanticscholar.org/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d", "ID": "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d", "Title": "Multiresolution Knowledge Distillation for Anomaly Detection", "Abstract": "This work proposes to use the \\\"distillation\\\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle anomaly detection and localization. Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the \\\"distillation\\\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks\u2019 intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert\u2019s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.", "PublicationYear": "2020", "Authors": ["Mohammadreza Salehi", "Niousha Sadjadi", "Soroosh Baselizadeh", "Mohammad Hossein Rohban", "Hamid R. Rabiee"], "RelatedTopics": ["Computer Science"], "References": ["4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "5db790198b9acf4e5efe350acdd814238fcacaa7", "0535625be630c6a67f4c244ebf3aa61ad088fc70", "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "41747cbdbed84762dfbfc305254c97021279dc6e", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "8381157eae4fbf8908d0312a9642f8e69e944449", "d9d7ab13ce305ccee309c989a2341d72b1252070", "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d"], "ReferenceCount": 62, "CitationCount": 213}, {"URL": "https://www.semanticscholar.org/paper/Data-analysis-strategies-for-image-based-cell-Caicedo-Cooper/1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5", "ID": "1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5", "Title": "Data-analysis strategies for image-based cell profiling", "Abstract": "The steps required to create high-quality image-based (i.e., morphological) profiles from a collection of microscopy images are introduced and techniques that have proven useful in each stage of the data analysis process are recommended on the basis of the experience of 20 laboratories worldwide that are refining their image- based cell-profiling methodologies. Image-based cell profiling is a high-throughput strategy for the quantification of phenotypic differences among a variety of cell populations. It paves the way to studying biological systems on a large scale by using chemical and genetic perturbations. The general workflow for this technology involves image acquisition with high-throughput microscopy systems and subsequent image processing and analysis. Here, we introduce the steps required to create high-quality image-based (i.e., morphological) profiles from a collection of microscopy images. We recommend techniques that have proven useful in each stage of the data analysis process, on the basis of the experience of 20 laboratories worldwide that are refining their image-based cell-profiling methodologies in pursuit of biological discovery. The recommended techniques cover alternatives that may suit various biological goals, experimental designs, and laboratories' preferences.", "PublicationYear": "2017", "Authors": ["Juan C. Caicedo", "Sam Cooper", "Florian Heigwer", "Scott Warchal", "Peng Qiu", "Csaba Molnar", "Aliaksei S. Vasilevich", "Joseph D Barry", "Harmanjit Singh Bansal", "Oren Z. Kraus", "Mathias Wawer", "Lassi Paavolainen", "Markus D. Herrmann", "Mohammad Hossein Rohban", "Jane Hung", "Holger Hennig", "John B. Concannon", "Ian Smith", "Paul A. Clemons", "Shantanu Singh", "Paul Rees", "P{\\'e}ter Horv{\\'a}th", "Roger G. Linington", "Anne E Carpenter"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["929a490198770abcb8c123d68a59384879b69adb", "29c736eb38861ecf346ce49eedf163c03974566b", "36748de338909976f72ffbadaf097470ec040da0", "6bfc1c0c7d3fc3cd9ebb9517cc0de73e841b7f74", "aa0875ccc516862edc0b6bd2181ee27ce882933d", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "8db554d7e597000f5a0e13712ef0cb3299c05187", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "8a7ce466e8f119f033aeace4210cc348ed62520b", "669832b732a20ccbdbb81c22393f4bc8f9371dbc"], "ReferenceCount": 154, "CitationCount": 483}, {"URL": "https://www.semanticscholar.org/paper/Minimax-Optimal-Sparse-Signal-Recovery-With-Poisson-Rohban-Saligrama/0e16a10560b4f7d5f891b932c79d1b2005407acf", "ID": "0e16a10560b4f7d5f891b932c79d1b2005407acf", "Title": "Minimax Optimal Sparse Signal Recovery With Poisson Statistics", "Abstract": "This work derives a minimax matching lower bound on the mean-squared error of the maximum likelihood decoder and shows that the constrained ML decoder is minimax optimal for this regime. We are motivated by problems that arise in a number of applications such as Online Marketing and Explosives detection, where the observations are usually modeled using Poisson statistics. We model each observation as a Poisson random variable whose mean is a sparse linear superposition of known patterns. Unlike many conventional problems observations here are not identically distributed since they are associated with different sensing modalities. We analyze the performance of a maximum likelihood (ML) decoder, which for our Poisson setting involves a non-linear optimization but yet is computationally tractable. We derive fundamental sample complexity bounds for sparse recovery when the measurements are contaminated with Poisson noise. In contrast to the least-squares linear regression setting with Gaussian noise, we observe that in addition to sparsity, the scale of the parameters also fundamentally impacts l2 error in the Poisson setting. We show that our upper bounds are tight under suitable regularity conditions. Specifically, we derive a minimax matching lower bound on the mean-squared error and show that our constrained ML decoder is minimax optimal for this regime.", "PublicationYear": "2015", "Authors": ["Mohammad Hossein Rohban", "Venkatesh Saligrama", "Delaram Motamed Vaziri"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["3ecba59e99a4cd5f146270debc5ef8d214697c77", "51ff6cfb98eec39da52035d87f329cf9e89462e6", "1ed22f981940b25d3ceac8846153b3521e8cae7b", "46dfa751eade5e60ab16b51496a9c764bced2322", "e4d56ec1be5603ddb2cd5b9264e365a19dbd5217", "8f4f9faa26027f8eae4474d90f6d31c0749acd49", "5f56320c5979faeab78dbd9ddb7db755ba4550f3", "e716688ddc25dcc8871ef04c7f864063949aa8b9", "fe09efb519b26d59c64c715c4efcbe752dc933be", "046d550f95db0dae9aa26b34c31cb502b5b72983"], "ReferenceCount": 25, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/ARAE%3A-Adversarially-Robust-Training-of-Autoencoders-Salehi-Arya/10b219619e88931fabb674037bbb633682775136", "ID": "10b219619e88931fabb674037bbb633682775136", "Title": "ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection", "Abstract": "Semantic Scholar extracted view of \\\"ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection\\\" by Mohammadreza Salehi et al.", "PublicationYear": "2020", "Authors": ["Mohammadreza Salehi", "Atrin Arya", "Barbod Pajoum", "Mohammad Otoofi", "Amirreza Shaeiri", "Mohammad Hossein Rohban", "Hamid R. Rabiee"], "RelatedTopics": ["Computer Science"], "References": ["70f9968a356d840040a1c9207906f60376dc6bd4", "8381157eae4fbf8908d0312a9642f8e69e944449", "0535625be630c6a67f4c244ebf3aa61ad088fc70", "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "6af440915b8a0718c93be1cf61905e41e620484a", "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803", "599fd051c9438011ec5b581983c89e8922b4a5e6", "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "0314e777333a63aca5735ea136c74e113aa8801d"], "ReferenceCount": 49, "CitationCount": 42}, {"URL": "https://www.semanticscholar.org/paper/Evaluation-of-Deep-Learning-Strategies-for-Nucleus-Caicedo-Roth/c89bfd998b0a6c656010b629814ab0cad3cff72e", "ID": "c89bfd998b0a6c656010b629814ab0cad3cff72e", "Title": "Evaluation of Deep Learning Strategies for Nucleus Segmentation in Fluorescence Images", "Abstract": "This work presents an evaluation framework to measure accuracy, types of errors, and computational efficiency; and uses it to compare two deep learning strategies (U-Net and DeepCell) alongside a classical approach implemented in CellProfiler. Identifying nuclei is often a critical first step in analyzing microscopy images of cells, and classical image processing algorithms are most commonly used for this task. Recent developments in deep learning can yield superior accuracy, but typical evaluation metrics for nucleus segmentation do not satisfactorily capture error modes that are relevant in cellular images. Besides, large image data sets with ground truth for evaluation have been limiting. We present an evaluation framework to measure accuracy, types of errors, and computational efficiency; and use it to compare two deep learning strategies (U-Net and DeepCell) alongside a classical approach implemented in CellProfiler. We publicly release a set of 23,165 manually annotated nuclei and source code to reproduce experiments. Our results show that U-Net outperforms both pixel-wise classification networks and classical algorithms. Also, our evaluation framework shows that deep learning improves accuracy and reduces the number of biologically relevant errors by half.", "PublicationYear": "2018", "Authors": ["Juan C. Caicedo", "Jonathan F Roth", "Allen Goodman", "Tim Becker", "Kyle W. Karhohs", "Claire McQuin", "Shantanu Singh", "Anne E Carpenter"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["e1b3ad532f9346d51578c32dc6b070c9744a8d88", "d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88", "68f30bd22817a17adc837eb285e51c9628f00e8d", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "318f82a3e593e391cfd0da7964b16d83299aa943", "2d8d74c7fd9375b17e9d6123773919b2aa512c56", "1268de7bda769e651dc6c089d006c7edbe37f563", "713e881b5c3134debf934026edf6f0ba3cb42c3c", "36748de338909976f72ffbadaf097470ec040da0"], "ReferenceCount": 53, "CitationCount": 226}, {"URL": "https://www.semanticscholar.org/paper/A-deep-learning-framework-for-nucleus-segmentation-Hollandi-Szkalisity/a1af04fa0a581a9f134a734363b1786ab2c355b7", "ID": "a1af04fa0a581a9f134a734363b1786ab2c355b7", "Title": "A deep learning framework for nucleus segmentation using image style transfer", "Abstract": "This work presents a deep learning approach aiming towards a truly general method for localizing nuclei across a diverse range of assays and light microscopy modalities and outperforms the 739 methods submitted to the 2018 Data Science Bowl on images representing a variety of realistic conditions. Single cell segmentation is typically one of the first and most crucial tasks of image-based cellular analysis. We present a deep learning approach aiming towards a truly general method for localizing nuclei across a diverse range of assays and light microscopy modalities. We outperform the 739 methods submitted to the 2018 Data Science Bowl on images representing a variety of realistic conditions, some of which were not represented in the training data. The key to our approach is to adapt our model to unseen and unlabeled data using image style transfer to generate augmented training samples. This allows the model to recognize nuclei in new and different experiments without requiring expert annotations.", "PublicationYear": "2019", "Authors": ["R{\\'e}ka Hollandi", "{\\'A}bel Szkalisity", "Timea Toth", "Ervin A. Tasn{\\'a}di", "Csaba Molnar", "Botond M{\\'a}th{\\'e}", "Istvan Grexa", "J{\\'o}zsef Moln{\\'a}r", "{\\'A}rp{\\'a}d B{\\'a}lind", "Mate Gorbe", "M{\\'a}ria Kov{\\'a}cs", "Ede Migh", "Allen Goodman", "Tam{\\'a}s Balassa", "Krisztian Koos", "Wenyu Wang", "Norbert Bara", "Ferenc Kov{\\'a}cs", "Lassi Paavolainen", "Tivadar Danka", "Andr{\\'a}s Kriston", "Anne E Carpenter", "Kevin Smith", "P{\\'e}ter Horv{\\'a}th"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["c89bfd998b0a6c656010b629814ab0cad3cff72e", "e1b3ad532f9346d51578c32dc6b070c9744a8d88", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "5c5be36e3111e42247d78a6d529e4b1d7d2ced12", "b2d952fbd6951cbed68ea13003a045300970731a", "268241fd604918a86e1b27e1a880d47e0ecc2d5b", "ea99a5535388196d0d44be5b4d7dd02029a43bb2", "8acbe90d5b852dadea7810345451a99608ee54c7", "318f82a3e593e391cfd0da7964b16d83299aa943", "6ff93aa6ca902002d16fb0c2d3fb48aead92c61e"], "ReferenceCount": 18, "CitationCount": 40}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-Automates-the-Quantitative-Analysis-Valen-Kudo/e1b3ad532f9346d51578c32dc6b070c9744a8d88", "ID": "e1b3ad532f9346d51578c32dc6b070c9744a8d88", "Title": "Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments", "Abstract": "Deep convolutional neural networks are an accurate method that require less curation time, are generalizable to a multiplicity of cell types, from bacteria to mammalian cells, and expand live-cell imaging capabilities to include multi-cell type systems. Live-cell imaging has opened an exciting window into the role cellular heterogeneity plays in dynamic, living systems. A major critical challenge for this class of experiments is the problem of image segmentation, or determining which parts of a microscope image correspond to which individual cells. Current approaches require many hours of manual curation and depend on approaches that are difficult to share between labs. They are also unable to robustly segment the cytoplasms of mammalian cells. Here, we show that deep convolutional neural networks, a supervised machine learning method, can solve this challenge for multiple cell types across the domains of life. We demonstrate that this approach can robustly segment fluorescent images of cell nuclei as well as phase images of the cytoplasms of individual bacterial and mammalian cells from phase contrast images without the need for a fluorescent cytoplasmic marker. These networks also enable the simultaneous segmentation and identification of different mammalian cell types grown in co-culture. A quantitative comparison with prior methods demonstrates that convolutional neural networks have improved accuracy and lead to a significant reduction in curation time. We relay our experience in designing and optimizing deep convolutional neural networks for this task and outline several design rules that we found led to robust performance. We conclude that deep convolutional neural networks are an accurate method that require less curation time, are generalizable to a multiplicity of cell types, from bacteria to mammalian cells, and expand live-cell imaging capabilities to include multi-cell type systems.", "PublicationYear": "2016", "Authors": ["David A. Van Valen", "Takamasa Kudo", "Keara M. Lane", "Derek N. Macklin", "Nicolas T. Quach", "Mialy M. DeFelice", "Inbal Maayan", "Yu Tanouchi", "Euan A. Ashley", "Markus W. Covert"], "RelatedTopics": ["Biology", "Computer Science", "Engineering"], "References": ["f9b78ff4e2688a7bcae801228359cce3da8af9e3", "dff96ab49f149abac97dcdd7197d30cee9652824", "40f00f7150b2dbdee48e80e8b6a7d63d9b34f149", "b2fda25ffe204246e5679669f7d387d23b73a4d1", "7dbb02543eae351a3eb8c268741bdde40519043e", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "eeb1ea310ed0c610aa20df843e26f98c142f3dce", "18516d4be3d9b478684d4b7659eda10f94133385", "9c3d224d328ec5a44b24f87589232d8aed499c11", "1268de7bda769e651dc6c089d006c7edbe37f563"], "ReferenceCount": 70, "CitationCount": 424}, {"URL": "https://www.semanticscholar.org/paper/A-deep-learning-algorithm-for-one-step-contour-of-Cui-Zhang/505e72b8d60e987e89b93fdd98859b857ca94207", "ID": "505e72b8d60e987e89b93fdd98859b857ca94207", "Title": "A deep learning algorithm for one-step contour aware nuclei segmentation of histopathology images", "Abstract": "An automatic end-to-end deep neural network algorithm for segmentation of individual nuclei using a nucleus-boundary model to predict nuclei and their boundaries simultaneously simultaneously using a fully convolutional neural network is proposed. This paper addresses the task of nuclei segmentation in high-resolution histopathology images. We propose an automatic end-to-end deep neural network algorithm for segmentation of individual nuclei. A nucleus-boundary model is introduced to predict nuclei and their boundaries simultaneously using a fully convolutional neural network. Given a color-normalized image, the model directly outputs an estimated nuclei map and a boundary map. A simple, fast, and parameter-free post-processing procedure is performed on the estimated nuclei map to produce the final segmented nuclei. An overlapped patch extraction and assembling method is also designed for seamless prediction of nuclei in large whole-slide images. We also show the effectiveness of data augmentation methods for nuclei segmentation task. Our experiments showed our method outperforms prior state-of-the-art methods. Moreover, it is efficient that one 1000\u00d71000 image can be segmented in less than 5 s. This makes it possible to precisely segment the whole-slide image in acceptable time. The source code is available at https://github.com/easycui/nuclei_segmentation. Graphical Abstract The neural network for nuclei segmentation The neural network for nuclei segmentation", "PublicationYear": "2018", "Authors": ["Yuxin Cui", "Guiying Zhang", "Zhonghao Liu", "Zheng Xiong", "Jianjun Hu"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88", "78db21fabea962592ac0aef54624251550929109", "63a373063d51489b31e07ee639ab74b6cf586240", "7256088eece603df2e5675025e8bed90c0f21171", "34c062e2b8a3f6421b9f4ff22f115a36d4aba823", "cf84f4ea635b2cdc0aeea7ec59fde01ab0a48ba9", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "b9eb38f50f9853f2ce1ee5a1737affad42cc6925", "e312652daf82ed144d1696aae7ab412030d4f7eb", "8ad3263bf71ffae41fbb777d600ef1e3e8689bb6"], "ReferenceCount": 38, "CitationCount": 101}, {"URL": "https://www.semanticscholar.org/paper/CellProfiler-3.0%3A-Next-generation-image-processing-McQuin-Goodman/713e881b5c3134debf934026edf6f0ba3cb42c3c", "ID": "713e881b5c3134debf934026edf6f0ba3cb42c3c", "Title": "CellProfiler 3.0: Next-generation image processing for biology", "Abstract": "CellProfiler 3.0 is described, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional image stacks, increasingly common in biomedical research. CellProfiler has enabled the scientific research community to create flexible, modular image analysis pipelines since its release in 2005. Here, we describe CellProfiler 3.0, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional (3D) image stacks, increasingly common in biomedical research. CellProfiler\u2019s infrastructure is greatly improved, and we provide a protocol for cloud-based, large-scale image processing. New plugins enable running pretrained deep learning models on images. Designed by and for biologists, CellProfiler equips researchers with powerful computational tools via a well-documented user interface, empowering biologists in all fields to create quantitative, reproducible image analysis workflows.", "PublicationYear": "2018", "Authors": ["Claire McQuin", "Allen Goodman", "Vasiliy S. Chernyshev", "Lee Kamentsky", "Beth A. Cimini", "Kyle W. Karhohs", "Minh Doan", "Liya Ding", "Susanne M. Rafelski", "Derek J. Thirstrup", "Winfried Wiegraebe", "Shantanu Singh", "Tim Becker", "Juan C. Caicedo", "Anne E Carpenter"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["b66561622170d97f4127f4131d485faefe3833f7", "d8b8805b824a17471f6005c838806ba3c892dd08", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5", "11e69f9757d3f4927a21a76dadc41eddaa35e2ec", "ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869", "29c736eb38861ecf346ce49eedf163c03974566b", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "36748de338909976f72ffbadaf097470ec040da0", "78bd4d517a6312ef2296243b5d6387c8f2e2abaf"], "ReferenceCount": 41, "CitationCount": 1392}, {"URL": "https://www.semanticscholar.org/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a", "ID": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "Title": "U-Net: Convolutional Networks for Biomedical Image Segmentation", "Abstract": "It is shown that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .", "PublicationYear": "2015", "Authors": ["Olaf Ronneberger", "Philipp Fischer", "Thomas Brox"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["6fc6803df5f9ae505cae5b2f178ade4062c768d0", "09193e19b59fc8f05bee9d6efbfb1607ca5b6501", "eb42cf88027de515750f230b23b1a057dc782108", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "6bdb186ec4726e00a8051119636d4df3b94043b5", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "428db42e86f6d51292e23fa57797e35cecd0e2ee", "4f03888450fde9e8234f616badaae499740e57a4", "3b2ccc97f1433cf8750a2ad5a05555ccd10e9cdf", "3bffa23a16c273ac2228a13e65dade6766ce7777"], "ReferenceCount": 18, "CitationCount": 56637}, {"URL": "https://www.semanticscholar.org/paper/Detection-and-Segmentation-of-Cell-Nuclei-in-A-Wienert-Heim/68f30bd22817a17adc837eb285e51c9628f00e8d", "ID": "68f30bd22817a17adc837eb285e51c9628f00e8d", "Title": "Detection and Segmentation of Cell Nuclei in Virtual Microscopy Images: A Minimum-Model Approach", "Abstract": "A novel contour-based \u201cminimum-model\u201d cell detection and segmentation approach that uses minimal a priori information and detects contours independent of their shape and allows for an accurate segmentation of a broad spectrum of normal and disease-related morphological features without the requirement of prior training. Automated image analysis of cells and tissues has been an active research field in medical informatics for decades but has recently attracted increased attention due to developments in computer and microscopy hardware and the awareness that scientific and diagnostic pathology require novel approaches to perform objective quantitative analyses of cellular and tissue specimens. Model-based approaches use a priori information on cell shape features to obtain the segmentation, which may introduce a bias favouring the detection of cell nuclei only with certain properties. In this study we present a novel contour-based \u201cminimum-model\u201d cell detection and segmentation approach that uses minimal a priori information and detects contours independent of their shape. This approach avoids a segmentation bias with respect to shape features and allows for an accurate segmentation (precision = 0.908; recall = 0.859; validation based on \u223c8000 manually-labeled cells) of a broad spectrum of normal and disease-related morphological features without the requirement of prior training.", "PublicationYear": "2012", "Authors": ["Stephan Wienert", "Daniel Heim", "Kai Saeger", "Albrecht Stenzinger", "Michael Beil", "Peter Hufnagl", "Manfred Dietel", "Carsten Denkert", "Frederick Klauschen"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["63a373063d51489b31e07ee639ab74b6cf586240", "a552cbbe0762a30ca00b922c6c99887de491ea18", "268241fd604918a86e1b27e1a880d47e0ecc2d5b", "3ab1348d060f3ab7e70a2e368a30af14bc57c35c", "856a3c76453a798556096cd23848402d1351c1f9", "0fe2cc66d44708792517bb87b73286a8b27e6263", "4b3e38280c8d81a0921e9f1c1660076bab1719aa", "d3bbf54a295b6dbed7bae6fac07fd89ac039b30d", "dcdd14ec1eaf86db85c67600ea94ad697f981fe2", "b6e091a9cfd00b4bef2c0d92683f0f14da06bc0c"], "ReferenceCount": 40, "CitationCount": 222}, {"URL": "https://www.semanticscholar.org/paper/Object%E2%80%90Oriented-Segmentation-of-Cell-Nuclei-in-Koyuncu-Cetin-Atalay/31a27c6500b6652d7ecc055c9b08457ad90128c1", "ID": "31a27c6500b6652d7ecc055c9b08457ad90128c1", "Title": "Object\u2010Oriented Segmentation of Cell Nuclei in Fluorescence Microscopy Images", "Abstract": "This article proposes to decompose an image into smaller homogeneous subregions, define edge\u2010 objects at four different orientations to encode the gradient information at the object level, and devise a merging algorithm, in which the edge\u2010objects vote for subregion pairs along their orientations and the pairs are iteratively merged if they get sufficient votes from multiple orientations. Cell nucleus segmentation remains an open and challenging problem especially to segment nuclei in cell clumps. Splitting a cell clump would be straightforward if the gradients of boundary pixels in\u2010between the nuclei were always higher than the others. However, imperfections may exist: inhomogeneities of pixel intensities in a nucleus may cause to define spurious boundaries whereas insufficient pixel intensity differences at the border of overlapping nuclei may cause to miss some true boundary pixels. In contrast, these imperfections are typically observed at the pixel\u2010level, causing local changes in pixel values without changing the semantics on a large scale. In response to these issues, this article introduces a new nucleus segmentation method that relies on using gradient information not at the pixel level but at the object level. To this end, it proposes to decompose an image into smaller homogeneous subregions, define edge\u2010objects at four different orientations to encode the gradient information at the object level, and devise a merging algorithm, in which the edge\u2010objects vote for subregion pairs along their orientations and the pairs are iteratively merged if they get sufficient votes from multiple orientations. Our experiments on fluorescence microscopy images reveal that this high\u2010level representation and the design of a merging algorithm using edge\u2010objects (gradients at the object level) improve the segmentation results.", "PublicationYear": "2018", "Authors": ["Can Fahrettin Koyuncu", "Rengul Cetin-Atalay", "Cigdem Gunduz-Demir"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["40521ea2dc363b5164e9bcdec9de908cab18b617", "4c8e87d996826725192d15273c14bc0f16a6f17e", "bf3a23566fad67f46f2154455b1bd802df612984", "1b979ed50b3a7c68c79726d7c22e078c579501f3", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "96a3a3bff71b9d470dfa02d67ce981cb42003133", "e10d7c818b3fea4f37c762c241965b2f665c9b70", "908dfcd908fe3fef9486bff01dbc04ccbde556d0", "7ba18c90be2166a848ab509f9e9de950750a91da", "7cb2f4f7b65ae227872e72d6cfcdbf47714bd9a0"], "ReferenceCount": 25, "CitationCount": 11}, {"URL": "https://www.semanticscholar.org/paper/Segmentation-of-confocal-microscope-images-of-cell-Sol%C3%B3rzano-Rodriguez/cee3035635eafa1c412934419d7563fdb06d73ae", "ID": "cee3035635eafa1c412934419d7563fdb06d73ae", "Title": "Segmentation of confocal microscope images of cell nuclei in thick tissue sections", "Abstract": "A 3D segmentation approach that combines the recognition capabilities of the human visual system with the efficiency of automatic image analysis algorithms to segmentate intact cell nuclei from three\u2010dimensional images of thick tissue sections is presented. Segmentation of intact cell nuclei from three\u2010dimensional (3D) images of thick tissue sections is an important basic capability necessary for many biological research studies. However, segmentation is often difficult because of the tight clustering of nuclei in many specimen types. We present a 3D segmentation approach that combines the recognition capabilities of the human visual system with the efficiency of automatic image analysis algorithms. The approach first uses automatic algorithms to separate the 3D image into regions of fluorescence\u2010stained nuclei and unstained background. This includes a novel step, based on the Hough transform and an automatic focusing algorithm to estimate the size of nuclei. Then, using an interactive display, each nuclear region is shown to the analyst, who classifies it as either an individual nucleus, a cluster of multiple nuclei, partial nucleus or debris. Next, automatic image analysis based on morphological reconstruction and the watershed algorithm divides clusters into smaller objects, which are reclassified by the analyst. Once no more clusters remain, the analyst indicates which partial nuclei should be joined to form complete nuclei. The approach was assessed by calculating the fraction of correctly segmented nuclei for a variety of tissue types: Caenorhabditis elegans embryos (839 correct out of a total of 848), normal human skin (343/362), benign human breast tissue (492/525), a human breast cancer cell line grown as a xenograft in mice (425/479) and invasive human breast carcinoma (260/335). Furthermore, due to the analyst's involvement in the segmentation process, it is always known which nuclei in a population are correctly segmented and which not, assuming that the analyst's visual judgement is correct.", "PublicationYear": "1999", "Authors": ["Carlos Ortiz de Sol{\\'o}rzano", "Enrique Garda Rodriguez", "Arthur Jones", "Daniel Pinkel", "Joe", "W. Gray", "Damir Sudar", "Stephen J. Lockett"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["ceb73c385a55ef1484e277a11a5fc2e78167a414", "13e3e4b75636122381693a527cccb96395a1aa3e", "b1c13d7abec88cff4ad5d612336ef54ef961dae3", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "52b7614dccf5b0b266e0bd2458bfcd2f1ff04f0c", "efde0638882cca4c714df59dc18f003e6d1ae7cb", "a0616d4f8d244450b849a9c5aa0ef08d3f31fbff", "a832e7a49c2ca71fab5b9f133e0b8ea0e9cbdabd", "aa95aeb4080576e9c7120a1ef57edcdf6faabe8c", "cd98167ffad104bdbcb7e89df411bca3014c6f89"], "ReferenceCount": 30, "CitationCount": 175}, {"URL": "https://www.semanticscholar.org/paper/Deep-learning-for-cellular-image-analysis-Moen-Bannon/48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852", "ID": "48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852", "Title": "Deep learning for cellular image analysis", "Abstract": "The intersection between deep learning and cellular image analysis is reviewed and an overview of both the mathematical mechanics and the programming frameworks of deep learning that are pertinent to life scientists are provided. Recent advances in computer vision and machine learning underpin a collection of algorithms with an impressive ability to decipher the content of images. These deep learning algorithms are being applied to biological images and are transforming the analysis and interpretation of imaging data. These advances are positioned to render difficult analyses routine and to enable researchers to carry out new, previously impossible experiments. Here we review the intersection between deep learning and cellular image analysis and provide an overview of both the mathematical mechanics and the programming frameworks of deep learning that are pertinent to life scientists. We survey the field\u2019s progress in four key applications: image classification, image segmentation, object tracking, and augmented microscopy. Last, we relay our labs\u2019 experience with three key aspects of implementing deep learning in the laboratory: annotating training data, selecting and training a range of neural network architectures, and deploying solutions. We also highlight existing datasets and implementations for each surveyed application. A Review on applications of deep machine learning in image analysis that offers practical guidance for biologists.", "PublicationYear": "2019", "Authors": ["Erick Moen", "Dylan Bannon", "Takamasa Kudo", "William Graf", "Markus W. Covert", "David Van Valen"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["08dc94471605308669c8d3d8284ba94fcc93e345", "d1f788e9ac58de5d2dc6a3928939b411cf9ec5a6", "c89bfd998b0a6c656010b629814ab0cad3cff72e", "e1b3ad532f9346d51578c32dc6b070c9744a8d88", "efd68f3724942c9de5dc804d3c7cb3f70f42234b", "7dae942104dc8283504ce7a492c9ca12fa119189", "9f7a89bc9b8ebb7152acacc95a84daead92d8f2c", "c051d469f9e9d5550d4633deecdb1ea8b11862dd", "f140829b7c37fb5d51713f631f720b1c7746d5e7", "054179c80dad0a77249384265677b38e34cb045e"], "ReferenceCount": 186, "CitationCount": 696}, {"URL": "https://www.semanticscholar.org/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "ID": "4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "Title": "Deep Semi-Supervised Anomaly Detection", "Abstract": "This work presents Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection, and introduces an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy the anomalous distribution, which can serve as a theoretical interpretation for the method. Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "PublicationYear": "2019", "Authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G{\\\"o}rnitz", "Alexander Binder", "Emmanuel M{\\\"u}ller", "Klaus-Robert M{\\\"u}ller", "M. Kloft"], "RelatedTopics": ["Computer Science"], "References": ["f5a951b9596be0df5ad7ede180b405c9e97a65c9", "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed", "2d8c97db4bae00ff243d122b957091a236a697a7", "ca4edb65a0664804e4819c5c809d0dfba9bdb2df", "a2e667e4382aaa8e02a17d0522c1a910790ab65b", "f076e4355c0facf111716dcab2837803367dd2d8", "6af440915b8a0718c93be1cf61905e41e620484a", "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "5db790198b9acf4e5efe350acdd814238fcacaa7", "0535625be630c6a67f4c244ebf3aa61ad088fc70"], "ReferenceCount": 88, "CitationCount": 387}, {"URL": "https://www.semanticscholar.org/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7", "ID": "5db790198b9acf4e5efe350acdd814238fcacaa7", "Title": "Deep Anomaly Detection Using Geometric Transformations", "Abstract": "The main idea behind the scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images, which generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We consider the problem of anomaly detection in images, and present a new detection technique. Given a sample of images, all known to belong to a \\\"normal\\\" class (e.g., dogs), we show how to train a deep neural model that can detect out-of-distribution images (i.e., non-dog objects). The main idea behind our scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images. The auxiliary expertise learned by the model generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We present extensive experiments using the proposed detector, which indicate that our algorithm improves state-of-the-art methods by a wide margin.", "PublicationYear": "2018", "Authors": ["Izhak Golan", "Ran El-Yaniv"], "RelatedTopics": ["Computer Science"], "References": ["6af440915b8a0718c93be1cf61905e41e620484a", "3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "547c854985629cfa9404a5ba8ca29367b5f8c25f", "c72e91b2e5c103f529510fa15a156d61c5633da1", "10a498003e9204f5fc1328e706510a37e514d8c7", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "061146b1d7938d7a8dae70e3531a00fceb3c78e8", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "d612d7c21d4130a457968273d79c2c2f6946953d"], "ReferenceCount": 45, "CitationCount": 512}, {"URL": "https://www.semanticscholar.org/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70", "ID": "0535625be630c6a67f4c244ebf3aa61ad088fc70", "Title": "GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training", "Abstract": "This work introduces a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space and shows the model efficacy and superiority over previous state-of-the-art approaches. Anomaly detection is a classical problem in computer vision, namely the determination of the normal from the abnormal when datasets are highly biased towards one class (normal) due to the insufficient sample size of the other class (abnormal). While this can be addressed as a supervised learning problem, a significantly more challenging problem is that of detecting the unknown/unseen anomaly case that takes us instead into the space of a one-class, semi-supervised learning paradigm. We introduce such a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space. Employing encoder-decoder-encoder sub-networks in the generator network enables the model to map the input image to a lower dimension vector, which is then used to reconstruct the generated output image. The use of the additional encoder network maps this generated image to its latent representation. Minimizing the distance between these images and the latent vectors during training aids in learning the data distribution for the normal samples. As a result, a larger distance metric from this learned data distribution at inference time is indicative of an outlier from that distribution - an anomaly. Experimentation over several benchmark datasets, from varying domains, shows the model efficacy and superiority over previous state-of-the-art approaches.", "PublicationYear": "2018", "Authors": ["Samet Ak\u00e7ay", "Amir Atapour-Abarghouei", "T. Breckon"], "RelatedTopics": ["Computer Science"], "References": ["e399a626ba21fafb19b3661603ec9724058e951b", "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "39b8f34e71553622bb16b547211d0d769563c61d", "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "571b0750085ae3d939525e62af510ee2cee9d5ea", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "86ee1835a56722b76564119437070782fc90eb19", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "e163a2e89c136cb4442e34c72f7173a0ff46dc79"], "ReferenceCount": 55, "CitationCount": 1000}, {"URL": "https://www.semanticscholar.org/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7", "ID": "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "Title": "MVTec AD \u2014 A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection", "Abstract": "This work introduces the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories, and conducts a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolved neural networks. The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the \ufb01eld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the \ufb01rst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.", "PublicationYear": "2019", "Authors": ["Paul Bergmann", "Michael Fauser", "David Sattlegger", "Carsten Steger"], "RelatedTopics": ["Computer Science"], "References": ["6af440915b8a0718c93be1cf61905e41e620484a", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "2d8c97db4bae00ff243d122b957091a236a697a7", "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "732c21998e251d64cd58b6a86886ee5907efeaa5", "9c24454b071bc8e96ea46c5064a7bddf07cca464", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "5d90f06bb70a0a3dced62413346235c02b1aa086"], "ReferenceCount": 29, "CitationCount": 744}, {"URL": "https://www.semanticscholar.org/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e", "ID": "41747cbdbed84762dfbfc305254c97021279dc6e", "Title": "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings", "Abstract": "A powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images by trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.", "PublicationYear": "2019", "Authors": ["Paul Bergmann", "Michael Fauser", "David Sattlegger", "Carsten Steger"], "RelatedTopics": ["Computer Science"], "References": ["3aa681914a7da79f7d7293f51a058eefe61c8bb7", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "2910bec6d4de87e22be5119cef3c488d2ae50e2a", "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6", "6af440915b8a0718c93be1cf61905e41e620484a", "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "317c172f314f8cb634f7569ed5bf3ae7dd25c313", "67b9c2b376a01d8757dc6d704be450d1c46c4ced"], "ReferenceCount": 37, "CitationCount": 373}, {"URL": "https://www.semanticscholar.org/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "ID": "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "Title": "Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection", "Abstract": "A Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised anomaly detection, which significantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement based on the standard F1 score. Unsupervised anomaly detection on multior high-dimensional data is of great importance in both fundamental machine learning research and industrial applications, for which density estimation lies at the core. Although previous approaches based on dimensionality reduction followed by density estimation have made fruitful progress, they mainly suffer from decoupled model learning with inconsistent optimization goals and incapability of preserving essential information in the low-dimensional space. In this paper, we present a Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised anomaly detection. Our model utilizes a deep autoencoder to generate a low-dimensional representation and reconstruction error for each input data point, which is further fed into a Gaussian Mixture Model (GMM). Instead of using decoupled two-stage training and the standard Expectation-Maximization (EM) algorithm, DAGMM jointly optimizes the parameters of the deep autoencoder and the mixture model simultaneously in an end-to-end fashion, leveraging a separate estimation network to facilitate the parameter learning of the mixture model. The joint optimization, which well balances autoencoding reconstruction, density estimation of latent representation, and regularization, helps the autoencoder escape from less attractive local optima and further reduce reconstruction errors, avoiding the need of pre-training. Experimental results on several public benchmark datasets show that, DAGMM significantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement based on the standard F1 score.", "PublicationYear": "2018", "Authors": ["Bo Zong", "Qi Song", "Martin Renqiang Min", "Wei Cheng", "Cristian Lumezanu", "Dae-ki Cho", "Haifeng Chen"], "RelatedTopics": ["Computer Science"], "References": ["60d4ec78a673119420bee41268672a8f8669bb31", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "10a498003e9204f5fc1328e706510a37e514d8c7", "aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "33a832399927971f144dee7fee50c0bcc5e1e659", "3eeb8b5d5ee2db86fa359ec479b730a793d5971e", "ca9f84c3922004ec6133aa9c2048ceeb17702fee", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "8080c7954944e4e293028768e7dcbaead190c85e"], "ReferenceCount": 34, "CitationCount": 1211}, {"URL": "https://www.semanticscholar.org/paper/Anomaly-Detection-with-Robust-Deep-Autoencoders-Zhou-Paffenroth/2b75ba7f75170b73d913c515cc0deefef6c88f5f", "ID": "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "Title": "Anomaly Detection with Robust Deep Autoencoders", "Abstract": "Novel extensions to deep autoencoders are demonstrated which not only maintain a deep autenkocoders' ability to discover high quality, non-linear features but can also eliminate outliers and noise without access to any clean training data. Deep autoencoders, and other deep neural networks, have demonstrated their effectiveness in discovering non-linear features across many problem domains. However, in many real-world problems, large outliers and pervasive noise are commonplace, and one may not have access to clean training data as required by standard deep denoising autoencoders. Herein, we demonstrate novel extensions to deep autoencoders which not only maintain a deep autoencoders' ability to discover high quality, non-linear features but can also eliminate outliers and noise without access to any clean training data. Our model is inspired by Robust Principal Component Analysis, and we split the input data X into two parts, $X = L_{D} + S$, where $L_{D}$ can be effectively reconstructed by a deep autoencoder and $S$ contains the outliers and noise in the original data X. Since such splitting increases the robustness of standard deep autoencoders, we name our model a \\\"Robust Deep Autoencoder (RDA)\\\". Further, we present generalizations of our results to grouped sparsity norms which allow one to distinguish random anomalies from other types of structured corruptions, such as a collection of features being corrupted across many instances or a collection of instances having more corruptions than their fellows. Such \\\"Group Robust Deep Autoencoders (GRDA)\\\" give rise to novel anomaly detection approaches whose superior performance we demonstrate on a selection of benchmark problems.", "PublicationYear": "2017", "Authors": ["Chong Zhou", "Randy Clinton Paffenroth"], "RelatedTopics": ["Computer Science"], "References": ["357733cc76e31a499a27ba2da8612174aafb3213", "00af02c2cb48920af477115e870a42ac4f8a3834", "fbb38946334941292800a82c99c0dc4feb0cb882", "843959ffdccf31c6694d135fad07425924f785b1", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "ec7e0ceea8f79735742ea671b3c37148cae9f22c", "a2017ec2c60d542af5e9993176ba68f89529dbce", "195d0a8233a7a46329c742eaff56c276f847fadc", "2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35", "a4cec122a08216fe8a3bc19b22e78fbaea096256"], "ReferenceCount": 27, "CitationCount": 1026}, {"URL": "https://www.semanticscholar.org/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449", "ID": "8381157eae4fbf8908d0312a9642f8e69e944449", "Title": "Adversarially Learned One-Class Classifier for Novelty Detection", "Abstract": "The results on MNIST and Caltech-256 image datasets, along with the challenging UCSD Ped2 dataset for video anomaly detection illustrate that the proposed method learns the target class effectively and is superior to the baseline and state-of-the-art methods. Novelty detection is the process of identifying the observation(s) that differ in some respect from the training observations (the target class). In reality, the novelty class is often absent during training, poorly sampled or not well defined. Therefore, one-class classifiers can efficiently model such problems. However, due to the unavailability of data from the novelty class, training an end-to-end deep network is a cumbersome task. In this paper, inspired by the success of generative adversarial networks for training deep models in unsupervised and semi-supervised settings, we propose an end-to-end architecture for one-class classification. Our architecture is composed of two deep networks, each of which trained by competing with each other while collaborating to understand the underlying concept in the target class, and then classify the testing samples. One network works as the novelty detector, while the other supports it by enhancing the inlier samples and distorting the outliers. The intuition is that the separability of the enhanced inliers and distorted outliers is much better than deciding on the original samples. The proposed framework applies to different related applications of anomaly and outlier detection in images and videos. The results on MNIST and Caltech-256 image datasets, along with the challenging UCSD Ped2 dataset for video anomaly detection illustrate that our proposed method learns the target class effectively and is superior to the baseline and state-of-the-art methods.", "PublicationYear": "2018", "Authors": ["M. Sabokrou", "Mohammad Khalooei", "Mahmood Fathy", "Ehsan Adeli"], "RelatedTopics": ["Computer Science"], "References": ["e399a626ba21fafb19b3661603ec9724058e951b", "571b0750085ae3d939525e62af510ee2cee9d5ea", "5d666e2761bbac7d8e0ac724280d20fd24d71a6b", "a7fae7dba0db74cc21a7c7b70157fe601784b681", "6f68ce1e03c56c186256dac689a21f6405ae8d96", "8388f1be26329fa45e5807e968a641ce170ea078", "9eb1b16fbd4786eaac91f308d75609b9321868ce", "9d5290fadb7625862a966e0330bd0f9e111fc99d", "6259b02912cebc224f3a2b1324e811a152a0177d", "60fef33549f57f5cbb6712a510c3a444ab682429"], "ReferenceCount": 52, "CitationCount": 579}, {"URL": "https://www.semanticscholar.org/paper/Iterative-energy-based-projection-on-a-normal-data-Dehaene-Frigo/d9d7ab13ce305ccee309c989a2341d72b1252070", "ID": "d9d7ab13ce305ccee309c989a2341d72b1252070", "Title": "Iterative energy-based projection on a normal data manifold for anomaly localization", "Abstract": "This paper proposes a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoen coder's loss function, augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder's loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.", "PublicationYear": "2020", "Authors": ["David Dehaene", "Oriel Frigo", "S{\\'e}bastien Combrexelle", "Pierre Eline"], "RelatedTopics": ["Computer Science"], "References": ["06fad023ef0274e7d6727ecbd1ef46887a6806df", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d", "9c24454b071bc8e96ea46c5064a7bddf07cca464", "061146b1d7938d7a8dae70e3531a00fceb3c78e8", "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa"], "ReferenceCount": 29, "CitationCount": 107}, {"URL": "https://www.semanticscholar.org/paper/Attention-Guided-Anomaly-Localization-in-Images-Venkataramanan-Peng/211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d", "ID": "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d", "Title": "Attention Guided Anomaly Localization in Images", "Abstract": "This work proposes Convolutional Adversarial Variational autoencoder with Guided Attention (CAVGA), which localizes the anomaly with a convolutional latent variable to preserve the spatial information and outperforms state-of-the-art anomaly localization methods on several datasets. Anomaly localization is an important problem in computer vision which involves localizing anomalous regions within images with applications in industrial inspection, surveillance, and medical imaging. This task is challenging due to the small sample size and pixel coverage of the anomaly in real-world scenarios. Most prior works need to use anomalous training images to compute a class-specific threshold to localize anomalies. Without the need of anomalous training images, we propose Convolutional Adversarial Variational autoencoder with Guided Attention (CAVGA), which localizes the anomaly with a convolutional latent variable to preserve the spatial information. In the unsupervised setting, we propose an attention expansion loss where we encourage CAVGA to focus on all normal regions in the image. Furthermore, in the weakly-supervised setting we propose a complementary guided attention loss, where we encourage the attention map to focus on all normal regions while minimizing the attention map corresponding to anomalous regions in the image. CAVGA outperforms the state-of-the-art (SOTA) anomaly localization methods on MVTec Anomaly Detection (MVTAD), modified ShanghaiTech Campus (mSTC) and Large-scale Attention based Glaucoma (LAG) datasets in the unsupervised setting and when using only 2% anomalous images in the weakly-supervised setting. CAVGA also outperforms SOTA anomaly detection methods on the MNIST, CIFAR-10, Fashion-MNIST, MVTAD, mSTC and LAG datasets.", "PublicationYear": "2019", "Authors": ["Shashanka Venkataramanan", "Kuan-Chuan Peng", "Rajat Vikram Singh", "Abhijit Mahalanobis"], "RelatedTopics": ["Computer Science"], "References": ["0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b", "39972fb3a9cbac1e25b2c096e3e28bba2eee7aa4", "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "8a6acba7fb2aad1299fcf35701417e063d410ed4", "d9d7ab13ce305ccee309c989a2341d72b1252070", "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f"], "ReferenceCount": 65, "CitationCount": 149}, {"URL": "https://www.semanticscholar.org/paper/Comparison-of-Methods-for-Image-Based-Profiling-of-Ljosa-Caie/929a490198770abcb8c123d68a59384879b69adb", "ID": "929a490198770abcb8c123d68a59384879b69adb", "Title": "Comparison of Methods for Image-Based Profiling of Cellular Morphological Responses to Small-Molecule Treatment", "Abstract": "This work provides the complete ground-truth and test data sets, as well as open-source implementations of the various methods in a common software framework to facilitate the ready application and future development of image-based phenotypic profiling methods. Quantitative microscopy has proven a versatile and powerful phenotypic screening technique. Recently, image-based profiling has shown promise as a means for broadly characterizing molecules\u2019 effects on cells in several drug-discovery applications, including target-agnostic screening and predicting a compound\u2019s mechanism of action (MOA). Several profiling methods have been proposed, but little is known about their comparative performance, impeding the wider adoption and further development of image-based profiling. We compared these methods by applying them to a widely applicable assay of cultured cells and measuring the ability of each method to predict the MOA of a compendium of drugs. A very simple method that is based on population means performed as well as methods designed to take advantage of the measurements of individual cells. This is surprising because many treatments induced a heterogeneous phenotypic response across the cell population in each sample. Another simple method, which performs factor analysis on the cellular measurements before averaging them, provided substantial improvement and was able to predict MOA correctly for 94% of the treatments in our ground-truth set. To facilitate the ready application and future development of image-based phenotypic profiling methods, we provide our complete ground-truth and test data sets, as well as open-source implementations of the various methods in a common software framework.", "PublicationYear": "2013", "Authors": ["Vebjorn Ljosa", "Peter David Caie", "Rob ter Horst", "Katherine L. Sokolnicki", "Emma L. Jenkins", "Sandeep Daya", "Mark E. Roberts", "Thouis Raymond Jones", "Shantanu Singh", "Auguste Genovesio", "Paul A. Clemons", "Neil O. Carragher", "Anne E Carpenter"], "RelatedTopics": ["Biology", "Medicine", "Computer Science"], "References": ["bfc8a8724b36cd2b1d068d1f997400e74791a68d", "8125727fe5b62492f4ccb1e25c66d473dd5c83c9", "3e5e4e1550416646ad33814ba3d6f20935ac742f", "140b7fab48719b56e933216594eaa8b5fc361c1b", "74b6fa545810f7953ca37ec9b765152d345a7081", "8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "fdb0014af8197c8f303dca3fccad5d27bd264dcd", "7d1096bc057b6e5e08a6ae821768d4f742d37b77", "b4440c42d5ef6d0ae40f5646d1a6a1011333e7d3", "c1317f812bfaec25958ec7b5b583eb035fe6d5a1"], "ReferenceCount": 27, "CitationCount": 143}, {"URL": "https://www.semanticscholar.org/paper/Applications-in-image-based-profiling-of-Caicedo-Singh/29c736eb38861ecf346ce49eedf163c03974566b", "ID": "29c736eb38861ecf346ce49eedf163c03974566b", "Title": "Applications in image-based profiling of perturbations.", "Abstract": "Semantic Scholar extracted view of \\\"Applications in image-based profiling of perturbations.\\\" by Juan C. Caicedo et al.", "PublicationYear": "2016", "Authors": ["Juan C. Caicedo", "Shantanu Singh", "Anne E Carpenter"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["aa0875ccc516862edc0b6bd2181ee27ce882933d", "929a490198770abcb8c123d68a59384879b69adb", "36748de338909976f72ffbadaf097470ec040da0", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "b90d44f59fcb74c71d3e31f67a3f09efab187a4e", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "df775e0093d4e96e2690fa9f48f60d76e4fede19", "040b4f257b8b048ffb0e61e5ee4a8d16ce2d32da", "a878e1a752403b4cfb425c9b4d9459b9eb2b2cfe", "cd989ec0c4b17b06921668b2030020ce51736f7c"], "ReferenceCount": 106, "CitationCount": 122}, {"URL": "https://www.semanticscholar.org/paper/Cell-Painting%2C-a-high-content-image-based-assay-for-Bray-Singh/36748de338909976f72ffbadaf097470ec040da0", "ID": "36748de338909976f72ffbadaf097470ec040da0", "Title": "Cell Painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes", "Abstract": "This protocol describes the design and execution of experiments using Cell Painting, which is a morphological profiling assay that multiplexes six fluorescent dyes, imaged in five channels, to reveal eight broadly relevant cellular components or organelles. In morphological profiling, quantitative data are extracted from microscopy images of cells to identify biologically relevant similarities and differences among samples based on these profiles. This protocol describes the design and execution of experiments using Cell Painting, which is a morphological profiling assay that multiplexes six fluorescent dyes, imaged in five channels, to reveal eight broadly relevant cellular components or organelles. Cells are plated in multiwell plates, perturbed with the treatments to be tested, stained, fixed, and imaged on a high-throughput microscope. Next, an automated image analysis software identifies individual cells and measures \u223c1,500 morphological features (various measures of size, shape, texture, intensity, and so on) to produce a rich profile that is suitable for the detection of subtle phenotypes. Profiles of cell populations treated with different experimental perturbations can be compared to suit many goals, such as identifying the phenotypic impact of chemical or genetic perturbations, grouping compounds and/or genes into functional pathways, and identifying signatures of disease. Cell culture and image acquisition takes 2 weeks; feature extraction and data analysis take an additional 1\u20132 weeks.", "PublicationYear": "2016", "Authors": ["Mark-Anthony Bray", "Shantanu Singh", "Han Han", "Chadwick T. Davis", "Blake Borgeson", "Cathy L. Hartland", "Maria Kost-Alimova", "Sigr{\\'u}n Margr{\\'e}t G{\\'u}stafsd{\\'o}ttir", "Christopher C. Gibson", "Anne E Carpenter"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["929a490198770abcb8c123d68a59384879b69adb", "df775e0093d4e96e2690fa9f48f60d76e4fede19", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "4cebfa50e9e48afc6260df161582f0271c84d86a", "9e93ab699a70701f8100a7730b9f6ee250bbaa18", "a1e06f125aeb3899c0eda9e9286820ccff76a494", "ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869", "fdb0014af8197c8f303dca3fccad5d27bd264dcd", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "cd989ec0c4b17b06921668b2030020ce51736f7c"], "ReferenceCount": 54, "CitationCount": 510}, {"URL": "https://www.semanticscholar.org/paper/High-Content-Screening-for-Quantitative-Cell-Usaj-Styles/6bfc1c0c7d3fc3cd9ebb9517cc0de73e841b7f74", "ID": "6bfc1c0c7d3fc3cd9ebb9517cc0de73e841b7f74", "Title": "High-Content Screening for Quantitative Cell Biology.", "Abstract": "Semantic Scholar extracted view of \\\"High-Content Screening for Quantitative Cell Biology.\\\" by Mojca Mattiazzi Usaj et al.", "PublicationYear": "2016", "Authors": ["Mojca Mattiazzi Usaj", "Erin B. Styles", "Adrian J. Verster", "Helena Friesen", "Charles Boone", "Brenda J. Andrews"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["eb3fd030883947c22305617308be8a04bacc5514", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "040b4f257b8b048ffb0e61e5ee4a8d16ce2d32da", "cf933679e4d3ba4e18e3c2ef13b3fe7b461fade2", "8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "50cc8dd825103c97204ff58a7c5da09c70bb128c", "67544e4467432aa001f6fb0e9aadfd3d5aa603e0", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "404428b72073b1d2fca8332a996b5e9cac6b5a68", "2551a9e46238c4a912d2110674e5b644b2a2fb27"], "ReferenceCount": 91, "CitationCount": 203}, {"URL": "https://www.semanticscholar.org/paper/Microscopy-Based-High-Content-Screening-Boutros-Heigwer/aa0875ccc516862edc0b6bd2181ee27ce882933d", "ID": "aa0875ccc516862edc0b6bd2181ee27ce882933d", "Title": "Microscopy-Based High-Content Screening", "Abstract": "Semantic Scholar extracted view of \\\"Microscopy-Based High-Content Screening\\\" by M. Boutros et al.", "PublicationYear": "2015", "Authors": ["Michael Boutros", "Florian Heigwer", "Christina Laufer"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["a37473b030751378f4d66599d5d109c75ca71d01", "3e36828fb7c7d9239afb13273b2988381abeece6", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "50cc8dd825103c97204ff58a7c5da09c70bb128c", "64993d9f5543631ce215dac860344c43533f0adf", "b90d44f59fcb74c71d3e31f67a3f09efab187a4e", "040b4f257b8b048ffb0e61e5ee4a8d16ce2d32da", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "7e582976a504cbb44633ad0d94954dfa2cdedc22", "e9bc178f3dc147be47e34c27667c5484ba6d5d40"], "ReferenceCount": 83, "CitationCount": 283}, {"URL": "https://www.semanticscholar.org/paper/CellProfiler%3A-image-analysis-software-for-and-cell-Carpenter-Jones/a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "ID": "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "Title": "CellProfiler: image analysis software for identifying and quantifying cell phenotypes", "Abstract": "The first free, open-source system designed for flexible, high-throughput cell image analysis, CellProfiler is described, which can address a variety of biological questions quantitatively. Biologists can now prepare and image thousands of samples per day using automation, enabling chemical screens and functional genomics (for example, using RNA interference). Here we describe the first free, open-source system designed for flexible, high-throughput cell image analysis, CellProfiler. CellProfiler can address a variety of biological questions quantitatively, including standard assays (for example, cell count, size, per-cell protein levels) and complex morphological assays (for example, cell/organelle shape or subcellular patterns of DNA or protein staining).", "PublicationYear": "2006", "Authors": ["Anne E Carpenter", "Thouis Raymond Jones", "Michael R. Lamprecht", "Colin Clarke", "In Han Kang", "Ola Friman", "David A. Guertin", "Joo Han Chang", "Robert A Lindquist", "Jason Moffat", "Polina Golland", "David M. Sabatini"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["3a320abd1b5444e9449c9098e0f3b7f2383b829e", "9fd701a40f584b8decb94bb7691ecb8d3f98d94a", "ae4c01a3463feb9d2af915e20f510d2749956f88", "a346d207aa0fe69d1e01179746532ea0e71142c3", "88c5ee4435438fbc0d8e8e3039f5cf8ab80a135b", "f4cbe92def586e12b22f8e31109d1dd6ffa5e86d", "42677cd15d29fec128cd1a0d35e0555325773b75", "fa757b408ec78abdd4487046c28fd55027a601e8", "a05b2552ba5dc6caea16ca709706d0ae3bbe4656", "8b73514fd708f6bdd3786d47a8673a97fdce4dfe"], "ReferenceCount": 67, "CitationCount": 4433}, {"URL": "https://www.semanticscholar.org/paper/Rapid-analysis-and-exploration-of-fluorescence-Pavie-Rajaram/8db554d7e597000f5a0e13712ef0cb3299c05187", "ID": "8db554d7e597000f5a0e13712ef0cb3299c05187", "Title": "Rapid analysis and exploration of fluorescence microscopy images.", "Abstract": "An alternate, cell-segmentation-free workflow based on PhenoRipper, an open-source software platform designed for the rapid analysis and exploration of microscopy images, is presented, which will lower the barriers to adopting quantitative analysis of image based screens. Despite rapid advances in high-throughput microscopy, quantitative image-based assays still pose significant challenges. While a variety of specialized image analysis tools are available, most traditional image-analysis-based workflows have steep learning curves (for fine tuning of analysis parameters) and result in long turnaround times between imaging and analysis. In particular, cell segmentation, the process of identifying individual cells in an image, is a major bottleneck in this regard. Here we present an alternate, cell-segmentation-free workflow based on PhenoRipper, an open-source software platform designed for the rapid analysis and exploration of microscopy images. The pipeline presented here is optimized for immunofluorescence microscopy images of cell cultures and requires minimal user intervention. Within half an hour, PhenoRipper can analyze data from a typical 96-well experiment and generate image profiles. Users can then visually explore their data, perform quality control on their experiment, ensure response to perturbations and check reproducibility of replicates. This facilitates a rapid feedback cycle between analysis and experiment, which is crucial during assay optimization. This protocol is useful not just as a first pass analysis for quality control, but also may be used as an end-to-end solution, especially for screening. The workflow described here scales to large data sets such as those generated by high-throughput screens, and has been shown to group experimental conditions by phenotype accurately over a wide range of biological systems. The PhenoBrowser interface provides an intuitive framework to explore the phenotypic space and relate image properties to biological annotations. Taken together, the protocol described here will lower the barriers to adopting quantitative analysis of image based screens.", "PublicationYear": "2014", "Authors": ["Benjamin Pavie", "Satwik Rajaram", "Austin Ouyang", "Jason M. Altschuler", "Robert J. Steininger", "Lani F. Wu", "Steven J. Altschuler"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["c6bb1291dc4d69d8362d05737dcd97020832c8d4", "c55585871acc109ce1dfe4d66a61d7d6baa7f58e", "c2a7df55c168a3d719eb85248da41734d7a8cf30", "d7c5d286ac2b41eb01c5961c04c1246da22d3702", "b3488cfbe8dcd1f38f3ef1687cdebe821757f2ed", "b58657eccdec07bd6b35ef00dab30670d1c9d5ed", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "60a1a5b868e3a669b0e916506f3dda7636b2a4dd", "0dd9d8bdd445db5928428b0059820199d0c53331", "6a6cd60c103ecfb989b63e05e65f689008592e39"], "ReferenceCount": 11, "CitationCount": 3}, {"URL": "https://www.semanticscholar.org/paper/Image-based-multivariate-profiling-of-drug-from-Loo-Wu/bfc8a8724b36cd2b1d068d1f997400e74791a68d", "ID": "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "Title": "Image-based multivariate profiling of drug responses from single cells", "Abstract": "This work presents a multivariate method for classifying untreated and treated human cancer cells based on \u223c300 single-cell phenotypic measurements and reports the most informative image features for each compound and fluorescence marker set using a method that will be useful for determining minimal collections of readouts for drug screens. Quantitative analytical approaches for discovering new compound mechanisms are required for summarizing high-throughput, image-based drug screening data. Here we present a multivariate method for classifying untreated and treated human cancer cells based on \u223c300 single-cell phenotypic measurements. This classification provides a score, measuring the magnitude of the drug effect, and a vector, indicating the simultaneous phenotypic changes induced by the drug. These two quantities were used to characterize compound activities and identify dose-dependent multiphasic responses. A systematic survey of profiles extracted from a 100-compound compendium of image data revealed that only 10\u201315% of the original features were required to detect a compound effect. We report the most informative image features for each compound and fluorescence marker set using a method that will be useful for determining minimal collections of readouts for drug screens. Our approach provides human-interpretable profiles and automatic determination of on- and off-target effects.", "PublicationYear": "2007", "Authors": ["Lit-Hsin Loo", "Lani F. Wu", "Steven J. Altschuler"], "RelatedTopics": ["Chemistry", "Computer Science", "Medicine"], "References": ["8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "8125727fe5b62492f4ccb1e25c66d473dd5c83c9", "a7138a6ca962b1a7774632e0bacf0ab911f71ee9", "d2fc13908e1d7ad9cebaed216e06ee73924bb274", "8a2b9eac4e36e5f62a59f118c7bfc1ed9763b59c", "2cf150bbc19e78ee3ea297cc447616922a1894c7", "e01c7387bcc4526cdb758581ccca2627d5eac4a4", "b4626f94678714c172cbaa273564afb68e9937cd", "57d70f9d46363a8e9cadb5123eab4fda1a5081e0", "01e4e8d24b4ba213f14aaa5812ec3ea5c1863a03"], "ReferenceCount": 31, "CitationCount": 318}, {"URL": "https://www.semanticscholar.org/paper/Large%E2%80%90scale-image%E2%80%90based-screening-and-profiling-of-Bougen-Zhukov-Loh/8a7ce466e8f119f033aeace4210cc348ed62520b", "ID": "8a7ce466e8f119f033aeace4210cc348ed62520b", "Title": "Large\u2010scale image\u2010based screening and profiling of cellular phenotypes", "Abstract": "The focus is on phenotypic profiling, a computational procedure for constructing quantitative and compact representations of cellular phenotypes based on the images collected in these screens. Cellular phenotypes are observable characteristics of cells resulting from the interactions of intrinsic and extrinsic chemical or biochemical factors. Image\u2010based phenotypic screens under large numbers of basal or perturbed conditions can be used to study the influences of these factors on cellular phenotypes. Hundreds to thousands of phenotypic descriptors can also be quantified from the images of cells under each of these experimental conditions. Therefore, huge amounts of data can be generated, and the analysis of these data has become a major bottleneck in large\u2010scale phenotypic screens. Here, we review current experimental and computational methods for large\u2010scale image\u2010based phenotypic screens. Our focus is on phenotypic profiling, a computational procedure for constructing quantitative and compact representations of cellular phenotypes based on the images collected in these screens. \u00a9 2016 International Society for Advancement of Cytometry", "PublicationYear": "2017", "Authors": ["Nicola Bougen-Zhukov", "Sheng Yang Michael Loh", "Hwee Kuan Lee", "Lit-Hsin Loo"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["614b6456b0aeb024fee659b094bdd999cb7d021e", "040b4f257b8b048ffb0e61e5ee4a8d16ce2d32da", "cd989ec0c4b17b06921668b2030020ce51736f7c", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "8125727fe5b62492f4ccb1e25c66d473dd5c83c9", "bd3f273590a34e121ddf5c2669c00750c8792e2b", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "68818b79d360aa92e479864e12414dc502820e1e", "83f4b74c4e2a247dc2e57e44ec1caeafa10e32e0", "50cc8dd825103c97204ff58a7c5da09c70bb128c"], "ReferenceCount": 121, "CitationCount": 47}, {"URL": "https://www.semanticscholar.org/paper/Machine-Learning-Improves-the-Precision-and-of-Horv%C3%A1th-Wild/669832b732a20ccbdbb81c22393f4bc8f9371dbc", "ID": "669832b732a20ccbdbb81c22393f4bc8f9371dbc", "Title": "Machine Learning Improves the Precision and Robustness of High-Content Screens", "Abstract": "A new graphical framework is established, the Advanced Cell Classifier, which provides a very accurate high-content screen analysis with minimal user interaction, offering access to a variety of advanced machine learning methods. Imaging-based high-content screens often rely on single cell-based evaluation of phenotypes in large data sets of microscopic images. Traditionally, these screens are analyzed by extracting a few image-related parameters and use their ratios (linear single or multiparametric separation) to classify the cells into various phenotypic classes. In this study, the authors show how machine learning\u2013based classification of individual cells outperforms those classical ratio-based techniques. Using fluorescent intensity and morphological and texture features, they evaluated how the performance of data analysis increases with increasing feature numbers. Their findings are based on a case study involving an siRNA screen monitoring nucleoplasmic and nucleolar accumulation of a fluorescently tagged reporter protein. For the analysis, they developed a complete analysis workflow incorporating image segmentation, feature extraction, cell classification, hit detection, and visualization of the results. For the classification task, the authors have established a new graphical framework, the Advanced Cell Classifier, which provides a very accurate high-content screen analysis with minimal user interaction, offering access to a variety of advanced machine learning methods.", "PublicationYear": "2011", "Authors": ["P{\\'e}ter Horv{\\'a}th", "Thomas Wild", "Ulrike Kutay", "Gabor Csucs"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["30d3cf944dc63c4451d393141641a205adf6030d", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "2e14d5736174492b5a6c2e17bc11407e27f367b8", "867bd62f7daeb6bb6f5ebe07af777c8378820ec4", "295d17c302c11e783defc08fd9c083320bba87f0", "c7b7027659ffe67670d41a5a73b7eece8f0ff493", "c5188696ee70031f453f1ea1e37356458bae1216", "7d4642da036febe5174da1390521444ef405c864", "5e302195a3d4761e19fdaa8609e269f80820a07a", "827c3aa696e06d17bbd4af16b3877a406323e807"], "ReferenceCount": 17, "CitationCount": 53}, {"URL": "https://www.semanticscholar.org/paper/Sparse-signal-recovery-under-Poisson-statistics-Motamedvaziri-Rohban/3ecba59e99a4cd5f146270debc5ef8d214697c77", "ID": "3ecba59e99a4cd5f146270debc5ef8d214697c77", "Title": "Sparse signal recovery under Poisson statistics", "Abstract": "It is shown that when the sensing matrix satisfies the so-called Restricted Eigenvalue (RE) condition the \u21131 regularized ML decoder is consistent and converges exponentially fast in terms of number of observations. We are motivated by problems that arise in a number of applications such as explosives detection and online Marketing, where the observations are governed by Poisson statistics. Here each observation is a Poisson random variable whose mean is a sparse linear superposition of known patterns. Unlike many conventional problems observations here are not identically distributed since they are associated with different sensing modalities. We analyse the performance of a Maximum Likelihood (ML) decoder, which for our Poisson setting is computationally tractable. We derive fundamental sample complexity bounds for sparse recovery in the high-dimensional setting. We show that when the sensing matrix satisfies the so-called Restricted Eigenvalue (RE) condition the \u21131 regularized ML decoder is consistent. Moreover, it converges exponentially fast in terms of number of observations. Our results apply to both deterministic and random sensing matrices and we present several results for both cases.", "PublicationYear": "2013", "Authors": ["Delaram Motamedvaziri", "Mohammad Hossein Rohban", "Venkatesh Saligrama"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["51ff6cfb98eec39da52035d87f329cf9e89462e6", "1ed22f981940b25d3ceac8846153b3521e8cae7b", "e4d56ec1be5603ddb2cd5b9264e365a19dbd5217", "cb83ea348192bff3acaff83d81cbcb0046f3205d", "ece5045d0f495834b25d2188735bcee982edd8c2", "e716688ddc25dcc8871ef04c7f864063949aa8b9", "dec6d5d1d76c60c337720e5629365f194a34a7d5", "5f56320c5979faeab78dbd9ddb7db755ba4550f3", "96c3209106cc0fd1310be658eac19124ec01bf85", "b570697525b947451d8ba0933c9cbde5f13286b7"], "ReferenceCount": 27, "CitationCount": 8}, {"URL": "https://www.semanticscholar.org/paper/Compressed-Sensing-Performance-Bounds-Under-Poisson-Raginsky-Willett/51ff6cfb98eec39da52035d87f329cf9e89462e6", "ID": "51ff6cfb98eec39da52035d87f329cf9e89462e6", "Title": "Compressed Sensing Performance Bounds Under Poisson Noise", "Abstract": "It is shown that, as the overall intensity of the underlying signal increases, an upper bound on the reconstruction error decays at an appropriate rate, but that for a fixed signal intensity, the error bound actually grows with the number of measurements or sensors. This paper describes performance bounds for compressed sensing (CS) where the underlying sparse or compressible (sparsely approximable) signal is a vector of nonnegative intensities whose measurements are corrupted by Poisson noise. In this setting, standard CS techniques cannot be applied directly for several reasons. First, the usual signal-independent and/or bounded noise models do not apply to Poisson noise, which is nonadditive and signal-dependent. Second, the CS matrices typically considered are not feasible in real optical systems because they do not adhere to important constraints, such as nonnegativity and photon flux preservation. Third, the typical l2 - l1 minimization leads to overfitting in the high-intensity regions and oversmoothing in the low-intensity areas. In this paper, we describe how a feasible positivity- and flux-preserving sensing matrix can be constructed, and then analyze the performance of a CS reconstruction approach for Poisson data that minimizes an objective function consisting of a negative Poisson log likelihood term and a penalty term which measures signal sparsity. We show that, as the overall intensity of the underlying signal increases, an upper bound on the reconstruction error decays at an appropriate rate (depending on the compressibility of the signal), but that for a fixed signal intensity, the error bound actually grows with the number of measurements or sensors. This surprising fact is both proved theoretically and justified based on physical intuition.", "PublicationYear": "2009", "Authors": ["Maxim Raginsky", "Rebecca M. Willett", "Zachary T. Harmany", "Roummel F. Marcia"], "RelatedTopics": ["Computer Science", "Physics"], "References": ["2586ebbb3d73dfbaca970e7cb22f7d011740cdfa", "e4d56ec1be5603ddb2cd5b9264e365a19dbd5217", "1ed22f981940b25d3ceac8846153b3521e8cae7b", "cb83ea348192bff3acaff83d81cbcb0046f3205d", "a6f5c8d82f27bd68eb4cc40bc3d0b00fccc5d469", "4a0ef8c1cd80b7f21f3b6fc3dc7a6654b3d923e3", "0c6398c4231aa0f03121bee8632d5cba4da67de3", "483813f8da20b4f5763eb12f80d210d9613cf44e", "a898ad13c96e5c068a2e4fc88227278e646b712e", "96c3209106cc0fd1310be658eac19124ec01bf85"], "ReferenceCount": 44, "CitationCount": 159}, {"URL": "https://www.semanticscholar.org/paper/Sparse-signal-recovery-with-exponential-family-Rish-Grabarnik/1ed22f981940b25d3ceac8846153b3521e8cae7b", "ID": "1ed22f981940b25d3ceac8846153b3521e8cae7b", "Title": "Sparse signal recovery with exponential-family noise", "Abstract": "It is shown that, under standard restricted isometry property (RIP) assumptions on the design matrix, l1-minimization can provide stable recovery of a sparse signal in presence of the exponential-family noise, provided that certain sufficient conditions on the noise distribution are satisfied. The problem of sparse signal recovery from a relatively small number of noisy measurements has been studied extensively in the recent literature on compressed sensing. However, the focus of those studies appears to be limited to the case of linear projections disturbed by Gaussian noise, and the sparse signal reconstruction problem is treated as linear regression with l1-norm regularization constraint. A natural question to ask is whether one can accurately recover sparse signals under different noise assumptions. Herein, we extend the results of [13] to the more general case of exponential-family noise that includes Gaussian noise as a particular case, and yields l1-regularized Generalized Linear Model (GLM) regression problem. We show that, under standard restricted isometry property (RIP) assumptions on the design matrix, l1-minimization can provide stable recovery of a sparse signal in presence of the exponential-family noise, provided that certain sufficient conditions on the noise distribution are satisfied.", "PublicationYear": "2009", "Authors": ["Irina Rish", "Genady Grabarnik"], "RelatedTopics": ["Computer Science", "Engineering", "Mathematics"], "References": ["5f56320c5979faeab78dbd9ddb7db755ba4550f3", "6f14a338e8837fae059cab41064155cd84cb9cd5", "915df1a8dda45221204f3ecbf70b07d8b34d7ba8", "36ab8bd64210ac5c4f7d326ed2c0a5745e91320f", "3424286d6d39de51080ddd683646565545d015e2", "c1180048929ed490ab25e0e612f8f7c3d7196450", "0f71f070ea61fd51a50e21e73c35f57b00ea7550", "b5e853572b2f3134acafa76d5ae80b9f28c7dca8", "927de77d0002851c150be9fb0ea2204880135f3f", "f312852b31a76bc09b59aca6e4017a9382f9cb39"], "ReferenceCount": 18, "CitationCount": 29}, {"URL": "https://www.semanticscholar.org/paper/Information-Theoretic-Bounds-for-Compressed-Sensing-Aeron-Saligrama/46dfa751eade5e60ab16b51496a9c764bced2322", "ID": "46dfa751eade5e60ab16b51496a9c764bced2322", "Title": "Information Theoretic Bounds for Compressed Sensing", "Abstract": "This paper derives information theoretic performance bounds to sensing and reconstruction of sparse phenomena from noisy projections by developing novel extensions to Fano's inequality to handle continuous domains and arbitrary distortions and shows that with constant SNR the number of measurements scales linearly with the rate-distortion function of the sparse phenomena. In this paper, we derive information theoretic performance bounds to sensing and reconstruction of sparse phenomena from noisy projections. We consider two settings: output noise models where the noise enters after the projection and input noise models where the noise enters before the projection. We consider two types of distortion for reconstruction: support errors and mean-squared errors. Our goal is to relate the number of measurements, m , and SNR, to signal sparsity, k, distortion level, d, and signal dimension, n . We consider support errors in a worst-case setting. We employ different variations of Fano's inequality to derive necessary conditions on the number of measurements and SNR required for exact reconstruction. To derive sufficient conditions, we develop new insights on max-likelihood analysis based on a novel superposition property. In particular, this property implies that small support errors are the dominant error events. Consequently, our ML analysis does not suffer the conservatism of the union bound and leads to a tighter analysis of max-likelihood. These results provide order-wise tight bounds. For output noise models, we show that asymptotically an SNR of ((n)) together with (k (n/k)) measurements is necessary and sufficient for exact support recovery. Furthermore, if a small fraction of support errors can be tolerated, a constant SNR turns out to be sufficient in the linear sparsity regime. In contrast for input noise models, we show that support recovery fails if the number of measurements scales as o(n(n)/SNR), implying poor compression performance for such cases. Motivated by the fact that the worst-case setup requires significantly high SNR and substantial number of measurements for input and output noise models, we consider a Bayesian setup. To derive necessary conditions, we develop novel extensions to Fano's inequality to handle continuous domains and arbitrary distortions. We then develop a new max-likelihood analysis over the set of rate distortion quantization points to characterize tradeoffs between mean-squared distortion and the number of measurements using rate-distortion theory. We show that with constant SNR the number of measurements scales linearly with the rate-distortion function of the sparse phenomena.", "PublicationYear": "2008", "Authors": ["S. Aeron", "Venkatesh Saligrama", "Manqi Zhao"], "RelatedTopics": ["Mathematics", "Computer Science"], "References": ["864f36c6d918f9baf4b11a1b1586629ba818957e", "36b9be6122cefacf7a77d1c147a80176916a5711", "8a3b8f4dd0304861ab4d07e8f5befae03207e18e", "7502fb7b2690ebfba309f0dc195320f7e51de0af", "ceca70071d3ff9f904d94dd971f6c56ce135662e", "5d6906070d7e69ed794058720b52e46d2899e96b", "f203242b7c0e953d2d98c495ccc602e456e123cd", "2e37e4844f214c34d0e4c75805dc35304603d736", "1a55ae68b459888c2ea8e0da5c1d35aea41623dc", "1cc73701c8afee2804c1b02bbfff1451dae429e3"], "ReferenceCount": 52, "CitationCount": 170}, {"URL": "https://www.semanticscholar.org/paper/Performance-Bounds-for-Expander-Based-Compressed-in-Raginsky-Jafarpour/e4d56ec1be5603ddb2cd5b9264e365a19dbd5217", "ID": "e4d56ec1be5603ddb2cd5b9264e365a19dbd5217", "Title": "Performance Bounds for Expander-Based Compressed Sensing in Poisson Noise", "Abstract": "A novel sensing paradigm based on expander graphs is developed and a maximum a posteriori (MAP) algorithm for recovering sparse or compressible signals from Poisson observations is proposed. This paper provides performance bounds for compressed sensing in the presence of Poisson noise using expander graphs. The Poisson noise model is appropriate for a variety of applications, including low-light imaging and digital streaming, where the signal-independent and/or bounded noise models used in the compressed sensing literature are no longer applicable. In this paper, we develop a novel sensing paradigm based on expander graphs and propose a maximum a posteriori (MAP) algorithm for recovering sparse or compressible signals from Poisson observations. The geometry of the expander graphs and the positivity of the corresponding sensing matrices play a crucial role in establishing the bounds on the signal reconstruction error of the proposed algorithm. We support our results with experimental demonstrations of reconstructing average packet arrival rates and instantaneous packet counts at a router in a communication network, where the arrivals of packets in each flow follow a Poisson process.", "PublicationYear": "2010", "Authors": ["Maxim Raginsky", "Sina Jafarpour", "Zachary T. Harmany", "Roummel F. Marcia", "Rebecca M. Willett", "Robert Calderbank"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["8f7e961ef79dadbc484b5c9852678211aa379fc5", "51ff6cfb98eec39da52035d87f329cf9e89462e6", "90ce366042075b7956f5fd0bd44bafa3fbc8f27a", "2deed777c51b42c989690528cf54d74662dde47d", "1ed22f981940b25d3ceac8846153b3521e8cae7b", "cb83ea348192bff3acaff83d81cbcb0046f3205d", "b1b3ae440512f6fa3bef48938a7b74a7ba873de9", "4a0ef8c1cd80b7f21f3b6fc3dc7a6654b3d923e3", "e7321ab0f3be0b29aaf5f073fd7de7da5fed2f92", "483813f8da20b4f5763eb12f80d210d9613cf44e"], "ReferenceCount": 42, "CitationCount": 55}, {"URL": "https://www.semanticscholar.org/paper/Sparse-signal-recovery-under-poisson-statistics-for-Motamedvaziri-Rohban/8f4f9faa26027f8eae4474d90f6d31c0749acd49", "ID": "8f4f9faa26027f8eae4474d90f6d31c0749acd49", "Title": "Sparse signal recovery under poisson statistics for online marketing applications", "Abstract": "This work analyzes the performance of a Maximum Likelihood (ML) decoder and proves consistency and shows an exponential rate of converge for sparse recovery in the high-dimensional Poisson setting. We are motivated by many applications such as problems that arise in online marketing applications, where the observations are governed by non-homogeneous Poisson models. We analyze the performance of a Maximum Likelihood (ML) decoder. We prove consistency and show an exponential rate of converge for sparse recovery in the high-dimensional Poisson setting. After verifying the efficiency of ML estimator empirically, we apply the ML decoder to study the dynamics of online marketing methods over time.", "PublicationYear": "2014", "Authors": ["Delaram Motamedvaziri", "Mohammad Hossein Rohban", "Venkatesh Saligrama"], "RelatedTopics": ["Business", "Computer Science"], "References": ["3ecba59e99a4cd5f146270debc5ef8d214697c77", "51ff6cfb98eec39da52035d87f329cf9e89462e6", "1ed22f981940b25d3ceac8846153b3521e8cae7b", "dbaeea209717db86bfcf359005d0130eff0b09c5", "5f56320c5979faeab78dbd9ddb7db755ba4550f3", "bb92178d5133f9165b704500cbe2e5a1b2dab01d", "cb83ea348192bff3acaff83d81cbcb0046f3205d", "ece5045d0f495834b25d2188735bcee982edd8c2", "dec6d5d1d76c60c337720e5629365f194a34a7d5", "fe09efb519b26d59c64c715c4efcbe752dc933be"], "ReferenceCount": 24, "CitationCount": 2}, {"URL": "https://www.semanticscholar.org/paper/A-unified-framework-for-high-dimensional-analysis-Negahban-Ravikumar/5f56320c5979faeab78dbd9ddb7db755ba4550f3", "ID": "5f56320c5979faeab78dbd9ddb7db755ba4550f3", "Title": "A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers", "Abstract": "A unified framework for establishing consistency and convergence rates for regularized M-estimators under high-dimensional scaling is provided and one main theorem is state and shown how it can be used to re-derive several existing results, and also to obtain several new results. High-dimensional statistical inference deals with models in which the the number of parameters p is comparable to or larger than the sample size n. Since it is usually impossible to obtain consistent procedures unless p/n \u2192 0, a line of recent work has studied models with various types of structure (e.g., sparse vectors; block-structured matrices; low-rank matrices; Markov assumptions). In such settings, a general approach to estimation is to solve a regularized convex program (known as a regularized M-estimator) which combines a loss function (measuring how well the model fits the data) with some regularization function that encourages the assumed structure. The goal of this paper is to provide a unified framework for establishing consistency and convergence rates for such regularized M-estimators under high-dimensional scaling. We state one main theorem and show how it can be used to re-derive several existing results, and also to obtain several new results on consistency and convergence rates. Our analysis also identifies two key properties of loss and regularization functions, referred to as restricted strong convexity and decomposability, that ensure the corresponding regularized M-estimators have fast convergence rates.", "PublicationYear": "2009", "Authors": ["Sahand N. Negahban", "Pradeep Ravikumar", "Martin J. Wainwright", "Bin Yu"], "RelatedTopics": ["Mathematics"], "References": ["a205ffddbd10b0a2be6953467a9d749aaa6c27d8", "6c7500fd3f25946323420563329a6599e67de429", "28a0b9a6da483c184ea5b5b95de7f55ce47fdbf9", "229f46e78c8ba96da2febc39a07e1c8e4daf4b7a", "398ff09f1ef9fdc1d70f59eeb744f06c06998528", "c8d4be093cd4da26f0402b6b9b2680d7ffae2959", "ece5045d0f495834b25d2188735bcee982edd8c2", "f35dfefdd5c44c5e717e17bb72c273b22b0878f1", "8124c3f9bf7fb7cef9cb28ba77117f0923039b14", "5214b65ed56efffd97493a59114a772dfb54caf1"], "ReferenceCount": 107, "CitationCount": 1313}, {"URL": "https://www.semanticscholar.org/paper/THE-LASSO-UNDER-POISSON-LIKE-HETEROSCEDASTICITY-Jia-Rohe/fe09efb519b26d59c64c715c4efcbe752dc933be", "ID": "fe09efb519b26d59c64c715c4efcbe752dc933be", "Title": "THE LASSO UNDER POISSON-LIKE HETEROSCEDASTICITY", "Abstract": "Simulations show that the Lasso performs equally well in terms of model selection performance on both Poisson-like data and homoscedastic data (with properly scaled noise vari- ance), across a range of parameterizations. The performance of the Lasso is well understood under the assumptions of the standard sparse linear model with homoscedastic noise. However, in several ap- plications, the standard model does not describe the important features of the data. This paper examines how the Lasso performs on a non-standard model that is mo- tivated by medical imaging applications. In these applications, the variance of the noise scales linearly with the expectation of the observation. Like all heteroscedas- tic models, the noise terms in this Poisson-like model are not independent of the design matrix. Under a sparse Poisson-like model for the high-dimension regime that allows the number of predictors (p) \u226b sample size (n), we give necessary and sufficient conditions for the sign consistency of the Lasso estimate. Simulations re- veal that the Lasso performs equally well in terms of model selection performance on both Poisson-like data and homoscedastic data (with properly scaled noise vari- ance), across a range of parameterizations.", "PublicationYear": "2013", "Authors": ["Jinzhu Jia", "Karl Rohe", "Bin Yu"], "RelatedTopics": ["Mathematics", "Medicine"], "References": ["dc5b06753fac11268bc2300b7c25d50cbbcdeb5c", "a35ec1830025da231863da9bffa2d9d769413264", "b365b8e45b7d81f081de44ac8f9eadf9144f3ca5", "99dc70afc02f49f56c0c511a578c10bc60c10c84", "7aa39f7f3b69473705e247dd2b3a9689f10fbbc3", "2f9d50dbbb050abb68881cbffd5348892e0c315b", "144feb8f6b2bd36775ef6cc39452387c671314ff", "c59c6afcfd5d03eb2c8fb5d1665afacc077771b9", "8d001fdf877f5de5d639811eab63c176231d1c22", "78a9b31d5c2544c5d3d519e4df0f938ed53196f8"], "ReferenceCount": 34, "CitationCount": 24}, {"URL": "https://www.semanticscholar.org/paper/Asymptotic-Behavior-of-Likelihood-Methods-for-when-Portnoy/046d550f95db0dae9aa26b34c31cb502b5b72983", "ID": "046d550f95db0dae9aa26b34c31cb502b5b72983", "Title": "Asymptotic Behavior of Likelihood Methods for Exponential Families when the Number of Parameters Tends to Infinity", "Abstract": "Consider a sample of size n from a regular exponential family in Pn dimensions. Let 6, denote the maximum likelihood estimator, and consider the case where Pn tends to infinity with n and where {(On} is a sequence of parameter values in RP-. Moment conditions are provided under which II6 0,JI = O?( p(,/n) and On6n On Xnll = Op (p,/n), where Xn is the sample mean. The latter result provides normal approximation results when p2/n 0. It is shown by example that even for a single coordinate of (6, in), pn2/n -? 0 may be needed for normal approximation. However, if pn3/2 /n O 0, the likelihood ratio test statistic A for a simple hypothesis has a chi-square approximation in the sense that (2 log A pn )/ 2Pn D A(0, 1).", "PublicationYear": "1988", "Authors": ["Stephen Portnoy"], "RelatedTopics": ["Mathematics"], "References": ["c87d573f82cfaaf7947476e56f9549dfe24ec896", "ea53d8bd34060ed48ed15b9737a8f8a197e34baf", "83fe7496f9f823ad81083a5b3f326ab501eb3a34", "0bb38cc2e9c8799f9cf21fe8a0d17d66587dcf2f", "7733d1213c533c05cd77f2e9fe5c7410f6085f95", "be414e62f977e82b56f6402d27c6a3144e318029", "1eafe60d624180b892bf0d5c7b5d1f8b48dbfcb6", "ef098e0154da4b210a6ee11b84ca30bd3e445ac6", "e28f9fcb242c728373f8900b9991a5b68e05bd3b", "3ee5972fa55e18c42746112754d3b4772f88249f"], "ReferenceCount": 12, "CitationCount": 246}, {"URL": "https://www.semanticscholar.org/paper/Generative-Probabilistic-Novelty-Detection-with-Pidhorskyi-Almohsen/70f9968a356d840040a1c9207906f60376dc6bd4", "ID": "70f9968a356d840040a1c9207906f60376dc6bd4", "Title": "Generative Probabilistic Novelty Detection with Adversarial Autoencoders", "Abstract": "This work makes the computation of the novelty probability feasible because it linearize the parameterized manifold capturing the underlying structure of the inlier distribution, and shows how the probability factorizes and can be computed with respect to local coordinates of the manifold tangent space. Novelty detection is the problem of identifying whether a new data point is considered to be an inlier or an outlier. We assume that training data is available to describe only the inlier distribution. Recent approaches primarily leverage deep encoder-decoder network architectures to compute a reconstruction error that is used to either compute a novelty score or to train a one-class classifier. While we too leverage a novel network of that kind, we take a probabilistic approach and effectively compute how likely it is that a sample was generated by the inlier distribution. We achieve this with two main contributions. First, we make the computation of the novelty probability feasible because we linearize the parameterized manifold capturing the underlying structure of the inlier distribution, and show how the probability factorizes and can be computed with respect to local coordinates of the manifold tangent space. Second, we improve the training of the autoencoder network. An extensive set of results show that the approach achieves state-of-the-art performance on several benchmark datasets.", "PublicationYear": "2018", "Authors": ["Stanislav Pidhorskyi", "Ranya Almohsen", "Donald A. Adjeroh", "Gianfranco Doretto"], "RelatedTopics": ["Computer Science"], "References": ["8381157eae4fbf8908d0312a9642f8e69e944449", "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "6b1160f6ff6c4a8e1418f4edba9c6b9c2c6f385a", "1130d8fdd931225c2d7563c3808367726cfa1c3a", "e8b8a7778ace2a02f8db6fe321a54520c6b283ca", "97e7c94a78ae17cfb90848c1cfca8c431082a7b2", "1972c73d96353e57599962fd6059572801382212", "431ba9fae8fccad1665979d455c6307786e47318", "a96449c7f9b1ed6bf4545db7e5ec095b766de3eb", "547c854985629cfa9404a5ba8ca29367b5f8c25f"], "ReferenceCount": 61, "CitationCount": 267}, {"URL": "https://www.semanticscholar.org/paper/Towards-Deep-Learning-Models-Resistant-to-Attacks-Madry-Makelov/7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "ID": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "Title": "Towards Deep Learning Models Resistant to Adversarial Attacks", "Abstract": "This work studies the adversarial robustness of neural networks through the lens of robust optimization, and suggests the notion of security against a first-order adversary as a natural and broad security guarantee. Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at this https URL and this https URL.", "PublicationYear": "2017", "Authors": ["Aleksander Madry", "Aleksandar Makelov", "Ludwig Schmidt", "Dimitris Tsipras", "Adrian Vladu"], "RelatedTopics": ["Computer Science"], "References": ["df40ce107a71b770c9d0354b78fdd8989da80d2f", "6adf016e7531c91100d3cf4a74f5d4c87b26b528", "c486cec6473c6f97cc2037d475c99c00d6ff9b23", "819167ace2f0caae7745d2f25a803979be5fbfae", "4f9f7434f06cbe31e54a0bb118975340b9e0a4c9", "567f01807f24abcc168c58b05b4c1659387f474f", "136dee73f203df2f4831994bf4f0c0a4ad2e764e", "e2a85a6766b982ff7c8980e57ca6342d22493827", "fd7789de401811fd8692466b8d49230e7184655f", "1deb6bd9bc6c0112cd06348fd738d7f50ff4b907"], "ReferenceCount": 44, "CitationCount": 9007}, {"URL": "https://www.semanticscholar.org/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a", "ID": "6af440915b8a0718c93be1cf61905e41e620484a", "Title": "Deep One-Class Classification", "Abstract": "This paper introduces a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective and shows the effectiveness of the method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GT-SRB stop signs. Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objec-tive. In this paper we introduce a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GT-SRB stop signs.", "PublicationYear": "2018", "Authors": ["Lukas Ruff", "Nico G{\\\"o}rnitz", "Lucas Deecke", "Shoaib Ahmed Siddiqui", "Robert A. Vandermeulen", "Alexander Binder", "Emmanuel M{\\\"u}ller", "M. Kloft"], "RelatedTopics": ["Computer Science"], "References": ["8388f1be26329fa45e5807e968a641ce170ea078", "bee044c8e8903fb67523c1f8c105ab4718600cdb", "f076e4355c0facf111716dcab2837803367dd2d8", "6259b02912cebc224f3a2b1324e811a152a0177d", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "843959ffdccf31c6694d135fad07425924f785b1", "1b225474e7a5794f98cdfbde8b12ccbc56799409", "60fef33549f57f5cbb6712a510c3a444ab682429"], "ReferenceCount": 58, "CitationCount": 1412}, {"URL": "https://www.semanticscholar.org/paper/Memorizing-Normality-to-Detect-Anomaly%3A-Deep-for-Gong-Liu/d65eb30e5f0d2013fd5e4f45d1413bc2969ee803", "ID": "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803", "Title": "Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection", "Abstract": "The proposed memory-augmented autoencoder called MemAE is free of assumptions on the data type and thus general to be applied to different tasks and proves the excellent generalization and high effectiveness of the proposed MemAE. Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder \\\"generalizes\\\" so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.", "PublicationYear": "2019", "Authors": ["Dong Gong", "Lingqiao Liu", "Vuong Le", "Budhaditya Saha", "Moussa Reda Mansour", "Svetha Venkatesh", "Anton van den Hengel"], "RelatedTopics": ["Computer Science"], "References": ["2b75ba7f75170b73d913c515cc0deefef6c88f5f", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "fef6f1e04fa64f2f26ac9f01cd143dd19e549790", "6af440915b8a0718c93be1cf61905e41e620484a", "10a498003e9204f5fc1328e706510a37e514d8c7", "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "8381157eae4fbf8908d0312a9642f8e69e944449", "99dff291f260b3cc3ff190106b0c2e3e685223a4", "afac99b10a5c7e531f73e4a4866d6ee3c9e86cd4", "bbd0e204f48a45735e1065c8b90b298077b73192"], "ReferenceCount": 54, "CitationCount": 849}, {"URL": "https://www.semanticscholar.org/paper/OCGAN%3A-One-Class-Novelty-Detection-Using-GANs-With-Perera-Nallapati/599fd051c9438011ec5b581983c89e8922b4a5e6", "ID": "599fd051c9438011ec5b581983c89e8922b4a5e6", "Title": "OCGAN: One-Class Novelty Detection Using GANs With Constrained Latent Representations", "Abstract": "A novel model called OCGAN is presented for the classical problem of one-class novelty detection, where, given a set of examples from a particular class, the goal is to determine if a query example is from the same class using a de-noising auto-encoder network. We present a novel model called OCGAN for the classical problem of one-class novelty detection, where, given a set of examples from a particular class, the goal is to determine if a query example is from the same class. Our solution is based on learning latent representations of in-class examples using a de-noising auto-encoder network. The key contribution of our work is our proposal to explicitly constrain the latent space to exclusively represent the given class. In order to accomplish this goal, firstly, we force the latent space to have bounded support by introducing a tanh activation in the encoder's output layer. Secondly, using a discriminator in the latent space that is trained adversarially, we ensure that encoded representations of in-class examples resemble uniform random samples drawn from the same bounded space. Thirdly, using a second adversarial discriminator in the input space, we ensure all randomly drawn latent samples generate examples that look real. Finally, we introduce a gradient-descent based sampling technique that explores points in the latent space that generate potential out-of-class examples, which are fed back to the network to further train it to generate in-class examples from those points. The effectiveness of the proposed method is measured across four publicly available datasets using two one-class novelty detection protocols where we achieve state-of-the-art results.", "PublicationYear": "2019", "Authors": ["Pramuditha Perera", "Ramesh Nallapati", "Bing Xiang"], "RelatedTopics": ["Computer Science"], "References": ["8381157eae4fbf8908d0312a9642f8e69e944449", "70f9968a356d840040a1c9207906f60376dc6bd4", "2910bec6d4de87e22be5119cef3c488d2ae50e2a", "6af440915b8a0718c93be1cf61905e41e620484a", "353ecf7b66b3e9ff5e9f41145a147e899a2eea5c", "967d532a66dab7edcb818b0f9dc59fe8da7dc171", "00695a31a80221c7125e49885a4767896ec2c4f7", "732c21998e251d64cd58b6a86886ee5907efeaa5", "8388f1be26329fa45e5807e968a641ce170ea078", "0936352b78a52bc5d2b5e3f04233efc56664af51"], "ReferenceCount": 30, "CitationCount": 415}, {"URL": "https://www.semanticscholar.org/paper/Latent-Space-Autoregression-for-Novelty-Detection-Abati-Porrello/5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "ID": "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "Title": "Latent Space Autoregression for Novelty Detection", "Abstract": "This proposal designs a general unsupervised framework where a deep autoencoder is equipped with a parametric density estimator that learns the probability distribution underlying the latent representations with an autoregressive procedure and shows that a maximum likelihood objective effectively acts as a regularizer for the task at hand. Novelty detection is commonly referred as the discrimination of observations that do not conform to a learned model of regularity. Despite its importance in different application settings, designing a novelty detector is utterly complex due to the unpredictable nature of novelties and its inaccessibility during the training procedure, factors which expose the unsupervised nature of the problem. In our proposal, we design a general unsupervised framework where we equip a deep autoencoder with a parametric density estimator that learns the probability distribution underlying the latent representations with an autoregressive procedure. We show that a maximum likelihood objective, optimized in conjunction with the reconstruction of normal samples, effectively acts as a regularizer for the task at hand, by minimizing the differential entropy of the distribution spanned by latent vectors. In addition to providing a very general formulation, extensive experiments of our model on publicly available datasets deliver on-par or superior performances if compared to state-of-the-art methods in one-class and in video anomaly detection settings. Differently from our competitors, we remark that our proposal does not make any assumption about the nature of the novelties, making our work easily applicable to disparate contexts.", "PublicationYear": "2018", "Authors": ["Davide Abati", "Angelo Porrello", "Simone Calderara", "Rita Cucchiara"], "RelatedTopics": ["Computer Science"], "References": ["8381157eae4fbf8908d0312a9642f8e69e944449", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "90f72fbbe5f0a29e627db28999e01a30a9655bc6", "97e7c94a78ae17cfb90848c1cfca8c431082a7b2", "792250ae660b7c25f85eeea7dcae623e4301d97c", "99dff291f260b3cc3ff190106b0c2e3e685223a4", "705fd4febe2fff810d2f72f48dcda20826eca77a", "3262e77099cefe24cff1308f204e673cac832451", "39e0c341351f8f4a39ac890b96217c7f4bde5369", "4eb82d0ae0b60311779f2b1e1fa2d8789fb38cb2"], "ReferenceCount": 49, "CitationCount": 357}, {"URL": "https://www.semanticscholar.org/paper/Exploring-the-Landscape-of-Spatial-Robustness-Engstrom-Tran/0314e777333a63aca5735ea136c74e113aa8801d", "ID": "0314e777333a63aca5735ea136c74e113aa8801d", "Title": "Exploring the Landscape of Spatial Robustness", "Abstract": "This work thoroughly investigate the vulnerability of neural network--based classifiers to rotations and translations and finds that, in contrast to the p-norm case, first-order methods cannot reliably find worst-case perturbations. The study of adversarial robustness has so far largely focused on perturbations bound in p-norms. However, state-of-the-art models turn out to be also vulnerable to other, more natural classes of perturbations such as translations and rotations. In this work, we thoroughly investigate the vulnerability of neural network--based classifiers to rotations and translations. While data augmentation offers relatively small robustness, we use ideas from robust optimization and test-time input aggregation to significantly improve robustness. Finally we find that, in contrast to the p-norm case, first-order methods cannot reliably find worst-case perturbations. This highlights spatial robustness as a fundamentally different setting requiring additional study. Code available at this https URL and this https URL.", "PublicationYear": "2017", "Authors": ["Logan Engstrom", "Brandon Tran", "Dimitris Tsipras", "Ludwig Schmidt", "Aleksander Madry"], "RelatedTopics": ["Computer Science", "Mathematics", "Physics"], "References": ["47eb8d7ea4f7c209040ddd82e264edf3945df6cb", "d3c071dbbb4520ed5875f7e064a9da87240534db", "818c52f4ba56cb8cf152ad614f2f4803057a5cfe", "a295f76c2afb7f79a970ccf086f16168d976bb93", "8dce99e33c6fceb3e79023f5894fdbe733c91e92", "4b23012689e0f17912fb38d4984775e567cff8d6", "52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35", "bee044c8e8903fb67523c1f8c105ab4718600cdb", "dbb6ded623159c867fbeca0772db7b2eb9489523", "966e3c7a65ec75a6359b55c0cecaf3896d318432"], "ReferenceCount": 36, "CitationCount": 467}, {"URL": "https://www.semanticscholar.org/paper/An-Automatic-Learning-Based-Framework-for-Robust-Xing-Xie/d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88", "ID": "d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88", "Title": "An Automatic Learning-Based Framework for Robust Nucleus Segmentation", "Abstract": "A learning-based framework for robust and automatic nucleus segmentation with shape preservation is proposed that is applicable to different staining histopathology images and general enough to perform well across multiple scenarios. Computer-aided image analysis of histopathology specimens could potentially provide support for early detection and improved characterization of diseases such as brain tumor, pancreatic neuroendocrine tumor (NET), and breast cancer. Automated nucleus segmentation is a prerequisite for various quantitative analyses including automatic morphological feature computation. However, it remains to be a challenging problem due to the complex nature of histopathology images. In this paper, we propose a learning-based framework for robust and automatic nucleus segmentation with shape preservation. Given a nucleus image, it begins with a deep convolutional neural network (CNN) model to generate a probability map, on which an iterative region merging approach is performed for shape initializations. Next, a novel segmentation algorithm is exploited to separate individual nuclei combining a robust selection-based sparse shape model and a local repulsive deformable model. One of the significant benefits of the proposed framework is that it is applicable to different staining histopathology images. Due to the feature learning characteristic of the deep CNN and the high level shape prior modeling, the proposed method is general enough to perform well across multiple scenarios. We have tested the proposed algorithm on three large-scale pathology image datasets using a range of different tissue and stain preparations, and the comparative experiments with recent state of the arts demonstrate the superior performance of the proposed approach.", "PublicationYear": "2016", "Authors": ["Fuyong Xing", "Yuanpu Xie", "L. Yang"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["3ba787154b2411fe89d88b6ab50ea84aa62dea04", "63a373063d51489b31e07ee639ab74b6cf586240", "897013b8611820c7738a256b0cb22b1eba4416e1", "721d4ae075de7bf9ea2cac01fe02e2920ee5c789", "b72fb054c8921dee2961076d5ea52d69205880b4", "05a75f3bda7fa3523ac698e0a1b23209da594018", "930b28f5255a6633ec89bdafb9f72af8e9148fac", "3bbf3eea36faa754e83be8c4cfd50f000931e7ef", "9f83bd0aa043f094343294895e7fe7c1b1028841", "d3b97c0b3628243acb7bdef7887c97955ec97b4c"], "ReferenceCount": 80, "CitationCount": 282}, {"URL": "https://www.semanticscholar.org/paper/Comparison-of-segmentation-algorithms-for-images-of-Dima-Elliott/cdecac6e2f578cfc56140e00aaa74a78f864fea2", "ID": "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "Title": "Comparison of segmentation algorithms for fluorescence microscopy images of cells", "Abstract": "This study compares segmentation results from nine different segmentation techniques applied to two different cell lines and five different sets of imaging conditions and proposes a method that quantifies cell edge character to provide an estimate of how accurately an algorithm will perform. The analysis of fluorescence microscopy of cells often requires the determination of cell edges. This is typically done using segmentation techniques that separate the cell objects in an image from the surrounding background. This study compares segmentation results from nine different segmentation techniques applied to two different cell lines and five different sets of imaging conditions. Significant variability in the results of segmentation was observed that was due solely to differences in imaging conditions or applications of different algorithms. We quantified and compared the results with a novel bivariate similarity index metric that evaluates the degree of underestimating or overestimating a cell object. The results show that commonly used threshold\u2010based segmentation techniques are less accurate than k\u2010means clustering with multiple clusters. Segmentation accuracy varies with imaging conditions that determine the sharpness of cell edges and with geometric features of a cell. Based on this observation, we propose a method that quantifies cell edge character to provide an estimate of how accurately an algorithm will perform. The results of this study will assist the development of criteria for evaluating interlaboratory comparability. Published 2011 Wiley\u2010Liss, Inc.", "PublicationYear": "2011", "Authors": ["Alden Dima", "John T. Elliott", "James J. Filliben", "Michael Halter", "Adele P. Peskin", "Javier Bernal", "Marcin Kocio\u0142ek", "Mary Brady", "Hai C. Tang", "Anne L. Plant"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["05aa33a5f87092bce8fb4f82b03b4ecc60fe6794", "f54389eb7c29b2c1748b87e49f1eb640e47ffef0", "537d8f273f7009e6fc9f36af49f53763d83f784e", "933392bae254c94d88b6c0a63b20d11199b3ccda", "88298080bc029f48104f99706421e67845437caa", "e9f4e30e96064e898323d941af1e446acfd3bd59", "7a678e800cec251dd35593ef6d1872c1f19468b1", "6cf6f0f14d2c58ccf92db17e8b64eaee05ca40e3", "99860ed8fde3a80c1b14f0f619246d337c94a114", "00b53e4fb622bc08d98cae925a45ce29753975fb"], "ReferenceCount": 46, "CitationCount": 106}, {"URL": "https://www.semanticscholar.org/paper/Accurate-Morphology-Preserving-Segmentation-of-on-Molnar-Jermyn/318f82a3e593e391cfd0da7964b16d83299aa943", "ID": "318f82a3e593e391cfd0da7964b16d83299aa943", "Title": "Accurate Morphology Preserving Segmentation of Overlapping Cells based on Active Contours", "Abstract": "This work combines the \u201cgas of near circles\u201d active contour model, which favors circular shapes but allows slight variations around them, with a new data model that captures a common property of many microscopic imaging techniques: the intensities from superposed nuclei are additive. The identification of fluorescently stained cell nuclei is the basis of cell detection, segmentation, and feature extraction in high content microscopy experiments. The nuclear morphology of single cells is also one of the essential indicators of phenotypic variation. However, the cells used in experiments can lose their contact inhibition, and can therefore pile up on top of each other, making the detection of single cells extremely challenging using current segmentation methods. The model we present here can detect cell nuclei and their morphology even in high-confluency cell cultures with many overlapping cell nuclei. We combine the \u201cgas of near circles\u201d active contour model, which favors circular shapes but allows slight variations around them, with a new data model. This captures a common property of many microscopic imaging techniques: the intensities from superposed nuclei are additive, so that two overlapping nuclei, for example, have a total intensity that is approximately double the intensity of a single nucleus. We demonstrate the power of our method on microscopic images of cells, comparing the results with those obtained from a widely used approach, and with manual image segmentations by experts.", "PublicationYear": "2016", "Authors": ["Csaba Molnar", "Ian H. Jermyn", "Zoltan Kato", "Vesa Rahkama", "P{\\\"a}ivi {\\\"O}stling", "Piia Mikkonen", "Vilja Pieti{\\\"a}inen", "P{\\'e}ter Horv{\\'a}th"], "RelatedTopics": ["Biology", "Computer Science", "Engineering"], "References": ["3ab1348d060f3ab7e70a2e368a30af14bc57c35c", "1ed39f653fa95414badbe16051730e2d1424655b", "a94669081db970a7e9f4d834c409b59e950b7807", "06791ac9c0d9fe98ddd7da2117ca8ef1809480e3", "b11b32abe663b84afc0cfc436c779a6d10a0630e", "18305601724d262acb98f1c0130cf202293a80d7", "c71671625c2d8ccbb746e364ed169de8877b64d4", "bacc7a056a800a0ba8901012c724d9b9a715beed", "f9df494f4411ae1094b22e687e530e101664a95e", "e9457a36e578bb438e15b81c3be8a157b12781e1"], "ReferenceCount": 41, "CitationCount": 57}, {"URL": "https://www.semanticscholar.org/paper/U-Net%3A-deep-learning-for-cell-counting%2C-detection%2C-Falk-Mai/2d8d74c7fd9375b17e9d6123773919b2aa512c56", "ID": "2d8d74c7fd9375b17e9d6123773919b2aa512c56", "Title": "U-Net: deep learning for cell counting, detection, and morphometry", "Abstract": "An ImageJ plugin is presented that enables non-machine-learning experts to analyze their data with U-Net on either a local computer or a remote server/cloud service and comes with pretrained models for single-cell segmentation. U-Net is a generic deep-learning solution for frequently occurring quantification tasks such as cell detection and shape measurements in biomedical image data. We present an ImageJ plugin that enables non-machine-learning experts to analyze their data with U-Net on either a local computer or a remote server/cloud service. The plugin comes with pretrained models for single-cell segmentation and allows for U-Net to be adapted to new tasks on the basis of a few annotated samples. A user-friendly ImageJ plugin enables the application and training of U-Nets for deep-learning-based image segmentation, detection and classification tasks with minimal labeling requirements.", "PublicationYear": "2018", "Authors": ["Thorsten Falk", "Dominic Mai", "Robert Bensch", "{\\\"O}zg{\\\"u}n \u00c7i\u00e7ek", "Ahmed Abdulkadir", "Yassine Marrakchi", "Anton B{\\\"o}hm", "Jan Deubner", "Zoe J{\\\"a}ckel", "Katharina Seiwald", "Alexander Dovzhenko", "Olaf Tietz", "Cristina Dal Bosco", "Sean Walsh", "Deniz Saltukoglu", "Tuan Leng Tay", "Marco Prinz", "Klaus Palme", "Matias Simons", "Ilka Diester", "Thomas Brox", "Olaf Ronneberger"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["1eab84d51b484d0f79e611979916fa97086e869d", "5e39ec7bb7fbf77fc15224ee0dc71bb4f2c44174", "6ff93aa6ca902002d16fb0c2d3fb48aead92c61e", "7b5be0cdec2a1b36cd8b61d161cff716b3594846", "66507340decdc4612b06329d4649b1e8f95a206a", "8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8", "7fc464470b441c691d10e7331b14a525bc79b8bb", "ff263a45eeebe41f6b79dcc3ec10f3bab6806029", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "6fc6803df5f9ae505cae5b2f178ade4062c768d0"], "ReferenceCount": 15, "CitationCount": 1223}, {"URL": "https://www.semanticscholar.org/paper/A-high%E2%80%90throughput-system-for-segmenting-nuclei-Gudla-Nandy/1268de7bda769e651dc6c089d006c7edbe37f563", "ID": "1268de7bda769e651dc6c089d006c7edbe37f563", "Title": "A high\u2010throughput system for segmenting nuclei using multiscale techniques", "Abstract": "The proposed segmentation method is efficient, robust, and accurate for segmenting individual nuclei from fluorescence images containing clustered and isolated nuclei and allows complete automation and facilitates reproducible and unbiased spatial analysis of DNA sequences. Automatic segmentation of cell nuclei is critical in several high\u2010throughput cytometry applications whereas manual segmentation is laborious and irreproducible. One such emerging application is measuring the spatial organization (radial and relative distances) of fluorescence in situ hybridization (FISH) DNA sequences, where recent investigations strongly suggest a correlation between nonrandom arrangement of genes to carcinogenesis. Current automatic segmentation methods have varying performance in the presence of nonuniform illumination and clustering, and boundary accuracy is seldom assessed, which makes them suboptimal for this application. The authors propose a modular and model\u2010based algorithm for extracting individual nuclei. It uses multiscale edge reconstruction for contrast stretching and edge enhancement as well as a multiscale entropy\u2010based thresholding for handling nonuniform intensity variations. Nuclei are initially oversegmented and then merged based on area followed by automatic multistage classification into single nuclei and clustered nuclei. Estimation of input parameters and training of the classifiers is automatic. The algorithm was tested on 4,181 lymphoblast nuclei with varying degree of background nonuniformity and clustering. It extracted 3,515 individual nuclei and identified single nuclei and individual nuclei in clusters with 99.8 \u00b1 0.3% and 95.5 \u00b1 5.1% accuracy, respectively. Segmented boundaries of the individual nuclei were accurate when compared with manual segmentation with an average RMS deviation of 0.26 \u03bcm (\u223c2 pixels). The proposed segmentation method is efficient, robust, and accurate for segmenting individual nuclei from fluorescence images containing clustered and isolated nuclei. The algorithm allows complete automation and facilitates reproducible and unbiased spatial analysis of DNA sequences. Published 2008 Wiley\u2010Liss, Inc.", "PublicationYear": "2008", "Authors": ["Prabhakar R. Gudla", "Kaustav Nandy", "J. A. Collins", "Karen J. Meaburn", "Tom Misteli", "Stephen J. Lockett"], "RelatedTopics": ["Computer Science", "Biology", "Engineering"], "References": ["365f296d58658cc81d5575e84af790abd33e0d9a", "e86c88e690715bc3beeebc8738ea7912f0c8ccc1", "933392bae254c94d88b6c0a63b20d11199b3ccda", "294d95770c44f6dcea0021042ec31dc63c94b14c", "6df51956de4e97a7ec87e071c84df69ad52ed6bc", "88298080bc029f48104f99706421e67845437caa", "0983d9f5c5a2c6c81530749d7020345ee56a6054", "7ed33c2e66c0ecd9510b80b3e003d3e3ad6a6e16", "bb8b945157a67a7973b011f4f490891641b9764f", "8af89d2ba43141968fc1126aceabd25e66c61a36"], "ReferenceCount": 66, "CitationCount": 77}, {"URL": "https://www.semanticscholar.org/paper/Ilastik%3A-Interactive-learning-and-segmentation-Sommer-Straehle/5c5be36e3111e42247d78a6d529e4b1d7d2ced12", "ID": "5c5be36e3111e42247d78a6d529e4b1d7d2ced12", "Title": "Ilastik: Interactive learning and segmentation toolkit", "Abstract": "Segmentation is the process of partitioning digital images into meaningful regions. The analysis of biological high content images often requires segmentation as a first step. We propose ilastik as an easy-to-use tool which allows the user without expertise in image processing to perform segmentation and classification in a unified way. ilastik learns from labels provided by the user through a convenient mouse interface. Based on these labels, ilastik infers a problem specific segmentation. A random forest classifier is used in the learning step, in which each pixel's neighborhood is characterized by a set of generic (nonlinear) features. ilastik supports up to three spatial plus one spectral dimension and makes use of all dimensions in the feature calculation. ilastik provides realtime feedback that enables the user to interactively refine the segmentation result and hence further fine-tune the classifier. An uncertainty measure guides the user to ambiguous regions in the images. Real time performance is achieved by multi-threading which fully exploits the capabilities of modern multi-core machines. Once a classifier has been trained on a set of representative images, it can be exported and used to automatically process a very large number of images (e.g. using the CellProfiler pipeline). ilastik is an open source project and released under the BSD license at www.ilastik.org.", "PublicationYear": "2011", "Authors": ["Christoph Sommer", "Christoph Nikolas Straehle", "U. K{\\\"o}the", "Fred A. Hamprecht"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["7a953aaf29ef67ee094943d4be50d753b3744573", "19243d3fd6c42a96fb662cda8447c6c12226abff", "fd27d6cef0a9dacbd72b2c58276909ebdf575d9a", "59d86a93c4ef54b5489bc375cd02e64205823f42", "0d3b177e8d027d44c191e739a3a70ccacc2eac82", "ac9748ea3945eb970cc32a37db7cfdfd0f22e74c", "767746905903ce168b7813d8b482ee63574bc743", "2ccd07c26e569c109056f9dadf23cd45e509a254", "44885e8f48a653f4e8fca4d28e5661823d91da7a", "b5ca39cfe25f8313c069a902bc85f9914fba5dad"], "ReferenceCount": 17, "CitationCount": 1125}, {"URL": "https://www.semanticscholar.org/paper/Clinically-applicable-deep-learning-for-diagnosis-Fauw-Ledsam/b2d952fbd6951cbed68ea13003a045300970731a", "ID": "b2d952fbd6951cbed68ea13003a045300970731a", "Title": "Clinically applicable deep learning for diagnosis and referral in retinal disease", "Abstract": "This work applies a novel deep learning architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scans from patients referred to a major eye hospital and demonstrates performance in making a referral recommendation that reaches or exceeds that of experts on a range of sight-threatening retinal diseases. The volume and complexity of diagnostic imaging is increasing at a pace faster than the availability of human expertise to interpret it. Artificial intelligence has shown great promise in classifying two-dimensional photographs of some common diseases and typically relies on databases of millions of annotated images. Until now, the challenge of reaching the performance of expert clinicians in a real-world clinical pathway with three-dimensional diagnostic scans has remained unsolved. Here, we apply a novel deep learning architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scans from patients referred to a major eye hospital. We demonstrate performance in making a referral recommendation that reaches or exceeds that of experts on a range of sight-threatening retinal diseases after training on only 14,884 scans. Moreover, we demonstrate that the tissue segmentations produced by our architecture act as a device-independent representation; referral accuracy is maintained when using tissue segmentations from a different type of device. Our work removes previous barriers to wider clinical use without prohibitive training data requirements across multiple pathologies in a real-world setting. A novel deep learning architecture performs device-independent tissue segmentation of clinical 3D retinal images followed by separate diagnostic classification that meets or exceeds human expert clinical diagnoses of retinal disease.", "PublicationYear": "2018", "Authors": ["Jeffrey De Fauw", "Joseph R. Ledsam", "Bernardino Romera-Paredes", "Stanislav Nikolov", "Nenad Toma{\\vs}ev", "Sam Blackwell", "Harry Askham", "Xavier Glorot", "Brendan O'Donoghue", "Daniela Visentin", "George Van Den Driessche", "Balaji Lakshminarayanan", "Clemens Meyer", "Faith Mackinder", "Simon Bouton", "Kareem Ayoub", "Reena Chopra", "Dominic King", "Alan Karthikesalingam", "C{\\'i}an O. Hughes", "Rosalind Raine", "J. Weston Hughes", "Dawn A. Sim", "Catherine A. Egan", "Adnan Tufail", "Hugh Montgomery", "Demis Hassabis", "Geraint E. Rees", "Trevor Back", "Peng Tee Khaw", "Mustafa Suleyman", "Julien Cornebise", "Pearse Andrew Keane", "Olaf Ronneberger"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["11f9eafe1611bb08bfb026af1910b2a26961ca13", "a3d30839f0be8bf20054ab6ff0cc70bbf491c334", "2263a534c99d78d29131228c3aae70b5968ddc5e", "6f9b97ddcaf9d72f228beff89452f43f24b49416", "5c45a5d05ac564adb67811eeb9d41d6460c70135", "e1ec11a1cb3d9745fb18d3bf74247f95a6663d08", "2bf42496de45923dae902fe285e34844750fd189", "8ede9e9f6361391e3d9ec53bad8bbba6efc45a78", "583d7131c93277f396bcd87c0963e83b3c035dda", "15dfb4f7b91f4073fab88bf8d2aa833118f75dfa"], "ReferenceCount": 45, "CitationCount": 1680}, {"URL": "https://www.semanticscholar.org/paper/Segmentation-of-touching-cell-nuclei-using-gradient-Li-Li/268241fd604918a86e1b27e1a880d47e0ecc2d5b", "ID": "268241fd604918a86e1b27e1a880d47e0ecc2d5b", "Title": "Segmentation of touching cell nuclei using gradient flow tracking", "Abstract": "This method is able to segment closely juxtaposed or clustered cell nuclei, with high sensitivity and specificity in different situations, with both over\u2010segmentation and under\u2010se segmentation rates below 3%. Reliable cell nuclei segmentation is an important yet unresolved problem in biological imaging studies. This paper presents a novel computerized method for robust cell nuclei segmentation based on gradient flow tracking. This method is composed of three key steps: (1) generate a diffused gradient vector flow field; (2) perform a gradient flow tracking procedure to attract points to the basin of a sink; and (3) separate the image into small regions, each containing one nucleus and nearby peripheral background, and perform local adaptive thresholding in each small region to extract the cell nucleus from the background. To show the generality of the proposed method, we report the validation and experimental results using microscopic image data sets from three research labs, with both over\u2010segmentation and under\u2010segmentation rates below 3%. In particular, this method is able to segment closely juxtaposed or clustered cell nuclei, with high sensitivity and specificity in different situations.", "PublicationYear": "2008", "Authors": ["Gang Li", "Gang Li", "Tian Qi Liu", "Tian Qi Liu", "Jingxin Nie", "Lei Guo", "J. Chen", "Jinmin Zhu", "Jinmin Zhu", "Weiming Xia", "Andrew Mara", "Scott A. Holley", "Stephen T. C. Wong", "Stephen T. C. Wong"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["c0da38acd8e44c77e732b21e505f7042a8736a9c", "cee3035635eafa1c412934419d7563fdb06d73ae", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "e86c88e690715bc3beeebc8738ea7912f0c8ccc1", "e3aa7e680a95d7343fcd3cd27cad85b443d1933d", "a9c006a11c8576350838c8f6ca8d418957f1287a", "f3a3254d7e233ae36baef93ebe5008c21151f467", "f859d132aa7e868609bace85291c0fc1c6636fe2", "41ae827281ac2949ed19a60890b047d02f1212da", "0a8a1b1f491ad1a99edadf9fe32f3a8702457269"], "ReferenceCount": 37, "CitationCount": 81}, {"URL": "https://www.semanticscholar.org/paper/Mask-R-CNN-He-Gkioxari/ea99a5535388196d0d44be5b4d7dd02029a43bb2", "ID": "ea99a5535388196d0d44be5b4d7dd02029a43bb2", "Title": "Mask R-CNN", "Abstract": "This work presents a conceptually simple, flexible, and general framework for object instance segmentation, which extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.", "PublicationYear": "2017", "Authors": ["Kaiming He", "Georgia Gkioxari", "Piotr Doll{\\'a}r", "Ross B. Girshick"], "RelatedTopics": ["Computer Science"], "References": ["342786659379879f58bf5c4ff43c84c83a6a7389", "888ddf8f543b2e0794f4a021d80a23d4eb05c8af", "b724c3f7ff395235b62537203ddeb710f0eb27bb", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "2a94c84383ee3de5e6211d43d16e7de387f68878", "7ffdbc358b63378f07311e883dddacc9faeeaf4b", "6b8d0df903496699e52b4daee5d1815b7b784cf7", "361b19d2c00d086fa8ef860374f5e1d862fd2f30", "3ad998a9b2c071c4a1971048f8a2d754530f08e8"], "ReferenceCount": 45, "CitationCount": 2903}, {"URL": "https://www.semanticscholar.org/paper/Image-to-Image-Translation-with-Conditional-Isola-Zhu/8acbe90d5b852dadea7810345451a99608ee54c7", "ID": "8acbe90d5b852dadea7810345451a99608ee54c7", "Title": "Image-to-Image Translation with Conditional Adversarial Networks", "Abstract": "Conditional adversarial networks are investigated as a general-purpose solution to image-to-image translation problems and it is demonstrated that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.", "PublicationYear": "2016", "Authors": ["Phillip Isola", "Jun-Yan Zhu", "Tinghui Zhou", "Alexei A. Efros"], "RelatedTopics": ["Computer Science"], "References": ["9c763df6843aba88d7fb3ab3c55a5937a5f39276", "fc7822f56dd255a872326b9536a0821bbf0277dd", "9e4a0ee35f5e5eef7feab42bb693ef23b163ae8a", "df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3", "cad4ac0d2389a89cf1955dd4788278c1e8ac1af9", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "6c7f040a150abf21dbcefe1f22e0f98fa184f41a", "102a2096ba2e2947dc252445f764e7583b557680", "5cd47e5d004d75fe773a252bde35b56d5d56ce06", "571b0750085ae3d939525e62af510ee2cee9d5ea"], "ReferenceCount": 70, "CitationCount": 16357}, {"URL": "https://www.semanticscholar.org/paper/Content-aware-image-restoration%3A-pushing-the-limits-Weigert-Schmidt/6ff93aa6ca902002d16fb0c2d3fb48aead92c61e", "ID": "6ff93aa6ca902002d16fb0c2d3fb48aead92c61e", "Title": "Content-aware image restoration: pushing the limits of fluorescence microscopy", "Abstract": "This work shows how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy, and bypasses the trade-offs between imaging speed, resolution, and maximal light exposure that limit fluorescence imaging to enable discovery. Fluorescence microscopy is a key driver of discoveries in the life sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy. We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME. Content-aware image restoration (CARE) uses deep learning to improve microscopy images. CARE bypasses the trade-offs between imaging speed, resolution, and maximal light exposure that limit fluorescence imaging to enable discovery.", "PublicationYear": "2018", "Authors": ["Martin Weigert", "Uwe Schmidt", "Tobias Boothe", "Andreas M{\\\"u}ller", "Alexandr Dibrov", "Akanksha Jain", "Benjamin Wilhelm", "Deborah Schmidt", "Coleman Broaddus", "Sia\u0302n Culley", "Maur{\\'i}cio Rocha-Martins", "Fabi{\\'a}n Segovia-Miranda", "Caren Norden", "Ricardo Henriques", "Marino Zerial", "Michele Solimena", "Jochen Christian Rink", "Pavel Toman{\\vc}{\\'a}k", "Loic A. Royer", "Florian Jug", "Eugene Wimberly Myers"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["8482a4aec0ae413839c1c281860ded5cac476376", "56cd4188544b8c00d119d0016fe4aa0c2b569d7a", "7175c673ef80f75232b027e9ea811ac75d6c98a4", "84f3798b05748e98d92e7336cb93089c2f3c99ac", "bb222542a13149ec5350ef4c68e48714bb7a7bad", "7493f17618fc0a5ffd39963ce2602c718f69de4d", "c9e59e4c26618e9b63d9caf13803ca5c7b20b296", "1fb42852a47f77d26efdbacbf75cddcb294b5c3d", "2c06c7e3e280542fe1a1dee30ebb0190ac0a9c79", "79be0bab14ca60479e7be0781afb44d8db56258a"], "ReferenceCount": 81, "CitationCount": 752}, {"URL": "https://www.semanticscholar.org/paper/Image-segmentation-and-dynamic-lineage-analysis-in-Wang-Niemi/f9b78ff4e2688a7bcae801228359cce3da8af9e3", "ID": "f9b78ff4e2688a7bcae801228359cce3da8af9e3", "Title": "Image segmentation and dynamic lineage analysis in single\u2010cell fluorescence microscopy", "Abstract": "Novel methods for automating key steps in the analysis of single\u2010cell, fluorescent images\u2014segmentation and lineage reconstruction\u2014to recognize and track individual cells over time are described. An increasingly common component of studies in synthetic and systems biology is analysis of dynamics of gene expression at the single\u2010cell level, a context that is heavily dependent on the use of time\u2010lapse movies. Extracting quantitative data on the single\u2010cell temporal dynamics from such movies remains a major challenge. Here, we describe novel methods for automating key steps in the analysis of single\u2010cell, fluorescent images\u2014segmentation and lineage reconstruction\u2014to recognize and track individual cells over time. The automated analysis iteratively combines a set of extended morphological methods for segmentation, and uses a neighborhood\u2010based scoring method for frame\u2010to\u2010frame lineage linking. Our studies with bacteria, budding yeast and human cells, demonstrate the portability and usability of these methods, whether using phase, bright field or fluorescent images. These examples also demonstrate the utility of our integrated approach in facilitating analyses of engineered and natural cellular networks in diverse settings. The automated methods are implemented in freely available, open\u2010source software. \u00a9 2009 International Society for Advancement of Cytometry", "PublicationYear": "2009", "Authors": ["Quanli Wang", "Jarad Niemi", "Cheemeng Tan", "Lingchong You", "Mike West"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["ec8ddf6a6bb0031c4dda4d1852ebd7064946c9d0", "3ab2b44a507c2bf0adfbfbd136af77dd082e7a8f", "2771e38006be941f578d1f1c5ffb4161158596ef", "41ae827281ac2949ed19a60890b047d02f1212da", "9c3c5f169a40c3bb723562f57abf0c1f8eb5ece7", "da661d78413773ee84d1e4015c3ab25130f78065", "0442ef15d5e43b43682fc82d8cb2c2e9f2ec1e0a", "e8d055e193d549b890debd15972992701176849f", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "06ec567309eef47e89033556346126be21b247a5"], "ReferenceCount": 34, "CitationCount": 104}, {"URL": "https://www.semanticscholar.org/paper/Hierarchical-Mergence-Approach-to-Cell-Detection-in-Chen-Zhang/dff96ab49f149abac97dcdd7197d30cee9652824", "ID": "dff96ab49f149abac97dcdd7197d30cee9652824", "Title": "Hierarchical Mergence Approach to Cell Detection in Phase Contrast Microscopy Images", "Abstract": "A hierarchical mergence approach to extract homogeneous patches out and heuristically add them up is presented and it is demonstrated that the proposed method outperforms previous methods within the authors' datasets. Phase contrast microscope is one of the most universally used instruments to observe long-term cell movements in different solutions. Most of classic segmentation methods consider a homogeneous patch as an object, while the recorded cell images have rich details and a lot of small inhomogeneous patches, as well as some artifacts, which can impede the applications. To tackle these challenges, this paper presents a hierarchical mergence approach (HMA) to extract homogeneous patches out and heuristically add them up. Initially, the maximum region of interest (ROI), in which only cell events exist, is drawn by using gradient information as a mask. Then, different levels of blurring based on kernel or grayscale morphological operations are applied to the whole image to produce reference images. Next, each of unconnected regions in the mask is applied with Otsu method independently according to different reference images. Consequently, the segmentation result is generated by the combination of usable patches in all informative layers. The proposed approach is more than simply a fusion of the basic segmentation methods, but a well-organized strategy that integrates these basic methods. Experiments demonstrate that the proposed method outperforms previous methods within our datasets.", "PublicationYear": "2014", "Authors": ["Lei Chen", "Jianhua Zhang", "Shengyong Chen", "Yao Lin", "Chunyan Yao", "Jianwei Zhang"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["7cb2f4f7b65ae227872e72d6cfcdbf47714bd9a0", "7dbb02543eae351a3eb8c268741bdde40519043e", "1b979ed50b3a7c68c79726d7c22e078c579501f3", "63d2935f5890b7b0923937e983dbe5404247fdb5", "052e43cd2cf27f63d717a31ee9ff6809d66aae40", "3850b228bfac862dae94469ba2fea5c71600e769", "8599bd2b33f494ee78fe24ad21ea773713f4ac12", "f1f0a67e9083f45bae08652adde95634c3de9baf", "3ab1348d060f3ab7e70a2e368a30af14bc57c35c", "8ae9fc1e08c790f737d52c4ab6e20234aa269faa"], "ReferenceCount": 31, "CitationCount": 5}, {"URL": "https://www.semanticscholar.org/paper/Empirical-gradient-threshold-technique-for-across-Chalfoun-Majurski/40f00f7150b2dbdee48e80e8b6a7d63d9b34f149", "ID": "40f00f7150b2dbdee48e80e8b6a7d63d9b34f149", "Title": "Empirical gradient threshold technique for automated segmentation across image modalities and cell lines", "Abstract": "Segmentation based on image gradient thresholding is fast and has a low memory footprint, however, existing techniques that automate the selection of the gradient image threshold do not work across image modalities, multiple cell lines, and a wide range of foreground/background densities. New microscopy technologies are enabling image acquisition of terabyte\u2010sized data sets consisting of hundreds of thousands of images. In order to retrieve and analyze the biological information in these large data sets, segmentation is needed to detect the regions containing cells or cell colonies. Our work with hundreds of large images (each 21 000\u00d721 000 pixels) requires a segmentation method that: (1) yields high segmentation accuracy, (2) is applicable to multiple cell lines with various densities of cells and cell colonies, and several imaging modalities, (3) can process large data sets in a timely manner, (4) has a low memory footprint and (5) has a small number of user\u2010set parameters that do not require adjustment during the segmentation of large image sets. None of the currently available segmentation methods meet all these requirements. Segmentation based on image gradient thresholding is fast and has a low memory footprint. However, existing techniques that automate the selection of the gradient image threshold do not work across image modalities, multiple cell lines, and a wide range of foreground/background densities (requirement 2) and all failed the requirement for robust parameters that do not require re\u2010adjustment with time (requirement 5).", "PublicationYear": "2015", "Authors": ["Joe Chalfoun", "Michael Majurski", "Adele P. Peskin", "Catherine Breen", "Peter Bajcsy", "Mary Brady"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["f82c12dd609c4f4b34603e81d4dfb60fd3272013", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "7dbb02543eae351a3eb8c268741bdde40519043e", "f9b78ff4e2688a7bcae801228359cce3da8af9e3", "f5c0f7389dba2e784427c949aae403a61830dc48", "2eb308f618a26faf8f5d194a842b325aca13722c", "33313f662b57105c7bc471736b6a7d39fa4fb687", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "8ac4f2f11ea9d1b8b9d01de364e74fc1f12a07b3", "7c5558e8d0dcf9cee02157b34e1df035a0df8c55"], "ReferenceCount": 22, "CitationCount": 40}, {"URL": "https://www.semanticscholar.org/paper/Survey-statistics-of-automated-segmentations-to-of-Bajcsy-Cardone/b2fda25ffe204246e5679669f7d387d23b73a4d1", "ID": "b2fda25ffe204246e5679669f7d387d23b73a4d1", "Title": "Survey statistics of automated segmentations applied to optical imaging of mammalian cells", "Abstract": "This survey paper presents the state-of-the-art overview of published papers about automated segmentation applied to optical microscopy imaging of mammalian cells, a classification of segmentation aspects in the context of cell optical imaging, and co-occurrence summary statistics about cellular measurements, segmentations, segmented objects, segmentation evaluations, and the use of computational platforms for accelerating segmentation execution. The goal of this survey paper is to overview cellular measurements using optical microscopy imaging followed by automated image segmentation. The cellular measurements of primary interest are taken from mammalian cells and their components. They are denoted as two- or three-dimensional (2D or 3D) image objects of biological interest. In our applications, such cellular measurements are important for understanding cell phenomena, such as cell counts, cell-scaffold interactions, cell colony growth rates, or cell pluripotency stability, as well as for establishing quality metrics for stem cell therapies. In this context, this survey paper is focused on automated segmentation as a software-based measurement leading to quantitative cellular measurements. We define the scope of this survey and a classification schema first. Next, all found and manually filteredpublications are classified according to the main categories: (1) objects of interests (or objects to be segmented), (2) imaging modalities, (3) digital data axes, (4) segmentation algorithms, (5) segmentation evaluations, (6) computational hardware platforms used for segmentation acceleration, and (7) object (cellular) measurements. Finally, all classified papers are converted programmatically into a set of hyperlinked web pages with occurrence and co-occurrence statistics of assigned categories. The survey paper presents to a reader: (a) the state-of-the-art overview of published papers about automated segmentation applied to optical microscopy imaging of mammalian cells, (b) a classification of segmentation aspects in the context of cell optical imaging, (c) histogram and co-occurrence summary statistics about cellular measurements, segmentations, segmented objects, segmentation evaluations, and the use of computational platforms for accelerating segmentation execution, and (d) open research problems to pursue. The novel contributions of this survey paper are: (1) a new type of classification of cellular measurements and automated segmentation, (2) statistics about the published literature, and (3) a web hyperlinked interface to classification statistics of the surveyed papers at https://isg.nist.gov/deepzoomweb/resources/survey/index.html.", "PublicationYear": "2015", "Authors": ["Peter Bajcsy", "Antonio Cardone", "Joe Chalfoun", "Michael Halter", "Derek Juba", "Marcin Kocio\u0142ek", "Michael Majurski", "Adele P. Peskin", "Carl G. Simon", "Mylene Simon", "Antoine Vandecreme", "Mary Brady"], "RelatedTopics": ["Biology", "Computer Science", "Engineering"], "References": ["cf6e03df089452289a62228e02388a90957f8a3b", "dcdd14ec1eaf86db85c67600ea94ad697f981fe2", "af08302f2e7646afb3ba99de4378909462f6dce0", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "88298080bc029f48104f99706421e67845437caa", "7dbb02543eae351a3eb8c268741bdde40519043e", "f914352479a35f2f6bf1ab558533a0130200ce82", "0a24de3fa8e1fd490587def4a4507653059bbf18", "537d8f273f7009e6fc9f36af49f53763d83f784e", "f82c12dd609c4f4b34603e81d4dfb60fd3272013"], "ReferenceCount": 175, "CitationCount": 46}, {"URL": "https://www.semanticscholar.org/paper/Segmenting-time%E2%80%90lapse-phase-contrast-images-of-NIH-Chalfoun-Kocio%C5%82ek/7dbb02543eae351a3eb8c268741bdde40519043e", "ID": "7dbb02543eae351a3eb8c268741bdde40519043e", "Title": "Segmenting time\u2010lapse phase contrast images of adjacent NIH 3T3 cells", "Abstract": "The segmentation method presented in this paper consists of background reconstruction to obtain noise\u2010free foreground pixels and incorporation of biological insight about dividing and nondividing cells into the segmentation process to achieve reliable separation of foreground pixels defined as pixels associated with individual cells. We present a new method for segmenting phase contrast images of NIH 3T3 fibroblast cells that is accurate even when cells are physically in contact with each other. The problem of segmentation, when cells are in contact, poses a challenge to the accurate automation of cell counting, tracking and lineage modelling in cell biology. The segmentation method presented in this paper consists of (1) background reconstruction to obtain noise\u2010free foreground pixels and (2) incorporation of biological insight about dividing and nondividing cells into the segmentation process to achieve reliable separation of foreground pixels defined as pixels associated with individual cells. The segmentation results for a time\u2010lapse image stack were compared against 238 manually segmented images (8219 cells) provided by experts, which we consider as reference data. We chose two metrics to measure the accuracy of segmentation: the \u2018Adjusted Rand Index\u2019 which compares similarities at a pixel level between masks resulting from manual and automated segmentation, and the \u2018Number of Cells per Field\u2019 (NCF) which compares the number of cells identified in the field by manual versus automated analysis. Our results show that the automated segmentation compared to manual segmentation has an average adjusted rand index of 0.96 (1 being a perfect match), with a standard deviation of 0.03, and an average difference of the two numbers of cells per field equal to 5.39% with a standard deviation of 4.6%.", "PublicationYear": "2013", "Authors": ["Joe Chalfoun", "Marcin Kocio\u0142ek", "Alden Dima", "Michael Halter", "Antonio Cardone", "Adele P. Peskin", "Peter Bajcsy", "Mary Brady"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["4cca8f71e476ecd1367cdd3bca01ec113ee274da", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "44a959272aa3e8757cb5e7b61eca8dc9514ad584", "3395db4e7edd054c9989eca65f1341372343ba9e", "ab0d576a9865d6f455ca2b227d6dabf38d9ecbe5", "25be5c4d79d564524812841623722457c6310761", "137136955d53b8a08e4b0fff2b7ec783ee9bbc6f", "632a6f2cc10bb43e7945fc37237cb2a08bcb3d79", "b98139a09a58d080b8c5640da44a0e9d9b794709", "58128f239297f9ee101874c4007e23375078cf80"], "ReferenceCount": 31, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Nanoparticle-vesicle-encoding-for-imaging-and-cell-Rees-Wills/eeb1ea310ed0c610aa20df843e26f98c142f3dce", "ID": "eeb1ea310ed0c610aa20df843e26f98c142f3dce", "Title": "Nanoparticle vesicle encoding for imaging and tracking cell populations", "Abstract": "This work demonstrates unique labeling of cells, driven by the heterogeneous random uptake of fluorescent nanoparticles of different emission colors, which generated a large number of unique digital codes, which corresponded to the cell-specific number of nanoparticle-loaded vesicles and were visible within a given fluorescence channel. For phenotypic behavior to be understood in the context of cell lineage and local environment, properties of individual cells must be measured relative to population-wide traits. However, the inability to accurately identify, track and measure thousands of single cells via high-throughput microscopy has impeded dynamic studies of cell populations. We demonstrate unique labeling of cells, driven by the heterogeneous random uptake of fluorescent nanoparticles of different emission colors. By sequentially exposing a cell population to different particles, we generated a large number of unique digital codes, which corresponded to the cell-specific number of nanoparticle-loaded vesicles and were visible within a given fluorescence channel. When three colors are used, the assay can self-generate over 17,000 individual codes identifiable using a typical fluorescence microscope. The color-codes provided immediate visualization of cell identity and allowed us to track human cells with a success rate of 78% across image frames separated by 8 h.", "PublicationYear": "2014", "Authors": ["Paul Rees", "John W. Wills", "M. Rowan Brown", "James A. Tonkin", "Mark D. Holton", "Nicole S. Hondow", "Andrew Paul Brown", "Rik Brydson", "Val Millar", "Anne E Carpenter", "Huw D. Summers"], "RelatedTopics": ["Biology", "Engineering", "Materials Science"], "References": ["9d488e4662b04472e3ce4542b5533c55dec636c8", "36d74bb7f82fbe4f2eebe6877cd8ee926c89ad4d", "eafb9e017816fd61f4829f1124c4ff98072a384b", "9a3b0cd3c589277366dc30b4063be5675b48ae3e", "b18b98e2fab0748bb0b2b491b562848508e25a2b", "e1da7834f58520c57d270932f13d9af2641fc5fe", "a6fa5e56a52c02969e540171b97a898a96b2817d", "9bee235efee5b59d6cdd252af9287849b26e47e3", "c9e0acb883944924f308902391e4288012c43411", "0cdb8cbb1d1b235fe7e5fba115e895aa54a71cf1"], "ReferenceCount": 28, "CitationCount": 31}, {"URL": "https://www.semanticscholar.org/paper/High-throughput%2C-single-cell-NF-%CE%BAB-dynamics.-Lee-Covert/18516d4be3d9b478684d4b7659eda10f94133385", "ID": "18516d4be3d9b478684d4b7659eda10f94133385", "Title": "High-throughput, single-cell NF-\u03baB dynamics.", "Abstract": "Semantic Scholar extracted view of \\\"High-throughput, single-cell NF-\u03baB dynamics.\\\" by Timothy K Lee et al.", "PublicationYear": "2010", "Authors": ["Timothy K Lee", "Markus W. Covert"], "RelatedTopics": ["Biology"], "References": ["c9d99a6f42acf0eda685e319f00e6f1ec8d418e5", "2c1ba3d679460f35c7e847f36785d0e48fbe2a2e", "34625f8293b792b8fe27fad96dfbab110d8567f7", "040b4f257b8b048ffb0e61e5ee4a8d16ce2d32da", "8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "253790c9bde66f5ec62f3466eee75f4dcf68727d", "fa757b408ec78abdd4487046c28fd55027a601e8", "c3f6dd937f7756c9600a0b2c25bdfbaac51824f9", "71f175342f227ce4b13a9e158b2724b2e11bd90e", "4651cf6a968735e6842b028e44e6364a03781895"], "ReferenceCount": 65, "CitationCount": 31}, {"URL": "https://www.semanticscholar.org/paper/Oufti%3A-an-integrated-software-package-for-analysis-Paintdakhi-Parry/9c3d224d328ec5a44b24f87589232d8aed499c11", "ID": "9c3d224d328ec5a44b24f87589232d8aed499c11", "Title": "Oufti: an integrated software package for high\u2010accuracy, high\u2010throughput quantitative microscopy analysis", "Abstract": "Oufti provides computational solutions for tracking touching cells in confluent samples, handles various cell morphologies, offers algorithms for quantitative analysis of both diffraction and non\u2010diffraction\u2010limited fluorescence signals and is scalable for high\u2010throughput analysis of massive datasets, all with subpixel precision. With the realization that bacteria display phenotypic variability among cells and exhibit complex subcellular organization critical for cellular function and behavior, microscopy has re\u2010emerged as a primary tool in bacterial research during the last decade. However, the bottleneck in today's single\u2010cell studies is quantitative image analysis of cells and fluorescent signals. Here, we address current limitations through the development of Oufti, a stand\u2010alone, open\u2010source software package for automated measurements of microbial cells and fluorescence signals from microscopy images. Oufti provides computational solutions for tracking touching cells in confluent samples, handles various cell morphologies, offers algorithms for quantitative analysis of both diffraction and non\u2010diffraction\u2010limited fluorescence signals and is scalable for high\u2010throughput analysis of massive datasets, all with subpixel precision. All functionalities are integrated in a single package. The graphical user interface, which includes interactive modules for segmentation, image analysis and post\u2010processing analysis, makes the software broadly accessible to users irrespective of their computational skills.", "PublicationYear": "2016", "Authors": ["Ahmad Paintdakhi", "Bradley R. Parry", "Manuel Campos", "Irnov Irnov", "Johan Elf", "Ivan V. Surovtsev", "Christine Jacobs-Wagner"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["4704dd41142999133809760b18843acd51d0684c", "6db8ea6129b4b303744f810ccc8e58eb64c82253", "37876b05636451c2305d3a872da6b7c89fa141a1", "6cc9ed1315377162a499967d18e99cb930d969c2", "b7649ecb35e9ff43391e8dc9c195ee87bde3b8f6", "0dfa1ba06c87b60927798d0a8513bcac0bc81049", "1a68de74fdb9b580ef4097b1f3bc5b6647efea22", "557f0447a2c0afb4c94a3868f855636cd3017fc0", "5e69bc2fd24fd0c70c9dc899d04c8ad2dce14c80", "b5978b756bdcad061e3269eafaa69452a0c43e1b"], "ReferenceCount": 12, "CitationCount": 296}, {"URL": "https://www.semanticscholar.org/paper/Nuclei-segmentation-in-histopathology-images-using-Naylor-La%C3%A9/78db21fabea962592ac0aef54624251550929109", "ID": "78db21fabea962592ac0aef54624251550929109", "Title": "Nuclei segmentation in histopathology images using deep neural networks", "Abstract": "This work presents a fully automated workflow to segment nuclei from histopathology image data by using deep neural networks trained from a set of manually annotated images and by processing the posterior probability maps in order to split jointly segmented nuclei. Analysis and interpretation of stained tumor sections is one of the main tools in cancer diagnosis and prognosis, which is mainly carried out manually by pathologists. The avent of digital pathology provides us with the challenging opportunity to automatically analyze large amounts of these complex image data in order to draw biological conclusions from them and to study cellular and tissular phenotypes at a large scale. One of the bottlenecks for such approaches is the automatic segmentation of cell nuclei from this type of image data. Here, we present a fully automated workflow to segment nuclei from histopathology image data by using deep neural networks trained from a set of manually annotated images and by processing the posterior probability maps in order to split jointly segmented nuclei. Further, we provide the image data set that has been generated for this study as a benchmark set to the scientific community.", "PublicationYear": "2017", "Authors": ["Peter Naylor", "Marick La{\\'e}", "Fabien Reyal", "Thomas Walter"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["7256088eece603df2e5675025e8bed90c0f21171", "8ad3263bf71ffae41fbb777d600ef1e3e8689bb6", "13de33ee941f1ebf3ed185c20fb4453a07302c30", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "9683c10ba2c01dddeb18330211b83d05d526d153", "09193e19b59fc8f05bee9d6efbfb1607ca5b6501", "cf986bfe13a24d4739f95df3a856a3c6e4ed4c1c", "038b582cccb00c54589c5563d9a00ee28dad83b0", "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "033352876e2bdb43b71cdfc6989501d795e9655e"], "ReferenceCount": 12, "CitationCount": 158}, {"URL": "https://www.semanticscholar.org/paper/Improved-Automatic-Detection-and-Segmentation-of-in-Al-Kofahi-Lassoued/63a373063d51489b31e07ee639ab74b6cf586240", "ID": "63a373063d51489b31e07ee639ab74b6cf586240", "Title": "Improved Automatic Detection and Segmentation of Cell Nuclei in Histopathology Images", "Abstract": "This paper presents a robust and accurate novel method for segmenting cell nuclei using a combination of ideas, and presents an efficient semiautomated approach to editing automated segmentation results that requires two mouse clicks per operation. Automatic segmentation of cell nuclei is an essential step in image cytometry and histometry. Despite substantial progress, there is a need to improve accuracy, speed, level of automation, and adaptability to new applications. This paper presents a robust and accurate novel method for segmenting cell nuclei using a combination of ideas. The image foreground is extracted automatically using a graph-cuts-based binarization. Next, nuclear seed points are detected by a novel method combining multiscale Laplacian-of-Gaussian filtering constrained by distance-map-based adaptive scale selection. These points are used to perform an initial segmentation that is refined using a second graph-cuts-based algorithm incorporating the method of alpha expansions and graph coloring to reduce computational complexity. Nuclear segmentation results were manually validated over 25 representative images (15 in vitro images and 10 in vivo images, containing more than 7400 nuclei) drawn from diverse cancer histopathology studies, and four types of segmentation errors were investigated. The overall accuracy of the proposed segmentation algorithm exceeded 86%. The accuracy was found to exceed 94% when only over- and undersegmentation errors were considered. The confounding image characteristics that led to most detection/segmentation errors were high cell density, high degree of clustering, poor image contrast and noisy background, damaged/irregular nuclei, and poor edge information. We present an efficient semiautomated approach to editing automated segmentation results that requires two mouse clicks per operation.", "PublicationYear": "2010", "Authors": ["Yousef Al-Kofahi", "Wiem Lassoued", "William Lee", "Badrinath Roysam"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["cee3035635eafa1c412934419d7563fdb06d73ae", "1268de7bda769e651dc6c089d006c7edbe37f563", "933392bae254c94d88b6c0a63b20d11199b3ccda", "ae296a86136e65a7823f4fdfc3afce1ada58b821", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "f3a3254d7e233ae36baef93ebe5008c21151f467", "b1c13d7abec88cff4ad5d612336ef54ef961dae3", "83dc3a624d437a0fff1dc030b8d5efc031aa08e7", "d9e7b61f4444bdb3fa6d9fca7ee4ccbef2458f74", "e86c88e690715bc3beeebc8738ea7912f0c8ccc1"], "ReferenceCount": 51, "CitationCount": 685}, {"URL": "https://www.semanticscholar.org/paper/Locality-Sensitive-Deep-Learning-for-Detection-and-Sirinukunwattana-Raza/7256088eece603df2e5675025e8bed90c0f21171", "ID": "7256088eece603df2e5675025e8bed90c0f21171", "Title": "Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images", "Abstract": "A Spatially Constrained Convolutional Neural Network (SC-CNN) to perform nucleus detection and a novel Neighboring Ensemble Predictor (NEP) coupled with CNN to more accurately predict the class label of detected cell nuclei are proposed. Detection and classification of cell nuclei in histopathology images of cancerous tissue stained with the standard hematoxylin and eosin stain is a challenging task due to cellular heterogeneity. Deep learning approaches have been shown to produce encouraging results on histopathology images in various studies. In this paper, we propose a Spatially Constrained Convolutional Neural Network (SC-CNN) to perform nucleus detection. SC-CNN regresses the likelihood of a pixel being the center of a nucleus, where high probability values are spatially constrained to locate in the vicinity of the centers of nuclei. For classification of nuclei, we propose a novel Neighboring Ensemble Predictor (NEP) coupled with CNN to more accurately predict the class label of detected cell nuclei. The proposed approaches for detection and classification do not require segmentation of nuclei. We have evaluated them on a large dataset of colorectal adenocarcinoma images, consisting of more than 20,000 annotated nuclei belonging to four different classes. Our results show that the joint detection and classification of the proposed SC-CNN and NEP produces the highest average F1 score as compared to other recently published approaches. Prospectively, the proposed methods could offer benefit to pathology practice in terms of quantitative analysis of tissue constituents in whole-slide images, and potentially lead to a better understanding of cancer.", "PublicationYear": "2016", "Authors": ["Korsuk Sirinukunwattana", "Shan E. Ahmed Raza", "Yee-Wah Tsang", "David R. J. Snead", "Ian A. Cree", "Nasir M. Rajpoot"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["8ad3263bf71ffae41fbb777d600ef1e3e8689bb6", "721d4ae075de7bf9ea2cac01fe02e2920ee5c789", "fc1ba8fdf8c9b45d255b36afbdf1af6d335df428", "55d66a61ce28eae0a752dcc7b4b6f35625fc2ce7", "8e204b0bbdb69fad9f8ea333af185d94d20051f0", "9226ff1a514271fb096d9f0897212baa26f84385", "13de33ee941f1ebf3ed185c20fb4453a07302c30", "39ac221f8526437ff8bf6ff5ef07df34d9961982", "c7900a7c6690444eb10b7db1c5b71c6e4316809a", "e312652daf82ed144d1696aae7ab412030d4f7eb"], "ReferenceCount": 38, "CitationCount": 971}, {"URL": "https://www.semanticscholar.org/paper/A-Dataset-and-a-Technique-for-Generalized-Nuclear-Kumar-Verma/34c062e2b8a3f6421b9f4ff22f115a36d4aba823", "ID": "34c062e2b8a3f6421b9f4ff22f115a36d4aba823", "Title": "A Dataset and a Technique for Generalized Nuclear Segmentation for Computational Pathology", "Abstract": "A large publicly accessible data set of hematoxylin and eosin (H&E)-stained tissue images with more than 21000 painstakingly annotated nuclear boundaries is introduced, whose quality was validated by a medical doctor. Nuclear segmentation in digital microscopic tissue images can enable extraction of high-quality features for nuclear morphometrics and other analysis in computational pathology. Conventional image processing techniques, such as Otsu thresholding and watershed segmentation, do not work effectively on challenging cases, such as chromatin-sparse and crowded nuclei. In contrast, machine learning-based segmentation can generalize across various nuclear appearances. However, training machine learning algorithms requires data sets of images, in which a vast number of nuclei have been annotated. Publicly accessible and annotated data sets, along with widely agreed upon metrics to compare techniques, have catalyzed tremendous innovation and progress on other image classification problems, particularly in object recognition. Inspired by their success, we introduce a large publicly accessible data set of hematoxylin and eosin (H&E)-stained tissue images with more than 21000 painstakingly annotated nuclear boundaries, whose quality was validated by a medical doctor. Because our data set is taken from multiple hospitals and includes a diversity of nuclear appearances from several patients, disease states, and organs, techniques trained on it are likely to generalize well and work right out-of-the-box on other H&E-stained images. We also propose a new metric to evaluate nuclear segmentation results that penalizes object- and pixel-level errors in a unified manner, unlike previous metrics that penalize only one type of error. We also propose a segmentation technique based on deep learning that lays a special emphasis on identifying the nuclear boundaries, including those between the touching or overlapping nuclei, and works well on a diverse set of test images.", "PublicationYear": "2017", "Authors": ["Neeraj Kumar", "Ruchika Verma", "Sanuj Sharma", "S. K. Bhargava", "Abhishek Vahadane", "Amit Sethi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["e312652daf82ed144d1696aae7ab412030d4f7eb", "d97e70d8fa6cbe4fcac9096491ce6e6a5e974e88", "63a373063d51489b31e07ee639ab74b6cf586240", "68f30bd22817a17adc837eb285e51c9628f00e8d", "ee07d8530c080caa5056a60bcc176569544a8927", "6c1108c63693a08da9d8fb418b14289bae73cc66", "13de33ee941f1ebf3ed185c20fb4453a07302c30", "930b28f5255a6633ec89bdafb9f72af8e9148fac", "7256088eece603df2e5675025e8bed90c0f21171", "856a3c76453a798556096cd23848402d1351c1f9"], "ReferenceCount": 46, "CitationCount": 661}, {"URL": "https://www.semanticscholar.org/paper/Automated-Segmentation-of-Nuclei-in-Breast-Cancer-Paramanandam-O'Byrne/cf84f4ea635b2cdc0aeea7ec59fde01ab0a48ba9", "ID": "cf84f4ea635b2cdc0aeea7ec59fde01ab0a48ba9", "Title": "Automated Segmentation of Nuclei in Breast Cancer Histopathology Images", "Abstract": "This paper proposes a novel segmentation algorithm for detecting individual nuclei from Hematoxylin and Eosin (H&E) stained breast histopathology images with optimal performance on the highly complex images presented in this paper. The process of Nuclei detection in high-grade breast cancer images is quite challenging in the case of image processing techniques due to certain heterogeneous characteristics of cancer nuclei such as enlarged and irregularly shaped nuclei, highly coarse chromatin marginalized to the nuclei periphery and visible nucleoli. Recent reviews state that existing techniques show appreciable segmentation accuracy on breast histopathology images whose nuclei are dispersed and regular in texture and shape; however, typical cancer nuclei are often clustered and have irregular texture and shape properties. This paper proposes a novel segmentation algorithm for detecting individual nuclei from Hematoxylin and Eosin (H&E) stained breast histopathology images. This detection framework estimates a nuclei saliency map using tensor voting followed by boundary extraction of the nuclei on the saliency map using a Loopy Back Propagation (LBP) algorithm on a Markov Random Field (MRF). The method was tested on both whole-slide images and frames of breast cancer histopathology images. Experimental results demonstrate high segmentation performance with efficient precision, recall and dice-coefficient rates, upon testing high-grade breast cancer images containing several thousand nuclei. In addition to the optimal performance on the highly complex images presented in this paper, this method also gave appreciable results in comparison with two recently published methods\u2014Wienert et al. (2012) and Veta et al. (2013), which were tested using their own datasets.", "PublicationYear": "2016", "Authors": ["Maqlin Paramanandam", "Michael O'Byrne", "Bidisha Ghosh", "Joy John Mammen", "Marie Therese Manipadam", "Robinson Thamburaj", "Vikram Pakrashi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["c70b25aed4932ed0f5c4330a11310f9a08771282", "e312652daf82ed144d1696aae7ab412030d4f7eb", "1e76d194ac9bf96632db26345de3abe3f25a5176", "3ba787154b2411fe89d88b6ab50ea84aa62dea04", "68f30bd22817a17adc837eb285e51c9628f00e8d", "13de33ee941f1ebf3ed185c20fb4453a07302c30", "39ac221f8526437ff8bf6ff5ef07df34d9961982", "7b48886785909c7a3d8891d59031ae404afef023", "80b0a281c520581e474d178e4020721c61ab5667", "473e14a05a557d826f745bc28aac7aacfe6de28f"], "ReferenceCount": 27, "CitationCount": 47}, {"URL": "https://www.semanticscholar.org/paper/Self-adjusting-nuclei-segmentation-(SANS)-of-breast-Cui-Hu/b9eb38f50f9853f2ce1ee5a1737affad42cc6925", "ID": "b9eb38f50f9853f2ce1ee5a1737affad42cc6925", "Title": "Self-adjusting nuclei segmentation (SANS) of Hematoxylin-Eosin stained histopathological breast cancer images", "Abstract": "This paper proposes a self-adjusting method for adaptive cell/nuclei segmentation from HE BC images, which works on BC images of different types and quality, and proposes a novel seed detection method based on the topological skeleton model in the marker-controlled watershed transform framework. Hematoxylin-Eosin (H&E) stained breast cancer (BC) histopathological images are widely used in breast cancer diagnosis, for which segmenting the cells/nuclei from the images is a major operation. However, most of current methods are sensitive to the characteristics of the images. In this paper, we propose a self-adjusting method for adaptive cell/nuclei segmentation from HE BC images, which works on BC images of different types and quality. To deal with the diversity of nuclei sizes, our approach employs an ellipse detector to estimate nuclei size, which is essential for noise elimination and for addressing the cell overlap issue. Then we propose a novel seed detection method based on the topological skeleton model in the marker-controlled watershed transform framework. The experiment result shows that our method is effective and efficient, and outperforms the state-of-the-art approaches on various types of HE BC images.", "PublicationYear": "2016", "Authors": ["Yuxin Cui", "Jianjun Hu"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["be9c59ec7ca1363828091cdd5e003e4e6e51b600", "e312652daf82ed144d1696aae7ab412030d4f7eb", "0117ee68f72debf4d7c98023076b8a572546fadd", "ef1206dbc7779b6df5e0c548b25d9111997667c4", "abeb57f4ddf0722c2ca3e29bcc1dacd0cc60f5b7", "63a373063d51489b31e07ee639ab74b6cf586240", "68f30bd22817a17adc837eb285e51c9628f00e8d", "297fced1eef09a7a1e85a5aef1fe3833f8d5e229", "a2b525aabe9b6f7340427fe0a52bddb510530e55", "f20c93ea2cd4f7ea52ebb354dd238b694c50f031"], "ReferenceCount": 22, "CitationCount": 9}, {"URL": "https://www.semanticscholar.org/paper/Automatic-Nuclei-Segmentation-in-H%26E-Stained-Breast-Veta-Diest/e312652daf82ed144d1696aae7ab412030d4f7eb", "ID": "e312652daf82ed144d1696aae7ab412030d4f7eb", "Title": "Automatic Nuclei Segmentation in H&E Stained Breast Cancer Histopathology Images", "Abstract": "An automated nuclei segmentation method that works with hematoxylin and eosin stained breast cancer histopathology images, which represent regions of whole digital slides, is developed. The introduction of fast digital slide scanners that provide whole slide images has led to a revival of interest in image analysis applications in pathology. Segmentation of cells and nuclei is an important first step towards automatic analysis of digitized microscopy images. We therefore developed an automated nuclei segmentation method that works with hematoxylin and eosin (H&E) stained breast cancer histopathology images, which represent regions of whole digital slides. The procedure can be divided into four main steps: 1) pre-processing with color unmixing and morphological operators, 2) marker-controlled watershed segmentation at multiple scales and with different markers, 3) post-processing for rejection of false regions and 4) merging of the results from multiple scales. The procedure was developed on a set of 21 breast cancer cases (subset A) and tested on a separate validation set of 18 cases (subset B). The evaluation was done in terms of both detection accuracy (sensitivity and positive predictive value) and segmentation accuracy (Dice coefficient). The mean estimated sensitivity for subset A was 0.875 (\u00b10.092) and for subset B 0.853 (\u00b10.077). The mean estimated positive predictive value was 0.904 (\u00b10.075) and 0.886 (\u00b10.069) for subsets A and B, respectively. For both subsets, the distribution of the Dice coefficients had a high peak around 0.9, with the vast majority of segmentations having values larger than 0.8.", "PublicationYear": "2013", "Authors": ["Mitko Veta", "Paul J. van Diest", "Robert Kornegoor", "A. Huisman", "Max A. Viergever", "Josien P. W. Pluim"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["7ca07ca599d3811eb1d8f9c302a203c6ead0e7fe", "1cd6073d141d748661b6996edc6acb4880ad5d54", "39ac221f8526437ff8bf6ff5ef07df34d9961982", "68f30bd22817a17adc837eb285e51c9628f00e8d", "e2f0bde9a9100d2a80482f9f3dcae24d5f7a9f6a", "bd898f483476e3dcacf83cd85efc64e6319da0e1", "3ab1348d060f3ab7e70a2e368a30af14bc57c35c", "f3a3fc97c25402ed2e8a96aad0c8c7bbe8e3fd12", "c8e45bba0d43c21be3a2fbb42a1c595d7f79d7fd", "05a75f3bda7fa3523ac698e0a1b23209da594018"], "ReferenceCount": 39, "CitationCount": 344}, {"URL": "https://www.semanticscholar.org/paper/Stacked-Sparse-Autoencoder-(SSAE)-for-Nuclei-on-Xu-Xiang/8ad3263bf71ffae41fbb777d600ef1e3e8689bb6", "ID": "8ad3263bf71ffae41fbb777d600ef1e3e8689bb6", "Title": "Stacked Sparse Autoencoder (SSAE) for Nuclei Detection on Breast Cancer Histopathology Images", "Abstract": "A Stacked Sparse Autoencoder, an instance of a deep learning strategy, is presented for efficient nuclei detection on high-resolution histopathological images of breast cancer and out-performed nine other state of the art nuclear detection strategies. Automated nuclear detection is a critical step for a number of computer assisted pathology related image analysis algorithms such as for automated grading of breast cancer tissue specimens. The Nottingham Histologic Score system is highly correlated with the shape and appearance of breast cancer nuclei in histopathological images. However, automated nucleus detection is complicated by 1) the large number of nuclei and the size of high resolution digitized pathology images, and 2) the variability in size, shape, appearance, and texture of the individual nuclei. Recently there has been interest in the application of \u201cDeep Learning\u201d strategies for classification and analysis of big image data. Histopathology, given its size and complexity, represents an excellent use case for application of deep learning strategies. In this paper, a Stacked Sparse Autoencoder (SSAE), an instance of a deep learning strategy, is presented for efficient nuclei detection on high-resolution histopathological images of breast cancer. The SSAE learns high-level features from just pixel intensities alone in order to identify distinguishing features of nuclei. A sliding window operation is applied to each image in order to represent image patches via high-level features obtained via the auto-encoder, which are then subsequently fed to a classifier which categorizes each image patch as nuclear or non-nuclear. Across a cohort of 500 histopathological images (2200 \u00d7 2200) and approximately 3500 manually segmented individual nuclei serving as the groundtruth, SSAE was shown to have an improved F-measure 84.49% and an average area under Precision-Recall curve (AveP) 78.83%. The SSAE approach also out-performed nine other state of the art nuclear detection strategies.", "PublicationYear": "2016", "Authors": ["Jun Xu", "L. Xiang", "Qingshan Liu", "Hannah Gilmore", "Jianzhong Wu", "Jinghai Tang", "Anant Madabhushi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["721d4ae075de7bf9ea2cac01fe02e2920ee5c789", "2df07ca5c6c3eff7766f8ac80579fae0e362142b", "d0ad4142e4e7fb052935b349dc67bac288c83ff3", "529b68e883ce82919deda9efdf1ac3492008e2e1", "13de33ee941f1ebf3ed185c20fb4453a07302c30", "c47d831e3b6d26bd867693428fde34055f385ce0", "930b28f5255a6633ec89bdafb9f72af8e9148fac", "ab59971d3ec82d6c9e8ddbb2622909e797d4d491", "0aa08e57845cf5ec9a4a28173d6bc83e3a1b5f07", "473e14a05a557d826f745bc28aac7aacfe6de28f"], "ReferenceCount": 42, "CitationCount": 734}, {"URL": "https://www.semanticscholar.org/paper/Improved-structure%2C-function-and-compatibility-for-Kamentsky-Jones/b66561622170d97f4127f4131d485faefe3833f7", "ID": "b66561622170d97f4127f4131d485faefe3833f7", "Title": "Improved structure, function and compatibility for CellProfiler: modular high-throughput image analysis software", "Abstract": "CellProfiler 2.0 is described, which has been engineered to meet the needs of its growing user base, with new algorithms and features to facilitate high-throughput work. UNLABELLED\\nThere is a strong and growing need in the biology research community for accurate, automated image analysis. Here, we describe CellProfiler 2.0, which has been engineered to meet the needs of its growing user base. It is more robust and user friendly, with new algorithms and features to facilitate high-throughput work. ImageJ plugins can now be run within a CellProfiler pipeline.\\n\\n\\nAVAILABILITY AND IMPLEMENTATION\\nCellProfiler 2.0 is free and open source, available at http://www.cellprofiler.org under the GPL v. 2 license. It is available as a packaged application for Macintosh OS X and Microsoft Windows and can be compiled for Linux.\\n\\n\\nCONTACT\\nanne@broadinstitute.org\\n\\n\\nSUPPLEMENTARY INFORMATION\\nSupplementary data are available at Bioinformatics online.", "PublicationYear": "2011", "Authors": ["Lee Kamentsky", "Thouis Raymond Jones", "Adam Fraser", "Mark-Anthony Bray", "David J. Logan", "Katherine L. Madden", "Vebjorn Ljosa", "Curtis T. Rueden", "Kevin W. Eliceiri", "Anne E Carpenter"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["9fd701a40f584b8decb94bb7691ecb8d3f98d94a", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "30d3cf944dc63c4451d393141641a205adf6030d", "c1317f812bfaec25958ec7b5b583eb035fe6d5a1", "7a5f7c5814131cf59f07abca197930e64855628f", "c5188696ee70031f453f1ea1e37356458bae1216", "0de11dbe54f90d71ba9362a9cafd174404b6c0ac", "9a3b0cd3c589277366dc30b4063be5675b48ae3e", "b2f015e8a5af0cff08caba67763fe9dbb2657c9a", "739ea25c52210c1883f2e2bbd1b64967ba98fb85"], "ReferenceCount": 16, "CitationCount": 971}, {"URL": "https://www.semanticscholar.org/paper/CellProfiler-Analyst%3A-interactive-data-exploration%2C-Dao-Fraser/d8b8805b824a17471f6005c838806ba3c892dd08", "ID": "d8b8805b824a17471f6005c838806ba3c892dd08", "Title": "CellProfiler Analyst: interactive data exploration, analysis and classification of large biological image sets", "Abstract": "The CellProfiler Analyst 2.0, completely rewritten in Python, builds on these features and adds enhanced supervised machine learning capabilities (in Classifier), as well as visualization tools to overview an experiment (Plate Viewer and Image Gallery). Summary CellProfiler Analyst allows the exploration and visualization of image-based data, together with the classification of complex biological phenotypes, via an interactive user interface designed for biologists and data scientists. CellProfiler Analyst 2.0, completely rewritten in Python, builds on these features and adds enhanced supervised machine learning capabilities (in Classifier), as well as visualization tools to overview an experiment (Plate Viewer and Image Gallery). Availability CellProfiler Analyst 2.0 is free and open source, available at http://www.cellprofiler.org/releases and from GitHub (https://github.com/CellProfiler/CellProfiler-Analyst) under the BSD license. It is available as a packaged application for Mac OS X and Microsoft Windows and can be compiled for Linux. We implemented an automatic build process that supports nightly updates and regular release cycles for the software. Contact anne@broadinstitute.org Supplementary information Supplementary Text 1: Manual to CellProfiler Analyst; updated versions are available at CellProfiler.org/CPA Supplementary Data 1: Benchmarking performance of classifiers in CPA 2.0 versus CPA 1.0", "PublicationYear": "2016", "Authors": ["David Dao", "Adam Fraser", "Jane Hung", "Vebjorn Ljosa", "Shantanu Singh", "Anne E Carpenter"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["b66561622170d97f4127f4131d485faefe3833f7", "2e14d5736174492b5a6c2e17bc11407e27f367b8", "506d89a6658debf6544d023e430e041daffbc552", "669832b732a20ccbdbb81c22393f4bc8f9371dbc", "c1317f812bfaec25958ec7b5b583eb035fe6d5a1", "5c5be36e3111e42247d78a6d529e4b1d7d2ced12", "50cc8dd825103c97204ff58a7c5da09c70bb128c", "36748de338909976f72ffbadaf097470ec040da0", "29c736eb38861ecf346ce49eedf163c03974566b", "ff7876b04bea55ac21ad7a8b457d9335bcbd0669"], "ReferenceCount": 19, "CitationCount": 104}, {"URL": "https://www.semanticscholar.org/paper/Data-analysis-strategies-for-image-based-cell-Caicedo-Cooper/1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5", "ID": "1e1f905c5d8c6a2ad18b09ce8eb5d2b4c6b174f5", "Title": "Data-analysis strategies for image-based cell profiling", "Abstract": "The steps required to create high-quality image-based (i.e., morphological) profiles from a collection of microscopy images are introduced and techniques that have proven useful in each stage of the data analysis process are recommended on the basis of the experience of 20 laboratories worldwide that are refining their image- based cell-profiling methodologies. Image-based cell profiling is a high-throughput strategy for the quantification of phenotypic differences among a variety of cell populations. It paves the way to studying biological systems on a large scale by using chemical and genetic perturbations. The general workflow for this technology involves image acquisition with high-throughput microscopy systems and subsequent image processing and analysis. Here, we introduce the steps required to create high-quality image-based (i.e., morphological) profiles from a collection of microscopy images. We recommend techniques that have proven useful in each stage of the data analysis process, on the basis of the experience of 20 laboratories worldwide that are refining their image-based cell-profiling methodologies in pursuit of biological discovery. The recommended techniques cover alternatives that may suit various biological goals, experimental designs, and laboratories' preferences.", "PublicationYear": "2017", "Authors": ["Juan C. Caicedo", "Sam Cooper", "Florian Heigwer", "Scott Warchal", "Peng Qiu", "Csaba Molnar", "Aliaksei S. Vasilevich", "Joseph D Barry", "Harmanjit Singh Bansal", "Oren Z. Kraus", "Mathias Wawer", "Lassi Paavolainen", "Markus D. Herrmann", "Mohammad Hossein Rohban", "Jane Hung", "Holger Hennig", "John B. Concannon", "Ian Smith", "Paul A. Clemons", "Shantanu Singh", "Paul Rees", "P{\\'e}ter Horv{\\'a}th", "Roger G. Linington", "Anne E Carpenter"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["929a490198770abcb8c123d68a59384879b69adb", "29c736eb38861ecf346ce49eedf163c03974566b", "36748de338909976f72ffbadaf097470ec040da0", "6bfc1c0c7d3fc3cd9ebb9517cc0de73e841b7f74", "aa0875ccc516862edc0b6bd2181ee27ce882933d", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "8db554d7e597000f5a0e13712ef0cb3299c05187", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "8a7ce466e8f119f033aeace4210cc348ed62520b", "669832b732a20ccbdbb81c22393f4bc8f9371dbc"], "ReferenceCount": 154, "CitationCount": 483}, {"URL": "https://www.semanticscholar.org/paper/MitoGen%3A-A-Framework-for-Generating-3D-Synthetic-of-Svoboda-Ulman/11e69f9757d3f4927a21a76dadc41eddaa35e2ec", "ID": "11e69f9757d3f4927a21a76dadc41eddaa35e2ec", "Title": "MitoGen: A Framework for Generating 3D Synthetic Time-Lapse Sequences of Cell Populations in Fluorescence Microscopy", "Abstract": "A novel framework, called MitoGen, is proposed, which is capable of generating ground truth datasets with fully 3D time-lapse sequences of synthetic fluorescence-stained cell populations and shows biologically justified cell motility, shape and texture changes as well as cell divisions. The proper analysis of biological microscopy images is an important and complex task. Therefore, it requires verification of all steps involved in the process, including image segmentation and tracking algorithms. It is generally better to verify algorithms with computer-generated ground truth datasets, which, compared to manually annotated data, nowadays have reached high quality and can be produced in large quantities even for 3D time-lapse image sequences. Here, we propose a novel framework, called MitoGen, which is capable of generating ground truth datasets with fully 3D time-lapse sequences of synthetic fluorescence-stained cell populations. MitoGen shows biologically justified cell motility, shape and texture changes as well as cell divisions. Standard fluorescence microscopy phenomena such as photobleaching, blur with real point spread function (PSF), and several types of noise, are simulated to obtain realistic images. The MitoGen framework is scalable in both space and time. MitoGen generates visually plausible data that shows good agreement with real data in terms of image descriptors and mean square displacement (MSD) trajectory analysis. Additionally, it is also shown in this paper that four publicly available segmentation and tracking algorithms exhibit similar performance on both real and MitoGen-generated data. The implementation of MitoGen is freely available.", "PublicationYear": "2017", "Authors": ["David Svoboda", "Vladim{\\'i}r Ulman"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["6b297521b83c4e3f117bcbc618929fc74b5ae988", "1d92328f6712dc8b2b22b5a2b6554187dd1787d2", "6179689e093d269c48574213a41acb7a4d3a8c6d", "06791ac9c0d9fe98ddd7da2117ca8ef1809480e3", "c63d67cd97a3737eebacd9b67cbe2aa728173c29", "4ea02721ff6cc1a46943a486ed9b18a4c89d4e04", "0a8a1b1f491ad1a99edadf9fe32f3a8702457269", "3a131e3bff0eee6ec7a130137614df99bfeeafb2", "b9356f1c1e56f1505915d709f0a9a0a6f07d60b2", "fde6f7273097e6e4a604293af1cc78e4bc806bcc"], "ReferenceCount": 57, "CitationCount": 39}, {"URL": "https://www.semanticscholar.org/paper/Annotated-high-throughput-microscopy-image-sets-for-Ljosa-Sokolnicki/ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869", "ID": "ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869", "Title": "Annotated high-throughput microscopy image sets for validation", "Abstract": "This work describes canonical ways to measure an algorithm\u2019s performance so that algorithms can be compared against each other fairly, and provides an optional framework to do so conveniently within CellProfiler. experiments and for providing biological ground truth for evaluating image-analysis algorithms. If an algorithm is sufficiently robust across samples to handle high-throughput experiments, lowthoughput applications also benefit because tolerance to variability in sample preparation and imaging makes the algorithm more likely to generalize to new image sets. Each image set in the BBBC is accompanied by a brief description of its motivating biological application and a set of groundtruth data against which algorithms can be evaluated. The ground truth sets can consist of cell or nucleus counts, foreground and background pixels, outlines of individual objects, or biological labels based on treatment conditions or orthogonal assays (such as a dose-response curve or positiveand negative-control images). We describe canonical ways to measure an algorithm\u2019s performance so that algorithms can be compared against each other fairly, and we provide an optional framework to do so conveniently within CellProfiler. For each image set, we list any published results of which we are aware. The BBBC is freely available from http://www.broadinstitute. org/bbbc/. The collection currently contains 18 image sets, including images of cells (Homo sapiens and Drosophila melanogaster) as well as of whole organisms (Caenorhabditis elegans) assayed in high throughput. We are continuing to extend the collection during the course of our research, and we encourage the submission of additional image sets, ground truth and published results of algorithms.", "PublicationYear": "2012", "Authors": ["Vebjorn Ljosa", "Katherine L. Sokolnicki", "Anne E Carpenter"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["b66561622170d97f4127f4131d485faefe3833f7", "a2e75b7d9727b7ea7cefb4060d93ac75813e3c48", "206aca9f166a0c287a4ac45dfcf35b957757a025"], "ReferenceCount": 10, "CitationCount": 444}, {"URL": "https://www.semanticscholar.org/paper/Visualization-and-Analysis-of-3D-Microscopic-Images-Long-Zhou/78bd4d517a6312ef2296243b5d6387c8f2e2abaf", "ID": "78bd4d517a6312ef2296243b5d6387c8f2e2abaf", "Title": "Visualization and Analysis of 3D Microscopic Images", "Abstract": "This primer first introduces several major methods for visualizing typical 3D images and related multi-scale, multi-time-point,Multi-color data sets, and discusses three key categories of image analysis tasks, namely segmentation, registration, and annotation. In a wide range of biological studies, it is highly desirable to visualize and analyze three-dimensional (3D) microscopic images. In this primer, we first introduce several major methods for visualizing typical 3D images and related multi-scale, multi-time-point, multi-color data sets. Then, we discuss three key categories of image analysis tasks, namely segmentation, registration, and annotation. We demonstrate how to pipeline these visualization and analysis modules using examples of profiling the single-cell gene-expression of C. elegans and constructing a map of stereotyped neurite tracts in a fruit fly brain.", "PublicationYear": "2012", "Authors": ["Fuhui Long", "Jianlong Zhou", "Hanchuan Peng"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["be7f7288313cde6123c462b6db02ef0863c63a82", "8cf9a1ec2c294c94e03ec6b2826dcd45fab1fde2", "9d6afb3efa0909de989dc8df4935055703401652", "7425b041e6af596fb4339ce851bb29c47633de33", "810a6d12e6d663d26780b10ac6f212564c970417", "65ff54147ae4c53bc3223e48dddd0604450263bc", "0fb280a700dffab6f0ee268ca7e2b1480027be9b", "40fa291d918a45e5da6f62597b142e7b504cf39b", "6b37b398b21109535e6b16b8d3e60a4e310a1890", "8ccd5a3c2eabf0db93b16c615561e846dea503ff"], "ReferenceCount": 41, "CitationCount": 77}, {"URL": "https://www.semanticscholar.org/paper/Fully-convolutional-networks-for-semantic-Shelhamer-Long/6fc6803df5f9ae505cae5b2f178ade4062c768d0", "ID": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "Title": "Fully convolutional networks for semantic segmentation", "Abstract": "The key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.", "PublicationYear": "2014", "Authors": ["Evan Shelhamer", "Jonathan Long", "Trevor Darrell"], "RelatedTopics": ["Computer Science"], "References": ["317aee7fc081f2b137a85c4f20129007fd8e717e", "cf986bfe13a24d4739f95df3a856a3c6e4ed4c1c", "39ad6c911f3351a3b390130a6e4265355b4d593b", "ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a", "f084f0126d48a0793cf7e60830089b93ef09c844", "3ad998a9b2c071c4a1971048f8a2d754530f08e8", "1a9658c0b7bea22075c0ea3c229b8c70c1790153", "792bf014f202938b798656c61a6fce2adc74403f", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "b8de958fead0d8a9619b55c7299df3257c624a96"], "ReferenceCount": 69, "CitationCount": 32913}, {"URL": "https://www.semanticscholar.org/paper/Deep-Neural-Networks-Segment-Neuronal-Membranes-in-Ciresan-Giusti/09193e19b59fc8f05bee9d6efbfb1607ca5b6501", "ID": "09193e19b59fc8f05bee9d6efbfb1607ca5b6501", "Title": "Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images", "Abstract": "This work addresses a central problem of neuroanatomy, namely, the automatic segmentation of neuronal structures depicted in stacks of electron microscopy images, using a special type of deep artificial neural network as a pixel classifier to segment biological neuron membranes. We address a central problem of neuroanatomy, namely, the automatic segmentation of neuronal structures depicted in stacks of electron microscopy (EM) images. This is necessary to efficiently map 3D brain structure and connectivity. To segment biological neuron membranes, we use a special type of deep artificial neural network as a pixel classifier. The label of each pixel (membrane or non-membrane) is predicted from raw pixel values in a square window centered on it. The input layer maps each window pixel to a neuron. It is followed by a succession of convolutional and max-pooling layers which preserve 2D information and extract features with increasing levels of abstraction. The output layer produces a calibrated probability for each class. The classifier is trained by plain gradient descent on a 512 \u00d7 512 \u00d7 30 stack with known ground truth, and tested on a stack of the same size (ground truth unknown to the authors) by the organizers of the ISBI 2012 EM Segmentation Challenge. Even without problem-specific postprocessing, our approach outperforms competing techniques by a large margin in all three considered metrics, i.e. rand error, warping error and pixel error. For pixel error, our approach is the only one outperforming a second human observer.", "PublicationYear": "2012", "Authors": ["Dan C. Ciresan", "Alessandro Giusti", "Luca Maria Gambardella", "J{\\\"u}rgen Schmidhuber"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["b7b544f1ae34eb28f17413729f25720492794f8c", "24f1765f3588ec70f56cec41714dfde60d74750f", "66fcdcefd643dff76cc34c1f1b07990fc0279942", "ecfc5d6f23d614f6789442519970db2c0d90363d", "a3f116cdf6f1a8441ec46df5c4a34d42d6749331", "398c296d0cc7f9d180f84969f8937e6d3a413796", "124dabf0da002ec1aa44eabd3885cd80873d304c", "1faf917f4f7388a63957d065607cdc706a7d2879", "69e68bfaadf2dccff800158749f5a50fe82d173b", "2c939086c9f779417f7a60b8bdad397d4338b019"], "ReferenceCount": 35, "CitationCount": 1383}, {"URL": "https://www.semanticscholar.org/paper/Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman/eb42cf88027de515750f230b23b1a057dc782108", "ID": "eb42cf88027de515750f230b23b1a057dc782108", "Title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "Abstract": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.", "PublicationYear": "2014", "Authors": ["Karen Simonyan", "Andrew Zisserman"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["e15cf50aa89fee8535703b9f9512fca5bfc43327", "14d9be7962a4ec5a6e55755f4c7588ea00793652", "d67175d17c450ab0ac9c256103828f9e9a0acb85", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "b8de958fead0d8a9619b55c7299df3257c624a96", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "c08f5fa876181fc040d76c75fe2433eee3c9b001", "67dccc9a856b60bdc4d058d83657a089b8ad4486", "1109b663453e78a59e4f66446d71720ac58cec25", "5a47ba057a858f8c024d2518cc3731fc7eb40de1"], "ReferenceCount": 43, "CitationCount": 85703}, {"URL": "https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/abd1c342495432171beb7ca8fd9551ef13cbd0ff", "ID": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "Title": "ImageNet classification with deep convolutional neural networks", "Abstract": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \\\"dropout\\\" that proved to be very effective. We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \\\"dropout\\\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "PublicationYear": "2012", "Authors": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "RelatedTopics": ["Computer Science"], "References": ["9952d4d5717afd4a27157ed8b98b0ee3dcb70d6c", "bea5780d621e669e8069f05d0f2fc0db9df4b50f", "82b9099ddf092463f497bd48bb112c46ca52c4d1", "398c296d0cc7f9d180f84969f8937e6d3a413796", "5d90f06bb70a0a3dced62413346235c02b1aa086", "5bdfd78fb2285b9306e93bd3a4b534d19bf55f06", "c43025c429b1fbf6f1379f61801a1b40834d62e7", "3a4a53fe47036ac89dad070ab87a9d8795b139b1", "5562a56da3a96dae82add7de705e2bd841eb00fc", "f354310098e09c1e1dc88758fca36767fd9d084d"], "ReferenceCount": 44, "CitationCount": 105591}, {"URL": "https://www.semanticscholar.org/paper/Caffe%3A-Convolutional-Architecture-for-Fast-Feature-Jia-Shelhamer/6bdb186ec4726e00a8051119636d4df3b94043b5", "ID": "6bdb186ec4726e00a8051119636d4df3b94043b5", "Title": "Caffe: Convolutional Architecture for Fast Feature Embedding", "Abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.", "PublicationYear": "2014", "Authors": ["Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross B. Girshick", "Sergio Guadarrama", "Trevor Darrell"], "RelatedTopics": ["Computer Science"], "References": ["b8de958fead0d8a9619b55c7299df3257c624a96", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "89d5b41b7fb0a122f811be270e6d5f72fc59d680", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "1109b663453e78a59e4f66446d71720ac58cec25", "c62a99e6491e14c32aac6bfea01ef3f943ce9129", "9b223c8a31e0ea1d1f2c9787ffd8416dfc90c912", "3449b65008b27f6e60a73d80c1fd990f0481126b", "a55879fff371aafffe8b5b2476cd20d03bf8ad8c", "2f7ad26514bce4df6c8ebc42c90383ef3a974df4"], "ReferenceCount": 12, "CitationCount": 14498}, {"URL": "https://www.semanticscholar.org/paper/Rich-Feature-Hierarchies-for-Accurate-Object-and-Girshick-Donahue/2f4df08d9072fc2ac181b7fced6a245315ce05c8", "ID": "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "Title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "Abstract": "This paper proposes a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.", "PublicationYear": "2013", "Authors": ["Ross B. Girshick", "Jeff Donahue", "Trevor Darrell", "Jitendra Malik"], "RelatedTopics": ["Computer Science"], "References": ["237a04dd8291cbdb59b6dc4b53e689af743fe2a3", "f99408de2ae6c5c036e1825bdadf7b193c3ba734", "06b2739f4daba0382870f7e34ab653fa444993c0", "1395f0561db13cad21a519e18be111cbe1e6d818", "1109b663453e78a59e4f66446d71720ac58cec25", "a920cdf9ab1f04680543bcd30dd4c5cf24892395", "2eb6caace8296fd4dfd4947efa4fe911c8e133b2", "42a5da01c672b2d37e76c62f851c1f88e6b988c0", "76f02eca773414828271da315b379efa9e1f57fa", "713f73ce5c3013d9fb796c21b981dc6629af0bd5"], "ReferenceCount": 55, "CitationCount": 22980}, {"URL": "https://www.semanticscholar.org/paper/Hypercolumns-for-object-segmentation-and-Hariharan-Arbel%C3%A1ez/428db42e86f6d51292e23fa57797e35cecd0e2ee", "ID": "428db42e86f6d51292e23fa57797e35cecd0e2ee", "Title": "Hypercolumns for object segmentation and fine-grained localization", "Abstract": "Using hypercolumns as pixel descriptors, this work defines the hypercolumn at a pixel as the vector of activations of all CNN units above that pixel, and shows results on three fine-grained localization tasks: simultaneous detection and segmentation, and keypoint localization. Recognition algorithms based on convolutional networks (CNNs) typically use the output of the last layer as a feature representation. However, the information in this layer may be too coarse spatially to allow precise localization. On the contrary, earlier layers may be precise in localization but will not capture semantics. To get the best of both worlds, we define the hypercolumn at a pixel as the vector of activations of all CNN units above that pixel. Using hypercolumns as pixel descriptors, we show results on three fine-grained localization tasks: simultaneous detection and segmentation [22], where we improve state-of-the-art from 49.7 mean APr [22] to 60.0, keypoint localization, where we get a 3.3 point boost over [20], and part labeling, where we show a 6.6 point gain over a strong baseline.", "PublicationYear": "2014", "Authors": ["Bharath Hariharan", "Pablo Arbel{\\'a}ez", "Ross B. Girshick", "Jitendra Malik"], "RelatedTopics": ["Computer Science"], "References": ["2f4df08d9072fc2ac181b7fced6a245315ce05c8", "342786659379879f58bf5c4ff43c84c83a6a7389", "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "3ad998a9b2c071c4a1971048f8a2d754530f08e8", "eb42cf88027de515750f230b23b1a057dc782108", "237a04dd8291cbdb59b6dc4b53e689af743fe2a3", "98bb60748eb8ef7a671cdd22faa87e377fd13060", "28fa525ca1e101335e877bb1f6999b6ccf476959", "531e412155cde56382906aeee2a1b28ec61259c5", "06b2739f4daba0382870f7e34ab653fa444993c0"], "ReferenceCount": 43, "CitationCount": 1543}, {"URL": "https://www.semanticscholar.org/paper/Image-Segmentation-with-Cascaded-Hierarchical-and-Seyedhosseini-Sajjadi/4f03888450fde9e8234f616badaae499740e57a4", "ID": "4f03888450fde9e8234f616badaae499740e57a4", "Title": "Image Segmentation with Cascaded Hierarchical Models and Logistic Disjunctive Normal Networks", "Abstract": "This work proposes a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation, and introduces a novel classification scheme, called logistic disjunctive normal networks (LDNN), which outperforms state-of-the-art classifiers and can be used in the CHM to improve object segmentation performance. Contextual information plays an important role in solving vision problems such as image segmentation. However, extracting contextual information and using it in an effective way remains a difficult problem. To address this challenge, we propose a multi-resolution contextual framework, called cascaded hierarchical model (CHM), which learns contextual information in a hierarchical framework for image segmentation. At each level of the hierarchy, a classifier is trained based on down sampled input images and outputs of previous levels. Our model then incorporates the resulting multi-resolution contextual information into a classifier to segment the input image at original resolution. We repeat this procedure by cascading the hierarchical framework to improve the segmentation accuracy. Multiple classifiers are learned in the CHM, therefore, a fast and accurate classifier is required to make the training tractable. The classifier also needs to be robust against over fitting due to the large number of parameters learned during training. We introduce a novel classification scheme, called logistic disjunctive normal networks (LDNN), which consists of one adaptive layer of feature detectors implemented by logistic sigmoid functions followed by two fixed layers of logical units that compute conjunctions and disjunctions, respectively. We demonstrate that LDNN outperforms state-of-the-art classifiers and can be used in the CHM to improve object segmentation performance.", "PublicationYear": "2013", "Authors": ["Mojtaba Seyedhosseini", "Mehdi S. M. Sajjadi", "Tolga Tasdizen"], "RelatedTopics": ["Computer Science"], "References": ["0ba6f4fb548d8289fb42d68ac64d55f9e3a274ca", "0d1bfcdfc90e662defd26b8b0deae6ef6e661b23", "6b2b7c5efae0bd7be3156323cad75e10fe83ed66", "2e0597fffc495e67ade645ab24017b76cae37387", "d8be51d4a941b9db67b13278a2d033e28517bfaa", "78662a293888d7e982061d16f6a71d0223420fad", "fa1243ca14758711c02c3b84a7f6b7a71bcdcbfe", "683874b070da69ce358ed5dd673ebe3e42fc2137", "be305b0684f1a6ec8407c107187d28502b48f993", "26c8c478a63b880cc52634b72e4b24e885269511"], "ReferenceCount": 31, "CitationCount": 81}, {"URL": "https://www.semanticscholar.org/paper/Fully-Convolutional-Multi-Class-Multiple-Instance-Pathak-Shelhamer/3b2ccc97f1433cf8750a2ad5a05555ccd10e9cdf", "ID": "3b2ccc97f1433cf8750a2ad5a05555ccd10e9cdf", "Title": "Fully Convolutional Multi-Class Multiple Instance Learning", "Abstract": "This work proposes a novel MIL formulation of multi-class semantic segmentation learning by a fully convolutional network that exploits the further supervision given by images with multiple labels. Multiple instance learning (MIL) can reduce the need for costly annotation in tasks such as semantic segmentation by weakening the required degree of supervision. We propose a novel MIL formulation of multi-class semantic segmentation learning by a fully convolutional network. In this setting, we seek to learn a semantic segmentation model from just weak image-level labels. The model is trained end-to-end to jointly optimize the representation while disambiguating the pixel-image label assignment. Fully convolutional training accepts inputs of any size, does not need object proposal pre-processing, and offers a pixelwise loss map for selecting latent instances. Our multi-class MIL loss exploits the further supervision given by images with multiple labels. We evaluate this approach through preliminary experiments on the PASCAL VOC segmentation challenge.", "PublicationYear": "2014", "Authors": ["Deepak Pathak", "Evan Shelhamer", "Jonathan Long", "Trevor Darrell"], "RelatedTopics": ["Computer Science"], "References": ["1cb8f556350a653b41245020496a2aa85eefb7b9", "0e6bcc235037d91ccdf74c449a1f6990848ce993", "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "7feff9a8f31520310ce99ffd591178feacdd98bb", "bda6bb50ef3ee4d086d502b42383e80eda633918", "eb42cf88027de515750f230b23b1a057dc782108", "0e01db4197f71450118f81ae5a69ce4916b46421", "e79272fe3d65197100eae8be9fec6469107969ae", "abd1c342495432171beb7ca8fd9551ef13cbd0ff"], "ReferenceCount": 15, "CitationCount": 292}, {"URL": "https://www.semanticscholar.org/paper/A-benchmark-for-comparison-of-cell-tracking-Ma%C5%A1ka-Ulman/3bffa23a16c273ac2228a13e65dade6766ce7777", "ID": "3bffa23a16c273ac2228a13e65dade6766ce7777", "Title": "A benchmark for comparison of cell tracking algorithms", "Abstract": "Six algorithms covering a variety of segmentation and tracking paradigms have been compared and ranked based on their performance on both synthetic and real datasets in the Cell Tracking Challenge. Motivation: Automatic tracking of cells in multidimensional time-lapse fluorescence microscopy is an important task in many biomedical applications. A novel framework for objective evaluation of cell tracking algorithms has been established under the auspices of the IEEE International Symposium on Biomedical Imaging 2013 Cell Tracking Challenge. In this article, we present the logistics, datasets, methods and results of the challenge and lay down the principles for future uses of this benchmark. Results: The main contributions of the challenge include the creation of a comprehensive video dataset repository and the definition of objective measures for comparison and ranking of the algorithms. With this benchmark, six algorithms covering a variety of segmentation and tracking paradigms have been compared and ranked based on their performance on both synthetic and real datasets. Given the diversity of the datasets, we do not declare a single winner of the challenge. Instead, we present and discuss the results for each individual dataset separately. Availability and implementation: The challenge Web site (http://www.codesolorzano.com/celltrackingchallenge) provides access to the training and competition datasets, along with the ground truth of the training videos. It also provides access to Windows and Linux executable files of the evaluation software and most of the algorithms that competed in the challenge. Contact: codesolorzano@unav.es Supplementary information: Supplementary data are available at Bioinformatics online.", "PublicationYear": "2014", "Authors": ["Martin Ma{\\vs}ka", "Vladim{\\'i}r Ulman", "David Svoboda", "Pavel Matula", "Petr Matula", "Cristina Ederra", "Ainhoa Urbiola", "Tom{\\'a}s Espa{\\~n}a", "Subramanian Venkatesan", "Deepak M W Balak", "Pavel Karas", "Tereza Bolckov{\\'a}", "Mark{\\'e}ta Streitov{\\'a}", "Craig A. Carthel", "Stefano P. Coraluppi", "Nathalie Harder", "Karl Rohr", "Klas E. G. Magnusson", "Joakim Jald{\\'e}n", "Helen M. Blau", "Oleh Dzyubachyk", "Pavel Kr{\\'i}zek", "Guy M. Hagen", "David Pastor-Escuredo", "Daniel Jimenez-Carretero", "Mar{\\'i}a J. Ledesma-Carbayo", "Arrate Mu{\\~n}oz-Barrutia", "Erik H. W. Meijering", "Michal Kozubek", "Carlos Ort{\\'i}z-de-Sol{\\'o}rzano"], "RelatedTopics": ["Medicine", "Computer Science", "Engineering"], "References": ["9b260bee3ae1e3dab5aa5750a5bd5a22a82a3629", "6179689e093d269c48574213a41acb7a4d3a8c6d", "6b297521b83c4e3f117bcbc618929fc74b5ae988", "f5a4da093ed3e6f9f25568c4dda2fdfdfe9824f7", "af11f14dff8ea68d0f2a79f9c79a95f4f154dc03", "60d5db6c247b4f949c066db7e0a0faf3cfc237d1", "a3b5c89eee650641f227496758bc8b1f3167458a", "c0da38acd8e44c77e732b21e505f7042a8736a9c", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "b9356f1c1e56f1505915d709f0a9a0a6f07d60b2"], "ReferenceCount": 34, "CitationCount": 373}, {"URL": "https://www.semanticscholar.org/paper/Automated-cell-nuclear-segmentation-in-color-images-Latson-Sebek/a552cbbe0762a30ca00b922c6c99887de491ea18", "ID": "a552cbbe0762a30ca00b922c6c99887de491ea18", "Title": "Automated cell nuclear segmentation in color images of hematoxylin and eosin-stained breast biopsy.", "Abstract": "An automated, reproducible epithelial cell nuclear segmentation method to quantify cytologic features quickly and accurately from breast biopsy was developed and was sensitive in that a small percentage of nuclei were missed. OBJECTIVE\\nTo develop an automated, reproducible epithelial cell nuclear segmentation method to quantify cytologic features quickly and accurately from breast biopsy.\\n\\n\\nSTUDY DESIGN\\nThe method, based on fuzzy c-mean clustering of the hue-band of color images and the watershed transform, was applied to 39 images from 3 histologic types (typical hyperplasia, atypical hyperplasia, and ductal carcinoma in situ [cribriform and solid]).\\n\\n\\nRESULTS\\nThe performance of the segmentation algorithm was evaluated by visually determining the percentage of badly segmented nuclei (approximately 25% for all types), the percentage of nuclei that remained in clumps (4.5-16.7%) and the percentage of missed nuclei (0.4-1.5%) for each image.\\n\\n\\nCONCLUSION\\nThe segmentation algorithm was sensitive in that a small percentage of nuclei were missed. However, the percentage of badly segmented nuclei was on the order of 25%, and the percentage of nuclei that remained in clumps was on the order of 10% of the total number of nuclei in the duct. Even so, &gt; 600 nuclei per duct, on average, were segmented correctly; that was a sufficient number by which to calculate accurate quantitative, cytologic, morphometric measurements of epithelial cell nuclei in stained tissue sections of breast biopsy.", "PublicationYear": "2003", "Authors": ["Larry Latson", "Bruce A. Sebek", "Kimerly A. Powell"], "RelatedTopics": ["Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 73}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-cell-nucleus-segmentation-with-active-Bamford-Lovell/3ab1348d060f3ab7e70a2e368a30af14bc57c35c", "ID": "3ab1348d060f3ab7e70a2e368a30af14bc57c35c", "Title": "Unsupervised cell nucleus segmentation with active contours", "Abstract": "Semantic Scholar extracted view of \\\"Unsupervised cell nucleus segmentation with active contours\\\" by P. Bamford et al.", "PublicationYear": "1998", "Authors": ["Pascal Bamford", "Brian C. Lovell"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["65cafc4dc05c4f3cfe8ee47a1b6af408b2ac030a", "711717a17cd716ef40946690b7fe2499b4e3e827", "fa96ee06d46e75e6beb55914bd56c18b2e03b99d", "7c9c20c8c250d78824924ce74d66622d364f3c08", "dd91d97e29303949448a72e421dd04c391e3a075", "29721791294478dc3bb72eb1871d54c757df75ed", "f7cac1078a1415abd1648c3e51936e5b9a0f7ead", "023c01c4c462e8fbfaa9f6aed8a032cbd7288bf7", "d10eede743d1896e80452c552878c5f603190399", "68558360f63942668c68f55034ca93e53b4dfd2f"], "ReferenceCount": 15, "CitationCount": 245}, {"URL": "https://www.semanticscholar.org/paper/Automated-gland-and-nuclei-segmentation-for-grading-Naik-Doyle/856a3c76453a798556096cd23848402d1351c1f9", "ID": "856a3c76453a798556096cd23848402d1351c1f9", "Title": "Automated gland and nuclei segmentation for grading of prostate and breast cancer histopathology", "Abstract": "The utility of the glandular and nuclear segmentation algorithm in accurate extraction of various morphological and nuclear features for automated grading of prostate cancer, breast cancer, and breast cancer specimens is demonstrated by distinguishing between cancerous and benign breast histology specimens. Automated detection and segmentation of nuclear and glandular structures is critical for classification and grading of prostate and breast cancer histopathology. In this paper, we present a methodology for automated detection and segmentation of structures of interest in digitized histopathology images. The scheme integrates image information from across three different scales: (1) low- level information based on pixel values, (2) high-level information based on relationships between pixels for object detection, and (3) domain-specific information based on relationships between histological structures. Low-level information is utilized by a Bayesian classifier to generate a likelihood that each pixel belongs to an object of interest. High-level information is extracted in two ways: (i) by a level-set algorithm, where a contour is evolved in the likelihood scenes generated by the Bayesian classifier to identify object boundaries, and (ii) by a template matching algorithm, where shape models are used to identify glands and nuclei from the low-level likelihood scenes. Structural constraints are imposed via domain- specific knowledge in order to verify whether the detected objects do indeed belong to structures of interest. In this paper we demonstrate the utility of our glandular and nuclear segmentation algorithm in accurate extraction of various morphological and nuclear features for automated grading of (a) prostate cancer, (b) breast cancer, and (c) distinguishing between cancerous and benign breast histology specimens. The efficacy of our segmentation algorithm is evaluated by comparing breast and prostate cancer grading and benign vs. cancer discrimination accuracies with corresponding accuracies obtained via manual detection and segmentation of glands and nuclei.", "PublicationYear": "2008", "Authors": ["Shivang Naik", "Scott Doyle", "Shannon C. Agner", "Anant Madabhushi", "Michael D. Feldman", "John E. Tomaszeweski"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["d44c1e41821dff02a96d72ef5141120b1870aa38", "fc09c5913c2467a571fcfedc8e076705f367227f", "a552cbbe0762a30ca00b922c6c99887de491ea18", "d0ad4142e4e7fb052935b349dc67bac288c83ff3", "0fe2cc66d44708792517bb87b73286a8b27e6263", "3ab1348d060f3ab7e70a2e368a30af14bc57c35c", "57c6ac99c1f4ee2892edb9069e88fe82ba4da5cb", "05ab5c9b7150e7a90e3768fa6b35b9a9b2f93cd8", "d243b5eb81a8501cc0477c47a4ce7d4feb524aee", "05f4cd3d3f1ab5748ac0a04a2b7b0a446924b0d7"], "ReferenceCount": 11, "CitationCount": 336}, {"URL": "https://www.semanticscholar.org/paper/Automatic-segmentation-of-cell-nuclei-in-bladder-Korde-Bartels/0fe2cc66d44708792517bb87b73286a8b27e6263", "ID": "0fe2cc66d44708792517bb87b73286a8b27e6263", "Title": "Automatic segmentation of cell nuclei in bladder and skin tissue for karyometric analysis", "Abstract": "This robust segmentation technique used properties of the image histogram to optimally select a threshold and create closed four-way chain code nuclei segmentations for karyometric analysis of bladder and skin histology images. Objective: To automatically segment cell nuclei in histology images of bladder and skin tissue for karyometric analysis. Materials/Methods: The four main steps in the program were as follows: 1) median filtering and thresholding, 2) segmentation, 3) categorizing, and 4) cusp correction. This robust segmentation technique used properties of the image histogram to optimally select a threshold and create closed four-way chain code nuclei segmentations. Each cell nucleus segmentation was treated as an individual object with properties of segmentation quality. A segmentation was placed in one of the following three categories based on its properties: throw away, salvageable, or good. Erosion/dilation and rethresholding were performed on salvageable nuclei to correct cusps. Results: Ten bladder histology images were segmented both by hand and using this automatic segmention algorithm. The automatic segmentation resulted in a sensitivity of 76.4%. The average difference between hand and automatic segmentations over 42 nuclei, calculated for each of the 95 features used in karyometric analysis, ranged between 0 and 48.3%, with an average of 2.8%. The same procedure was performed on 10 skin histology images with a sensitivity of 83.0%. Average differences over 44 nuclei ranged between 0 and 200%, with an average of 10.0%. Conclusion: The close agreement in karyometric features with hand segmentation shows that automated segmentation can be used for analysis of bladder and skin histology images. Average differences between hand and automatic segmentations were smaller in bladder histology images because these images contained less contrast, and therefore the range of the karyometric feature values was smaller.", "PublicationYear": "2007", "Authors": ["Vrushali R. Korde", "Hubert G. Bartels", "James R Ranger-Moore", "Jennifer K. Barton"], "RelatedTopics": ["Biology", "Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 36}, {"URL": "https://www.semanticscholar.org/paper/Histopathology-tissue-segmentation-by-combining-Bunyak-Hafiane/4b3e38280c8d81a0921e9f1c1660076bab1719aa", "ID": "4b3e38280c8d81a0921e9f1c1660076bab1719aa", "Title": "Histopathology tissue segmentation by combining fuzzy clustering with multiphase vector level sets.", "Abstract": "This chapter presents an automatic segmentation system for histopathology imaging that combines multispectral edge and region informations through a vector multiphase level set framework and Beltrami color metric tensors refines the segmentation. High resolution, multispectral, and multimodal imagery of tissue biopsies is an indispensable source of information for diagnosis and prognosis of diseases. Automatic extraction of relevant features from these imagery is a valuable assistance for medical experts. A primary step in computational histology is accurate image segmentation to detect the number and spatial distribution of cell nuclei in the tissue, along with segmenting other structures such as lumen and epithelial regions which together make up a gland structure. This chapter presents an automatic segmentation system for histopathology imaging. Spatial constraint fuzzy C-means provides an unsupervised initialization. An active contour algorithm that combines multispectral edge and region informations through a vector multiphase level set framework and Beltrami color metric tensors refines the segmentation. An improved iterative kernel filtering approach detects individual nuclei centers and decomposes densely clustered nuclei structures. The obtained results show high performances for nuclei detection compared to the human annotation.", "PublicationYear": "2011", "Authors": ["Filiz Bunyak", "Adel Hafiane", "Kannappan Palaniappan"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["8692feed83813deee88d139bd0e7e8938a62c2fe", "10aa8d430078b2900cef62b550c8d8bb049a11a7", "7ba9f58129db0dc29b6b363202903b05a21d5a48", "e1e442f91d78b1558779c35eb7b6a47eb85f1591", "0e29033445026c1c3187d9a000a0126dd89d2c5d", "4cca8f71e476ecd1367cdd3bca01ec113ee274da", "c0d7f8448e856532bb7b91a3530b62b33bcc781b", "6609d08aceb5b2d4e040db4d10be2ccba4700b14", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "428377e8c7d9178873032e76b951f09ff1949ac1"], "ReferenceCount": 32, "CitationCount": 48}, {"URL": "https://www.semanticscholar.org/paper/Leukocytes-segmentation-using-Markov-random-fields.-Reta-Gonzalez/d3bbf54a295b6dbed7bae6fac07fd89ac039b30d", "ID": "d3bbf54a295b6dbed7bae6fac07fd89ac039b30d", "Title": "Leukocytes segmentation using Markov random fields.", "Abstract": "A novel method to segment leukocytes and their respective nucleus and cytoplasm from microscopic bone marrow leukemia cell images is presented, which uses color and texture contextual information of image pixels to extract cellular elements from images, which show heterogeneous color and textures staining and high-cell population. The segmentation of leukocytes and their components plays an important role in the extraction of geometric, texture, and morphological characteristics used to diagnose different diseases. This paper presents a novel method to segment leukocytes and their respective nucleus and cytoplasm from microscopic bone marrow leukemia cell images. Our method uses color and texture contextual information of image pixels to extract cellular elements from images, which show heterogeneous color and texture staining and high-cell population. The CIEL (\u2009\u2217\u2009) a (\u2009\u2217\u2009) b (\u2009\u2217\u2009) color space is used to extract color features, whereas a 2D Wold Decomposition model is applied to extract structural and stochastic texture features. The color and texture contextual information is incorporated into an unsupervised binary Markov Random Field segmentation model. Experimental results show the performance of the proposed method on both synthetic and real leukemia cell images. An average accuracy of 95% was achieved in the segmentation of real cell images by comparing those results with manually segmented cell images.", "PublicationYear": "2011", "Authors": ["Carolina Reta", "Jesus A. Gonzalez", "Raquel D{\\'i}az", "Jose S. Guichard"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["573b4af2e1e08c8cf50d408a61d9f301b994ae60", "8e47244ff9de254703b0d869f611069503e6d9ba", "188efb707a1448acdb4d21f3ed11d8a97e039bfe", "29e45108c8779693a0fec2c6817e4672ff157a76", "bf1b9c4407f0f6d52cdc5b389adbcbee708a8764", "19b9a5352960e1c9a6fea9d6bd5adc0d9f79de79", "85d3f7f2eaae2574ae93baedc0fe004f9c61fc78", "c68cf46bcfe46440ff5b2928932861ea94fc4db9", "0e4ab8c33da601300677a5a62be07df322e48d83", "7d53d18031dd8cb5d243227b878557ce2e685956"], "ReferenceCount": 12, "CitationCount": 10}, {"URL": "https://www.semanticscholar.org/paper/An-automatic-segmentation-algorithm-for-3D-cell-Indhumathi-Cai/dcdd14ec1eaf86db85c67600ea94ad697f981fe2", "ID": "dcdd14ec1eaf86db85c67600ea94ad697f981fe2", "Title": "An automatic segmentation algorithm for 3D cell cluster splitting using volumetric confocal images", "Abstract": "A novel and efficient 3D cluster splitting algorithm based on concavity analysis and interslice spatial coherence is proposed to separate the touching or overlapping cells or nuclei in a 3D native way. With the rapid advance of three\u2010dimensional (3D) confocal imaging technology, more and more 3D cellular images will be available. Segmentation of intact cells is a critical task in automated image analysis and quantification of cellular microscopic images. One of the major complications in the automatic segmentation of cellular images arises due to the fact that cells are often closely clustered. Several algorithms are proposed for segmenting cell clusters but most of them are 2D based. In other words, these algorithms are designed to segment 2D cell clusters from a single image. Given 2D segmentation methods developed, they can certainly be applied to each image slice with the 3D cellular volume to obtain the segmented cell clusters. Apparently, in such case, the 3D depth information with the volumetric images is not really used. Often, 3D reconstruction is conducted after the individualized segmentation to build the 3D cellular models from segmented 2D cellular contours. Such 2D native process is not appropriate as stacking of individually segmented 2D cells or nuclei do not necessarily form the correct and complete 3D cells or nuclei in 3D. This paper proposes a novel and efficient 3D cluster splitting algorithm based on concavity analysis and interslice spatial coherence. We have taken the advantage of using the 3D boundary points detected using higher order statistics as an input contour for performing the 3D cluster splitting algorithm. The idea is to separate the touching or overlapping cells or nuclei in a 3D native way. Experimental results show the efficiency of our algorithm for 3D microscopic cellular images.", "PublicationYear": "2011", "Authors": ["Chandrasekaran Indhumathi", "Yiyu Cai", "Y. Q. Guan", "Michal Opas"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["cee3035635eafa1c412934419d7563fdb06d73ae", "b1c13d7abec88cff4ad5d612336ef54ef961dae3", "f3a3254d7e233ae36baef93ebe5008c21151f467", "d11f2d0b0fddbbf9372ca8384f8f2386c59e848d", "018b5c0c4d4a89f13ba1acdfa7818372396932ca", "d83867f64e19ff66012b90dcd78a86cdff1dd3ee", "e74680e34677bce9a5ac203db73fbbad0e7ea5b3", "0158370196cd847a302bf7ff91ff4a5700d530cb", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "c0d7f8448e856532bb7b91a3530b62b33bcc781b"], "ReferenceCount": 40, "CitationCount": 32}, {"URL": "https://www.semanticscholar.org/paper/Automated-microscopy-in-diagnostic-histopathology%3A-Bartels-Gahm/b6e091a9cfd00b4bef2c0d92683f0f14da06bc0c", "ID": "b6e091a9cfd00b4bef2c0d92683f0f14da06bc0c", "Title": "Automated microscopy in diagnostic histopathology: From image processing to automated reasoning", "Abstract": "A machine vision system for diagnostic histopathology offers five modules for the automated detection of regions of abnormality in histopathologic sections and for individual patient targeted prognosis based on a case\u2010based reasoning process. A machine vision system for diagnostic histopathology offers five modules: 1) for the automated detection of regions of abnormality in histopathologic sections; 2) for fully automated image segmentation and diagnostic information extraction by a knowledge\u2010guided procedure; 3) for the derivation of histometric indices, such as a progression index or grade for a lesion; 4) for diagnostic evidence evaluation by Bayesian inference networks; and 5) for individual patient targeted prognosis based on a case\u2010based reasoning process. The system has been in operation for several years. Correct segmentation for even complex scenes such as cribriform glands has been achieved with a high success rate for histopathologic sections from prostate, colon, and breast. The lesion search module and prognostic module have passed feasibility testing and are still undergoing development. \u00a9 1997 John Wiley & Sons, Inc. Int J Imaging Syst Technol, 8, 214\u2013223, 1997", "PublicationYear": "1997", "Authors": ["Peter H. Bartels", "Thomas Gahm", "Deborah B. Thompson"], "RelatedTopics": ["Computer Science", "Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 27}, {"URL": "https://www.semanticscholar.org/paper/Attributed-Relational-Graphs-for-Cell-Nucleus-in-Arslan-Ersahin/40521ea2dc363b5164e9bcdec9de908cab18b617", "ID": "40521ea2dc363b5164e9bcdec9de908cab18b617", "Title": "Attributed Relational Graphs for Cell Nucleus Segmentation in Fluorescence Microscopy Images", "Abstract": "This algorithm models how a human locates a nucleus by identifying the nucleus boundaries and piecing them together, and reduces the nucleus identification problem to finding predefined structural patterns in the constructed graph. More rapid and accurate high-throughput screening in molecular cellular biology research has become possible with the development of automated microscopy imaging, for which cell nucleus segmentation commonly constitutes the core step. Although several promising methods exist for segmenting the nuclei of monolayer isolated and less-confluent cells, it still remains an open problem to segment the nuclei of more-confluent cells, which tend to grow in overlayers. To address this problem, we propose a new model-based nucleus segmentation algorithm. This algorithm models how a human locates a nucleus by identifying the nucleus boundaries and piecing them together. In this algorithm, we define four types of primitives to represent nucleus boundaries at different orientations and construct an attributed relational graph on the primitives to represent their spatial relations. Then, we reduce the nucleus identification problem to finding predefined structural patterns in the constructed graph and also use the primitives in region growing to delineate the nucleus borders. Working with fluorescence microscopy images, our experiments demonstrate that the proposed algorithm identifies nuclei better than previous nucleus segmentation algorithms.", "PublicationYear": "2013", "Authors": ["Salim Arslan", "Tulin Ersahin", "Rengul Cetin-Atalay", "Cigdem Demir"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["aa57234fe51ae928060de11f78232627a8fdf0c8", "4229dec01a6fc87be8816114ca72b685ace2774c", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "63a373063d51489b31e07ee639ab74b6cf586240", "0e29033445026c1c3187d9a000a0126dd89d2c5d", "1b979ed50b3a7c68c79726d7c22e078c579501f3", "e5faf0932f1e96b8491a51fc83a6875d9edb386e", "1268de7bda769e651dc6c089d006c7edbe37f563", "d40ce680467941eeaccecc2fe85d7417f1fcb16d", "b98139a09a58d080b8c5640da44a0e9d9b794709"], "ReferenceCount": 42, "CitationCount": 54}, {"URL": "https://www.semanticscholar.org/paper/Iterative-h%E2%80%90minima%E2%80%90based-marker%E2%80%90controlled-for-cell-Koyuncu-Akhan/4c8e87d996826725192d15273c14bc0f16a6f17e", "ID": "4c8e87d996826725192d15273c14bc0f16a6f17e", "Title": "Iterative h\u2010minima\u2010based marker\u2010controlled watershed for cell nucleus segmentation", "Abstract": "A new watershed algorithm is proposed that iteratively identifies its markers, considering a set of different h values, and the use of multiple h values in this iterative algorithm leads to better segmentation results, compared to its counterparts. Automated microscopy imaging systems facilitate high\u2010throughput screening in molecular cellular biology research. The first step of these systems is cell nucleus segmentation, which has a great impact on the success of the overall system. The marker\u2010controlled watershed is a technique commonly used by the previous studies for nucleus segmentation. These studies define their markers finding regional minima on the intensity/gradient and/or distance transform maps. They typically use the h\u2010minima transform beforehand to suppress noise on these maps. The selection of the h value is critical; unnecessarily small values do not sufficiently suppress the noise, resulting in false and oversegmented markers, and unnecessarily large ones suppress too many pixels, causing missing and undersegmented markers. Because cell nuclei show different characteristics within an image, the same h value may not work to define correct markers for all the nuclei. To address this issue, in this work, we propose a new watershed algorithm that iteratively identifies its markers, considering a set of different h values. In each iteration, the proposed algorithm defines a set of candidates using a particular h value and selects the markers from those candidates provided that they fulfill the size requirement. Working with widefield fluorescence microscopy images, our experiments reveal that the use of multiple h values in our iterative algorithm leads to better segmentation results, compared to its counterparts. \u00a9 2016 International Society for Advancement of Cytometry", "PublicationYear": "2016", "Authors": ["Can Fahrettin Koyuncu", "Ece Akhan", "Tulin Ersahin", "Rengul Cetin-Atalay", "Cigdem Gunduz-Demir"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["792b106addcf69a2bfaf8c5248cd4a55a2fbd821", "1b979ed50b3a7c68c79726d7c22e078c579501f3", "40521ea2dc363b5164e9bcdec9de908cab18b617", "aa57234fe51ae928060de11f78232627a8fdf0c8", "7ba18c90be2166a848ab509f9e9de950750a91da", "cdecac6e2f578cfc56140e00aaa74a78f864fea2", "3ba787154b2411fe89d88b6ab50ea84aa62dea04", "f3a3254d7e233ae36baef93ebe5008c21151f467", "de844fed270218dfebf43c4414c0072bb5d98243", "41ae827281ac2949ed19a60890b047d02f1212da"], "ReferenceCount": 24, "CitationCount": 23}, {"URL": "https://www.semanticscholar.org/paper/Automatic-segmentation-of-granular-objects-in-local-Yang-Ahuja/bf3a23566fad67f46f2154455b1bd802df612984", "ID": "bf3a23566fad67f46f2154455b1bd802df612984", "Title": "Automatic segmentation of granular objects in images: Combining local density clustering and gradient-barrier watershed", "Abstract": "Semantic Scholar extracted view of \\\"Automatic segmentation of granular objects in images: Combining local density clustering and gradient-barrier watershed\\\" by Huiguang Yang et al.", "PublicationYear": "2014", "Authors": ["Huiguang Yang", "Narendra Ahuja"], "RelatedTopics": ["Computer Science", "Physics"], "References": ["f3a3254d7e233ae36baef93ebe5008c21151f467", "932ee7ac02eab63b17acfbe3f127b9fd7926f06e", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "808aa686dd0877e53a5f4f6d18dfb0f28e49b6f2", "e74680e34677bce9a5ac203db73fbbad0e7ea5b3", "4202b41915ac3345a91ca12fa108aee61a128456", "4cee6f0f821c4cc5799e53aeda06f92666691667", "b79418076c5b180d977e80b89d6e2b316fa66db3", "4229dec01a6fc87be8816114ca72b685ace2774c", "d11f2d0b0fddbbf9372ca8384f8f2386c59e848d"], "ReferenceCount": 41, "CitationCount": 60}, {"URL": "https://www.semanticscholar.org/paper/Nuclei-Segmentation-Using-Marker-Controlled-Using-Yang-Li/1b979ed50b3a7c68c79726d7c22e078c579501f3", "ID": "1b979ed50b3a7c68c79726d7c22e078c579501f3", "Title": "Nuclei Segmentation Using Marker-Controlled Watershed, Tracking Using Mean-Shift, and Kalman Filter in Time-Lapse Microscopy", "Abstract": "A novel marker-controlled watershed based on mathematical morphology is proposed, which can effectively segment clustered cells with less oversegmentation and design a tracking method based on modified mean shift algorithm, in which several kernels with adaptive scale, shape, and direction are designed. It is important to observe and study cancer cells' cycle progression in order to better understand drug effects on cancer cells. Time-lapse microscopy imaging serves as an important method to measure the cycle progression of individual cells in a large population. Since manual analysis is unreasonably time consuming for the large volumes of time-lapse image data, automated image analysis is proposed. Existing approaches dealing with time-lapse image data are rather limited and often give inaccurate analysis results, especially in segmenting and tracking individual cells in a cell population. In this paper, we present a new approach to segment and track cell nuclei in time-lapse fluorescence image sequence. First, we propose a novel marker-controlled watershed based on mathematical morphology, which can effectively segment clustered cells with less oversegmentation. To further segment undersegmented cells or to merge oversegmented cells, context information among neighboring frames is employed, which is proved to be an effective strategy. Then, we design a tracking method based on modified mean shift algorithm, in which several kernels with adaptive scale, shape, and direction are designed. Finally, we combine mean-shift and Kalman filter to achieve a more robust cell nuclei tracking method than existing ones. Experimental results show that our method can obtain 98.8% segmentation accuracy, 97.4% cell division tracking accuracy, and 97.6% cell tracking accuracy", "PublicationYear": "2006", "Authors": ["Xiaodong Yang", "Houqiang Li", "Xiaobo Zhou"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["41ae827281ac2949ed19a60890b047d02f1212da", "861fa32053e4a60fcb70b843e0fb5145ce83d3b0", "c0da38acd8e44c77e732b21e505f7042a8736a9c", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "8cab9cb75d98c6f3c98800bd94cec9016717a648", "0da210f9888f5d61b02ee12b2c8fa21bc5a63666", "e74680e34677bce9a5ac203db73fbbad0e7ea5b3", "098f4af513aebe82cb25ce46780c4f1a16ed71e2", "15f24630b00ae3db97acb0a7a0be22d69fa433a4", "4e25adb8e95fcd05e66cab6f3a9eaf0e143af463"], "ReferenceCount": 29, "CitationCount": 385}, {"URL": "https://www.semanticscholar.org/paper/Overlapping-nuclei-segmentation-based-on-Bayesian-Jeong-Ko/96a3a3bff71b9d470dfa02d67ce981cb42003133", "ID": "96a3a3bff71b9d470dfa02d67ce981cb42003133", "Title": "Overlapping nuclei segmentation based on Bayesian networks and stepwise merging strategy", "Abstract": "Experimental results using fluorescence in situ hybridization images confirm that the proposed system produced better segmentation results when compared to previous methods, because of the nuclei classification before separating the overlapping nuclei. This paper presents a new approach to the segmentation of fluorescence in situ hybridization images. First, to segment the cell nuclei from the background, a threshold is estimated using a Gaussian mixture model and maximizing the likelihood function of the grey values for the cell images. After the nuclei segmentation, the overlapping and isolated nuclei are classified to facilitate a more accurate nuclei analysis. To do this, the morphological features of the nuclei, such their compactness, smoothness and moments, are extracted from training data to generate three probability distribution functions that are then applied to a Bayesian network as evidence. Following the nuclei classification, the overlapping nuclei are segmented into isolated nuclei using an intensity gradient transform and watershed algorithm. A new stepwise merging strategy is also proposed to merge fragments into a major nucleus. Experimental results using fluorescence in situ hybridization images confirm that the proposed system produced better segmentation results when compared to previous methods, because of the nuclei classification before separating the overlapping nuclei.", "PublicationYear": "2009", "Authors": ["Miae Jeong", "Byung-Chul Ko", "Jae-Yeal Nam"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["988859967b0c3085075d38920832dfdc4ba3dcea", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "e74680e34677bce9a5ac203db73fbbad0e7ea5b3", "21a9efebafdc258d1969779736bc08602c81ae3c", "762ec12ae5b254aa7a56aba83c107972aa52508e", "0158370196cd847a302bf7ff91ff4a5700d530cb", "0983d9f5c5a2c6c81530749d7020345ee56a6054", "6a2d01d36926854fbf839f0b883694186fab6147", "b1609ceb28b2c73ce92edd5fe19751ab62bda82f", "41ae827281ac2949ed19a60890b047d02f1212da"], "ReferenceCount": 16, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/Cell-Detection-and-Segmentation-Using-Correlation-Zhang-Yarkony/e10d7c818b3fea4f37c762c241965b2f665c9b70", "ID": "e10d7c818b3fea4f37c762c241965b2f665c9b70", "Title": "Cell Detection and Segmentation Using Correlation Clustering", "Abstract": "A learning-based method applicable to different modalities and cell types, in particular to cells that appear almost transparent in the images, is presented, which demonstrates very good performance in various bright field and phase contrast microscopy experiments. Cell detection and segmentation in microscopy images is important for quantitative high-throughput experiments. We present a learning-based method that is applicable to different modalities and cell types, in particular to cells that appear almost transparent in the images. We first train a classifier to detect (partial) cell boundaries. The resulting predictions are used to obtain superpixels and a weighted region adjacency graph. Here, edge weights can be either positive (attractive) or negative (repulsive). The graph partitioning problem is then solved using correlation clustering segmentation. One variant we newly propose here uses a length constraint that achieves state-of-art performance and improvements in some datasets. This constraint is approximated using non-planar correlation clustering. We demonstrate very good performance in various bright field and phase contrast microscopy experiments.", "PublicationYear": "2014", "Authors": ["Chong Zhang", "Julian Yarkony", "Fred A. Hamprecht"], "RelatedTopics": ["Computer Science"], "References": ["3afc61ccfc0ab25f5f32c5c24342909ef8985ef1", "cd04167e26f1676a1dc9ec10e018bd11b7768341", "7c61dd86ec0474b9a39161548c22d9a9e1610ba8", "d22531e9d4961cfa06cbd4bf174457247ea74f93", "1b715b9829acc372c7df51b4146f82edb98942c6", "1a5c50cff736ab5340a5d8c6c57685423e30de03", "5c5be36e3111e42247d78a6d529e4b1d7d2ced12", "c48364ff33b5bd106d616777b29f2de8abb83cf2", "5eff8fdccc35ae899c579ca8d65fd9e57c390c40", "a0d47ffa57d18944aa1e0567768d6d4e9c81c8c6"], "ReferenceCount": 13, "CitationCount": 57}, {"URL": "https://www.semanticscholar.org/paper/Detecting-overlapping-instances-in-microscopy-using-Arteta-Lempitsky/908dfcd908fe3fef9486bff01dbc04ccbde556d0", "ID": "908dfcd908fe3fef9486bff01dbc04ccbde556d0", "Title": "Detecting overlapping instances in microscopy images using extremal region trees", "Abstract": "Semantic Scholar extracted view of \\\"Detecting overlapping instances in microscopy images using extremal region trees\\\" by C. Arteta et al.", "PublicationYear": "2016", "Authors": ["Carlos Arteta", "Victor S. Lempitsky", "Julia Alison Noble", "Andrew Zisserman"], "RelatedTopics": ["Computer Science"], "References": ["e10d7c818b3fea4f37c762c241965b2f665c9b70", "3afc61ccfc0ab25f5f32c5c24342909ef8985ef1", "68f30bd22817a17adc837eb285e51c9628f00e8d", "f4c7ff4b8613f700aa9f89a2c0653b6ffcf658be", "63a373063d51489b31e07ee639ab74b6cf586240", "b57850ecca10bf6dc3dbfc63ad2d778b01f50e5c", "797179eced7eb227ede4aa275f4a0f261d447648", "c5eab4b9e278d9f0af1221d5c980fd1c49372c8e", "2557e2ed0a19cbe2d78e3d4daa5d39e62be5d009", "78662a293888d7e982061d16f6a71d0223420fad"], "ReferenceCount": 33, "CitationCount": 70}, {"URL": "https://www.semanticscholar.org/paper/Segmenting-Clustered-Nuclei-Using-H-minima-Marker-Jung-Kim/7ba18c90be2166a848ab509f9e9de950750a91da", "ID": "7ba18c90be2166a848ab509f9e9de950750a91da", "Title": "Segmenting Clustered Nuclei Using H-minima Transform-Based Marker Extraction and Contour Parameterization", "Abstract": "A novel watershed-based method for segmentation of cervical and breast cell images based on a hypothesis concerning the nuclei, which involves a priori knowledge with respect to the shape of nuclei is tested to solve the optimization problem. In this letter, we present a novel watershed-based method for segmentation of cervical and breast cell images. We formulate the segmentation of clustered nuclei as an optimization problem. A hypothesis concerning the nuclei, which involves a priori knowledge with respect to the shape of nuclei, is tested to solve the optimization problem. We first apply the distance transform to the clustered nuclei. A marker extraction scheme based on the H -minima transform is introduced to obtain the optimal segmentation result from the distance map. In order to estimate the optimal h-value, a size-invariant segmentation distortion evaluation function is defined based on the fitting residuals between the segmented region boundaries and fitted models. Ellipsoidal modeling of contours is introduced to adjust nuclei contours for more effective analysis. Experiments on a variety of real microscopic cell images show that the proposed method yields more accurate segmentation results than the state-of-the-art watershed-based methods.", "PublicationYear": "2010", "Authors": ["Chanho Jung", "Changick Kim"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["c8c01302a507ded468351b6cdef39895856184c5", "1b979ed50b3a7c68c79726d7c22e078c579501f3", "de844fed270218dfebf43c4414c0072bb5d98243", "aa57234fe51ae928060de11f78232627a8fdf0c8", "c1e11f3517a5df76c1d6e730154e7fc24712a674", "717a348468aa1d5d5cd5b857c911b055211783ac", "b11b6ad1ceb23d80899a903a7e8fc1b8233dfec8", "c66502bd854c5b9e3b8af9fda207c317a761d87a", "0defd1207109e37b6eaf6104f86834d60aef39e7", "91343f9ce2e7d702c2ff837830bd35259ff8fd99"], "ReferenceCount": 14, "CitationCount": 217}, {"URL": "https://www.semanticscholar.org/paper/Cell-segmentation-in-phase-contrast-microscopy-via-Su-Yin/7cb2f4f7b65ae227872e72d6cfcdbf47714bd9a0", "ID": "7cb2f4f7b65ae227872e72d6cfcdbf47714bd9a0", "Title": "Cell segmentation in phase contrast microscopy images via semi-supervised classification over optics-related features", "Abstract": "Semantic Scholar extracted view of \\\"Cell segmentation in phase contrast microscopy images via semi-supervised classification over optics-related features\\\" by Hang Su et al.", "PublicationYear": "2013", "Authors": ["Hang Su", "Zhaozheng Yin", "Seungil Huh", "Takeo Kanade"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["052e43cd2cf27f63d717a31ee9ff6809d66aae40", "3850b228bfac862dae94469ba2fea5c71600e769", "3b99bdb18481217bd952cb766dddd921c7c9826f", "f54389eb7c29b2c1748b87e49f1eb640e47ffef0", "242be4f1f86fd367c2b90127a07648342c32ee0c", "db7e78e7538b37b2dfdca48bcb933f6f51f9d720", "7446c4f47b46f8e31fdbf72b816057c98d69edfc", "f1f0a67e9083f45bae08652adde95634c3de9baf", "cca4734dd92da48ad9b1c0d30cff6541f7fa213f", "f965c077c8ff03796fe8f4be3720985294609292"], "ReferenceCount": 32, "CitationCount": 82}, {"URL": "https://www.semanticscholar.org/paper/Efficient%2C-interactive%2C-and-three-dimensional-of-in-Lockett-Sudar/ceb73c385a55ef1484e277a11a5fc2e78167a414", "ID": "ceb73c385a55ef1484e277a11a5fc2e78167a414", "Title": "Efficient, interactive, and three-dimensional segmentation of cell nuclei in thick tissue sections.", "Abstract": "An optional, automatic surface optimization algorithm is described that results in segmented objects that correspond to individual, visually identifiable nuclei that may not exactly represent the true nuclear surface. Segmentation of intact cell nuclei in three-dimensional (3D) images of thick tissue sections is an important basic capability necessary for many biological research studies. Because automatic algorithms do not correctly segment all nuclei in tissue sections, interactive algorithms may be preferable for some applications. Existing interactive segmentation algorithms require the analyst to draw a border around the nucleus under consideration in all successive two-dimensional (2D) planes of the 3D image. The present paper describes an algorithm with two main advantages over the existing method. First, the analyst draws borders only in 2D planes that cut approximately through the center of the nucleus under consideration so that the nuclear borders generally are most distinct. Second, the analyst draws only five borders around each nucleus, and then the algorithm interpolates the entire surface. The algorithm results in segmented objects that correspond to individual, visually identifiable nuclei. The segmented surfaces, however, may not exactly represent the true nuclear surface. An optional, automatic surface optimization algorithm can be applied to reduce this error.", "PublicationYear": "1998", "Authors": ["Stephen J. Lockett", "Damir Sudar", "Curtis T. Thompson", "Daniel Pinkel", "Joe W. Gray"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["b1c13d7abec88cff4ad5d612336ef54ef961dae3", "13e3e4b75636122381693a527cccb96395a1aa3e", "8791a2589311ab6b4b70b6a2ee6b092a976672e6", "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "f063b8057e46e5f3743de6210c82bda526ef8d0f", "aa9b4b673549283117b84803fccdc5ba03624179", "35a6e5d4749107d8d708eb86976718b37617a7f5", "d4fcccd52b2b2857cbb66ef363855cc1676ada6a", "e237d5e6075df78ca7b7169650e12ce398c35c0e", "b0d58835cee7382078e615c7db301bd6172a2f67"], "ReferenceCount": 44, "CitationCount": 55}, {"URL": "https://www.semanticscholar.org/paper/Automatic-Hough-Transform-Based-3D-Segmentation-of-Lockett-Rodriguez/13e3e4b75636122381693a527cccb96395a1aa3e", "ID": "13e3e4b75636122381693a527cccb96395a1aa3e", "Title": "Automatic Hough Transform-Based 3D Segmentation of Cell Nuclei in Thick Tissue Sections", "Abstract": "This work presents a completely automatic, 3D algorithm for detecting molecular species in individual cells based on the Hough transform (HT), which is a powerful approach for gaining insight into the underlying disease mechanisms of carcinogenesis. Combining pathology, which reports the structural features of individual cells and their spatial organi-zation in a tissue specimen, with molecular biology techniques (immunocytochemistry and fluores-cence in situ hybridization, FISH) for detecting the distribution of specific molecular species in individual cells is a powerful approach for gaining insight into the underlying disease mechanisms of carcinogenesis. This approach requires analysis of thick (&gt;20 \u00bcm) tissue sections in which cells are preserved intact within the context of their environment. 3D (confocal) microscope image acquisition followed by 3D image analysis (IA) for extracting quantitative information are then used for quantita-tive analysis of tissue features such as nuclear and/or cell volume, shape, total fluorescence or FISH signal number. An essential component of the IA is detection of the individual cells, or their nuclei since many molecular species of interest are localized within the nucleus (e.g. genetic aberrations). We present here a completely automatic, 3D algorithm for this task, which based on the Hough transform (HT).", "PublicationYear": "1997", "Authors": ["S. J. Lockett", "Enrique Garcia Rodriguez", "Carlos Ortiz de Sol{\\'o}rzano", "Damir Sudar", "Daniel Pinkel", "Jw. Gray"], "RelatedTopics": ["Medicine", "Computer Science", "Biology"], "References": [], "ReferenceCount": 0, "CitationCount": 3}, {"URL": "https://www.semanticscholar.org/paper/Advances-in-automated-3-D-image-analyses-of-cell-by-Ancin-Roysam/b1c13d7abec88cff4ad5d612336ef54ef961dae3", "ID": "b1c13d7abec88cff4ad5d612336ef54ef961dae3", "Title": "Advances in automated 3-D image analyses of cell populations imaged by confocal microscopy.", "Abstract": "Algorithms for efficient data pre-processing and adaptive segmentation, effective handling of image anisotrophy, and fast 3-D morphological algorithms for separating overlapping or connected clusters utilizing image gradient information whenever available are reported. Automated three-dimensional (3-D) image analysis methods are presented for rapid and effective analysis of populations of fluorescently labeled cells or nuclei in thick tissue sections that have been imaged three dimensionally using a confocal microscope. The methods presented here greatly improve upon our earlier work (Roysam et al.:J Microsc 173: 115-126, 1994). The principal advances reported are: algorithms for efficient data pre-processing and adaptive segmentation, effective handling of image anisotrophy, and fast 3-D morphological algorithms for separating overlapping or connected clusters utilizing image gradient information whenever available. A particular feature of this method is its ability to separate densely packed and connected clusters of cell nuclei. Some of the challenges overcome in this work include the efficient and effective handling of imaging noise, anisotrophy, and large variations in image parameters such as intensity, object size, and shape. The method is able to handle significant inter-cell, intra-cell, inter-image, and intra-image variations. Studies indicate that this method is rapid, robust, and adaptable. Examples were presented to illustrate the applicability of this approach to analyzing images of nuclei from densely packed regions in thick sections of rat liver, and brain that were labeled with a fluorescent Schiff reagent.", "PublicationYear": "1996", "Authors": ["Hakan Ancin", "Badrinath Roysam", "Thomas E. Dufresne", "Matthew M. Chestnut", "Gregg M. Ridder", "Donald H. Szarowski", "James N. Turner"], "RelatedTopics": ["Biology", "Computer Science", "Engineering"], "References": ["8f25b129be3514bd126eda0674b489d1923954ac", "018b5c0c4d4a89f13ba1acdfa7818372396932ca", "beb8b793230e22c0e3fbd3e5943dd1b08b9aeb57", "aa9b4b673549283117b84803fccdc5ba03624179", "5b9d3685427c6126c5343c21dae6fd2f29e96c63", "a0616d4f8d244450b849a9c5aa0ef08d3f31fbff", "f08156ba67ca17ed58e1e3a7987feab9bada3324", "39ee3ca01d8a4ed444a1821b47e6fab2542b662f", "2bb2998b435fa2944016f4d28b75a51c41edfe78", "5200dca81f7e349f815cd2b0c4440afc4c6499ca"], "ReferenceCount": 40, "CitationCount": 64}, {"URL": "https://www.semanticscholar.org/paper/Applying-watershed-algorithms-to-the-segmentation-Malpica-Sol%C3%B3rzano/0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "ID": "0640f9ac79a8a4fa033c379f1cbde7033a41eeea", "Title": "Applying watershed algorithms to the segmentation of clustered nuclei.", "Abstract": "An algorithm based on morphological watersheds has been implemented and tested on the segmentation of microscopic nuclei clusters and provides a tool that can be used for the implementation of both gradient- and domain-based algorithms, and, more importantly, for the Implementation of mixed (gradient- and shape-based) algorithms. Cluster division is a critical issue in fluorescence microscopy-based analytical cytology when preparation protocols do not provide appropriate separation of objects. Overlooking clustered nuclei and analyzing only isolated nuclei may dramatically increase analysis time or affect the statistical validation of the results. Automatic segmentation of clustered nuclei requires the implementation of specific image segmentation tools. Most algorithms are inspired by one of the two following strategies: 1) cluster division by the detection of internuclei gradients; or 2) division by definition of domains of influence (geometrical approach). Both strategies lead to completely different implementations, and usually algorithms based on a single view strategy fail to correctly segment most clustered nuclei, or perform well just for a specific type of sample. An algorithm based on morphological watersheds has been implemented and tested on the segmentation of microscopic nuclei clusters. This algorithm provides a tool that can be used for the implementation of both gradient- and domain-based algorithms, and, more importantly, for the implementation of mixed (gradient- and shape-based) algorithms. Using this algorithm, almost 90% of the test clusters were correctly segmented in peripheral blood and bone marrow preparations. The algorithm was valid for both types of samples, using the appropriate markers and transformations.", "PublicationYear": "1998", "Authors": ["Norberto Malpica", "Carlos Ortiz de Sol{\\'o}rzano", "Juan Jos{\\'e} Vaquero", "Andr{\\'e}s Santos", "Isabel Vallcorba", "Jos{\\'e} Miguel Garc{\\'i}a-Sagredo", "Francisco del Pozo"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["aa9b4b673549283117b84803fccdc5ba03624179", "4202b41915ac3345a91ca12fa108aee61a128456", "4f429474eebb8f785fa8446bdb8fd2fd32441f73", "79d63562b5176571e05edb84c5789215551845d5", "fbb7c6b06d9ff137a45fd77b92fc3845b5e1f5cb", "e6434f788a6d3457fabcd3974f56a2ffc909db88", "8ae9fc1e08c790f737d52c4ab6e20234aa269faa", "e9b12607e34e5c0b89dde8885ffddb2021a82700", "679424fde825da349d6e2149d9cd67342dc26e3d", "a890ccc0838e139a51ae83de986bee6bc8c7de32"], "ReferenceCount": 25, "CitationCount": 480}, {"URL": "https://www.semanticscholar.org/paper/A-unified-geometric-model-for-3D-confocal-image-in-Sarti-Ort%C3%ADz/52b7614dccf5b0b266e0bd2458bfcd2f1ff04f0c", "ID": "52b7614dccf5b0b266e0bd2458bfcd2f1ff04f0c", "Title": "A unified geometric model for 3D confocal image analysis in cytology", "Abstract": "This paper builds a chain of methods that includes an edge-preserving image smoothing mechanism, an automatic segmentation method, a geometry-driven scheme to regularize the shapes and improve edge fidelity, and an interactive method to split shape clusters and reclassify them. In this paper, we use partial differential equation based analysis as a methodology for computer-aided cytology. We wish to accurately extract and classify the shapes of nuclei from noisy confocal microscopy images. This is a prerequisite to an accurate quantitative intranuclear (genotypic and phenotypic) and internuclear (tissue structure) analysis of cancerous and pre-cancerous specimens. We study the use of a geometric-driven scheme for improving the results obtained by a nuclear segmentation method, based on automatic segmentation, followed by object reconstruction and interactive classification. We build a chain of methods that includes an edge-preserving image smoothing mechanism, an automatic (albeit non-regularized) segmentation method, a geometry-driven scheme to regularize the shapes and improve edge fidelity, and an interactive method to split shape clusters and reclassify them.", "PublicationYear": "1998", "Authors": ["Alessandro Sarti", "Cristina Gallego Ort{\\'i}z", "S. J. Lockett", "Ravi Malladi"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["b1c13d7abec88cff4ad5d612336ef54ef961dae3", "cee3035635eafa1c412934419d7563fdb06d73ae", "ceb73c385a55ef1484e277a11a5fc2e78167a414", "276954935c75995c01a58ac2703127be1ce4e9fc", "a832e7a49c2ca71fab5b9f133e0b8ea0e9cbdabd", "a0616d4f8d244450b849a9c5aa0ef08d3f31fbff", "7b6b9aa6570895ce2a3f5a90b39b193565726e36", "e4c2d802cf9fe8de8f213727512e18bbfe3dc631", "4a958297ee05c87ee7dd7cacef8615fe0b806b06", "cd98167ffad104bdbcb7e89df411bca3014c6f89"], "ReferenceCount": 30, "CitationCount": 19}, {"URL": "https://www.semanticscholar.org/paper/Groping-for-Quantitative-Digital-3-D-Image-An-to-In-Rodenacker-Aubele/efde0638882cca4c714df59dc18f003e6d1ae7cb", "ID": "efde0638882cca4c714df59dc18f003e6d1ae7cb", "Title": "Groping for Quantitative Digital 3-D Image Analysis: An Approach to Quantitative Fluorescence In Situ Hybridization in Thick Tissue Sections of Prostate Carcinoma", "Abstract": "A semi\u2010automatic segmentation method is presented here to answer the methodical questions of computer\u2010aided analysis of large 3\u2010D image data sets for pathologists. In molecular pathology numerical chromosome aberrations have been found to be decisive for the prognosis of malignancy in tumours. The existence of such aberrations can be detected by interphase fluorescence in situ hybridization (FISH). The gain or loss of certain base sequences in the desoxyribonucleic acid (DNA) can be estimated by counting the number of FISH signals per cell nucleus. The quantitative evaluation of such events is a necessary condition for a prospective use in diagnostic pathology. To avoid occlusions of signals, the cell nucleus has to be analyzed in three dimensions. Confocal laser scanning microscopy is the means to obtain series of optical thin sections from fluorescence stained or marked material to fulfill the conditions mentioned above. A graphical user interface (GUI) to a software package for display, inspection, count and (semi\u2010)automatic analysis of 3\u2010D images for pathologists is outlined including the underlying methods of 3\u2010D image interaction and segmentation developed. The preparative methods are briefly described. Main emphasis is given to the methodical questions of computer\u2010aided analysis of large 3\u2010D image data sets for pathologists. Several automated analysis steps can be performed for segmentation and succeeding quantification. However tumour material is in contrast to isolated or cultured cells even for visual inspection, a difficult material. For the present a fully automated digital image analysis of 3\u2010D data is not in sight. A semi\u2010automatic segmentation method is thus presented here.", "PublicationYear": "1997", "Authors": ["Karsten Rodenacker", "Michaela Aubele", "Peter J. S. Hutzler", "P. S. Umesh Adiga"], "RelatedTopics": ["Medicine"], "References": ["a832e7a49c2ca71fab5b9f133e0b8ea0e9cbdabd", "33b2131bfa5ef5138fded49f42de1337540b7483", "c1c0a2b564c9ca953f1b7094c506e1663e1625a6", "e237d5e6075df78ca7b7169650e12ce398c35c0e", "66b9a4b66b48caccec32e1f9a98429570cebd412", "fde0b747301ff958ade54c6e82c1d56c38c8cde7", "316b72c84cb12e3f71e74e6e2a651f631d6a2aa4", "9afb54d0a943550ec506c39edc56ae2d28b26d15", "48a34876cb8d17257bd086b63597410bf06c2ed1", "a2dc01029f640e39fbc457f974913b71c6705637"], "ReferenceCount": 26, "CitationCount": 34}, {"URL": "https://www.semanticscholar.org/paper/Three-dimensional-DNA-image-cytometry-by-confocal-Rigaut-Vassy/a0616d4f8d244450b849a9c5aa0ef08d3f31fbff", "ID": "a0616d4f8d244450b849a9c5aa0ef08d3f31fbff", "Title": "Three-dimensional DNA image cytometry by confocal scanning laser microscopy in thick tissue blocks.", "Abstract": "Applications to an adult rat liver and a human in situ carcinoma of theesophagus are shown to demonstrate the precision of the confocal image cytometry method and its potential usefulness in histopathology. A method for the quantification of nuclear DNA in thick tissue blocks by confocal scanning laser microscopy is presented. Tissues were stained en bloc for DNA by chromomycin A3. Three-dimensional images, 60 microns deep, were obtained by stacking up confocal fluorescent images obtained with an MRC-500 (Bio-Rad, Richmond, CA). The effects due to bleaching and attenuation by depth of fluorescence emission were corrected mathematically. The DNA contents were estimated by summing up the detected emission intensities (discretized into pixel gray levels) from each segmented nucleus. Applications to an adult rat liver and to a human in situ carcinoma of theesophagus are shown to demonstrate, respectively, the precision of the method and its potential usefulness in histopathology. Comparisons are made with DNA histograms obtained on the same materials by image cytometry on smears and by flow cytometry. Ploidy peaks obtained with the confocal method, although wider than with other methods, are well separated. Confocal image cytometry offers the invaluable advantage of preserving the tissue architecture and therefore allowing, for instance, the selection of histological regions and the evaluation of the degree of heterogeneity of a tumor.", "PublicationYear": "1991", "Authors": ["Jean Paul Rigaut", "J Vassy", "Paulette Herlin", "Fran\u00e7oise Duigou", "E. Masson", "Dominique Briane", "Jean Foucrier", "Santos Carvajal-Gonzalez", "Angela M. Downs", "A. M. Mandard"], "RelatedTopics": ["Biology", "Medicine"], "References": ["b3ec02732259f9184765e679573ae86e254d380b", "f08156ba67ca17ed58e1e3a7987feab9bada3324", "ca8e62e4395c4d6766056aa1ef3397ba9b1d3647", "595070f275973f9845b0bb5f392afb6eceb1a2ee", "edd4083efc5bed16a185a37d6f2c9467434c69b7", "2a709468fb3ded98d5bf2f569f8cf120eebe72f0", "c41b03eb22becbc013642a8cb8b9a1b77f954f94", "eeebac5cb562e25de7e56fa95edb6040187df4e5", "694765b99ecf0d2371003c38d2d0734d59ff978c", "8c1eb49c37c7fb2f0342c0a653f5e6710c7208cf"], "ReferenceCount": 52, "CitationCount": 70}, {"URL": "https://www.semanticscholar.org/paper/Three-dimensional-DNA-image-cytometry-by-confocal-Irinopoulou-Vassy/a832e7a49c2ca71fab5b9f133e0b8ea0e9cbdabd", "ID": "a832e7a49c2ca71fab5b9f133e0b8ea0e9cbdabd", "Title": "Three-dimensional DNA image cytometry by confocal scanning laser microscopy in thick tissue blocks of prostatic lesions.", "Abstract": "An image processing system for the acquisition and processing of three-dimensional images based on confocal scanning laser microscopy (CSLM) based on the development of the automatic method for the 3D segmentation of cell nuclei for DNA cytometry and nuclear measurements. DNA ploidy provides important information for the evaluation of the prognosis of prostate cancer. For the purpose of DNA cytometry and nuclear measurements, we developed an image processing system for the acquisition and processing of three-dimensional (3D) images based on confocal scanning laser microscopy (CSLM). The advantage of the CSLM is the preservation of the tissue architecture and the possibility of multilabeling. It is possible to determine both individual nuclear features and cellular features and the degree of the spatial heterogeneity of several markers. Special attention was paid to the development of the automatic method for the 3D segmentation of cell nuclei. Thick tissue slides (100 microm), stained for DNA with chromomycin A3, from 4 patients (with benign hyperplasia, prostatic intraepithelial neoplasia (PIN), and well-and poorly-differentiated adenocarcinoma of the prostate), were studied in order to test the practicability of the developed methodology. DNA histograms showed a single peak in the diploid range for the hyperplasia and PIN cases. For the case of well-differentiated carcinoma, 2 peaks were observed, 1 in the diploid range and I in the tetraploid range. The case of poorly-differentiated carcinoma was characterized by an aneuploid distribution. For the cases of PIN and carcinomas, we observed a considerable variation of the volume of nuclei.", "PublicationYear": "1997", "Authors": ["Theano Irinopoulou", "Jany Vassy", "Michael Beil", "Polyxeni Nicolopoulou", "David Encaoua", "Jean Paul Rigaut"], "RelatedTopics": ["Medicine"], "References": ["a0616d4f8d244450b849a9c5aa0ef08d3f31fbff", "78f01b8c000d15a4436824bf4d6401c906cff325", "55dd3f597db67c2cb03eb30edae1567e57073af4", "80566ef8ad43d417ed5aef5616776981cd06ee10", "66f6749064757744394e16db154ed30caecb9a6b", "ab7103ead33da7fe56befa1490f523d74a241ea9", "17a663a3ad7bca63fdd5c961225bd57febb6113a", "99d233b1a6b241113a10b3c4b79eb5afbf769f38", "9a40ead28af4eba320d1a4aece0ed7f55acb548d", "38217c8aab07e18d47224ee34d0e71d5fbce35b7"], "ReferenceCount": 27, "CitationCount": 44}, {"URL": "https://www.semanticscholar.org/paper/Automated-fluorescence-image-cytometry.-DNA-and-of-Lockett-O'Rand/aa95aeb4080576e9c7120a1ef57edcdf6faabe8c", "ID": "aa95aeb4080576e9c7120a1ef57edcdf6faabe8c", "Title": "Automated fluorescence image cytometry. DNA quantification and detection of chlamydial infections.", "Abstract": "The hardware and software of a prototype image-based cytometer that can identify fluorescent objects, discriminate true objects from artifacts and divide overlapping pairs of objects are described. Digitized fluorescence microscopy in conjunction with automated image segmentation is a promising approach for screening clinical specimens quickly and reliably. This paper describes the hardware and software of a prototype image-based cytometer that can identify fluorescent objects, discriminate true objects from artifacts and divide overlapping pairs of objects. The use of this image cytometer is discussed for: (1) the measurement of the DNA ploidy distribution of isolated mature rat liver nuclei labeled with 4',6-diamidine-2-phenylindole; (2) the comparison of the DNA ploidy distributions of the same samples measured by image cytometry (ICM) and flow cytometry (FCM); and (3) the quantification of chlamydial infection by double labeling cells with antichlamydiae antibody and Hoechst 33258 for nuclear DNA analysis. Ploidy distributions measured by the automated image cytometer compared favorably to those obtained by FCM. All pairs of overlapping nuclei were automatically detected by an additional computer algorithm, and those pairs that were clearly more than one nucleus by visual inspection were correctly divided. The irregular morphology of the chlamydiae-infected cells meant that 26% of them were not correctly identified in the fluorescein-stained images (as judged by manual inspection), but all cells were nevertheless detected correctly from the images of the Hoechst-stained samples. Automated fluorescence ICM yielded results similar to those obtained with FCM and had the additional benefit of maintaining cell and tissue architecture while preserving the opportunity for subsequent manual inspection of the specimen.", "PublicationYear": "1991", "Authors": ["Stephen J. Lockett", "Michael G O'Rand", "Clifford A. Jr. Rinehart", "David G. Kaufman", "B Herman", "Ken Jacobson"], "RelatedTopics": ["Biology", "Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 30}, {"URL": "https://www.semanticscholar.org/paper/Confocal-3-dimensional-DNA-image-cytometry-in-thick-Czader-Liljeborg/cd98167ffad104bdbcb7e89df411bca3014c6f89", "ID": "cd98167ffad104bdbcb7e89df411bca3014c6f89", "Title": "Confocal 3-dimensional DNA image cytometry in thick tissue sections.", "Abstract": "3D-CICM permitted the DNA quantitation even in large cells with highly increased DNA ploidy values such as megakaryocytes and Reed-Sternberg cells of Hodgkin's disease, and allowed evaluation or morphometric parameters and 3-dimensional reconstruction of studied cells. We present a three-dimensional confocal DNA image cytometry (3-D CICM) method for analysis of DNA content in 30-40-microns-thick sections of routinely processed paraffin-embedded specimens. A comparison of DNA ploidy profiles obtained by 3-D CICM and conventional DNA image cytometry (ICM) on tissue sections sections showed significantly higher numbers of cells with high DNA content in DNA histograms by 3-D CICM. As estimated by 3-D CICM, the size of nuclei frequently exceeded the thickness of tissue sections used in conventional ICM, which suggested that many nuclei measured by this technique may be incomplete. This artifact was excluded in 3-D CICM by automatic rejection of cut nuclear profiles. This and the favorable ratio of tissue thickness to nuclear size in 3-D CICM permitted the DNA quantitation even in large cells with highly increased DNA ploidy values such as megakaryocytes and Reed-Sternberg cells of Hodgkin's disease. Additionally, 3D-CICM allowed evaluation or morphometric parameters and 3-dimensional reconstruction of studied cells.", "PublicationYear": "1996", "Authors": ["Magdalena Czader", "Anders Liljeborg", "Gert Auer", "Anna Porwit"], "RelatedTopics": ["Biology", "Medicine"], "References": ["a0616d4f8d244450b849a9c5aa0ef08d3f31fbff", "7da17dcc7d29fa197c0d2a234bd87ac804500ed5", "2426a5c6cf6540a7b6140db5176da587a405eda5", "2f1ab5f34fbd965271cdeea730d6135a7eb6a343", "299dc371e06aead86348906b182dff860485d1b0", "71ea615d344299907867d1d3abfe636100ec1646", "48b2b96fa1e333dfc3588158db7308fa034633b2", "80954cd1559a1a7b30a8f770d4abb875083ca060", "350b5f876f6d0d1513dc9199f95038344b6b01fb", "f0a20306a85569a3f0780ce84c7ca0d232324e3e"], "ReferenceCount": 32, "CitationCount": 20}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-in-Microscopy-Image-Analysis%3A-A-Xing-Xie/08dc94471605308669c8d3d8284ba94fcc93e345", "ID": "08dc94471605308669c8d3d8284ba94fcc93e345", "Title": "Deep Learning in Microscopy Image Analysis: A Survey", "Abstract": "A snapshot of the fast-growing deep learning field for microscopy image analysis, which explains the architectures and the principles of convolutional neural networks, fully Convolutional networks, recurrent neural Networks, stacked autoencoders, and deep belief networks and their formulations or modelings for specific tasks on various microscopy images. Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning.", "PublicationYear": "2018", "Authors": ["Fuyong Xing", "Yuanpu Xie", "Hai Su", "Fujun Liu", "Lin Yang"], "RelatedTopics": ["Computer Science", "Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 277}, {"URL": "https://www.semanticscholar.org/paper/Classifying-and-segmenting-microscopy-images-with-Kraus-Ba/d1f788e9ac58de5d2dc6a3928939b411cf9ec5a6", "ID": "d1f788e9ac58de5d2dc6a3928939b411cf9ec5a6", "Title": "Classifying and segmenting microscopy images with deep multiple instance learning", "Abstract": "A new neural network architecture is introduced that uses MIL to simultaneously classify and segment microscopy images with populations of cells and it is shown that training end-to-end MIL CNNs outperforms several previous methods on both mammalian and yeast datasets without requiring any segmentation steps. Motivation: High-content screening (HCS) technologies have enabled large scale imaging experiments for studying cell biology and for drug screening. These systems produce hundreds of thousands of microscopy images per day and their utility depends on automated image analysis. Recently, deep learning approaches that learn feature representations directly from pixel intensity values have dominated object recognition challenges. These tasks typically have a single centered object per image and existing models are not directly applicable to microscopy datasets. Here we develop an approach that combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) in order to classify and segment microscopy images using only whole image level annotations. Results: We introduce a new neural network architecture that uses MIL to simultaneously classify and segment microscopy images with populations of cells. We base our approach on the similarity between the aggregation function used in MIL and pooling layers used in CNNs. To facilitate aggregating across large numbers of instances in CNN feature maps we present the Noisy-AND pooling function, a new MIL operator that is robust to outliers. Combining CNNs with MIL enables training CNNs using whole microscopy images with image level labels. We show that training end-to-end MIL CNNs outperforms several previous methods on both mammalian and yeast datasets without requiring any segmentation steps. Availability and implementation: Torch7 implementation available upon request. Contact: oren.kraus@mail.utoronto.ca", "PublicationYear": "2015", "Authors": ["Oren Z. Kraus", "Jimmy Ba", "Brendan J. Frey"], "RelatedTopics": ["Computer Science"], "References": ["b6fafb9870efbc0118c1b3e46a3e0a198a88e95e", "a7897e61633a97e648057bee95c082c1aab40d41", "0f84a81f431b18a78bd97f59ed4b9d8eda390970", "09193e19b59fc8f05bee9d6efbfb1607ca5b6501", "ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "39ad6c911f3351a3b390130a6e4265355b4d593b", "b9225378c30ffd018b29efd39316206559ac1bd7", "dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71", "eb42cf88027de515750f230b23b1a057dc782108"], "ReferenceCount": 36, "CitationCount": 369}, {"URL": "https://www.semanticscholar.org/paper/Deep-learning-for-computational-biology-Angermueller-P%C3%A4rnamaa/efd68f3724942c9de5dc804d3c7cb3f70f42234b", "ID": "efd68f3724942c9de5dc804d3c7cb3f70f42234b", "Title": "Deep learning for computational biology", "Abstract": "This review provides background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights, and highlights possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology. Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.", "PublicationYear": "2016", "Authors": ["Christof Angermueller", "Tanel P{\\\"a}rnamaa", "Leopold Parts", "Oliver Stegle"], "RelatedTopics": ["Biology", "Computer Science"], "References": ["9873d43696165b50fab955d27b9dde838c0a0152", "4b733a188198dbff57cb8bd1ec996044fe272ce5", "30501640908567ef13640d82c633b6ac6b265dfc", "4286abc71594117f019a09d3505332ca83b4b6c8", "c051d469f9e9d5550d4633deecdb1ea8b11862dd", "f5bc9fcbf6e46efcd0f0fb4029d1e9fee9c1f172", "cd293c1092d9f88a146ba0b148acd8df117ceb7e", "19bcb1b3fd7cfd8f2e4ea4579effa32d808adb0e", "42d3ae61ca296558cba61446bd95b8a6e5b1082d", "d1f788e9ac58de5d2dc6a3928939b411cf9ec5a6"], "ReferenceCount": 139, "CitationCount": 725}, {"URL": "https://www.semanticscholar.org/paper/Applications%2C-promises%2C-and-pitfalls-of-deep-for-Belthangady-Royer/7dae942104dc8283504ce7a492c9ca12fa119189", "ID": "7dae942104dc8283504ce7a492c9ca12fa119189", "Title": "Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction", "Abstract": "Key questions are discussed, including how to obtain training data, whether discovery of unknown structures is possible, and the danger of inferring unsubstantiated image details. Deep learning is becoming an increasingly important tool for image reconstruction in fluorescence microscopy. We review state-of-the-art applications such as image restoration and super-resolution imaging, and discuss how the latest deep learning research could be applied to other image reconstruction tasks. Despite its successes, deep learning also poses substantial challenges and has limits. We discuss key questions, including how to obtain training data, whether discovery of unknown structures is possible, and the danger of inferring unsubstantiated image details. This Perspective highlights recent applications of deep learning in fluorescence microscopy image reconstruction and discusses future directions and limitations of these approaches.", "PublicationYear": "2018", "Authors": ["Chinmay Belthangady", "Loic A. Royer"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["ce6454d4d63da26e2bab21044409b89d67914078", "1fb42852a47f77d26efdbacbf75cddcb294b5c3d", "7cefad5c41c5d7b6fda64cb2ef701068c615e5d8", "48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852", "56cd4188544b8c00d119d0016fe4aa0c2b569d7a", "6ff93aa6ca902002d16fb0c2d3fb48aead92c61e", "10805953dc97340addf33f99ae97d94438b030e3", "608779346a66affdc04d7587ed98e32ed89baa7d", "44ca841f31c92d022a64c1109623eee6b3be0b8a", "c9e59e4c26618e9b63d9caf13803ca5c7b20b296"], "ReferenceCount": 119, "CitationCount": 325}, {"URL": "https://www.semanticscholar.org/paper/DeepCell-2.0%3A-Automated-cloud-deployment-of-deep-Bannon-Moen/9f7a89bc9b8ebb7152acacc95a84daead92d8f2c", "ID": "9f7a89bc9b8ebb7152acacc95a84daead92d8f2c", "Title": "DeepCell 2.0: Automated cloud deployment of deep learning models for large-scale cellular image analysis", "Abstract": "DeepCell 2.0, an open source library for training and delivering deep learning models with cloud computing, is developed and it is demonstrated that users with suitable training data can train models and analyze data with those models through a web interface. Deep learning is transforming the ability of life scientists to extract information from images. While these techniques have superior accuracy in comparison to conventional approaches and enable previously impossible analyses, their unique hardware and software requirements have prevented widespread adoption by life scientists. To meet this need, we have developed DeepCell 2.0, an open source library for training and delivering deep learning models with cloud computing. This library enables users to configure and manage a cloud deployment of DeepCell 2.0 on all commonly used operating systems. Using single-cell segmentation as a use case, we show that users with suitable training data can train models and analyze data with those models through a web interface. We demonstrate that by matching analysis tasks with their hardware requirements, we can efficiently use computational resources in the cloud and scale those resources to meet demand, significantly reducing the time necessary for large-scale image analysis. By reducing the barriers to entry, this work will empower life scientists to apply deep learning methods to their data. A persistent deployment is available at http://www.deepcell.org.", "PublicationYear": "2018", "Authors": ["Dylan Bannon", "Erick Moen", "Enrico Borba", "Andrew Ho", "I. Camplisson", "Brian Chang", "Erik Osterman", "William Graf", "David Van Valen"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["48cc41c7b2fac21d7bbd2988c5c6a2c5f9744852", "1eab84d51b484d0f79e611979916fa97086e869d", "2bb4e8fe111e7c9269a68282e16b8a63eb193804", "20c97e24db99e4667813051dc1fa3e8f5b4d4983", "e1b3ad532f9346d51578c32dc6b070c9744a8d88", "c5170ea129b176df1d46915d4a0b798b0a38ac50", "9c32a3dfad76a4dae4ed347cde0f19ac07de4c04", "2d8d74c7fd9375b17e9d6123773919b2aa512c56", "713e881b5c3134debf934026edf6f0ba3cb42c3c", "823a46e28dd0006050f6d5f32baefd6e433d8898"], "ReferenceCount": 44, "CitationCount": 28}, {"URL": "https://www.semanticscholar.org/paper/Accurate-Classification-of-Protein-Subcellular-from-P%C3%A4rnamaa-Parts/c051d469f9e9d5550d4633deecdb1ea8b11862dd", "ID": "c051d469f9e9d5550d4633deecdb1ea8b11862dd", "Title": "Accurate Classification of Protein Subcellular Localization from High-Throughput Microscopy Images Using Deep Learning", "Abstract": "An 11-layer neural network is trained on data from mapping thousands of yeast proteins, achieving per cell localization classification accuracy of 91%, and per protein accuracy of 99% on held-out images, which are the most accurate subcellular localization classifications to date. High-throughput microscopy of many single cells generates high-dimensional data that are far from straightforward to analyze. One important problem is automatically detecting the cellular compartment where a fluorescently-tagged protein resides, a task relatively simple for an experienced human, but difficult to automate on a computer. Here, we train an 11-layer neural network on data from mapping thousands of yeast proteins, achieving per cell localization classification accuracy of 91%, and per protein accuracy of 99% on held-out images. We confirm that low-level network features correspond to basic image characteristics, while deeper layers separate localization classes. Using this network as a feature calculator, we train standard classifiers that assign proteins to previously unseen compartments after observing only a small number of training examples. Our results are the most accurate subcellular localization classifications to date, and demonstrate the usefulness of deep learning for high-throughput microscopy.", "PublicationYear": "2016", "Authors": ["Tanel P{\\\"a}rnamaa", "Leopold Parts"], "RelatedTopics": ["Computer Science", "Biology"], "References": ["8ce8ed0c8649d481b6064be25d02ac11404a870f", "7e69f6339d3684adfeec45254fdd73b7e88e5c4e", "b74a1062e55eb4ba865a3cd68c1397cc5aefdc94", "67544e4467432aa001f6fb0e9aadfd3d5aa603e0", "b4626f94678714c172cbaa273564afb68e9937cd", "7bbba97c0dcd3ac659381555da091ede27e18421", "c2c0b60afe277a5b0d965a48cdb5a24eca1dcba9", "c4be616182df8a3e3b5455162743b96c6b120eec", "09193e19b59fc8f05bee9d6efbfb1607ca5b6501", "0cbc480e0d380bbaa04bfb21a396c9e8da6e930e"], "ReferenceCount": 68, "CitationCount": 129}, {"URL": "https://www.semanticscholar.org/paper/Deep-learning-achieves-super-resolution-in-Wang-Rivenson/f140829b7c37fb5d51713f631f720b1c7746d5e7", "ID": "f140829b7c37fb5d51713f631f720b1c7746d5e7", "Title": "Deep learning achieves super-resolution in fluorescence microscopy", "Abstract": "This work presents a deep learning-based method for achieving super-resolution in fluorescence microscopy, which is solely based on training a generative adversarial network, which statistically learns to transform low resolution input images into super-resolved ones. We present a deep learning-based method for achieving super-resolution in fluorescence microscopy. This data-driven approach does not require any numerical models of the imaging process or the estimation of a point spread function, and is solely based on training a generative adversarial network, which statistically learns to transform low resolution input images into super-resolved ones. Using this method, we super-resolve wide-field images acquired with low numerical aperture objective lenses, matching the resolution that is acquired using high numerical aperture objectives. We also demonstrate that diffraction-limited confocal microscopy images can be transformed by the same framework into super-resolved fluorescence images, matching the image resolution acquired with a stimulated emission depletion (STED) microscope. The deep network rapidly outputs these super-resolution images, without any iterations or parameter search, and even works for types of samples that it was not trained for.", "PublicationYear": "2018", "Authors": ["Hongda Wang", "Yair Rivenson", "Yiyin Jin", "Zhensong Wei", "Ronald Gao", "Harun G{\\\"u}nayd\u0131n", "Laurent A. Bentolila", "Aydogan Ozcan"], "RelatedTopics": ["Computer Science", "Engineering", "Physics"], "References": ["1fb42852a47f77d26efdbacbf75cddcb294b5c3d", "56cd4188544b8c00d119d0016fe4aa0c2b569d7a", "6ff93aa6ca902002d16fb0c2d3fb48aead92c61e", "e95c46d3dda815857abb584dd53deb706f8a4dc7", "36e577586bd2e184f1f8939f0abe9d5fe7b36c86", "d8df8e2c10fce631173aae694f017dd136226284", "5fe6c9795bb37bd8d2ee706e45917bff2060fd93", "0f64bc0746bbb8f6f531f494f25e243c62fcf221", "7ff6849bbbb3bbc04c0860b633e301a3552f0c38", "6364fdaa0a0eccd823a779fcdd489173f938e91a"], "ReferenceCount": 46, "CitationCount": 24}, {"URL": "https://www.semanticscholar.org/paper/Stem-cell-motion-tracking-by-using-deep-neural-with-Wang-Mao/054179c80dad0a77249384265677b38e34cb045e", "ID": "054179c80dad0a77249384265677b38e34cb045e", "Title": "Stem cell motion-tracking by using deep neural networks with multi-output", "Abstract": "A deep learning framework with convolutional structure and multi-output layers is proposed for overcoming stem cell tracking problems and demonstrates increased tracking performance and robustness compared with other frequently used methods. The aim of automated stem cell motility analysis is reliable processing and evaluation of cell behaviors such as translocation, mitosis, death, and so on. Cell tracking plays an important role in this research. In practice, tracking stem cells is difficult because they have frequent motion, deformation activities, and small resolution sizes in microscopy images. Previous tracking approaches designed to address this problem have been unable to generalize the rapid morphological deformation of cells in a complex living environment, especially for real-time tracking tasks. Herein, a deep learning framework with convolutional structure and multi-output layers is proposed for overcoming stem cell tracking problems. A convolutional structure is used to learn robust cell features through deep features learned on massive visual data by a transfer learning strategy. With multi-output layers, this framework tracks the cell\u2019s motion and simultaneously detects its mitosis as an assistant task. This improves the generalization ability of the model and facilitates practical applications for stem cell research. The proposed framework, tracking and detection neural networks, also contains a particle filter-based motion model, a specialized cell sampling strategy, and corresponding model update strategy. Its current application to a microscopy image dataset of human stem cells demonstrates increased tracking performance and robustness compared with other frequently used methods. Moreover, mitosis detection performance was verified against manually labeled mitotic events of the tracked cell. Experimental results demonstrate good performance of the proposed framework for addressing problems associated with stem cell tracking.", "PublicationYear": "2019", "Authors": ["Yangxu Wang", "Hua Mao", "Zhang Yi"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["60d5db6c247b4f949c066db7e0a0faf3cfc237d1", "7f5d77be9d6aeda8a00da95798f0a75803dda1e2", "af11f14dff8ea68d0f2a79f9c79a95f4f154dc03", "3bffa23a16c273ac2228a13e65dade6766ce7777", "a3b5c89eee650641f227496758bc8b1f3167458a", "c1cb6b91c30915d66c474ab894cf012b6cbf7309", "30f1f571e15fe5e520bf381665daa5d3ca26654b", "3ab2b44a507c2bf0adfbfbd136af77dd082e7a8f", "c189f2d98d70eb02869eefad0fed5f20f7c03f52", "8cab9cb75d98c6f3c98800bd94cec9016717a648"], "ReferenceCount": 33, "CitationCount": 18}, {"URL": "https://www.semanticscholar.org/paper/Toward-Supervised-Anomaly-Detection-G%C3%B6rnitz-Kloft/f5a951b9596be0df5ad7ede180b405c9e97a65c9", "ID": "f5a951b9596be0df5ad7ede180b405c9e97a65c9", "Title": "Toward Supervised Anomaly Detection", "Abstract": "It is argued that semi-supervised anomaly detection needs to ground on the unsupervised learning paradigm and devise a novel algorithm that meets this requirement and it is shown that the optimization problem has a convex equivalent under relatively mild assumptions. Anomaly detection is being regarded as an unsupervised learning task as anomalies stem from adversarial or unlikely events with unknown distributions. However, the predictive performance of purely unsupervised anomaly detection often fails to match the required detection rates in many tasks and there exists a need for labeled data to guide the model generation. Our first contribution shows that classical semi-supervised approaches, originating from a supervised classifier, are inappropriate and hardly detect new and unknown anomalies. We argue that semi-supervised anomaly detection needs to ground on the unsupervised learning paradigm and devise a novel algorithm that meets this requirement. Although being intrinsically non-convex, we further show that the optimization problem has a convex equivalent under relatively mild assumptions. Additionally, we propose an active learning strategy to automatically filter candidates for labeling. In an empirical study on network intrusion detection data, we observe that the proposed learning methodology requires much less labeled data than the state-of-the-art, while achieving higher detection accuracies.", "PublicationYear": "2014", "Authors": ["Nico G{\\\"o}rnitz", "M. Kloft", "Konrad Rieck", "Ulf Brefeld"], "RelatedTopics": ["Computer Science"], "References": ["e98236e37049b46453c7d78f77c8cfaeefc0bfe9", "d612d7c21d4130a457968273d79c2c2f6946953d", "5f9b6151708f85dddd4a1ab03b82c85850fb73da", "6087667d775e160913277d356554698e63d23be9", "803d421305e07f471f0d0fd278d6043d26763767", "9e23e2881be1fadbfd270e4356ff35c1d060b53e", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "1e8984b6c962011be62b227bc931a067e543337c", "633305d1f4043fcd61df5a688ba496558230a946", "a4c52c6c4c852341304305afe909ab466551d0dc"], "ReferenceCount": 66, "CitationCount": 331}, {"URL": "https://www.semanticscholar.org/paper/Deep-Anomaly-Detection-with-Deviation-Networks-Pang-Shen/f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed", "ID": "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed", "Title": "Deep Anomaly Detection with Deviation Networks", "Abstract": "A novel anomaly detection framework and its instantiation that can be trained substantially more data-efficiently and achieves significantly better anomaly scoring than state-of-the-art competing methods is introduced. Although deep learning has been applied to successfully address many data mining problems, relatively limited work has been done on deep learning for anomaly detection. Existing deep anomaly detection methods, which focus on learning new feature representations to enable downstream anomaly detection methods, perform indirect optimization of anomaly scores, leading to data-inefficient learning and suboptimal anomaly scoring. Also, they are typically designed as unsupervised learning due to the lack of large-scale labeled anomaly data. As a result, they are difficult to leverage prior knowledge (e.g., a few labeled anomalies) when such information is available as in many real-world anomaly detection applications. This paper introduces a novel anomaly detection framework and its instantiation to address these problems. Instead of representation learning, our method fulfills an end-to-end learning of anomaly scores by a neural deviation learning, in which we leverage a few (e.g., multiple to dozens) labeled anomalies and a prior probability to enforce statistically significant deviations of the anomaly scores of anomalies from that of normal data objects in the upper tail. Extensive results show that our method can be trained substantially more data-efficiently and achieves significantly better anomaly scoring than state-of-the-art competing methods.", "PublicationYear": "2019", "Authors": ["Guansong Pang", "Chunhua Shen", "Anton van den Hengel"], "RelatedTopics": ["Computer Science"], "References": ["5f61089d3d548a515f01b473f0119137d1f340d4", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "6af440915b8a0718c93be1cf61905e41e620484a", "83fcb78e3b58c230a051914daac3bfb00482b34c", "267502d21b44884570fcd95a855821cc3e86e6eb", "93790640c42cfd72929af51e9ca13219e4803fca", "dcd9f5d61bc9a70c40be84a8d78fbee822ffcd9e", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "b5781eaafe1aff25a084d83dc38831ea09db42f3", "882e06d18c0fc0645ae559633eb178a7a41cfe79"], "ReferenceCount": 31, "CitationCount": 233}, {"URL": "https://www.semanticscholar.org/paper/Deep-Anomaly-Detection-with-Outlier-Exposure-Hendrycks-Mazeika/2d8c97db4bae00ff243d122b957091a236a697a7", "ID": "2d8c97db4bae00ff243d122b957091a236a697a7", "Title": "Deep Anomaly Detection with Outlier Exposure", "Abstract": "In extensive experiments on natural language processing and small- and large-scale vision tasks, it is found that Outlier Exposure significantly improves detection performance and that cutting-edge generative models trained on CIFar-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; OE is used to mitigate this issue. It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.", "PublicationYear": "2018", "Authors": ["Dan Hendrycks", "Mantas Mazeika", "Thomas G. Dietterich"], "RelatedTopics": ["Computer Science"], "References": ["4dcdae25a5e33682953f0853ee4cf7ca93be58a9", "54d2b5c64a67f65c5dd812b89e07973f97699552", "431ba9fae8fccad1665979d455c6307786e47318", "36653f8705b56e39642bcd123494eb680cd1636b", "d65ce2b8300541414bfe51d03906fca72e93523c", "1c4e9156ca07705531e45960b7a919dc473abb51", "123df44051ac8170a5cd60abd17c0e404e23955f", "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b", "b022f2a277a4bf5f42382e86e4380b96340b9e86", "8388f1be26329fa45e5807e968a641ce170ea078"], "ReferenceCount": 53, "CitationCount": 1117}, {"URL": "https://www.semanticscholar.org/paper/A-Hybrid-Semi-Supervised-Anomaly-Detection-Model-Song-Jiang/ca4edb65a0664804e4819c5c809d0dfba9bdb2df", "ID": "ca4edb65a0664804e4819c5c809d0dfba9bdb2df", "Title": "A Hybrid Semi-Supervised Anomaly Detection Model for High-Dimensional Data", "Abstract": "A hybrid semi-supervised anomaly detection model for high-dimensional data that consists of a deep autoencoder (DAE) and an ensemble k-nearest neighbor graphs- (K-NNG-) based anomaly detector is proposed. Anomaly detection, which aims to identify observations that deviate from a nominal sample, is a challenging task for high-dimensional data. Traditional distance-based anomaly detection methods compute the neighborhood distance between each observation and suffer from the curse of dimensionality in high-dimensional space; for example, the distances between any pair of samples are similar and each sample may perform like an outlier. In this paper, we propose a hybrid semi-supervised anomaly detection model for high-dimensional data that consists of two parts: a deep autoencoder (DAE) and an ensemble k-nearest neighbor graphs- (K-NNG-) based anomaly detector. Benefiting from the ability of nonlinear mapping, the DAE is first trained to learn the intrinsic features of a high-dimensional dataset to represent the high-dimensional data in a more compact subspace. Several nonparametric KNN-based anomaly detectors are then built from different subsets that are randomly sampled from the whole dataset. The final prediction is made by all the anomaly detectors. The performance of the proposed method is evaluated on several real-life datasets, and the results confirm that the proposed hybrid model improves the detection accuracy and reduces the computational complexity.", "PublicationYear": "2017", "Authors": ["Hongchao Song", "Zhuqing Jiang", "Aidong Men", "Bo Yang"], "RelatedTopics": ["Computer Science"], "References": ["f076e4355c0facf111716dcab2837803367dd2d8", "a8ad5657a52f549523fb5608c7a78801e8b7a950", "45cdc0c64f3c690c734c7022f22f2973986c356a", "43eced5f4cd0fc76975b97d7ce9664c8488174e2", "dcb207ce848b358aeb2e4698c9ea1ad273ce98db", "71df4b737c35fb3d05f44036419e78b5330b580f", "dcafe812c7f0ec094b25f32fe71010cad7323797", "b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b", "e3116ebb52c152deae918a04c34441ac0d956b8a", "8f923ad5bb95f67cd51f1de0a16c2c794cee2b29"], "ReferenceCount": 43, "CitationCount": 100}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-for-Anomaly-Detection%3A-A-Survey-Chalapathy-Chawla/a2e667e4382aaa8e02a17d0522c1a910790ab65b", "ID": "a2e667e4382aaa8e02a17d0522c1a910790ab65b", "Title": "Deep Learning for Anomaly Detection: A Survey", "Abstract": "A structured and comprehensive overview of research methods in deep learning-based anomaly detection, grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.", "PublicationYear": "2019", "Authors": ["Raghavendra Chalapathy", "Sanjay Chawla"], "RelatedTopics": ["Computer Science"], "References": ["a9d7904a78d6c4df31e003c9df55c78a9ca485de", "10a498003e9204f5fc1328e706510a37e514d8c7", "f3bf9356fefb63c9d04fd2f74e947a34f691969e", "f16b23e8e0788e3298e533e71bafef7135300a5e", "f6904e4f58aedbd26a257491b0bfedd74e331417", "1d4ec24a6da3be62dc5d7efbae2a101c63f187e8", "030dff9a7cba9b85be1fec18a895c86673264680", "69e460953d9b13aded4d906b974c0d80c1ceaef7", "d100f625580dd6df123c69abff1d094e2d745613", "355692eb86b06a0a23af45c106cfb02c95bf380e"], "ReferenceCount": 477, "CitationCount": 1197}, {"URL": "https://www.semanticscholar.org/paper/High-dimensional-and-large-scale-anomaly-detection-Erfani-Rajasegarar/f076e4355c0facf111716dcab2837803367dd2d8", "ID": "f076e4355c0facf111716dcab2837803367dd2d8", "Title": "High-dimensional and large-scale anomaly detection using a linear one-class SVM with deep learning", "Abstract": "Semantic Scholar extracted view of \\\"High-dimensional and large-scale anomaly detection using a linear one-class SVM with deep learning\\\" by S. Erfani et al.", "PublicationYear": "2016", "Authors": ["Sarah Monazam Erfani", "Sutharshan Rajasegarar", "Shanika Karunasekera", "Christopher Leckie"], "RelatedTopics": ["Computer Science"], "References": ["869a75dc4a7c54b940dcb07ada1a845c027e7350", "45e9cd822e6c285232a2a097ae485f384bfe6e34", "1430b115443d524b1a09c09172eb6152100b4e80", "0a230009eb4196214bfb5a3e678a419e3f8896fe", "5578f3d9e6931c3762b2275f5265113e8f94369a", "96c9f11fd9901f2edeaab8cf6bbff2590cea93c4", "cf03fdf52dd6e4249cbbdbd0bffbbbe5ca389feb", "e65bfaf266289c3932996799999633dd9e7539d4", "b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b", "aea23355420b2a679d2d6f0e6cc01f4a153710cb"], "ReferenceCount": 64, "CitationCount": 884}, {"URL": "https://www.semanticscholar.org/paper/Anomaly-Detection-using-One-Class-Neural-Networks-Chalapathy-Menon/67b9c2b376a01d8757dc6d704be450d1c46c4ced", "ID": "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "Title": "Anomaly Detection using One-Class Neural Networks", "Abstract": "A comprehensive set of experiments demonstrate that on complex data sets (like CIFAR and PFAM), OC-NN significantly outperforms existing state-of-the-art anomaly detection methods. We propose a one-class neural network (OC-NN) model to detect anomalies in complex data sets. OC-NN combines the ability of deep networks to extract a progressively rich representation of data with the one-class objective of creating a tight envelope around normal data. The OC-NN approach breaks new ground for the following crucial reason: data representation in the hidden layer is driven by the OC-NN objective and is thus customized for anomaly detection. This is a departure from other approaches which use a hybrid approach of learning deep features using an autoencoder and then feeding the features into a separate anomaly detection method like one-class SVM (OC-SVM). The hybrid OC-SVM approach is sub-optimal because it is unable to influence representational learning in the hidden layers. A comprehensive set of experiments demonstrate that on complex data sets (like CIFAR and GTSRB), OC-NN performs on par with state-of-the-art methods and outperformed conventional shallow methods in some scenarios.", "PublicationYear": "2018", "Authors": ["Raghavendra Chalapathy", "Aditya Krishna Menon", "Sanjay Chawla"], "RelatedTopics": ["Computer Science"], "References": ["f076e4355c0facf111716dcab2837803367dd2d8", "6af440915b8a0718c93be1cf61905e41e620484a", "1d4ec24a6da3be62dc5d7efbae2a101c63f187e8", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "88f761749f5ac789f84b19ed0cff75c131dd8a29", "c53352a4239568cc915ad968aff51c49924a3072", "00a1077d298f2917d764eb729ab1bc86af3bd241", "081651b38ff7533550a3adfc1c00da333a8fe86c", "995c5f5e62614fcb4d2796ad2faab969da51713e", "527cc8cd2af06a9ac2e5cded806bab5c3faad9cf"], "ReferenceCount": 46, "CitationCount": 352}, {"URL": "https://www.semanticscholar.org/paper/Image-Anomaly-Detection-with-Generative-Adversarial-Deecke-Vandermeulen/3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "ID": "3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "Title": "Image Anomaly Detection with Generative Adversarial Networks", "Abstract": "This work proposes a novel approach to anomaly detection using generative adversarial networks, based on searching for a good representation of that sample in the latent space of the generator; if such a representation is not found, the sample is deemed anomalous. Many anomaly detection methods exist that perform well on low-dimensional problems however there is a notable lack of effective methods for high-dimensional spaces, such as images. Inspired by recent successes in deep learning we propose a novel approach to anomaly detection using generative adversarial networks. Given a sample under consideration, our method is based on searching for a good representation of that sample in the latent space of the generator; if such a representation is not found, the sample is deemed anomalous. We achieve state-of-the-art performance on standard image benchmark datasets and visual inspection of the most anomalous samples reveals that our method does indeed return anomalies.", "PublicationYear": "2018", "Authors": ["Lucas Deecke", "Robert A. Vandermeulen", "Lukas Ruff", "Stephan Mandt", "M. Kloft"], "RelatedTopics": ["Computer Science"], "References": ["6af440915b8a0718c93be1cf61905e41e620484a", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "8388f1be26329fa45e5807e968a641ce170ea078", "74ff6d48f9c62e937023106629d27ef2d2ddf8bc", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "e2ef0f1a528cd0f415be8265a04466a6d3f74e6c", "9a700c7a7e7468e436f00c34551fbe3e0f70e42f", "86ee1835a56722b76564119437070782fc90eb19"], "ReferenceCount": 52, "CitationCount": 182}, {"URL": "https://www.semanticscholar.org/paper/Enhancing-The-Reliability-of-Out-of-distribution-in-Liang-Li/547c854985629cfa9404a5ba8ca29367b5f8c25f", "ID": "547c854985629cfa9404a5ba8ca29367b5f8c25f", "Title": "Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks", "Abstract": "The proposed ODIN method, based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in- and out-of-distribution images, allowing for more effective detection, consistently outperforms the baseline approach by a large margin. We consider the problem of detecting out-of-distribution images in neural networks. We propose ODIN, a simple and effective method that does not require any change to a pre-trained neural network. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in- and out-of-distribution images, allowing for more effective detection. We show in a series of experiments that ODIN is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach by a large margin, establishing a new state-of-the-art performance on this task. For example, ODIN reduces the false positive rate from the baseline 34.7% to 4.3% on the DenseNet (applied to CIFAR-10) when the true positive rate is 95%.", "PublicationYear": "2017", "Authors": ["Shiyu Liang", "Yixuan Li", "Rayadurgam Srikant"], "RelatedTopics": ["Computer Science"], "References": ["eb42cf88027de515750f230b23b1a057dc782108", "6259b02912cebc224f3a2b1324e811a152a0177d", "6ff2a434578ff2746b9283e45abf296887f48a2d", "4dcdae25a5e33682953f0853ee4cf7ca93be58a9", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "4543670c4b2d88a9b67525e0084044adef94ae76", "d65ce2b8300541414bfe51d03906fca72e93523c", "5d90f06bb70a0a3dced62413346235c02b1aa086", "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad"], "ReferenceCount": 54, "CitationCount": 1518}, {"URL": "https://www.semanticscholar.org/paper/Model-selection-for-anomaly-detection-Burnaev-Erofeev/c72e91b2e5c103f529510fa15a156d61c5633da1", "ID": "c72e91b2e5c103f529510fa15a156d61c5633da1", "Title": "Model selection for anomaly detection", "Abstract": "This paper generalizes several kernel selection methods from binary-class case to the case of one-class classification and performs extensive comparison of these approaches using both synthetic and real-world data. Anomaly detection based on one-class classification algorithms is broadly used in many applied domains like image processing (e.g. detection of whether a patient is \u201ccancerous\u201d or \u201chealthy\u201d from mammography image), network intrusion detection, etc. Performance of an anomaly detection algorithm crucially depends on a kernel, used to measure similarity in a feature space. The standard approaches (e.g. cross-validation) for kernel selection, used in two-class classification problems, can not be used directly due to the specific nature of a data (absence of a second, abnormal, class data). In this paper we generalize several kernel selection methods from binary-class case to the case of one-class classification and perform extensive comparison of these approaches using both synthetic and real-world data.", "PublicationYear": "2015", "Authors": ["Evgeny Burnaev", "Pavel Erofeev", "Dmitry Smolyakov"], "RelatedTopics": ["Computer Science"], "References": ["153a99ad39e85eb09f6ae56b1eb72795265cb8a0", "4c65c5f32a8c47505f763b00c4e65a859856a3b3", "0407271bfd724bf397a44b5d146a400a2a39d9c3", "633f7d2b4014e3213c6eabfd6b157d14803dad2e", "44e4ae2fa3e71934e66f6c7996bd585b67ae103c", "7e2fd9c6205613c4858b36ebb4e1b655d915c099", "9fb8a2911f3d93c9f7ae4468990df944463e80ed", "8cb44f06586f609a29d9b496cc752ec01475dffe", "b94d0d78b705aafff7bc77174059f1921e6c5a77", "9cd3539312f5ddc59d9af2eab18f2834d44d76f5"], "ReferenceCount": 13, "CitationCount": 32}, {"URL": "https://www.semanticscholar.org/paper/Deep-Structured-Energy-Based-Models-for-Anomaly-Zhai-Cheng/10a498003e9204f5fc1328e706510a37e514d8c7", "ID": "10a498003e9204f5fc1328e706510a37e514d8c7", "Title": "Deep Structured Energy Based Models for Anomaly Detection", "Abstract": "This paper proposes deep structured energy based models (DSEBMs), where the energy function is the output of a deterministic deep neural network with structure, and develops novel model architectures to integrate EBMs with different types of data such as static data, sequential data, and spatial data. In this paper, we attack the anomaly detection problem by directly modeling the data distribution with deep architectures. We propose deep structured energy based models (DSEBMs), where the energy function is the output of a deterministic deep neural network with structure. We develop novel model architectures to integrate EBMs with different types of data such as static data, sequential data, and spatial data, and apply appropriate model architectures to adapt to the data structure. Our training algorithm is built upon the recent development of score matching \\\\cite{sm}, which connects an EBM with a regularized autoencoder, eliminating the need for complicated sampling method. Statistically sound decision criterion can be derived for anomaly detection purpose from the perspective of the energy landscape of the data distribution. We investigate two decision criteria for performing anomaly detection: the energy score and the reconstruction error. Extensive empirical studies on benchmark tasks demonstrate that our proposed model consistently matches or outperforms all the competing methods.", "PublicationYear": "2016", "Authors": ["Shuangfei Zhai", "Yu Cheng", "Weining Lu", "Zhongfei Zhang"], "RelatedTopics": ["Computer Science"], "References": ["72d9aa4abe4f8fd812377ee3595f13c314e0baa0", "2d851f681f82c71a934aebd16e8112adf1239f85", "4549ebd94667461cdcccadd4147c6f5fe54d6879", "7fc604e1a3e45cd2d2742f96d62741930a363efa", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "b68c34c55925a75804f97491b745de66b1ffc4be", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "390132e92cd34b912c56fd53dc086d53abb8780e", "abd1c342495432171beb7ca8fd9551ef13cbd0ff"], "ReferenceCount": 28, "CitationCount": 385}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Anomaly-Detection-with-Generative-to-Schlegl-Seeb%C3%B6ck/e163a2e89c136cb4442e34c72f7173a0ff46dc79", "ID": "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "Title": "Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery", "Abstract": "AnoGAN, a deep convolutional generative adversarial network is proposed to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.", "PublicationYear": "2017", "Authors": ["Thomas Schlegl", "Philipp Seeb{\\\"o}ck", "Sebastian M. Waldstein", "Ursula Margarethe Schmidt-Erfurth", "Georg Langs"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["45f490710b4dd6697dba4c9b385a49554501711a", "84f7f9e121c1285e15cefbfc44bcb3322f73b6aa", "75a838cbc1541858b9c484001cade327640dc280", "05dc42d9262c0ba8dd2d3a3798a2ce1e233cd3cc", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "8388f1be26329fa45e5807e968a641ce170ea078", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "571b0750085ae3d939525e62af510ee2cee9d5ea", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "f076e4355c0facf111716dcab2837803367dd2d8"], "ReferenceCount": 20, "CitationCount": 1798}, {"URL": "https://www.semanticscholar.org/paper/Variational-Autoencoder-based-Anomaly-Detection-An-Cho/061146b1d7938d7a8dae70e3531a00fceb3c78e8", "ID": "061146b1d7938d7a8dae70e3531a00fceb3c78e8", "Title": "Variational Autoencoder based Anomaly Detection using Reconstruction Probability", "Abstract": "The reconstruction probability has a theoretical background making it a more principled and objective anomaly score than the reconstruction error, which is used by autoencoder and principal components based anomaly detection methods. We propose an anomaly detection method using the reconstruction probability from the variational autoencoder. The reconstruction probability is a probabilistic measure that takes into account the variability of the distribution of variables. The reconstruction probability has a theoretical background making it a more principled and objective anomaly score than the reconstruction error, which is used by autoencoder and principal components based anomaly detection methods. Experimental results show that the proposed method outperforms autoencoder based and principal components based methods. Utilizing the generative characteristics of the variational autoencoder enables deriving the reconstruction of the data to analyze the underlying cause of the anomaly.", "PublicationYear": "2015", "Authors": ["Jinwon An", "Sungzoon Cho"], "RelatedTopics": ["Computer Science"], "References": ["43ad00536ded47beec2d3c63ca4370840752f10b", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "6bacf99c87991523a97165610b492f28c8cacbb2", "484ad17c926292fbe0d5211540832a8c8a8e958b", "2964d30862d0402b0d0ad4a427067f69e4a52130", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "66ad2fbc8b73242a889699868611fcf239e3435d", "195d0a8233a7a46329c742eaff56c276f847fadc", "375d7b8a70277d5d7b5e0cc999b03ba395c42901", "9ceb1dea15ac3df3d610fd0b3cc52b9a4e9141a3"], "ReferenceCount": 16, "CitationCount": 1122}, {"URL": "https://www.semanticscholar.org/paper/Anomaly-detection%3A-A-survey-Chandola-Banerjee/71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "ID": "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "Title": "Anomaly detection: A survey", "Abstract": "This survey tries to provide a structured and comprehensive overview of the research on anomaly detection by grouping existing techniques into different categories based on the underlying approach adopted by each technique. Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.", "PublicationYear": "2009", "Authors": ["Varun Chandola", "Arindam Banerjee", "Vipin Kumar"], "RelatedTopics": ["Computer Science"], "References": ["fe04438184800230074ca343785da8985682d6c9", "a1345a6a94b10273c2a0246d972f3b961685b702", "153a99ad39e85eb09f6ae56b1eb72795265cb8a0", "863efef58318bdc21986470200f6d4f2d206e039", "62fdd44b8048848c5bd25cab55ff4913215da731", "a8c065c45e557ef1c5b831b43915fd8497ce3c32", "0195d819d26355e714007d8a4bce04d0700312ed", "441c26ac495a92e4020d04f5b70113045da9f862", "63b23d8fac97dd64a878471b5d2b08514f511569", "0da52a5651004a7fe0411b036cf898914b672e79"], "ReferenceCount": 399, "CitationCount": 9874}, {"URL": "https://www.semanticscholar.org/paper/Semi-Supervised-Novelty-Detection-Blanchard-Lee/d612d7c21d4130a457968273d79c2c2f6946953d", "ID": "d612d7c21d4130a457968273d79c2c2f6946953d", "Title": "Semi-Supervised Novelty Detection", "Abstract": "It is argued that novelty detection in this semi-supervised setting is naturally solved by a general reduction to a binary classification problem and provides a general solution to the general two-sample problem, that is, the problem of determining whether two random samples arise from the same distribution. A common setting for novelty detection assumes that labeled examples from the nominal class are available, but that labeled examples of novelties are unavailable. The standard (inductive) approach is to declare novelties where the nominal density is low, which reduces the problem to density level set estimation. In this paper, we consider the setting where an unlabeled and possibly contaminated sample is also available at learning time. We argue that novelty detection in this semi-supervised setting is naturally solved by a general reduction to a binary classification problem. In particular, a detector with a desired false positive rate can be achieved through a reduction to Neyman-Pearson classification. Unlike the inductive approach, semi-supervised novelty detection (SSND) yields detectors that are optimal (e.g., statistically consistent) regardless of the distribution on novelties. Therefore, in novelty detection, unlabeled data have a substantial impact on the theoretical properties of the decision rule. We validate the practical utility of SSND with an extensive experimental study. We also show that SSND provides distribution-free, learning-theoretic solutions to two well known problems in hypothesis testing. First, our results provide a general solution to the general two-sample problem, that is, the problem of determining whether two random samples arise from the same distribution. Second, a specialization of SSND coincides with the standard p-value approach to multiple testing under the so-called random effects model. Unlike standard rejection regions based on thresholded p-values, the general SSND framework allows for adaptation to arbitrary alternative distributions in multiple dimensions.", "PublicationYear": "2010", "Authors": ["Gilles Blanchard", "Gyemin Lee", "Clayton D. Scott"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["c8c8c29c231a7658c03613a5c7dcd8b136d4c79a", "1d844bb8b556a795115144e0264b44d7f68b841a", "13bacb18ed105ee7adb4355c7a40bedddb8f563a", "153a99ad39e85eb09f6ae56b1eb72795265cb8a0", "2a69315ff7e0eb8b815810922f2ef0374f99acd0", "5b7addfb161b6e43937c9b8db3c85f10de671d0c", "41d9b4104b6d8cb8c135560b5f775bc8cd7a720d", "8d714eb3d004a8a5f8981e246d5098fabdcf9a3a", "536845bbf379fd380ea2485aa883163205b0210d", "5a002b24c0a8a63527a8c0e0681d4747e227aa6f"], "ReferenceCount": 40, "CitationCount": 264}, {"URL": "https://www.semanticscholar.org/paper/Training-Adversarial-Discriminators-for-Abnormal-in-Ravanbakhsh-Sangineto/e399a626ba21fafb19b3661603ec9724058e951b", "ID": "e399a626ba21fafb19b3661603ec9724058e951b", "Title": "Training Adversarial Discriminators for Cross-Channel Abnormal Event Detection in Crowds", "Abstract": "Generative Adversarial Nets (GANs), which are trained to generate only the normal distribution of the data, are proposed, which outperforms previous state-of-the-art methods in both the frame-level and the pixel-level evaluation. Abnormal crowd behaviour detection attracts a large interest due to its importance in video surveillance scenarios. However, the ambiguity and the lack of sufficient abnormal ground truth data makes end-to-end training of large deep networks hard in this domain. In this paper we propose to use Generative Adversarial Nets (GANs), which are trained to generate only the normal distribution of the data. During the adversarial GAN training, a discriminator (D) is used as a supervisor for the generator network (G) and vice versa. At testing time we use D to solve our discriminative task (abnormality detection), where D has been trained without the need of manually-annotated abnormal data. Moreover, in order to prevent G learn a trivial identity function, we use a cross-channel approach, forcing G to transform raw-pixel data in motion information and vice versa. The quantitative results on standard benchmarks show that our method outperforms previous state-of-the-art methods in both the frame-level and the pixel-level evaluation.", "PublicationYear": "2017", "Authors": ["Mahdyar Ravanbakhsh", "E. Sangineto", "Moin Nabi", "N. Sebe"], "RelatedTopics": ["Computer Science"], "References": ["9d5290fadb7625862a966e0330bd0f9e111fc99d", "7d8755284169f6f721e046798df1eeb1170ebdd0", "571b0750085ae3d939525e62af510ee2cee9d5ea", "89b4fb65abb4a81bc492c3b686f5dfc5f175546d", "6259b02912cebc224f3a2b1324e811a152a0177d", "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "97e7c94a78ae17cfb90848c1cfca8c431082a7b2", "6f68ce1e03c56c186256dac689a21f6405ae8d96", "e5366a704ffa3b41aacd385f3c087ec3fd566934", "655b1f83ef218ee6a030b5541d2865bc6599e6d9"], "ReferenceCount": 37, "CitationCount": 175}, {"URL": "https://www.semanticscholar.org/paper/Inverting-the-Generator-of-a-Generative-Adversarial-Creswell-Bharath/559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "ID": "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "Title": "Inverting the Generator of a Generative Adversarial Network", "Abstract": "This paper introduces a technique, inversion, to project data samples, specifically images, to the latent space using a pretrained GAN, and demonstrates how the proposed inversion technique may be used to quantitatively compare the performance of various GAN models trained on three image data sets. Generative adversarial networks (GANs) learn a deep generative model that is able to synthesize novel, high-dimensional data samples. New data samples are synthesized by passing latent samples, drawn from a chosen prior distribution, through the generative model. Once trained, the latent space exhibits interesting properties that may be useful for downstream tasks such as classification or retrieval. Unfortunately, GANs do not offer an \u201cinverse model,\u201d a mapping from data space back to latent space, making it difficult to infer a latent representation for a given data sample. In this paper, we introduce a technique, inversion, to project data samples, specifically images, to the latent space using a pretrained GAN. Using our proposed inversion technique, we are able to identify which attributes of a data set a trained GAN is able to model and quantify GAN performance, based on a reconstruction loss. We demonstrate how our proposed inversion technique may be used to quantitatively compare the performance of various GAN models trained on three image data sets. We provide codes for all of our experiments in the website (https://github.com/ToniCreswell/InvertingGAN).", "PublicationYear": "2016", "Authors": ["Antonia Creswell", "Anil Anthony Bharath"], "RelatedTopics": ["Computer Science"], "References": ["39b8f34e71553622bb16b547211d0d769563c61d", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "571b0750085ae3d939525e62af510ee2cee9d5ea", "81d5740cac256489978c2751e867128e97620eae", "6de1299a192fdb852846e3cfa4a428b8fe81523f", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "edf73ab12595c6709f646f542a0d2b33eb20a3f4", "eb7ee0bc355652654990bcf9f92f124688fde493", "744fe47157477235032f7bb3777800f9f2f45e52", "32c09d2933a4638b034343f9be20544dacf6031f"], "ReferenceCount": 28, "CitationCount": 293}, {"URL": "https://www.semanticscholar.org/paper/Inverting-The-Generator-Of-A-Generative-Adversarial-Creswell-Bharath/39b8f34e71553622bb16b547211d0d769563c61d", "ID": "39b8f34e71553622bb16b547211d0d769563c61d", "Title": "Inverting The Generator Of A Generative Adversarial Network (II)", "Abstract": "This paper introduces a technique, inversion, to project data samples, specifically images, to the latent space using a pre-trained GAN, and demonstrates how the proposed inversion technique may be used to quantitatively compare performance of various GAN models trained on three image datasets. Generative adversarial networks (GANs) learn a deep generative model that is able to synthesise novel, high-dimensional data samples. New data samples are synthesised by passing latent samples, drawn from a chosen prior distribution, through the generative model. Once trained, the latent space exhibits interesting properties, that may be useful for down stream tasks such as classification or retrieval. Unfortunately, GANs do not offer an \\\"inverse model\\", "PublicationYear": "2018", "Authors": ["Antonia Creswell", "Anil Anthony Bharath"], "RelatedTopics": ["Computer Science"], "References": ["1db6e3078597386ac4222ba6c3f4f61b61f53539", "571b0750085ae3d939525e62af510ee2cee9d5ea", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "6de1299a192fdb852846e3cfa4a428b8fe81523f", "13bc4e683075bdd6a3f0155241c276a772d4aa06", "eb7ee0bc355652654990bcf9f92f124688fde493", "458039cf3eafd40ce27f6d6cae557753f50e51b1", "8388f1be26329fa45e5807e968a641ce170ea078", "9a700c7a7e7468e436f00c34551fbe3e0f70e42f", "fc7822f56dd255a872326b9536a0821bbf0277dd"], "ReferenceCount": 16, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Adversarial-Autoencoders-Makhzani-Shlens/c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "ID": "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "Title": "Adversarial Autoencoders", "Abstract": "It is shown how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. In this paper, we propose the\\\"adversarial autoencoder\\\"(AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.", "PublicationYear": "2015", "Authors": ["Alireza Makhzani", "Jonathon Shlens", "Navdeep Jaitly", "Ian J. Goodfellow"], "RelatedTopics": ["Computer Science"], "References": ["2904a9932f4cd0f0886121dc1f2d4aaac0455176", "543f21d81bbea89f901dfcc01f4e332a9af6682d", "3e47c4c2dd98c49b7771c7228812d5fd9eee56a3", "d450b0f12ae0437048e4047a630c31d902002d0c", "5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d", "729b18d8d91035f4bb84bf2e61b0517824e5d31b", "6bacf99c87991523a97165610b492f28c8cacbb2", "39e0c341351f8f4a39ac890b96217c7f4bde5369", "995c5f5e62614fcb4d2796ad2faab969da51713e", "f6f5ca064e91b7836f728e313d0c92666756914d"], "ReferenceCount": 26, "CitationCount": 1925}, {"URL": "https://www.semanticscholar.org/paper/Improved-Techniques-for-Training-GANs-Salimans-Goodfellow/571b0750085ae3d939525e62af510ee2cee9d5ea", "ID": "571b0750085ae3d939525e62af510ee2cee9d5ea", "Title": "Improved Techniques for Training GANs", "Abstract": "This work focuses on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic, and presents ImageNet samples with unprecedented resolution and shows that the methods enable the model to learn recognizable features of ImageNet classes. We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.", "PublicationYear": "2016", "Authors": ["Tim Salimans", "Ian J. Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "RelatedTopics": ["Computer Science"], "References": ["2904a9932f4cd0f0886121dc1f2d4aaac0455176", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "4e2f6b4bc889eed1afe5833d5190f6f02e501061", "a9d83b30c3e615286d3e24b6a2e2228872b39bc8", "32c09d2933a4638b034343f9be20544dacf6031f", "d450b0f12ae0437048e4047a630c31d902002d0c", "543f21d81bbea89f901dfcc01f4e332a9af6682d", "b321e8eca4dbf424a9e30dd938fb423786c90b76", "4cd168514e9638e0212d130c382d78044e2b262a", "23ffaa0fe06eae05817f527a47ac3291077f9e58"], "ReferenceCount": 28, "CitationCount": 7506}, {"URL": "https://www.semanticscholar.org/paper/Adversarially-Learned-Inference-Dumoulin-Belghazi/fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "ID": "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "Title": "Adversarially Learned Inference", "Abstract": "The adversarially learned inference (ALI) model is introduced, which jointly learns a generation network and an inference network using an adversarial process and the usefulness of the learned representations is confirmed by obtaining a performance competitive with state-of-the-art on the semi-supervised SVHN and CIFAR10 tasks. We introduce the adversarially learned inference (ALI) model, which jointly learns a generation network and an inference network using an adversarial process. The generation network maps samples from stochastic latent variables to the data space while the inference network maps training examples in data space to the space of latent variables. An adversarial game is cast between these two networks and a discriminative network is trained to distinguish between joint latent/data-space samples from the generative network and joint samples from the inference network. We illustrate the ability of the model to learn mutually coherent inference and generation networks through the inspections of model samples and reconstructions and confirm the usefulness of the learned representations by obtaining a performance competitive with state-of-the-art on the semi-supervised SVHN and CIFAR10 tasks.", "PublicationYear": "2016", "Authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Mart{\\'i}n Arjovsky", "Olivier Mastropietro", "Aaron C. Courville"], "RelatedTopics": ["Computer Science"], "References": ["1db6e3078597386ac4222ba6c3f4f61b61f53539", "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "eb7ee0bc355652654990bcf9f92f124688fde493", "543f21d81bbea89f901dfcc01f4e332a9af6682d", "8388f1be26329fa45e5807e968a641ce170ea078", "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "571b0750085ae3d939525e62af510ee2cee9d5ea", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "729b18d8d91035f4bb84bf2e61b0517824e5d31b", "5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d"], "ReferenceCount": 44, "CitationCount": 1240}, {"URL": "https://www.semanticscholar.org/paper/Adversarial-Feature-Learning-Donahue-Kr%C3%A4henb%C3%BChl/1db6e3078597386ac4222ba6c3f4f61b61f53539", "ID": "1db6e3078597386ac4222ba6c3f4f61b61f53539", "Title": "Adversarial Feature Learning", "Abstract": "Bidirectional Generative Adversarial Networks are proposed as a means of learning the inverse mapping of GANs, and it is demonstrated that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning. The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.", "PublicationYear": "2016", "Authors": ["Jeff Donahue", "Philipp Kr{\\\"a}henb{\\\"u}hl", "Trevor Darrell"], "RelatedTopics": ["Computer Science"], "References": ["fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "8388f1be26329fa45e5807e968a641ce170ea078", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "b8de958fead0d8a9619b55c7299df3257c624a96", "fc1b1c9364c58ec406f494dd944b609a6a038ba6", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "c3af47db3186691270192d5399bb5259e05c87a7", "2ec8f7e0257a07d3914322b36072d1bbcd58a1e0"], "ReferenceCount": 36, "CitationCount": 1678}, {"URL": "https://www.semanticscholar.org/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/86ee1835a56722b76564119437070782fc90eb19", "ID": "86ee1835a56722b76564119437070782fc90eb19", "Title": "Generative Adversarial Nets", "Abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.", "PublicationYear": "2014", "Authors": ["Ian J. Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron C. Courville", "Yoshua Bengio"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d", "23b80dc704e25cf52b5a14935002fc083ce9c317", "6bf0414dae4f10c7e54fb9e5e8af5d0d0cab290b", "d9704f8119d6ba748230b4f2ad59f0e8c64fdfb0", "695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864", "5d90f06bb70a0a3dced62413346235c02b1aa086", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "6bacf99c87991523a97165610b492f28c8cacbb2", "484ad17c926292fbe0d5211540832a8c8a8e958b"], "ReferenceCount": 35, "CitationCount": 769}, {"URL": "https://www.semanticscholar.org/paper/Context-Encoders%3A-Feature-Learning-by-Inpainting-Pathak-Kr%C3%A4henb%C3%BChl/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "ID": "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "Title": "Context Encoders: Feature Learning by Inpainting", "Abstract": "It is found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures, and can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods. We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders - a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.", "PublicationYear": "2016", "Authors": ["Deepak Pathak", "Philipp Kr{\\\"a}henb{\\\"u}hl", "Jeff Donahue", "Trevor Darrell", "Alexei A. Efros"], "RelatedTopics": ["Computer Science"], "References": ["fc1b1c9364c58ec406f494dd944b609a6a038ba6", "6d4ff172c2d1820f33c0c72286d52b846ab5a216", "b8de958fead0d8a9619b55c7299df3257c624a96", "c3af47db3186691270192d5399bb5259e05c87a7", "8388f1be26329fa45e5807e968a641ce170ea078", "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "843959ffdccf31c6694d135fad07425924f785b1", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "d0a8b5cf98b6721b743571ee13e6032ff5598aea", "c426ba865e9158a0f7962a86a50575aa943051b1"], "ReferenceCount": 42, "CitationCount": 4665}, {"URL": "https://www.semanticscholar.org/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c", "ID": "eb60fe884c53b420edbce57059b242cfcbae0f7c", "Title": "Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain MR Images", "Abstract": "This work shows that deep spatial autoencoding models can be efficiently used to capture normal anatomical variability of entire 2D brain MR images and shows that constraints on the latent space and adversarial training can further improve the segmentation performance over standard deep representation learning. Reliably modeling normality and differentiating abnormal appearances from normal cases is a very appealing approach for detecting pathologies in medical images. A plethora of such unsupervised anomaly detection approaches has been made in the medical domain, based on statistical methods, content-based retrieval, clustering and recently also deep learning. Previous approaches towards deep unsupervised anomaly detection model patches of normal anatomy with variants of Autoencoders or GANs, and detect anomalies either as outliers in the learned feature space or from large reconstruction errors. In contrast to these patch-based approaches, we show that deep spatial autoencoding models can be efficiently used to capture normal anatomical variability of entire 2D brain MR images. A variety of experiments on real MR data containing MS lesions corroborates our hypothesis that we can detect and even delineate anomalies in brain MR images by simply comparing input images to their reconstruction. Results show that constraints on the latent space and adversarial training can further improve the segmentation performance over standard deep representation learning.", "PublicationYear": "2018", "Authors": ["Christoph Baur", "Benedikt Wiestler", "Shadi Albarqouni", "Nassir Navab"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["e163a2e89c136cb4442e34c72f7173a0ff46dc79", "c62bf15759f48bab3bcfb6412dcd2858034f9fbe", "45f490710b4dd6697dba4c9b385a49554501711a", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "4714f863564b32be86dab6f2cd7ef8fbecc9bafb", "e8b8a7778ace2a02f8db6fe321a54520c6b283ca", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "39d08fa8b028217384daeb3e622848451809a422", "199f0f56bc6cc5ff13cda5274797d46c3022e7c5", "527cc8cd2af06a9ac2e5cded806bab5c3faad9cf"], "ReferenceCount": 21, "CitationCount": 381}, {"URL": "https://www.semanticscholar.org/paper/Learning-Deep-Features-for-One-Class-Classification-Perera-Patel/732c21998e251d64cd58b6a86886ee5907efeaa5", "ID": "732c21998e251d64cd58b6a86886ee5907efeaa5", "Title": "Learning Deep Features for One-Class Classification", "Abstract": "A novel deep-learning-based approach for one-class transfer learning in which labeled data from an unrelated task is used for feature learning in one- class classification and achieves significant improvements over the state-of-the-art. We present a novel deep-learning-based approach for one-class transfer learning in which labeled data from an unrelated task is used for feature learning in one-class classification. The proposed method operates on top of a convolutional neural network (CNN) of choice and produces descriptive features while maintaining a low intra-class variance in the feature space for the given class. For this purpose two loss functions, compactness loss and descriptiveness loss, are proposed along with a parallel CNN architecture. A template matching-based framework is introduced to facilitate the testing process. Extensive experiments on publicly available anomaly detection, novelty detection, and mobile active authentication datasets show that the proposed deep one-class (DOC) classification method achieves significant improvements over the state-of-the-art.", "PublicationYear": "2018", "Authors": ["Pramuditha Perera", "Vishal M. Patel"], "RelatedTopics": ["Computer Science"], "References": ["00695a31a80221c7125e49885a4767896ec2c4f7", "2910bec6d4de87e22be5119cef3c488d2ae50e2a", "6af440915b8a0718c93be1cf61905e41e620484a", "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "b8de958fead0d8a9619b55c7299df3257c624a96", "eb42cf88027de515750f230b23b1a057dc782108", "0b822de3ed689344862eecb5ad86c36eb2ff9de5", "f5a3598028cd375071a38f90f1b2122308e3a100", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "2f4df08d9072fc2ac181b7fced6a245315ce05c8"], "ReferenceCount": 58, "CitationCount": 324}, {"URL": "https://www.semanticscholar.org/paper/Improving-Unsupervised-Defect-Segmentation-by-to-Bergmann-L%C3%B6we/9c24454b071bc8e96ea46c5064a7bddf07cca464", "ID": "9c24454b071bc8e96ea46c5064a7bddf07cca464", "Title": "Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders", "Abstract": "This work proposes to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a pixel-wise reconstruction error based on an $\\\\ell^p$ distance. This procedure, however, leads to large residuals whenever the reconstruction encompasses slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that it cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over the state of the art approaches for unsupervised defect segmentation that use pixel-wise reconstruction error metrics.", "PublicationYear": "2018", "Authors": ["Paul Bergmann", "Sindy L{\\\"o}we", "Michael Fauser", "David Sattlegger", "Carsten Steger"], "RelatedTopics": ["Computer Science"], "References": ["90e4f12fa8fb126d0f416c8b61bfb5f73f8b7b74", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "8d7aa1e9c135c6998e9abe098c9478874a73f357", "9179e740dad4ca4c183f7677b854e5b15f9a122f", "eae2e0fa72e898c289365c0af16daf57a7a6cf40", "63eb7986f726c7a8cf14b720fa6eba3ab168c4a4", "6180c1217c2c37d0b2f3e41930032d5f64b28af2", "75a838cbc1541858b9c484001cade327640dc280", "85384a8871030bbd1681adee9e9956dce4d751ba", "e163a2e89c136cb4442e34c72f7173a0ff46dc79"], "ReferenceCount": 27, "CitationCount": 440}, {"URL": "https://www.semanticscholar.org/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d", "ID": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "Title": "Deep Residual Learning for Image Recognition", "Abstract": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.", "PublicationYear": "2015", "Authors": ["Kaiming He", "X. Zhang", "Shaoqing Ren", "Jian Sun"], "RelatedTopics": ["Computer Science"], "References": ["eb42cf88027de515750f230b23b1a057dc782108", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd", "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "d6f2f611da110b5b5061731be3fc4c7f45d8ee23", "995c5f5e62614fcb4d2796ad2faab969da51713e", "5e83ab70d0cbc003471e87ec306d27d9c80ecb16", "5d90f06bb70a0a3dced62413346235c02b1aa086", "b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14", "8ad35df17ae4064dd174690efb04d347428f1117"], "ReferenceCount": 55, "CitationCount": 152004}, {"URL": "https://www.semanticscholar.org/paper/Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky/5d90f06bb70a0a3dced62413346235c02b1aa086", "ID": "5d90f06bb70a0a3dced62413346235c02b1aa086", "Title": "Learning Multiple Layers of Features from Tiny Images", "Abstract": "It is shown how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex, using a novel parallelization algorithm to distribute the work among multiple machines connected on a network. Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images.", "PublicationYear": "2009", "Authors": ["Alex Krizhevsky"], "RelatedTopics": ["Computer Science"], "References": ["54d2b5c64a67f65c5dd812b89e07973f97699552", "73e93d0346e8eee6c2ab45e46c26eaafb66e12a8", "71e3d9fc53ba14c2feeb7390f0dc99076553b05a", "ca1d23be869380ac9e900578c601c2d1febcc0c9", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "939d584316be99e2db3fec3fbf7d71f22a477f67", "08d0ea90b53aba0008d25811268fe46562cfb38c", "9360e5ce9c98166bb179ad479a9d2919ff13d022", "4f7476037408ac3d993f5088544aab427bc319c1", "73d6a26f407db77506959fdf3f7b853e44f3844a"], "ReferenceCount": 15, "CitationCount": 27159}, {"URL": "https://www.semanticscholar.org/paper/Deep-Transfer-Learning-for-Multiple-Class-Novelty-Perera-Patel/2910bec6d4de87e22be5119cef3c488d2ae50e2a", "ID": "2910bec6d4de87e22be5119cef3c488d2ae50e2a", "Title": "Deep Transfer Learning for Multiple Class Novelty Detection", "Abstract": "It is shown that thresholding the maximal activation of the proposed network can be used to identify novel objects effectively, and that the proposed method achieves significant improvements over the state-of-the-art methods. We propose a transfer learning-based solution for the problem of multiple class novelty detection. In particular, we propose an end-to-end deep-learning based approach in which we investigate how the knowledge contained in an external, out-of-distributional dataset can be used to improve the performance of a deep network for visual novelty detection. Our solution differs from the standard deep classification networks on two accounts. First, we use a novel loss function, membership loss, in addition to the classical cross-entropy loss for training networks. Secondly, we use the knowledge from the external dataset more effectively to learn globally negative filters, filters that respond to generic objects outside the known class set. We show that thresholding the maximal activation of the proposed network can be used to identify novel objects effectively. Extensive experiments on four publicly available novelty detection datasets show that the proposed method achieves significant improvements over the state-of-the-art methods.", "PublicationYear": "2019", "Authors": ["Pramuditha Perera", "Vishal M. Patel"], "RelatedTopics": ["Computer Science"], "References": ["732c21998e251d64cd58b6a86886ee5907efeaa5", "890e560015e39bbf4a6d34ff335430d22fa04877", "87e5b4d95f95a0975e855cf5ad402db7a3c64ff5", "599fd051c9438011ec5b581983c89e8922b4a5e6", "00695a31a80221c7125e49885a4767896ec2c4f7", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "1972c73d96353e57599962fd6059572801382212", "eb42cf88027de515750f230b23b1a057dc782108", "d094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c", "e31fa9510047c0df23fb4dd37ee7c70783a3fa60"], "ReferenceCount": 30, "CitationCount": 85}, {"URL": "https://www.semanticscholar.org/paper/q-Space-Novelty-Detection-with-Variational-Vasilev-Golkov/68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6", "ID": "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6", "Title": "q-Space Novelty Detection with Variational Autoencoders", "Abstract": "This work proposes novelty detection methods based on training variational autoencoders (VAEs) on normal data to magnetic resonance imaging, namely to the detection of diffusion-space (q-space) abnormalities in diffusion MRI scans of multiple sclerosis patients, and shows that many of them are able to outperform the state of the art. In machine learning, novelty detection is the task of identifying novel unseen data. During training, only samples from the normal class are available. Test samples are classified as normal or abnormal by assignment of a novelty score. Here we propose novelty detection methods based on training variational autoencoders (VAEs) on normal data. Since abnormal samples are not used during training, we define novelty metrics based on the (partially complementary) assumptions that the VAE is less capable of reconstructing abnormal samples well; that abnormal samples more strongly violate the VAE regularizer; and that abnormal samples differ from normal samples not only in input-feature space, but also in the VAE latent space and VAE output. These approaches, combined with various possibilities of using (e.g. sampling) the probabilistic VAE to obtain scalar novelty scores, yield a large family of methods. We apply these methods to magnetic resonance imaging, namely to the detection of diffusion-space (q-space) abnormalities in diffusion MRI scans of multiple sclerosis patients, i.e. to detect multiple sclerosis lesions without using any lesion labels for training. Many of our methods outperform previously proposed q-space novelty detection methods. We also evaluate the proposed methods on the MNIST handwritten digits dataset and show that many of them are able to outperform the state of the art.", "PublicationYear": "2018", "Authors": ["Aleksei Vasilev", "Vladimir Golkov", "Ilona Lipp", "Eleonora Sgarlata", "Valentina Tomassini", "Derek K. Jones", "Daniel Cremers"], "RelatedTopics": ["Computer Science"], "References": ["98af3dc5af084967adcfeda40b58b0012f98e1e9", "705df884b2944e1a6f86e72ff1946318b4ad3bdd", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "6b1160f6ff6c4a8e1418f4edba9c6b9c2c6f385a", "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "817d88916e962b3bcf71de8bf49207916cfebb50", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "9acc51b06f54b07836fad4cc24633187dc21317f", "061146b1d7938d7a8dae70e3531a00fceb3c78e8"], "ReferenceCount": 21, "CitationCount": 51}, {"URL": "https://www.semanticscholar.org/paper/f%E2%80%90AnoGAN%3A-Fast-unsupervised-anomaly-detection-with-Schlegl-Seeb%C3%B6ck/f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "ID": "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "Title": "f\u2010AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks", "Abstract": "Semantic Scholar extracted view of \\\"f\u2010AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks\\\" by T. Schlegl et al.", "PublicationYear": "2019", "Authors": ["Thomas Schlegl", "Philipp Seeb{\\\"o}ck", "Sebastian M. Waldstein", "Georg Langs", "Ursula Margarethe Schmidt-Erfurth"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["e163a2e89c136cb4442e34c72f7173a0ff46dc79", "c1cc356ae6303b254ce88919ade3907221a5b58d", "71c076b4c606174a6e83d7d64d2064827d6b6d11", "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "571b0750085ae3d939525e62af510ee2cee9d5ea", "2bf3a05467939fcb00de606cc1bcc9353ad288cb", "9d5290fadb7625862a966e0330bd0f9e111fc99d", "2a863a1ab6df3ca9a55573befcb89e1ed7b7df74", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "05dc42d9262c0ba8dd2d3a3798a2ce1e233cd3cc"], "ReferenceCount": 45, "CitationCount": 777}, {"URL": "https://www.semanticscholar.org/paper/Metric-Learning-for-Novelty-and-Anomaly-Detection-Masana-Ruiz/317c172f314f8cb634f7569ed5bf3ae7dd25c313", "ID": "317c172f314f8cb634f7569ed5bf3ae7dd25c313", "Title": "Metric Learning for Novelty and Anomaly Detection", "Abstract": "This work proposes to use metric learning which does not have the drawback of the softmax layer (inherent to cross-entropy methods), which forces the network to divide its prediction power over the learned classes. When neural networks process images which do not resemble the distribution seen during training, so called out-of-distribution images, they often make wrong predictions, and do so too confidently. The capability to detect out-of-distribution images is therefore crucial for many real-world applications. We divide out-of-distribution detection between novelty detection ---images of classes which are not in the training set but are related to those---, and anomaly detection ---images with classes which are unrelated to the training set. By related we mean they contain the same type of objects, like digits in MNIST and SVHN. Most existing work has focused on anomaly detection, and has addressed this problem considering networks trained with the cross-entropy loss. Differently from them, we propose to use metric learning which does not have the drawback of the softmax layer (inherent to cross-entropy methods), which forces the network to divide its prediction power over the learned classes. We perform extensive experiments and evaluate both novelty and anomaly detection, even in a relevant application such as traffic sign recognition, obtaining comparable or better results than previous works.", "PublicationYear": "2018", "Authors": ["Marc Masana", "Idoia Ruiz", "Joan Serrat", "Joost van de Weijer", "Antonio M. L{\\'o}pez"], "RelatedTopics": ["Computer Science"], "References": ["547c854985629cfa9404a5ba8ca29367b5f8c25f", "36653f8705b56e39642bcd123494eb680cd1636b", "890e560015e39bbf4a6d34ff335430d22fa04877", "cdd8bad29b5e90a1f92080eaca51ba123f34ada5", "5d90f06bb70a0a3dced62413346235c02b1aa086", "1972c73d96353e57599962fd6059572801382212", "2ed7cc027367295b1a7d7cd49406acfa5c580138", "6ff2a434578ff2746b9283e45abf296887f48a2d", "9acc51b06f54b07836fad4cc24633187dc21317f", "4dcdae25a5e33682953f0853ee4cf7ca93be58a9"], "ReferenceCount": 36, "CitationCount": 69}, {"URL": "https://www.semanticscholar.org/paper/A-Gaussian-Mixture-Model-layer-jointly-optimized-a-Variani-McDermott/60d4ec78a673119420bee41268672a8f8669bb31", "ID": "60d4ec78a673119420bee41268672a8f8669bb31", "Title": "A Gaussian Mixture Model layer jointly optimized with discriminative features within a Deep Neural Network architecture", "Abstract": "The proposed Gaussian Mixture Model represented as the last layer of a Deep Neural Network architecture and jointly optimized with all previous layers using Asynchronous Stochastic Gradient Descent (ASGD) were found to yield Word Error Rates competitive with state-of-the-art DNN systems. This article proposes and evaluates a Gaussian Mixture Model (GMM) represented as the last layer of a Deep Neural Network (DNN) architecture and jointly optimized with all previous layers using Asynchronous Stochastic Gradient Descent (ASGD). The resulting \u201cDeep GMM\u201d architecture was investigated with special attention to the following issues: (1) The extent to which joint optimization improves over separate optimization of the DNN-based feature extraction layers and the GMM layer; (2) The extent to which depth (measured in number of layers, for a matched total number of parameters) helps a deep generative model based on the GMM layer, compared to a vanilla DNN model; (3) Head-to-head performance of Deep GMM architectures vs. equivalent DNN architectures of comparable depth, using the same optimization criterion (frame-level Cross Entropy (CE)) and optimization method (ASGD); (4) Expanded possibilities for modeling offered by the Deep GMM generative model. The proposed Deep GMMs were found to yield Word Error Rates (WERs) competitive with state-of-the-art DNN systems, at the cost of pre-training using standard DNNs to initialize the Deep GMM feature extraction layers. An extension to Deep Subspace GMMs is described, resulting in additional gains.", "PublicationYear": "2015", "Authors": ["Ehsan Variani", "Erik McDermott", "Georg Heigold"], "RelatedTopics": ["Computer Science"], "References": ["837ccad58318a1f18d1409bed60ee1e3fa90de94", "0523e14247d74c4505cd5e32e1f0495f291ec432", "375d7b8a70277d5d7b5e0cc999b03ba395c42901", "6dfce7144275e7ca3ada3a2075b82c0f97491243", "008e9e2d3908c964d5b1c408c478215709dbea10", "4326617172d0fc3901d3695091e040f17e226840", "06c152df89ca6a1f1b8f8e139ddda82cd4539415", "e33cbb25a8c7390aec6a398e36381f4f7770c283", "2443dc59cf3d6cc1deba6d3220d61664b1a7eada", "f084596fdc853f33e8bfdb86c114985202ead24b"], "ReferenceCount": 25, "CitationCount": 60}, {"URL": "https://www.semanticscholar.org/paper/Integrating-Gaussian-mixtures-into-deep-neural-with-T%C3%BCske-Tahir/aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "ID": "aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "Title": "Integrating Gaussian mixtures into deep neural networks: Softmax layer with hidden variables", "Abstract": "This paper shows that GMM can be easily integrated into the deep neural network framework by exploiting its equivalence with the log-linear mixture model (LMM), which can be transformed to a large softmax layer followed by a summation pooling layer. In the hybrid approach, neural network output directly serves as hidden Markov model (HMM) state posterior probability estimates. In contrast to this, in the tandem approach neural network output is used as input features to improve classic Gaussian mixture model (GMM) based emission probability estimates. This paper shows that GMM can be easily integrated into the deep neural network framework. By exploiting its equivalence with the log-linear mixture model (LMM), GMM can be transformed to a large softmax layer followed by a summation pooling layer. Theoretical and experimental results indicate that the jointly trained and optimally chosen GMM and bottleneck tandem features cannot perform worse than a hybrid model. Thus, the question \u201chybrid vs. tandem\u201d simplifies to optimizing the output layer of a neural network. Speech recognition experiments are carried out on a broadcast news and conversations task using up to 12 feed-forward hidden layers with sigmoid and rectified linear unit activation functions. The evaluation of the LMM layer shows recognition gains over the classic softmax output.", "PublicationYear": "2015", "Authors": ["Zolt{\\'a}n T{\\\"u}ske", "Muhammad Ali Tahir", "Ralf Schl{\\\"u}ter", "Hermann Ney"], "RelatedTopics": ["Computer Science"], "References": ["837ccad58318a1f18d1409bed60ee1e3fa90de94", "71f922985c2ca4553c0fbfc4fd30c240c798b6e3", "5e9082caea65c76bfd23b8763872804473ee7872", "3d82e058a5c40954b8f5db170a298a889a254c37", "4326617172d0fc3901d3695091e040f17e226840", "d82354fab1c800f3a50632d1371f083348af0971", "c510600e68740890f7d36c2c8545ddcff275fa99", "28a23135790ea496cf6564cf43b9f3caab6cd632", "5cea23330c76994cb626df20bed31cc2588033df", "b9e0a7eb79ab7ab02c30e43a3e5c75b48ea46b31"], "ReferenceCount": 27, "CitationCount": 40}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Dimensionality-Reduction-for-Gaussian-Yang-Huang/33a832399927971f144dee7fee50c0bcc5e1e659", "ID": "33a832399927971f144dee7fee50c0bcc5e1e659", "Title": "Unsupervised Dimensionality Reduction for Gaussian Mixture Model", "Abstract": "Experimental results show that the joint learning significantly outperforms the comparison method in terms of three criteria for supervised learning. Dimensionality reduction is a fundamental yet active research topic in pattern recognition and machine learning. On the other hand, Gaussian Mixture Model (GMM), a famous model, has been widely used in various applications, e.g., clustering and classification. For high-dimensional data, previous research usually performs dimensionality reduction first, and then inputs the reduced features to other available models, e.g., GMM. In particular, there are very few investigations or discussions on how dimensionality reduction could be interactively and systematically conducted together with the important GMM. In this paper, we study the problem how unsupervised dimensionality reduction could be performed together with GMM and if such joint learning could lead to improvement in comparison with the traditional unsupervised method. Specifically, we engage the Mixture of Factor Analyzers with the assumption that a common factor loading exist for all the components. Such setting exactly optimizes a dimensionality reduction together with the parameters of GMM. We compare the joint learning approach and the separate dimensionality reduction plus GMM method on both synthetic data and real data sets. Experimental results show that the joint learning significantly outperforms the comparison method in terms of three criteria for supervised learning.", "PublicationYear": "2014", "Authors": ["Xi Yang", "Kaizhu Huang", "Rui Zhang"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["b095d70aa087c3e3c90fbbffe7c0cc5bbfb326ee", "a67d2d9a318736560977a374c9a23d4dcf395f2b", "0f71e564c1558dff2c1bc7027848d18439be16b6", "0352f5a9ec509e78c0ee584f1e145725f12dfbb2", "4825aa7cc50db6c99b3678c4b77515875c1bad1b", "5e52081e0f9e534e609d3b47c96558afec2df276"], "ReferenceCount": 6, "CitationCount": 8}, {"URL": "https://www.semanticscholar.org/paper/Joint-Learning-of-Unsupervised-Dimensionality-and-Yang-Huang/3eeb8b5d5ee2db86fa359ec479b730a793d5971e", "ID": "3eeb8b5d5ee2db86fa359ec479b730a793d5971e", "Title": "Joint Learning of Unsupervised Dimensionality Reduction and Gaussian Mixture Model", "Abstract": "This paper compares the proposed joint learning approach with two competitive algorithms on one synthetic and six real data sets and shows that the joint learning significantly outperforms the comparison methods in terms of three criteria. Dimensionality reduction (DR) has been one central research topic in information theory, pattern recognition, and machine learning. Apparently, the performance of many learning models significantly rely on dimensionality reduction: successful DR can largely improve various approaches in clustering and classification, while inappropriate DR may deteriorate the systems. When applied on high-dimensional data, some existing research approaches often try to reduce the dimensionality first, and then input the reduced features to other available models, e.g., Gaussian mixture model (GMM). Such independent learning could however significantly limit the performance, since the optimal subspace given by a particular DR approach may not be appropriate for the following model. In this paper, we focus on investigating how unsupervised dimensionality reduction could be performed together with GMM and if such joint learning could lead to improvement in comparison with the traditional unsupervised method. In particular, we engage the mixture of factor analyzers with the assumption that a common factor loading exists for all the components. Based on that, we then present EM-algorithm that converges to a local optimal solution. Such setting exactly optimizes a dimensionality reduction together with the parameters of GMM. We describe the framework, detail the algorithm, and conduct a series of experiments to validate the effectiveness of our proposed approach. Specifically, we compare the proposed joint learning approach with two competitive algorithms on one synthetic and six real data sets. Experimental results show that the joint learning significantly outperforms the comparison methods in terms of three criteria.", "PublicationYear": "2017", "Authors": ["Xi Yang", "Kaizhu Huang", "John Yannis Goulermas", "Rui Zhang"], "RelatedTopics": ["Computer Science"], "References": ["33a832399927971f144dee7fee50c0bcc5e1e659", "b095d70aa087c3e3c90fbbffe7c0cc5bbfb326ee", "291c1274ee45bf78662ed60831ef1bdaf89bed94", "a67d2d9a318736560977a374c9a23d4dcf395f2b", "9b819c146dba12efdc7996d975fb3d4fac2faa9d", "b08e2ea6f1ed75e14c74c8e303bf11c0abfedad4", "5cc77c2e2cb74b192e183aa62b3fe86be778ff48", "0352f5a9ec509e78c0ee584f1e145725f12dfbb2", "802f2afd13b209d4c6d6d3622efc48a7256d7207", "801ecc5cb8b81da722fc7cfb1e41d2b1d7bfe94a"], "ReferenceCount": 22, "CitationCount": 20}, {"URL": "https://www.semanticscholar.org/paper/Towards-K-means-friendly-Spaces%3A-Simultaneous-Deep-Yang-Fu/ca9f84c3922004ec6133aa9c2048ceeb17702fee", "ID": "ca9f84c3922004ec6133aa9c2048ceeb17702fee", "Title": "Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering", "Abstract": "A joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN) while exploiting theDeep neural network's ability to approximate any nonlinear function is proposed. Most learning approaches treat dimensionality reduction (DR) and clustering separately (i.e., sequentially), but recent research has shown that optimizing the two tasks jointly can substantially improve the performance of both. The premise behind the latter genre is that the data samples are obtained via linear transformation of latent representations that are easy to cluster; but in practice, the transformation from the latent space to the data can be more complicated. In this work, we assume that this transformation is an unknown and possibly nonlinear function. To recover the 'clustering-friendly' latent representations and to better cluster the data, we propose a joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN). The motivation is to keep the advantages of jointly optimizing the two tasks, while exploiting the deep neural network's ability to approximate any nonlinear function. This way, the proposed approach can work well for a broad class of generative models. Towards this end, we carefully design the DNN structure and the associated joint optimization criterion, and propose an effective and scalable algorithm to handle the formulated optimization problem. Experiments using different real datasets are employed to showcase the effectiveness of the proposed approach.", "PublicationYear": "2016", "Authors": ["Bo Yang", "Xiao Fu", "N. Sidiropoulos", "Mingyi Hong"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["2eecf2a2788117b808b72321802731efc86526b2", "ac120ca0a53715d3674410bf7d3384116a81338a", "3332dc72fbe3907e45e8a500c6a1202ad5092c0f", "8db95dbd08e4ee64fb258e5380e78cfa507ed94d", "f44ff4fc0ed0142cb18472a5ba421bb538aa837e", "995c5f5e62614fcb4d2796ad2faab969da51713e", "e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "5aa26299435bdf7db874ef1640a6c3b5a4a2c394", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd"], "ReferenceCount": 47, "CitationCount": 719}, {"URL": "https://www.semanticscholar.org/paper/Stacked-Denoising-Autoencoders%3A-Learning-Useful-in-Vincent-Larochelle/e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "ID": "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "Title": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion", "Abstract": "This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations. We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.", "PublicationYear": "2010", "Authors": ["Pascal Vincent", "H. Larochelle", "Isabelle Lajoie", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "RelatedTopics": ["Computer Science"], "References": ["843959ffdccf31c6694d135fad07425924f785b1", "b2af2a2f2d1be22ebf473f7e0f501f1f5c02f222", "0d2336389dff3031910bd21dd1c44d1b4cd51725", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "739edc6ae61cb246493a7d2ab6e320d10ace4412", "05fd1da7b2e34f86ec7f010bef068717ae964332", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "202cbbf671743aefd380d2f23987bd46b9caaf97", "932c2a02d462abd75af018125413b1ceaa1ee3f4"], "ReferenceCount": 60, "CitationCount": 6680}, {"URL": "https://www.semanticscholar.org/paper/Neural-Variational-Inference-and-Learning-in-Belief-Mnih-Gregor/331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "ID": "331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "Title": "Neural Variational Inference and Learning in Belief Networks", "Abstract": "This work proposes a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior and shows that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset. Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference network gradient is too high-variance to be useful, we make it practical by applying several straightforward model-independent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.", "PublicationYear": "2014", "Authors": ["Andriy Mnih", "Karol Gregor"], "RelatedTopics": ["Computer Science"], "References": ["6bacf99c87991523a97165610b492f28c8cacbb2", "f87247fb37f6b48da0757d7a1acf38da44510cdb", "08d0ea90b53aba0008d25811268fe46562cfb38c", "484ad17c926292fbe0d5211540832a8c8a8e958b", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "6a667700100e228cb30a5d884258a0db921603fe", "00cd1dab559a9671b692f39f14c1573ab2d1416b", "695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864", "512ea8d0c5b5de896129e76d4276f7b996fe88d8", "9ceb1dea15ac3df3d610fd0b3cc52b9a4e9141a3"], "ReferenceCount": 34, "CitationCount": 692}, {"URL": "https://www.semanticscholar.org/paper/Speaker-adaptive-joint-training-of-Gaussian-mixture-T%C3%BCske-Golik/8080c7954944e4e293028768e7dcbaead190c85e", "ID": "8080c7954944e4e293028768e7dcbaead190c85e", "Title": "Speaker adaptive joint training of Gaussian mixture models and bottleneck features", "Abstract": "Experiments show that the deeper backpropagation through the speaker dependent layer is necessary for improved recognition performance, and the speaker adaptively and jointly trained BN-GMM results in 5% relative improvement over very strong speaker-independent hybrid baseline on the Quaero English broadcast news and conversations task, and on the 300-hour Switchboard task. In the tandem approach, the output of a neural network (NN) serves as input features to a Gaussian mixture model (GMM) aiming to improve the emission probability estimates. As has been shown in our previous work, GMM with pooled covariance matrix can be integrated into a neural network framework as a softmax layer with hidden variables, which allows for joint estimation of both neural network and Gaussian mixture parameters. Here, this approach is extended to include speaker adaptive training (SAT) by introducing a speaker dependent neural network layer. Error backpropagation beyond this speaker dependent layer realizes the adaptive training of the Gaussian parameters as well as the optimization of the bottleneck (BN) tandem features of the underlying acoustic model, simultaneously. In this study, after the initialization by constrained maximum likelihood linear regression (CMLLR) the speaker dependent layer itself is kept constant during the joint training. Experiments show that the deeper backpropagation through the speaker dependent layer is necessary for improved recognition performance. The speaker adaptively and jointly trained BN-GMM results in 5% relative improvement over very strong speaker-independent hybrid baseline on the Quaero English broadcast news and conversations task, and on the 300-hour Switchboard task.", "PublicationYear": "2015", "Authors": ["Zolt{\\'a}n T{\\\"u}ske", "Pavel Golik", "Ralf Schl{\\\"u}ter", "Hermann Ney"], "RelatedTopics": ["Computer Science"], "References": ["aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "247425484c95e37554989be2ac3444f244bd8b07", "d1a60aa2362783b479cfe37963e14ab28d3d9181", "8e46a2e57ce37b846bef48d776aeafa16c411681", "778015de7b81dfde54367dd57fb76c86faa72be4", "05de249c56353b8916d3eb2fec76ddf7fbd47f33", "ae4614f758dfa344a04b33377c96abc10d5eeda7", "398dc5a65123364bd327bfbb17d2a2533b08c301", "3afede5fa4234141788a7667169b5dfe02f8266e", "7600cf5da33b19d37266da4d2edcbd32bc0ecb5e"], "ReferenceCount": 51, "CitationCount": 27}, {"URL": "https://www.semanticscholar.org/paper/Robust-feature-learning-by-stacked-autoencoder-with-Qi-Wang/357733cc76e31a499a27ba2da8612174aafb3213", "ID": "357733cc76e31a499a27ba2da8612174aafb3213", "Title": "Robust feature learning by stacked autoencoder with maximum correntropy criterion", "Abstract": "A robust stacked autoencoder based on maximum correntropy criterion (MCC) to deal with the data containing non-Gaussian noises and outliers is proposed and Experimental results show that R-SAE is capable of learning robust features on noisy data. Unsupervised feature learning with deep networks has been widely studied in the recent years. Despite the progress, most existing models would be fragile to non-Gaussian noises and outliers due to the criterion of mean square error (MSE). In this paper, we propose a robust stacked autoencoder (R-SAE) based on maximum correntropy criterion (MCC) to deal with the data containing non-Gaussian noises and outliers. By replacing MSE with MCC, the anti-noise ability of stacked autoencoder is improved. The proposed method is evaluated using the MNIST benchmark dataset. Experimental results show that, compared with the ordinary stacked autoencoder, the R-SAE improves classification accuracy by 14% and reduces the reconstruction error by 39%, which demonstrates that R-SAE is capable of learning robust features on noisy data.", "PublicationYear": "2014", "Authors": ["Yu Qi", "Yueming Wang", "Xiaoxiang Zheng", "Zhaohui Wu"], "RelatedTopics": ["Computer Science"], "References": ["843959ffdccf31c6694d135fad07425924f785b1", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "0ff94e25a8ff3bd5c98899684d0885423fbe4f91", "a2017ec2c60d542af5e9993176ba68f89529dbce", "8a09668efc95eafd6c3056ff1f0fbc43bb5774db", "fbaecde38bf43214778193d3728f8f33471b0a91", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "298ecc682355a202e520ae0640191cdfbec85b1a", "268b8f10a45e71f63daab6403bb453da31ae28a7", "c22ca1c712bc18915dc9737e9d61b69574455021"], "ReferenceCount": 15, "CitationCount": 79}, {"URL": "https://www.semanticscholar.org/paper/Robust-feature-learning-by-improved-auto-encoder-Zhao-Guo/00af02c2cb48920af477115e870a42ac4f8a3834", "ID": "00af02c2cb48920af477115e870a42ac4f8a3834", "Title": "Robust feature learning by improved auto-encoder from non-Gaussian noised images", "Abstract": "Experimental results show that, compared with the traditional auto-encoders, the proposed method learns robust features, improves classification accuracy and reduces the reconstruction error, which demonstrates thatThe proposed method is capable of learning robust features on noisy data. Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Net-works(DBN) and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and languages datasets. These learning algorithms aim to find good representations for data, which can be used for classification, reconstruction, visualization and so on. Despite the progress, most existing algorithms would be fragile to non-Gaussian noises and outliers due to the criterion of mean square error(MSE) and cross entropy(CE). In this paper, we propose a robust auto-encoder called correntropy-based contractive auto-encoder(C-CAE) to learn robust features from data with non-Gaussian noises and outliers. The maximum correntropy criterion(MCC) is adopted as reconstruction cost function and a well chosen penalty term is added to the reconstruction cost function. By replacing cross entropy with MCC, the proposed method can learn robust features from the data containing non-Gaussian noises and outliers. The penalty term corresponds to the Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input. By adding the penalty term, the antinoise ability of the proposed method is improved. The proposed method is evaluated using the MNIST benchmark dataset. Experimental results show that, compared with the traditional auto-encoders, the proposed method learns robust features, improves classification accuracy and reduces the reconstruction error, which demonstrates that the proposed method is capable of learning robust features on noisy data.", "PublicationYear": "2015", "Authors": ["Dan Zhao", "Bao-long Guo", "Jinfu Wu", "Weikang Ning", "Yunyi Yan"], "RelatedTopics": ["Computer Science"], "References": ["357733cc76e31a499a27ba2da8612174aafb3213", "195d0a8233a7a46329c742eaff56c276f847fadc", "a2017ec2c60d542af5e9993176ba68f89529dbce", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "843959ffdccf31c6694d135fad07425924f785b1", "2964d30862d0402b0d0ad4a427067f69e4a52130", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "2617b3108d6cd2c4c92e48b71520317d1b1bd2a3"], "ReferenceCount": 29, "CitationCount": 8}, {"URL": "https://www.semanticscholar.org/paper/Research-on-denoising-sparse-autoencoder-Meng-Ding/fbb38946334941292800a82c99c0dc4feb0cb882", "ID": "fbb38946334941292800a82c99c0dc4feb0cb882", "Title": "Research on denoising sparse autoencoder", "Abstract": "The results suggest that different autoencoders mentioned in this paper have some close relation and the model the authors researched can extract interesting features which can reconstruct original data well, and all results show a promising approach to utilizing the proposed autoencoder to build deep models. Autoencoder can learn the structure of data adaptively and represent data efficiently. These properties make autoencoder not only suit huge volume and variety of data well but also overcome expensive designing cost and poor generalization. Moreover, using autoencoder in deep learning to implement feature extraction could draw better classification accuracy. However, there exist poor robustness and overfitting problems when utilizing autoencoder. In order to extract useful features, meanwhile improve robustness and overcome overfitting, we studied denoising sparse autoencoder through adding corrupting operation and sparsity constraint to traditional autoencoder. The results suggest that different autoencoders mentioned in this paper have some close relation and the model we researched can extract interesting features which can reconstruct original data well. In addition, all results show a promising approach to utilizing the proposed autoencoder to build deep models.", "PublicationYear": "2017", "Authors": ["Lingheng Meng", "Shifei Ding", "Yu Xue"], "RelatedTopics": ["Computer Science"], "References": ["f3ad764e559d3589063d31efcdf2baac64e6ebfc", "b94043a133e3d07ed0b1cfc036829e619ea0ba22", "843959ffdccf31c6694d135fad07425924f785b1", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "23c833a82e757b05dda2d1e8b647d3a5af2cc46f", "a5bdc9026d96b0a3317c93110fc2e56f59db2f9a", "2a4774a811ec32f005a043653dd15eb184d96dfa", "bb1d6215f0cfd84b5efc7173247b016ade4c976e", "53959db687bb17f6f1438c0f8c70eb389dd1ece1", "9dd460477be1b1c4e1d65b2cbfa3d1653df6df87"], "ReferenceCount": 32, "CitationCount": 49}, {"URL": "https://www.semanticscholar.org/paper/Extracting-and-composing-robust-features-with-Vincent-Larochelle/843959ffdccf31c6694d135fad07425924f785b1", "ID": "843959ffdccf31c6694d135fad07425924f785b1", "Title": "Extracting and composing robust features with denoising autoencoders", "Abstract": "This work introduces and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.", "PublicationYear": "2008", "Authors": ["Pascal Vincent", "H. Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["41fef1a197fab9684a4608b725d3ae72e1ab4b39", "e07416eabd4ba6c69fa473756bb04ae7161177be", "932c2a02d462abd75af018125413b1ceaa1ee3f4", "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3", "b8012351bc5ebce4a4b3039bbbba3ce393bc3315", "2077d0f30507d51a0d3bbec4957d55e817d66a59", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "d90df19826e5ccf940f8259c7d7ca054e1506b00", "43c8a545f7166659e9e21c88fe234e0323855216"], "ReferenceCount": 30, "CitationCount": 6719}, {"URL": "https://www.semanticscholar.org/paper/Parallel-auto-encoder-for-efficient-outlier-Ma-Zhang/ec7e0ceea8f79735742ea671b3c37148cae9f22c", "ID": "ec7e0ceea8f79735742ea671b3c37148cae9f22c", "Title": "Parallel auto-encoder for efficient outlier detection", "Abstract": "This paper builds a replicator model of the input data to obtain the representation of sample data, and uses this model to measure the replicability of test data, where records having higher reconstruction errors are classified as outliers. Detecting outliers from big data plays an important role in network security. Previous outlier detection algorithms are generally incapable of handling big data. In this paper we present an parallel outlier detection method for big data, based on a new parallel auto-encoder method. Specifically, we build a replicator model of the input data to obtain the representation of sample data. Then, the replicator model is used to measure the replicability of test data, where records having higher reconstruction errors are classified as outliers. Experimental results show the performance of the proposed parallel algorithm.", "PublicationYear": "2013", "Authors": ["Yunlong Ma", "Peng Zhang", "Yanan Cao", "Li Guo"], "RelatedTopics": ["Computer Science"], "References": ["353b5ed7874b7134ee95021bce60b7ac0ee7e1ed", "83e9565cede81b2b88a9fa241833135da142f4d3", "a3f8a3948e5999def4a0819d0dbaef2ae05e1599", "d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "8eb453d79c172c4bca3dd184679a7796ade1ff01", "b8434eecf8cdcedc9ae5f33af382f175b3d5d815"], "ReferenceCount": 6, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Image-Denoising-and-Inpainting-with-Deep-Neural-Xie-Xu/a2017ec2c60d542af5e9993176ba68f89529dbce", "ID": "a2017ec2c60d542af5e9993176ba68f89529dbce", "Title": "Image Denoising and Inpainting with Deep Neural Networks", "Abstract": "A novel approach to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder (DA) is presented and can automatically remove complex patterns like superimposed text from an image, rather than simple patterns like pixels missing at random. We present a novel approach to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder (DA). We propose an alternative training scheme that successfully adapts DA, originally designed for unsupervised feature learning, to the tasks of image denoising and blind inpainting. Our method's performance in the image denoising task is comparable to that of KSVD which is a widely used sparse coding technique. More importantly, in blind image inpainting task, the proposed method provides solutions to some complex problems that have not been tackled before. Specifically, we can automatically remove complex patterns like superimposed text from an image, rather than simple patterns like pixels missing at random. Moreover, the proposed method does not need the information regarding the region that requires inpainting to be given a priori. Experimental results demonstrate the effectiveness of the proposed method in the tasks of image denoising and blind inpainting. We also show that our new training scheme for DA is more effective and can improve the performance of unsupervised feature learning.", "PublicationYear": "2012", "Authors": ["Junyuan Xie", "Linli Xu", "Enhong Chen"], "RelatedTopics": ["Computer Science"], "References": ["b2af2a2f2d1be22ebf473f7e0f501f1f5c02f222", "51a7a32dd55f46d60509044da79cd963e150e89c", "92281d5002178003bd7060fc66677a3471cdaa4b", "bff8a31320941e41123a94c8818bef9f1c898c7d", "0f6395aa7c09bf81c7753a04c789a1dac0c0eb5c", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "e07416eabd4ba6c69fa473756bb04ae7161177be", "4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c", "e763e059cead07d1c03646bfb8cb4a0a75ffc3ef", "a4b01a1eb80f004fc67d4180c24cb4c203324e21"], "ReferenceCount": 23, "CitationCount": 1369}, {"URL": "https://www.semanticscholar.org/paper/Contractive-Auto-Encoders%3A-Explicit-Invariance-Rifai-Vincent/195d0a8233a7a46329c742eaff56c276f847fadc", "ID": "195d0a8233a7a46329c742eaff56c276f847fadc", "Title": "Contractive Auto-Encoders: Explicit Invariance During Feature Extraction", "Abstract": "It is found empirically that this penalty helps to carve a representation that better captures the local directions of variation dictated by the data, corresponding to a lower-dimensional non-linear manifold, while being more invariant to the vast majority of directions orthogonal to the manifold. We present in this paper a novel approach for training deterministic auto-encoders. We show that by adding a well chosen penalty term to the classical reconstruction cost function, we can achieve results that equal or surpass those attained by other regularized auto-encoders as well as denoising auto-encoders on a range of datasets. This penalty term corresponds to the Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input. We show that this penalty term results in a localized space contraction which in turn yields robust features on the activation layer. Furthermore, we show how this penalty term is related to both regularized auto-encoders and denoising auto-encoders and how it can be seen as a link between deterministic and non-deterministic auto-encoders. We find empirically that this penalty helps to carve a representation that better captures the local directions of variation dictated by the data, corresponding to a lower-dimensional non-linear manifold, while being more invariant to the vast majority of directions orthogonal to the manifold. Finally, we show that by using the learned features to initialize a MLP, we achieve state of the art classification error on a range of datasets, surpassing other methods of pretraining.", "PublicationYear": "2011", "Authors": ["Salah Rifai", "Pascal Vincent", "Xavier Muller", "Xavier Glorot", "Yoshua Bengio"], "RelatedTopics": ["Computer Science"], "References": ["e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3", "ff32cebbdb8a436ccd8ae797647428615ae32d74", "2805537bec87a6177037b18f9a3a9d3f1038867b", "9552ac39a57daacf3d75865a268935b5a0df9bbb", "5d90f06bb70a0a3dced62413346235c02b1aa086", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "54a9c2553138932426faebcaa67a63a84a56b55d", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "1e80f755bcbf10479afd2338cec05211fdbd325c"], "ReferenceCount": 19, "CitationCount": 1423}, {"URL": "https://www.semanticscholar.org/paper/Extracting-deep-bottleneck-features-using-stacked-Gehring-Miao/2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35", "ID": "2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35", "Title": "Extracting deep bottleneck features using stacked auto-encoders", "Abstract": "It is found that increasing the number of auto-encoders in the network produces more useful features, but requires pre-training, especially when little training data is available. In this work, a novel training scheme for generating bottleneck features from deep neural networks is proposed. A stack of denoising auto-encoders is first trained in a layer-wise, unsupervised manner. Afterwards, the bottleneck layer and an additional layer are added and the whole network is fine-tuned to predict target phoneme states. We perform experiments on a Cantonese conversational telephone speech corpus and find that increasing the number of auto-encoders in the network produces more useful features, but requires pre-training, especially when little training data is available. Using more unlabeled data for pre-training only yields additional gains. Evaluations on larger datasets and on different system setups demonstrate the general applicability of our approach. In terms of word error rate, relative improvements of 9.2% (Cantonese, ML training), 9.3% (Tagalog, BMMI-SAT training), 12% (Tagalog, confusion network combinations with MFCCs), and 8.7% (Switchboard) are achieved.", "PublicationYear": "2013", "Authors": ["Jonas Gehring", "Yajie Miao", "Florian Metze", "Alexander H. Waibel"], "RelatedTopics": ["Computer Science"], "References": ["008e9e2d3908c964d5b1c408c478215709dbea10", "375d7b8a70277d5d7b5e0cc999b03ba395c42901", "6658bbf68995731b2083195054ff45b4eca38b3a", "137b572ca406ba8fc86e985c185233b8cd6517d2", "31868290adf1c000c611dfc966b514d5a34e8d23", "843959ffdccf31c6694d135fad07425924f785b1", "1528918ae0c9f70ba6da030cb8dbc72f71bc198b", "e33cbb25a8c7390aec6a398e36381f4f7770c283", "cd62c9976534a6a2096a38244f6cbb03635a127e", "06c152df89ca6a1f1b8f8e139ddda82cd4539415"], "ReferenceCount": 24, "CitationCount": 295}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-LeCun-Bengio/a4cec122a08216fe8a3bc19b22e78fbaea096256", "ID": "a4cec122a08216fe8a3bc19b22e78fbaea096256", "Title": "Deep Learning", "Abstract": "Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years, and will have many more successes in the near future because it requires very little engineering by hand and can easily take advantage of increases in the amount of available computation and data. Machine-learning technology powers many aspects of modern society: from web searches to content filtering on social networks to recommendations on e-commerce websites, and it is increasingly present in consumer products such as cameras and smartphones. Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users\u2019 interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition or machine-learning system required careful engineering and considerable domain expertise to design a feature extractor that transformed the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input. Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification. Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned. For classification tasks, higher layers of representation amplify aspects of the input that are important for discrimination and suppress irrelevant variations. An image, for example, comes in the form of an array of pixel values, and the learned features in the first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image. The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions. The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects, and subsequent layers would detect objects as combinations of these parts. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. In addition to beating records in image recognition and speech recognition, it has beaten other machine-learning techniques at predicting the activity of potential drug molecules, analysing particle accelerator data, reconstructing brain circuits, and predicting the effects of mutations in non-coding DNA on gene expression and disease. Perhaps more surprisingly, deep learning has produced extremely promising results for various tasks in natural language understanding, particularly topic classification, sentiment analysis, question answering and language translation. We think that deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data. New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.", "PublicationYear": "2015", "Authors": ["Yann LeCun", "Yoshua Bengio", "Geoffrey E. Hinton"], "RelatedTopics": ["Computer Science"], "References": ["5d90f06bb70a0a3dced62413346235c02b1aa086", "be9a17321537d9289875fe475b71f4821457b435", "25badc676197a70aaf9911865eb03469e402ba57", "3137bc367c61c0e507a5e3c1f8caeb26f292d79f", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "162d958ff885f1462aeda91cd72582323fd6a1f4", "755e9f43ce398ae8737366720c5f82685b0c253e", "72e93aa6767ee683de7f001fa72f1314e40a8f35", "1128c5607a19af6022be723d10dbf8fad3ca26ab", "081651b38ff7533550a3adfc1c00da333a8fe86c"], "ReferenceCount": 831, "CitationCount": 58363}, {"URL": "https://www.semanticscholar.org/paper/Incremental-Kernel-Null-Space-Discriminant-Analysis-Liu-Lian/5d666e2761bbac7d8e0ac724280d20fd24d71a6b", "ID": "5d666e2761bbac7d8e0ac724280d20fd24d71a6b", "Title": "Incremental Kernel Null Space Discriminant Analysis for Novelty Detection", "Abstract": "Experiments demonstrate that the proposed Incremental Kernel Null Space based Discriminant Analysis (IKNDA) algorithm yields comparable performance as the batch KNDA yet significantly reduces the computational complexity, and markedly outperform approaches using deep neural network (DNN) classifiers. Novelty detection, which aims to determine whether a given data belongs to any category of training data or not, is considered to be an important and challenging problem in areas of Pattern Recognition, Machine Learning, etc. Recently, kernel null space method (KNDA) was reported to have state-of-the-art performance in novelty detection. However, KNDA is hard to scale up because of its high computational cost. With the ever-increasing size of data, accelerating the implementing speed of KNDA is desired and critical. Moreover, it becomes incapable when there exist successively injected data. To address these issues, we propose the Incremental Kernel Null Space based Discriminant Analysis (IKNDA) algorithm. The key idea is to extract new information brought by newly-added samples and integrate it with the existing model by an efficient updating scheme. Experiments conducted on two publicly-available datasets demonstrate that the proposed IKNDA yields comparable performance as the batch KNDA yet significantly reduces the computational complexity, and our IKNDA based novelty detection methods markedly outperform approaches using deep neural network (DNN) classifiers. This validates the superiority of our IKNDA against the state of the art in novelty detection for large-scale data.", "PublicationYear": "2017", "Authors": ["Juncheng Liu", "Zhouhui Lian", "Yi Wang", "Jianguo Xiao"], "RelatedTopics": ["Computer Science"], "References": ["1972c73d96353e57599962fd6059572801382212", "ecade8c741e29b89143450f6b098cd618bc5237d", "0145c5d5b916d844088a136b114f5597ead2244c", "20830f958fa822fe8f0fb8aecd2a2655e595438a", "78874a205a307f4412f46c5284b97649b6b2dc3e", "20ff2e46a193dfe9add95f780f7f81536f4bb279", "4e326167b7bb989215ac4d35e0c5d1f4102451a0", "9acc51b06f54b07836fad4cc24633187dc21317f", "724d0b9b7f6a62adbc7395f7c2bfa8436622d423", "3cc33df94447c7e1959c876d9d0bc14edebc0c96"], "ReferenceCount": 27, "CitationCount": 52}, {"URL": "https://www.semanticscholar.org/paper/Image-Denoising-via-CNNs%3A-An-Adversarial-Approach-Divakar-Babu/a7fae7dba0db74cc21a7c7b70157fe601784b681", "ID": "a7fae7dba0db74cc21a7c7b70157fe601784b681", "Title": "Image Denoising via CNNs: An Adversarial Approach", "Abstract": "A new CNN architecture for blind image denoising which synergically combines three architecture components, a multi-scale feature extraction layer which helps in reducing the effect of noise on feature maps, an \u2113p regularizer which helps on selecting only the appropriate feature maps for the task of reconstruction, and a three step training approach which leverages adversarial training to give the final performance boost to the model. Is it possible to recover an image from its noisy version using convolutional neural networks? This is an interesting problem as convolutional layers are generally used as feature detectors for tasks like classification, segmentation and object detection. We present a new CNN architecture for blind image denoising which synergically combines three architecture components, a multi-scale feature extraction layer which helps in reducing the effect of noise on feature maps, an \u2113p regularizer which helps in selecting only the appropriate feature maps for the task of reconstruction, and finally a three step training approach which leverages adversarial training to give the final performance boost to the model. The proposed model shows competitive denoising performance when compared to the state-of-the-art approaches.", "PublicationYear": "2017", "Authors": ["Nithish Divakar", "R. Venkatesh Babu"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["47900aca2f0b50da3010ad59b394c870f0e6c02e", "b2af2a2f2d1be22ebf473f7e0f501f1f5c02f222", "8388f1be26329fa45e5807e968a641ce170ea078", "1d70937202d843664c5591fde4fb0d48627d1cf6", "df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3", "eb42cf88027de515750f230b23b1a057dc782108", "17fa1c2a24ba8f731c8b21f1244463bc4b465681", "571b0750085ae3d939525e62af510ee2cee9d5ea", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "e15cf50aa89fee8535703b9f9512fca5bfc43327"], "ReferenceCount": 27, "CitationCount": 69}, {"URL": "https://www.semanticscholar.org/paper/Deep-Cascade%3A-Cascading-3D-Deep-Neural-Networks-for-Sabokrou-Fayyaz/6f68ce1e03c56c186256dac689a21f6405ae8d96", "ID": "6f68ce1e03c56c186256dac689a21f6405ae8d96", "Title": "Deep-Cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes", "Abstract": "It is shown that the proposed novel technique, characterised by a cascade of two cascaded classifiers, performs comparable to current top-performing detection and localization methods on standard benchmarks, but outperforms those in general with respect to required computation time. This paper proposes a fast and reliable method for anomaly detection and localization in video data showing crowded scenes. Time-efficient anomaly localization is an ongoing challenge and subject of this paper. We propose a cubic-patch-based method, characterised by a cascade of classifiers, which makes use of an advanced feature-learning approach. Our cascade of classifiers has two main stages. First, a light but deep 3D auto-encoder is used for early identification of \u201cmany\u201d normal cubic patches. This deep network operates on small cubic patches as being the first stage, before carefully resizing the remaining candidates of interest, and evaluating those at the second stage using a more complex and deeper 3D convolutional neural network (CNN). We divide the deep auto-encoder and the CNN into multiple sub-stages, which operate as cascaded classifiers. Shallow layers of the cascaded deep networks (designed as Gaussian classifiers, acting as weak single-class classifiers) detect \u201csimple\u201d normal patches, such as background patches and more complex normal patches, are detected at deeper layers. It is shown that the proposed novel technique (a cascade of two cascaded classifiers) performs comparable to current top-performing detection and localization methods on standard benchmarks, but outperforms those in general with respect to required computation time.", "PublicationYear": "2017", "Authors": ["M. Sabokrou", "Mohsen Fayyaz", "Mahmood Fathy", "Reinhard Klette"], "RelatedTopics": ["Computer Science"], "References": ["2e61eb4a5c6fe6c0fdb36cfb84d460ee1524099f", "60fef33549f57f5cbb6712a510c3a444ab682429", "ae8d8f417ca05bba10dac49400dc9a09e71ac2b2", "5727ec1431551cee254201c5465fa384198bc4ca", "11655f8630262e5830352b68962bb721ed261f7d", "851ff5f13fbff7023717c3913f2df4a7551a374a", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "d7c3c875f2f0c8ff1e8361802eca52c7b1d481c5", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "109eef0f2319c6173b7cc22120254f01746ef77a"], "ReferenceCount": 53, "CitationCount": 305}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078", "ID": "8388f1be26329fa45e5807e968a641ce170ea078", "Title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks", "Abstract": "This work introduces a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrates that they are a strong candidate for unsupervised learning. In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.", "PublicationYear": "2015", "Authors": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "RelatedTopics": ["Computer Science"], "References": ["47900aca2f0b50da3010ad59b394c870f0e6c02e", "1e80f755bcbf10479afd2338cec05211fdbd325c", "c08f5fa876181fc040d76c75fe2433eee3c9b001", "0f84a81f431b18a78bd97f59ed4b9d8eda390970", "bcaf73e6389261da6f2fdf88b20b17f4fc2add90", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "571b0750085ae3d939525e62af510ee2cee9d5ea", "4dcdae25a5e33682953f0853ee4cf7ca93be58a9", "182015c5edff1956cbafbcb3e7bbe294aa54f9fc", "86ee1835a56722b76564119437070782fc90eb19"], "ReferenceCount": 46, "CitationCount": 12535}, {"URL": "https://www.semanticscholar.org/paper/One-class-classification%3A-taxonomy-of-study-and-of-Khan-Madden/9eb1b16fbd4786eaac91f308d75609b9321868ce", "ID": "9eb1b16fbd4786eaac91f308d75609b9321868ce", "Title": "One-class classification: taxonomy of study and review of techniques", "Abstract": "A unified view of the general problem of OCC is presented by presenting a taxonomy of study for OCC problems, which is based on the availability of training data, algorithms used and the application domains applied. Abstract One-class classification (OCC) algorithms aim to build classification models when the negative class is either absent, poorly sampled or not well defined. This unique situation constrains the learning of efficient classifiers by defining class boundary just with the knowledge of positive class. The OCC problem has been considered and applied under many research themes, such as outlier/novelty detection and concept learning. In this paper, we present a unified view of the general problem of OCC by presenting a taxonomy of study for OCC problems, which is based on the availability of training data, algorithms used and the application domains applied. We further delve into each of the categories of the proposed taxonomy and present a comprehensive literature review of the OCC algorithms, techniques and methodologies with a focus on their significance, limitations and applications. We conclude our paper by discussing some open research problems in the field of OCC and present our vision for future research.", "PublicationYear": "2013", "Authors": ["Shehroz S. Khan", "Michael G. Madden"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["c0c07935977e70e71d296535729fc718636d76c4", "27a9048fdb07a7c49dd9941c59fbad5d6b9e443d", "b72f1ff0f1a29888546b21a925484f267ef15c30", "0bb0c6dfeb8f838470f27cefd0ba42192ecaf90a", "5ff9cb1a917026e313f6f7e3ae59cb21825d9a49", "0bacda847c2eaaa4690ec341a819994ebddbbd3d", "82ee4bb629b61096c154e3e05e4782f533006630", "a61509ec3c93e5fb00661606289cc12accd283d2", "c72bb6c83db08e17e2736bc1d2cf439fe1f71905", "9a336d940160cc8ef20b3fcef15b8774a3a8c41a"], "ReferenceCount": 195, "CitationCount": 491}, {"URL": "https://www.semanticscholar.org/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d", "ID": "9d5290fadb7625862a966e0330bd0f9e111fc99d", "Title": "Abnormal event detection in videos using generative adversarial nets", "Abstract": "Experimental results on challenging abnormality detection datasets show the superiority of the proposed method compared to the state of the art in both frame-level and pixel-level abnormality Detection tasks. In this paper we address the abnormality detection problem in crowded scenes. We propose to use Generative Adversarial Nets (GANs), which are trained using normal frames and corresponding optical-flow images in order to learn an internal representation of the scene normality. Since our GANs are trained with only normal data, they are not able to generate abnormal events. At testing time the real data are compared with both the appearance and the motion representations reconstructed by our GANs and abnormal areas are detected by computing local differences. Experimental results on challenging abnormality detection datasets show the superiority of the proposed method compared to the state of the art in both frame-level and pixel-level abnormality detection tasks.", "PublicationYear": "2017", "Authors": ["Mahdyar Ravanbakhsh", "Moin Nabi", "E. Sangineto", "Lucio Marcenaro", "Carlo S. Regazzoni", "N. Sebe"], "RelatedTopics": ["Computer Science"], "References": ["7d8755284169f6f721e046798df1eeb1170ebdd0", "e5366a704ffa3b41aacd385f3c087ec3fd566934", "655b1f83ef218ee6a030b5541d2865bc6599e6d9", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6", "fd52349a019d928cd9b09c2f6a8a689f174bbbf2", "869b17632ed4f19f93b3b58dcaa9f0b8e92108f3", "67dccc9a856b60bdc4d058d83657a089b8ad4486", "571b0750085ae3d939525e62af510ee2cee9d5ea", "8388f1be26329fa45e5807e968a641ce170ea078"], "ReferenceCount": 31, "CitationCount": 379}, {"URL": "https://www.semanticscholar.org/paper/Fully-Convolutional-Neural-Network-for-Fast-Anomaly-Sabokrou-Fayyaz/6259b02912cebc224f3a2b1324e811a152a0177d", "ID": "6259b02912cebc224f3a2b1324e811a152a0177d", "Title": "Fully Convolutional Neural Network for Fast Anomaly Detection in Crowded Scenes", "Abstract": "An FCN-based architecture for anomaly detection and localization in crowded scenes videos is proposed, which includes two main components, one for feature representation, and one for cascaded out-layer detection. We present an efficient method for detecting and localizing anomalies in videos showing crowded scenes. Research on {\\\\it fully convolutional neural networks} (FCNs) has shown the potentials of this technology for object detection and localization, especially in images. We investigate how to involve temporal data, and how to transform a supervised FCN into an unsupervised one such that the resulting FCN ensures anomaly detection. Altogether, we propose an FCN-based architecture for anomaly detection and localization in crowded scenes videos. For reducing computations and, consequently, improving performance both with respect to speed and accuracy, we investigate the use of cascaded out-layer detection. Our architecture includes two main components, one for feature representation, and one for cascaded out-layer detection. Experimental results on Subway and UCSD benchmarks confirm that the detection and localization accuracy of our method is comparable to state-of-the-art methods, but at a significantly increased speed of 370 fps.", "PublicationYear": "2016", "Authors": ["M. Sabokrou", "Mohsen Fayyaz", "Mahmood Fathy", "Reinhard Klette"], "RelatedTopics": ["Computer Science", "Engineering"], "References": [], "ReferenceCount": 0, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Learning-Deep-Representations-of-Appearance-and-for-Xu-Ricci/60fef33549f57f5cbb6712a510c3a444ab682429", "ID": "60fef33549f57f5cbb6712a510c3a444ab682429", "Title": "Learning Deep Representations of Appearance and Motion for Anomalous Event Detection", "Abstract": "This work proposes Appearance and Motion DeepNet (AMDN) which utilizes deep neural networks to automatically learn feature representations, and introduces a novel double fusion framework, combining both the benefits of traditional early fusion and late fusion strategies. We present a novel unsupervised deep learning framework for anomalous event detection in complex video scenes. While most existing works merely use hand-crafted appearance and motion features, we propose Appearance and Motion DeepNet (AMDN) which utilizes deep neural networks to automatically learn feature representations. To exploit the complementary information of both appearance and motion patterns, we introduce a novel double fusion framework, combining both the benefits of traditional early fusion and late fusion strategies. Specifically, stacked denoising autoencoders are proposed to separately learn both appearance and motion features as well as a joint representation (early fusion). Based on the learned representations, multiple one-class SVM models are used to predict the anomaly scores of each input, which are then integrated with a late fusion strategy for final anomaly detection. We evaluate the proposed method on two publicly available video surveillance datasets, showing competitive performance with respect to state of the art approaches.", "PublicationYear": "2015", "Authors": ["Dan Xu", "Elisa Ricci", "Yan Yan", "Jingkuan Song", "N. Sebe"], "RelatedTopics": ["Computer Science"], "References": ["e5366a704ffa3b41aacd385f3c087ec3fd566934", "146adb105ebcece295a24e8cf3643c9fd0f89bcb", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "67dccc9a856b60bdc4d058d83657a089b8ad4486", "2dccec3c1a8a17883cece784e8f0fc0af413eb83", "b2180fc4f5cb46b5b5394487842399c501381d67", "a605a375d0803794adee9eac225011d294dfbada", "ae37774ff871575b7799411bf87f42eb52634390", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "ce9edb785f28c81bd7c2864940ed001429178e1e"], "ReferenceCount": 40, "CitationCount": 480}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Anomaly-Localization-using-Variational-Zimmerer-Isensee/06fad023ef0274e7d6727ecbd1ef46887a6806df", "ID": "06fad023ef0274e7d6727ecbd1ef46887a6806df", "Title": "Unsupervised Anomaly Localization using Variational Auto-Encoders", "Abstract": "Results show that the proposed formalism outperforms the state of the art VAE-based localization of anomalies across many hyperparameter settings and also shows a competitive max performance. An assumption-free automatic check of medical images for potentially overseen anomalies would be a valuable assistance for a radiologist. Deep learning and especially Variational Auto-Encoders (VAEs) have shown great potential in the unsupervised learning of data distributions. In principle, this allows for such a check and even the localization of parts in the image that are most suspicious. Currently, however, the reconstruction-based localization by design requires adjusting the model architecture to the specific problem looked at during evaluation. This contradicts the principle of building assumption-free models. We propose complementing the localization part with a term derived from the Kullback-Leibler (KL)-divergence. For validation, we perform a series of experiments on FashionMNIST as well as on a medical task including &gt;1000 healthy and &gt;250 brain tumor patients. Results show that the proposed formalism outperforms the state of the art VAE-based localization of anomalies across many hyperparameter settings and also shows a competitive max performance.", "PublicationYear": "2019", "Authors": ["David Zimmerer", "Fabian Isensee", "Jens Petersen", "Simon A. A. Kohl", "Klaus Maier-Hein"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["a14b354fe3e1f1f3fec821fbcde02064fcbe297a", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476", "a3fce9324329581d484dfc8c3f018bc31751ca82", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "5ad2476610312f380dd4e6475ee706199560b21a", "31a2053ebda7f6f77afe8c3fc53269b73567e446", "f6a201eed70e8b48e2f60d97c98cfc8fe3b7b175", "5bd34f60889c33aba677c7c123e6d4dbb86b8350", "8388f1be26329fa45e5807e968a641ce170ea078"], "ReferenceCount": 23, "CitationCount": 90}, {"URL": "https://www.semanticscholar.org/paper/A-Case-for-the-Score%3A-Identifying-Image-Anomalies-Zimmerer-Petersen/fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d", "ID": "fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d", "Title": "A Case for the Score: Identifying Image Anomalies using Variational Autoencoder Gradients", "Abstract": "It is argued that pixel-wise anomaly ratings derived from a Variational Autoencoder based score approximation yield a theoretically better grounded and more faithful estimate on unsupervisedpixel-wise tumor detection on the BraTS-2017 dataset. Through training on unlabeled data, anomaly detection has the potential to impact computer-aided diagnosis by outlining suspicious regions. Previous work on deep-learning-based anomaly detection has primarily focused on the reconstruction error. We argue instead, that pixel-wise anomaly ratings derived from a Variational Autoencoder based score approximation yield a theoretically better grounded and more faithful estimate. In our experiments, Variational Autoencoder gradient-based rating outperforms other approaches on unsupervised pixel-wise tumor detection on the BraTS-2017 dataset with a ROC-AUC of 0.94.", "PublicationYear": "2019", "Authors": ["David Zimmerer", "Jens Petersen", "Simon A. A. Kohl", "Klaus Maier-Hein"], "RelatedTopics": ["Computer Science"], "References": ["eb60fe884c53b420edbce57059b242cfcbae0f7c", "f538dca4def5167a32fbc12107b69a05f0c9d832", "7198f45e979d4e7bb2ad2f8a5f098ab196c532b6", "a3fce9324329581d484dfc8c3f018bc31751ca82", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476", "21b786b3f870fc7fa247c143aa41de88b1fc6141", "1cb5dea2a8f6abf0ef61ce229ee866594b6c5228", "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b", "6bacf99c87991523a97165610b492f28c8cacbb2"], "ReferenceCount": 20, "CitationCount": 21}, {"URL": "https://www.semanticscholar.org/paper/Classification-Accuracy-Score-for-Conditional-Ravuri-Vinyals/ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa", "ID": "ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa", "Title": "Classification Accuracy Score for Conditional Generative Models", "Abstract": "This work uses class-conditional generative models from a number of model classes---variational autoencoders, autoregressive models, and generative adversarial networks (GANs)---to infer the class labels of real data and reveals some surprising results not identified by traditional metrics. Deep generative models (DGMs) of images are now sufficiently mature that they produce nearly photorealistic samples and obtain scores similar to the data distribution on heuristics such as Frechet Inception Distance (FID). These results, especially on large-scale datasets such as ImageNet, suggest that DGMs are learning the data distribution in a perceptually meaningful space and can be used in downstream tasks. To test this latter hypothesis, we use class-conditional generative models from a number of model classes---variational autoencoders, autoregressive models, and generative adversarial networks (GANs)---to infer the class labels of real data. We perform this inference by training an image classifier using only synthetic data and using the classifier to predict labels on real data. The performance on this task, which we call Classification Accuracy Score (CAS), reveals some surprising results not identified by traditional metrics and constitute our contributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1 and Top-5 accuracy decrease by 27.9\\\\% and 41.6\\\\%, respectively, compared to the original data; and conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on this benchmark. Second, CAS automatically surfaces particular classes for which generative models failed to capture the data distribution, and were previously unknown in the literature. Third, we find traditional GAN metrics such as Inception Score (IS) and FID neither predictive of CAS nor useful when evaluating non-GAN models. Furthermore, in order to facilitate better diagnoses of generative models, we open-source the proposed metric.", "PublicationYear": "2019", "Authors": ["Suman V. Ravuri", "Oriol Vinyals"], "RelatedTopics": ["Computer Science"], "References": ["571b0750085ae3d939525e62af510ee2cee9d5ea", "1ea9f643171115e4a89e77c9a770c593f0794712", "9e94feb128625ea51b0ef04e74ea6fe84f237c8f", "fcdcde3f796fc2c7d6bdeeb4f6b2281ec18be614", "6be216d93421bf19c1659e7721241ae73d483baf", "097ccdfc47f1974591e2c1c6d17532b9b96a17a1", "8b1a1949789d12997b0a5ade953309308a81e115", "22aab110058ebbd198edb1f1e7b4f69fb13c0613", "d383dd8ced85d7898d8b1546c514a34fb626ea16", "60b2e0b0f91432aa7e6500d6d0f92d391c96e717"], "ReferenceCount": 48, "CitationCount": 168}, {"URL": "https://www.semanticscholar.org/paper/Towards-Visually-Explaining-Variational-Liu-Li/0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b", "ID": "0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b", "Title": "Towards Visually Explaining Variational Autoencoders", "Abstract": "This work proposes the first technique to visually explain VAEs by means of gradient-based attention, and presents methods to generate visual attention from the learned latent space, and shows how such attention explanations serve more than just explaining VAE predictions. Recent advances in Convolutional Neural Network (CNN) model interpretability have led to impressive progress in visualizing and understanding model predictions. In particular, gradient-based visual attention methods have driven much recent effort in using visual attention maps as a means for visual explanations. A key problem, however, is these methods are designed for classification and categorization tasks, and their extension to explaining generative models, e.g., variational autoencoders (VAE) is not trivial. In this work, we take a step towards bridging this crucial gap, proposing the first technique to visually explain VAEs by means of gradient-based attention. We present methods to generate visual attention from the learned latent space, and also demonstrate such attention explanations serve more than just explaining VAE predictions. We show how these attention maps can be used to localize anomalies in images, demonstrating state-of-the-art performance on the MVTec-AD dataset. We also show how they can be infused into model training, helping bootstrap the VAE into learning improved latent space disentanglement, demonstrated on the Dsprites dataset.", "PublicationYear": "2019", "Authors": ["Wenqian Liu", "Runze Li", "Meng Zheng", "Srikrishna Karanam", "Ziyan Wu", "Bir Bhanu", "Richard J. Radke", "Octavia I. Camps"], "RelatedTopics": ["Computer Science"], "References": ["6bacf99c87991523a97165610b492f28c8cacbb2", "04541599accc47d8174f63345ce9c987ef21685b", "a90226c41b79f8b06007609f39f82757073641e2", "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "13bc4e683075bdd6a3f0155241c276a772d4aa06", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "0d0a810f622a0d753ef41f32cf963254ba9926b8", "e3b5c2fecec38ab3a7139fcc45814073f1369248", "3aa681914a7da79f7d7293f51a058eefe61c8bb7"], "ReferenceCount": 48, "CitationCount": 152}, {"URL": "https://www.semanticscholar.org/paper/Pathology-Aware-Deep-Network-Visualization-and-Its-Wang-Xu/39972fb3a9cbac1e25b2c096e3e28bba2eee7aa4", "ID": "39972fb3a9cbac1e25b2c096e3e28bba2eee7aa4", "Title": "Pathology-Aware Deep Network Visualization and Its Application in Glaucoma Image Synthesis", "Abstract": "This paper proposes a novel pathology-aware visualization approach for DNN-based glaucoma classification, which is used to locate the pathological evidence from fundus images for glAUcoma, and applies the visualization framework to the glauca images synthesis task, through which specific pathological areas of synthesized images can be enhanced. The past few years have witnessed the great success of applying deep neural networks (DNNs) in computer-aided diagnosis. However, little attention has been paid to provide pathological evidence in the existing DNNs for medical diagnosis. In fact, feature visualization in DNNs is able to help understanding how the computer make decisions, and thus it shows promise on finding pathological evidence from computer-aided diagnosis. In this paper, we propose a novel pathology-aware visualization approach for DNN-based glaucoma classification, which is used to locate the pathological evidence from fundus images for glaucoma. Besides, we apply the visualization framework to the glaucoma images synthesis task, through which specific pathological areas of synthesized images can be enhanced. Finally, experimental results show that the visualization heat maps can pinpoint different glaucoma pathologies with high accuracy, and that the generated glaucoma images are more pathophysiologically clear in rim loss (RL) and retinal neural fiber layer damage (RNFLD), which is verified by the ophthalmologist.", "PublicationYear": "2019", "Authors": ["Xiaofei Wang", "Mai Xu", "Liu Li", "Zulin Wang", "Zhenyu Guan"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["90e86fa36b56c8860719ef11ecfa2ebf3333ad1e", "d95abb4a05e21e4e2929c3cfccf58abce7d18796", "872de2cc2613f18a3a08c75883b834747708a583", "6380f7d6f61646a4dc07a6b489ddf445a0da5df4", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "e1ec11a1cb3d9745fb18d3bf74247f95a6663d08", "35d0998f2c5b53591073d36c9e2b0ddc89a496b1", "159f4c05bc29e86bcbf8c1bcd9eae1f33ce2f3da", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "9b86f1ceafed523f97ac574f105c50757e144884"], "ReferenceCount": 13, "CitationCount": 9}, {"URL": "https://www.semanticscholar.org/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4", "ID": "8a6acba7fb2aad1299fcf35701417e063d410ed4", "Title": "Future Frame Prediction for Anomaly Detection - A New Baseline", "Abstract": "This paper proposes to tackle the anomaly detection problem within a video prediction framework by introducing a motion (temporal) constraint in video prediction by enforcing the optical flow between predicted frames and ground truth frames to be consistent, and is the first work that introduces a temporal constraint into the video prediction task. Anomaly detection in videos refers to the identification of events that do not conform to expected behavior. However, almost all existing methods tackle the problem by minimizing the reconstruction errors of training data, which cannot guarantee a larger reconstruction error for an abnormal event. In this paper, we propose to tackle the anomaly detection problem within a video prediction framework. To the best of our knowledge, this is the first work that leverages the difference between a predicted future frame and its ground truth to detect an abnormal event. To predict a future frame with higher quality for normal events, other than the commonly used appearance (spatial) constraints on intensity and gradient, we also introduce a motion (temporal) constraint in video prediction by enforcing the optical flow between predicted frames and ground truth frames to be consistent, and this is the first work that introduces a temporal constraint into the video prediction task. Such spatial and motion constraints facilitate the future frame prediction for normal events, and consequently facilitate to identify those abnormal events that do not conform the expectation. Extensive experiments on both a toy dataset and some publicly available datasets validate the effectiveness of our method in terms of robustness to the uncertainty in normal events and the sensitivity to abnormal events. All codes are released in https://github.com/StevenLiuWen/ano_pred_cvpr2018.", "PublicationYear": "2017", "Authors": ["Wen Liu", "Weixin Luo", "Dongze Lian", "Shenghua Gao"], "RelatedTopics": ["Computer Science"], "References": ["84f7f9e121c1285e15cefbfc44bcb3322f73b6aa", "7a89447be0a176368926f1ef108512f4df5e27be", "792250ae660b7c25f85eeea7dcae623e4301d97c", "731a2844c5af6b072d3b404ecabbb488cdad9d46", "60fef33549f57f5cbb6712a510c3a444ab682429", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "094ac7510d1723cb9c2da01db47291322aa29025", "f36f8d32252679f4221c3d2afc2407a9f56b29a7", "ae37774ff871575b7799411bf87f42eb52634390", "17fa1c2a24ba8f731c8b21f1244463bc4b465681"], "ReferenceCount": 46, "CitationCount": 795}, {"URL": "https://www.semanticscholar.org/paper/Learning-Deep-Features-for-Discriminative-Zhou-Khosla/31f9eb39d840821979e5df9f34a6e92dd9c879f2", "ID": "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "Title": "Learning Deep Features for Discriminative Localization", "Abstract": "This work revisits the global average pooling layer proposed in [13], and sheds light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.", "PublicationYear": "2015", "Authors": ["Bolei Zhou", "Aditya Khosla", "{\\`A}gata Lapedriza", "Aude Oliva", "Antonio Torralba"], "RelatedTopics": ["Computer Science"], "References": ["bd2f443fc18947d2c9ecb81192b3f0a9cd2cf3f1", "1109b663453e78a59e4f66446d71720ac58cec25", "eb42cf88027de515750f230b23b1a057dc782108", "ec679c45e88fa25fec32c30bc7c1b7d7fd0facec", "b8de958fead0d8a9619b55c7299df3257c624a96", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "c08f5fa876181fc040d76c75fe2433eee3c9b001", "401192b00b650adfa5ac49de59b720e1c81f1410", "e15cf50aa89fee8535703b9f9512fca5bfc43327", "125f7b539e89cd0940ff89c231902b1d4023b3ba"], "ReferenceCount": 37, "CitationCount": 7709}, {"URL": "https://www.semanticscholar.org/paper/Attention-Based-Glaucoma-Detection%3A-A-Large-Scale-Li-Xu/97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f", "ID": "97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f", "Title": "Attention Based Glaucoma Detection: A Large-Scale Database and CNN Model", "Abstract": "The proposed AG-CNN approach significantly advances state-of-the-art glaucoma detection, including an attention prediction subnet, a pathological area localization subnet and a glauca classification subnet. Recently, the attention mechanism has been successfully applied in convolutional neural networks (CNNs), significantly boosting the performance of many computer vision tasks. Unfortunately, few medical image recognition approaches incorporate the attention mechanism in the CNNs. In particular, there exists high redundancy in fundus images for glaucoma detection, such that the attention mechanism has potential in improving the performance of CNN-based glaucoma detection. This paper proposes an attention-based CNN for glaucoma detection (AG-CNN). Specifically, we first establish a large-scale attention based glaucoma (LAG) database, which includes 5,824 fundus images labeled with either positive glaucoma (2,392) or negative glaucoma (3,432). The attention maps of the ophthalmologists are also collected in LAG database through a simulated eye-tracking experiment. Then, a new structure of AG-CNN is designed, including an attention prediction subnet, a pathological area localization subnet and a glaucoma classification subnet. Different from other attention-based CNN methods, the features are also visualized as the localized pathological area, which can advance the performance of glaucoma detection. Finally, the experiment results show that the proposed AG-CNN approach significantly advances state-of-the-art glaucoma detection.", "PublicationYear": "2019", "Authors": ["Liu Li", "Mai Xu", "Xiaofei Wang", "Lai Jiang", "Hanruo Liu"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["d95abb4a05e21e4e2929c3cfccf58abce7d18796", "d3dad3c88acfa4080747767d01eabe92b4f7b3c3", "115e499872480ae3e54277a4861e7fd9295a25d7", "90e86fa36b56c8860719ef11ecfa2ebf3333ad1e", "f550c444c91174592a73df4476f9bc921af3c393", "9ec2f647349aaf43615bb50742176741d5accd2e", "26b632d486741a346e4658d5f9b0d5431cb6e7dc", "b954efe5e46b8952f5a8daf42e7e535119b5408b", "c8eec916ea6e6d2a57a0d9ca29c9b95525b53314", "5c45a5d05ac564adb67811eeb9d41d6460c70135"], "ReferenceCount": 47, "CitationCount": 153}, {"URL": "https://www.semanticscholar.org/paper/An-Unbiased-Cell-Morphology%E2%80%93Based-Screen-for-New%2C-Tanaka-Bateman/8125727fe5b62492f4ccb1e25c66d473dd5c83c9", "ID": "8125727fe5b62492f4ccb1e25c66d473dd5c83c9", "Title": "An Unbiased Cell Morphology\u2013Based Screen for New, Biologically Active Small Molecules", "Abstract": "An unbiased cell morphology\u2013based screen to identify small-molecule modulators of cellular processes using the Cytometrix (TM) automated imaging and analysis system revealed a previously unknown function for CBR1 in serum-withdrawal-induced apoptosis, and studies indicateCBR1 inhibitors may enhance the effectiveness of anticancer anthracyclines. We have implemented an unbiased cell morphology\u2013based screen to identify small-molecule modulators of cellular processes using the Cytometrix (TM) automated imaging and analysis system. This assay format provides unbiased analysis of morphological effects induced by small molecules by capturing phenotypic readouts of most known classes of pharmacological agents and has the potential to read out pathways for which little is known. Four human-cancer cell lines and one noncancerous primary cell type were treated with 107 small molecules comprising four different protein kinase\u2013inhibitor scaffolds. Cellular phenotypes induced by each compound were quantified by multivariate statistical analysis of the morphology, staining intensity, and spatial attributes of the cellular nuclei, microtubules, and Golgi compartments. Principal component analysis was used to identify inhibitors of cellular components not targeted by known protein kinase inhibitors. Here we focus on a hydroxyl-substituted analog (hydroxy-PP) of the known Src-family kinase inhibitor PP2 because it induced cell-specific morphological features distinct from all known kinase inhibitors in the collection. We used affinity purification to identify a target of hydroxy-PP, carbonyl reductase 1 (CBR1), a short-chain dehydrogenase-reductase. We solved the X-ray crystal structure of the CBR1/hydroxy-PP complex to 1.24 \u00c5 resolution. Structure-based design of more potent and selective CBR1 inhibitors provided probes for analyzing the biological function of CBR1 in A549 cells. These studies revealed a previously unknown function for CBR1 in serum-withdrawal-induced apoptosis. Further studies indicate CBR1 inhibitors may enhance the effectiveness of anticancer anthracyclines. Morphology-based screening of diverse cancer cell types has provided a method for discovering potent new small-molecule probes for cell biological studies and anticancer drug candidates.", "PublicationYear": "2005", "Authors": ["Masahiro Tanaka", "Raynard L. Bateman", "Daniel Rauh", "Eugeni A. Vaisberg", "Shyam Ramachandani", "Chao Zhang", "Kirk C. Hansen", "Alma L. Burlingame", "Jay Kenneth Trautman", "Kevan M. Shokat", "Cynthia L. Adams"], "RelatedTopics": ["Biology", "Chemistry", "Medicine"], "References": ["2cf150bbc19e78ee3ea297cc447616922a1894c7", "e835b06ed61e0eb5eae3c083dbd150e8655c85ce", "8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "3a452db2e9ed79d8d54ba771cdcc3183e32ab7b0", "c9ce08df6e9e008538284be17ee35a7e743688dd", "b1ca8b061685ff136c83b7b7f69ce3c0c4351ced", "95c31e45c2e3e6144fc8caa8dad7f94c552113da", "e9a9794fc2f2ed7846e0fdfcb28f09caa9c8882c", "0ff02325e2a24a7c47d65ee3294b019ca9ad8404", "c987a40103c8bde5939230f521dcde0127eb3188"], "ReferenceCount": 43, "CitationCount": 240}, {"URL": "https://www.semanticscholar.org/paper/High-Content-Phenotypic-Profiling-of-Drug-Response-Caie-Walls/3e5e4e1550416646ad33814ba3d6f20935ac742f", "ID": "3e5e4e1550416646ad33814ba3d6f20935ac742f", "Title": "High-Content Phenotypic Profiling of Drug Response Signatures across Distinct Cancer Cells", "Abstract": "The utility of a cell-based assay and custom designed image analysis algorithms designed to monitor morphologic phenotypic response in detail across distinct cancer cell types are shown and have the potential to drive the development of a new generation of novel therapeutic classes encompassing pharmacologic compositions or polypharmacology in appropriate disease context. The application of high-content imaging in conjunction with multivariate clustering techniques has recently shown value in the confirmation of cellular activity and further characterization of drug mode of action following pharmacologic perturbation. However, such practical examples of phenotypic profiling of drug response published to date have largely been restricted to cell lines and phenotypic response markers that are amenable to basic cellular imaging. As such, these approaches preclude the analysis of both complex heterogeneous phenotypic responses and subtle changes in cell morphology across physiologically relevant cell panels. Here, we describe the application of a cell-based assay and custom designed image analysis algorithms designed to monitor morphologic phenotypic response in detail across distinct cancer cell types. We further describe the integration of these methods with automated data analysis workflows incorporating principal component analysis, Kohonen neural networking, and kNN classification to enable rapid and robust interrogation of such data sets. We show the utility of these approaches by providing novel insight into pharmacologic response across four cancer cell types, Ovcar3, MiaPaCa2, and MCF7 cells wild-type and mutant for p53. These methods have the potential to drive the development of a new generation of novel therapeutic classes encompassing pharmacologic compositions or polypharmacology in appropriate disease context. Mol Cancer Ther; 9(6); 1913\u201326. \u00a92010 AACR.", "PublicationYear": "2010", "Authors": ["Peter David Caie", "Rebecca E. Walls", "Alexandra Ingleston-Orme", "Sandeep Daya", "Tom Houslay", "Rob Eagle", "Mark E. Roberts", "Neil O. Carragher"], "RelatedTopics": ["Biology", "Computer Science", "Medicine"], "References": ["7656c3e309fd58a85dd26ebdd5d4436ce6a2f51a", "796f794f3aa5366e8f525a0d2c814fa19c917db4", "3ffe91ef45c94689ede866e3415aeb89c38863f0", "74b6fa545810f7953ca37ec9b765152d345a7081", "6c61dee445c8e5c1710f9f4e1d4106ddb946e981", "66b034bf667aef1bb6f205c6dedbef3b444ee5b7", "b9a3c42c69e1482093ed7178f612bb575fb7953f", "717c3f1d375142809ef32d0bdbd70f95a3056691", "001ae469fb84f6756914947d8d089e972ab69a21", "e1f273b94cf7cc6a24591a7932d32720dcf8058c"], "ReferenceCount": 31, "CitationCount": 149}, {"URL": "https://www.semanticscholar.org/paper/Connecting-synthetic-chemistry-decisions-to-cell-Wagner-Clemons/140b7fab48719b56e933216594eaa8b5fc361c1b", "ID": "140b7fab48719b56e933216594eaa8b5fc361c1b", "Title": "Connecting synthetic chemistry decisions to cell and genome biology using small-molecule phenotypic profiling.", "Abstract": "Semantic Scholar extracted view of \\\"Connecting synthetic chemistry decisions to cell and genome biology using small-molecule phenotypic profiling.\\\" by B. Wagner et al.", "PublicationYear": "2009", "Authors": ["Bridget K. Wagner", "Paul A. Clemons"], "RelatedTopics": ["Chemistry", "Biology"], "References": ["74b6fa545810f7953ca37ec9b765152d345a7081", "a46ded22f95f29329066e5dc88162d632dd5e8f5", "a2af4588e416a3e932287f54fd4129ef1cc79dfa", "edd3988b7d1d0847143949ce4188256b1f11eb9a", "b6288a7d9bbe87eec6f766795f9aa38a3f50e660", "62d1948f6c3b39e42b2c5bf0406fb2c6a7564857", "570d4ea51fb40863390d356efb09c5233b00d100", "2c00fdecc37c1fdad416257c7c78dec105807fc9", "f69df8f75f53222bec749e4593119b26ebde96cb", "addbb21ddfaf0e794ed704b993072329aee0b879"], "ReferenceCount": 63, "CitationCount": 33}, {"URL": "https://www.semanticscholar.org/paper/Multi-parameter-phenotypic-profiling%3A-using-effects-Feng-Mitchison/74b6fa545810f7953ca37ec9b765152d345a7081", "ID": "74b6fa545810f7953ca37ec9b765152d345a7081", "Title": "Multi-parameter phenotypic profiling: using cellular effects to characterize small-molecule compounds", "Abstract": "It is thought that an earlier integration of phenotypic profiling technologies, combined with effective experimental and in silico target identification approaches, can improve success rates of lead selection and optimization in the drug discovery process. Multi-parameter phenotypic profiling of small molecules provides important insights into their mechanisms of action, as well as a systems level understanding of biological pathways and their responses to small molecule treatments. It therefore deserves more attention at an early step in the drug discovery pipeline. Here, we summarize the technologies that are currently in use for phenotypic profiling \u2014 including mRNA-, protein- and imaging-based multi-parameter profiling \u2014 in the drug discovery context. We think that an earlier integration of phenotypic profiling technologies, combined with effective experimental and in silico target identification approaches, can improve success rates of lead selection and optimization in the drug discovery process.", "PublicationYear": "2009", "Authors": ["Yan Feng", "Timothy J. Mitchison", "Andreas Bender", "Daniel W. Young", "John A. Tallarico"], "RelatedTopics": ["Medicine", "Chemistry", "Biology", "Computer Science"], "References": ["c418ac71c1a35d4747ae4e0d34659ef8c0ac52cb", "3f79a9a3157076c199afce126064e47117a1ac96", "a2af4588e416a3e932287f54fd4129ef1cc79dfa", "7d1096bc057b6e5e08a6ae821768d4f742d37b77", "bfc8a8724b36cd2b1d068d1f997400e74791a68d", "9b9f382be6cd016ee35be43220f14af1afbb788f", "166d169a62037ad62717721008f69ec1d15518e5", "192885e68723991a09a0cd4d100107cf6c6b2a5f", "8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "46a7044bf96bd357f5b035b2f7fd3dbb6eb86ae7"], "ReferenceCount": 82, "CitationCount": 268}, {"URL": "https://www.semanticscholar.org/paper/Multidimensional-Drug-Profiling-By-Automated-Perlman-Slack/8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "ID": "8b73514fd708f6bdd3786d47a8673a97fdce4dfe", "Title": "Multidimensional Drug Profiling By Automated Microscopy", "Abstract": "This method successfully categorized blinded drugs and suggested targets for drugs of uncertain mechanism with a titration-invariant similarity score (TISS) and is useful for discovering the mechanism and predicting the toxicity of new drugs. We present a method for high-throughput cytological profiling by microscopy. Our system provides quantitative multidimensional measures of individual cell states over wide ranges of perturbations. We profile dose-dependent phenotypic effects of drugs in human cell culture with a titration-invariant similarity score (TISS). This method successfully categorized blinded drugs and suggested targets for drugs of uncertain mechanism. Multivariate single-cell analysis is a starting point for identifying relationships among drug effects at a systems level and a step toward phenotypic profiling at the single-cell level. Our methods will be useful for discovering the mechanism and predicting the toxicity of new drugs.", "PublicationYear": "2004", "Authors": ["Zachary E. Perlman", "Michael D. Slack", "Yan Feng", "Timothy J. Mitchison", "Lani F. Wu", "Steven J. Altschuler"], "RelatedTopics": ["Medicine", "Computer Science", "Chemistry"], "References": ["c9ce08df6e9e008538284be17ee35a7e743688dd", "b4626f94678714c172cbaa273564afb68e9937cd", "9217da1362b16c77c2576df7d0a11244438b7605", "feae36b19d8f8566aefbb8b30e9fb55c1592f0a7", "40331a31b6c0d045c5879db9505e6ce83423902f", "c6a180d752228b859b77cb6fdc65a043cbd2192e", "fe0db487bd82e00cca20024f3952d590bf4e2d90", "2cf150bbc19e78ee3ea297cc447616922a1894c7", "1a3d2bed793521813b5e561712d1835ce47e1623", "f2c26f632cae778d5acc7a221299dbdb789e4303"], "ReferenceCount": 59, "CitationCount": 616}]