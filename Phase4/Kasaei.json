[{"URL": "https://www.semanticscholar.org/paper/The-Eighth-Visual-Object-Tracking-VOT2020-Challenge-Kristan-Leonardis/12508951ba96b7d4c0906ed95542287d3ebdfd95", "ID": "12508951ba96b7d4c0906ed95542287d3ebdfd95", "Title": "The Eighth Visual Object Tracking VOT2020 Challenge Results", "Abstract": "A significant novelty is introduction of a new VOT short-term tracking evaluation methodology, and introduction of segmentation ground truth in the VOT-ST2020 challenge \u2013 bounding boxes will no longer be used in theVDT challenges. The Visual Object Tracking challenge VOT2020 is the eighth annual tracker benchmarking activity organized by the VOT initiative. Results of 58 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The VOT2020 challenge was composed of five sub-challenges focusing on different tracking domains: (i) VOT-ST2020 challenge focused on short-term tracking in RGB, (ii) VOT-RT2020 challenge focused on \u201creal-time\u201d short-term tracking in RGB, (iii) VOT-LT2020 focused on long-term tracking namely coping with target disappearance and reappearance, (iv) VOT-RGBT2020 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2020 challenge focused on long-term tracking in RGB and depth imagery. Only the VOT-ST2020 datasets were refreshed. A significant novelty is introduction of a new VOT short-term tracking evaluation methodology, and introduction of segmentation ground truth in the VOT-ST2020 challenge \u2013 bounding boxes will no longer be used in the VOT-ST challenges. A The Eighth Visual Object Tracking VOT2020 Challenge Results 3 new VOT Python toolkit that implements all these novelites was introduced. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.", "PublicationYear": "2020", "Authors": ["Matej Kristan", "Ale{\\vs} Leonardis", "Jiri Matas", "Michael Felsberg", "Roman P. Pflugfelder", "Joni-Kristian K{\\\"a}m{\\\"a}r{\\\"a}inen", "Martin Danelljan", "Luka Cehovin Zajc", "Alan Luke{\\vz}i{\\vc}", "Ondrej Drbohlav", "Linbo He", "Yushan Zhang", "Song Yan", "Jinyu Yang", "Gustavo Javier Fernandez", "Alexander G. Hauptmann", "Alireza Memarmoghadam", "{\\'A}lvaro Garc{\\'i}a-Mart{\\'i}n", "Andreas Robinson", "Anton Yuriiovych Varfolomieiev", "Awet Haileslassie Gebrehiwot", "Bedirhan Uzun", "Bin Yan", "Bing Li", "Chen Qian", "Chi-Yi Tsai", "Christian Micheloni", "Dong Wang", "Fei Wang", "Fei Xie", "Felix J{\\\"a}remo Lawin", "Fredrik K. Gustafsson", "Gian Luca Foresti", "Goutam Bhat", "Guang-Gui Chen", "Haibin Ling", "Haitao Zhang", "Hakan Cevikalp", "Haojie Zhao", "Haoran Bai", "Hari Chandana Kuchibhotla", "Hasan Saribas", "Heng Fan", "Hossein Ghanei-Yakhdan", "Houqiang Li", "Houwen Peng", "Huchuan Lu", "Hui Li", "Javad Khaghani", "Jes{\\'u}s Besc{\\'o}s", "Jianhua Li", "Jianlong Fu", "Jiaqian Yu", "Jingtao Xu", "Josef Kittler", "Jun Yin", "Junhyun Lee", "Kaicheng Yu", "Kaiwen Liu", "Kang Yang", "Kenan Dai", "Li Cheng", "Li Zhang", "Lijun Wang", "Linyuan Wang", "Luc Van Gool", "Luca Bertinetto", "Matteo Dunnhofer", "Miao Cheng", "Mohana Murali Dasari", "Ning Wang", "Pengyu Zhang", "Philip H. S. Torr", "Qiang Wang", "Radu Timofte", "Rama Krishna Sai Subrahmanyam Gorthi", "Seokeon Choi", "Seyed Mojtaba Marvasti-Zadeh", "Shaochuan Zhao", "Shohreh Kasaei", "Shoumeng Qiu", "Shuhao Chen", "Thomas Bo Sch{\\\"o}n", "Tianyang Xu", "Wei Lu", "Weiming Hu", "Wen-gang Zhou", "Xi Qiu", "Xiao Ke", "Xiaojun Wu", "Xiaolin Zhang", "Xiaoyun Yang", "Xuefeng Zhu", "Yingjie Jiang", "Yingming Wang", "Yiwei Chen", "Yu Ye", "Yuezhou Li", "Yuncon Yao", "Yunsung Lee", "Yuzhang Gu", "Zezhou Wang", "Zhangyong Tang", "Zhenhua Feng", "Zhijun Mai", "Zhipeng Zhang", "Zhirong Wu", "Ziang Ma"], "RelatedTopics": ["Computer Science"], "References": ["786577081e00d69eeac8e9612eaf2dad59765e73", "219e9a4527110baf1feb3df20db12064eeafdfb7", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508", "dd45fe910a0200d43aaa77362f658542f6e175ff", "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7", "45512d44f1205bc92775f2e880858b3f23c9f5fd", "320d05db95ab42ade69294abe46cd1aca6aca602"], "ReferenceCount": 87, "CitationCount": 187}, {"URL": "https://www.semanticscholar.org/paper/Benign-and-malignant-breast-tumors-classification-Rouhi-Jafari/c6db34ade32b3681a92068b22a354903b2953d52", "ID": "c6db34ade32b3681a92068b22a354903b2953d52", "Title": "Benign and malignant breast tumors classification based on region growing and CNN segmentation", "Abstract": "Semantic Scholar extracted view of \\\"Benign and malignant breast tumors classification based on region growing and CNN segmentation\\\" by R. Rouhi et al.", "PublicationYear": "2015", "Authors": ["Rahimeh Rouhi", "Mehdi Jafari", "Shohreh Kasaei", "Peiman Keshavarzian"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["3c948ca247c6f55ef994400e713412b5f845dd40", "9b5d0a48b0feb156a1270da54d90d0963a3f0404", "76389ebb7c1496239e66fd663b0e7e43d391bca9", "d0059280e3f69b8fd07ce036e7d2407e3ebcff9e", "2dfb1fd3adfa58a3448251e03b1a5a78239958b3", "46c409dd878e643271ef63f1817ded8b57abc01e", "342da5d8633aebf27d914a8618e523579a130289", "fe83150bc326fd62d352cb2993ac91344f195e10", "483f0f12feb8ac1c396349e5526a7552b6b067cd", "a9d0b3485f3091e832f87edb469c350c90cabae1"], "ReferenceCount": 58, "CitationCount": 352}, {"URL": "https://www.semanticscholar.org/paper/Event-Detection-and-Summarization-in-Soccer-Videos-Tavassolipour-Karimian/ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73", "ID": "ac2e54cec3aa2d1e67288d00c7fce7b7b17f9a73", "Title": "Event Detection and Summarization in Soccer Videos Using Bayesian Network and Copula", "Abstract": "A novel Bayesian network-based method that is capable of detecting seven different events in soccer videos; namely, goal, card, goal attempt, corner, foul, offside, and nonhighlights is proposed. Semantic video analysis and automatic concept extraction play an important role in several applications; including content-based search engines, video indexing, and video summarization. As the Bayesian network is a powerful tool for learning complex patterns, a novel Bayesian network-based method is proposed for automatic event detection and summarization in soccer videos. The proposed method includes efficient algorithms for shot boundary detection, shot view classification, mid-level visual feature extraction, and construction of the related Bayesian network. The method contains of three main stages. In the first stage, the shot boundaries are detected. Using the hidden Markov model, the video is segmented into large and meaningful semantic units, called play-break sequences. In the next stage, several features are extracted from each of these units. Finally, in the last stage, in order to achieve high level semantic features (events and concepts), the Bayesian network is used. The basic part of the method is constructing the Bayesian network, for which the structure is estimated using the Chow-Liu tree. The joint distributions of random variables of the network are modeled by applying the Farlie-Gumbel-Morgenstern family of Copulas. The performance of the proposed method is evaluated on a dataset with about 9 h of soccer videos. The method is capable of detecting seven different events in soccer videos; namely, goal, card, goal attempt, corner, foul, offside, and nonhighlights. Experimental results show the effectiveness and robustness of the proposed method on detecting these events.", "PublicationYear": "2014", "Authors": ["Mostafa Tavassolipour", "Mahmood Karimian", "Shohreh Kasaei"], "RelatedTopics": ["Computer Science"], "References": ["d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f", "d71c84fbaff0d7f2cbcf2f03630e189c58939a4a", "43eb2d80721daa318cc19e4cce405122934e88f2", "0cca81f3b2928f6d4005e1a8b617960e2fb14d3e", "0365c1382924394e200cb627e59cb9c21f8e75bd", "c9edc10d5c22ae62a700c37a41bb0ea22961a0aa", "90fbd777cf57096e9292601dfe0dbab30198d40f", "f7b4fcc9dbb97997dc1793d7a366cba274f53134", "8e0f60b718fa19c2ed10bd93401796683af79512", "c2f8178ce89a6cc1ad0e1dd5db4bf155d5a80620"], "ReferenceCount": 40, "CitationCount": 98}, {"URL": "https://www.semanticscholar.org/paper/An-efficient-PCA-based-color-transfer-method-Abadpour-Kasaei/53fc0415e0d00f9691994a49b8232a1cc2dfad5f", "ID": "53fc0415e0d00f9691994a49b8232a1cc2dfad5f", "Title": "An efficient PCA-based color transfer method", "Abstract": "Semantic Scholar extracted view of \\\"An efficient PCA-based color transfer method\\\" by A. Abadpour et al.", "PublicationYear": "2007", "Authors": ["Arash Abadpour", "Shohreh Kasaei"], "RelatedTopics": ["Computer Science"], "References": ["e1dfff8cff33ede3564a35724632bddc5b8619b1", "d93e4e77e2baba98f1af7f23d47fbf9b46be4df5", "05f63bdf9e60d0a299cfe5e8d7ba043904f1fea1", "0c2ced886708cc3aea4705f8765d152cd3f69cd2", "a2882b8b0c9635d39d15a28138e3f47907f3177b", "61579369e7b97dec9c699c058edaafcde2817d21", "4a6c5c9b1fb106f7d82508ae593d30e207c8ea45", "ab67b9d0da50e251a4f7e42370540547b891ceb1", "d5c6edb53dc41f298f145041cd2c53e40e3acf2b", "ed7e166f65bcecc522c6c4bbb29fcf8048010873"], "ReferenceCount": 45, "CitationCount": 67}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-for-Visual-Tracking%3A-A-Comprehensive-Marvasti-Zadeh-Cheng/1fbb4201af091aef55360f113ba35814063923e4", "ID": "1fbb4201af091aef55360f113ba35814063923e4", "Title": "Deep Learning for Visual Tracking: A Comprehensive Survey", "Abstract": "This survey aims to systematically investigate the current DL-based visual tracking methods, benchmark datasets, and evaluation metrics, and extensively evaluates and analyzes the leading visualtracking methods. Visual target tracking is one of the most sought-after yet challenging research topics in computer vision. Given the ill-posed nature of the problem and its popularity in a broad range of real-world scenarios, a number of large-scale benchmark datasets have been established, on which considerable methods have been developed and demonstrated with significant progress in recent years \u2013 predominantly by recent deep learning (DL)-based methods. This survey aims to systematically investigate the current DL-based visual tracking methods, benchmark datasets, and evaluation metrics. It also extensively evaluates and analyzes the leading visual tracking methods. First, the fundamental characteristics, primary motivations, and contributions of DL-based methods are summarized from nine key aspects of: network architecture, network exploitation, network training for visual tracking, network objective, network output, exploitation of correlation filter advantages, aerial-view tracking, long-term tracking, and online tracking. Second, popular visual tracking benchmarks and their respective properties are compared, and their evaluation metrics are summarized. Third, the state-of-the-art DL-based methods are comprehensively examined on a set of well-established benchmarks of OTB2013, OTB2015, VOT2018, LaSOT, UAV123, UAVDT, and VisDrone2019. Finally, by conducting critical analyses of these state-of-the-art trackers quantitatively and qualitatively, their pros and cons under various common scenarios are investigated. It may serve as a gentle use guide for practitioners to weigh when and under what conditions to choose which method(s). It also facilitates a discussion on ongoing issues and sheds light on promising research directions.", "PublicationYear": "2019", "Authors": ["Seyed Mojtaba Marvasti-Zadeh", "Li Cheng", "Hossein Ghanei-Yakhdan", "Shohreh Kasaei"], "RelatedTopics": ["Computer Science"], "References": ["26e2ca763087be09e3799ad294302aa91077942d", "021d0c7013da519b508610064f264c76d768fdf1", "0a400fd7f0ee28694889baaa4faef150b6912dfa", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "388d29f001411ff80650f80cf197afc440d98b51", "f24015a365ea2454391c285cd30b8ae723dbb05e", "7574b7e5a75fdd338c27af5aeb77ab79460c4437", "320d05db95ab42ade69294abe46cd1aca6aca602", "1855818c492d5f42dbe14814e4dd9b5733d54790", "e2e34b202363e4a46a14cd35fd4088d88b2e650e"], "ReferenceCount": 272, "CitationCount": 203}, {"URL": "https://www.semanticscholar.org/paper/The-Seventh-Visual-Object-Tracking-VOT2019-Results-Kristan-Matas/786577081e00d69eeac8e9612eaf2dad59765e73", "ID": "786577081e00d69eeac8e9612eaf2dad59765e73", "Title": "The Seventh Visual Object Tracking VOT2019 Challenge Results", "Abstract": "The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative; results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed of five challenges focusing on different tracking domains: (i) VOTST2019 challenge focused on short-term tracking in RGB, (ii) VOT-RT2019 challenge focused on \\\"real-time\\\" shortterm tracking in RGB, (iii) VOT-LT2019 focused on longterm tracking namely coping with target disappearance and reappearance. Two new challenges have been introduced: (iv) VOT-RGBT2019 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2019 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2019, VOT-RT2019 and VOT-LT2019 datasets were refreshed while new datasets were introduced for VOT-RGBT2019 and VOT-RGBD2019. The VOT toolkit has been updated to support both standard shortterm, long-term tracking and tracking with multi-channel imagery. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.", "PublicationYear": "2019", "Authors": ["Matej Kristan", "Jiri Matas", "Ale{\\vs} Leonardis", "Michael Felsberg", "Roman P. Pflugfelder", "Joni-Kristian", "K{\\\"a}m{\\\"a}r{\\\"a}inen", "Luka Cehovin Zajc", "Ondrej Drbohlav", "Alan Luke{\\vz}i{\\vc}", "Amanda Berg", "Abdelrahman", "Eldesokey", "Jani K{\\\"a}pyl{\\\"a}", "Gustavo Javier Fernandez", "Abel Gonzalez-Garcia", "Alireza", "Memarmoghadam", "Andong Lu", "Anfeng He", "Anton Yuriiovych Varfolomieiev", "Antoni B. Chan", "Ardhendu Shekhar", "Tripathi", "Arnold W. M. Smeulders", "Bala Suraj Pedasingu", "Bao Xin Chen", "Baopeng Zhang", "Baoyuan Wu", "Bi", "Li", "Bin He", "Bin Yan", "Bing Bai", "Bing Li", "Bo Li", "Byeong Hak Kim", "Chao Ma", "Chen Fang", "Chen", "Qian", "Cheng Chen", "Chenglong Li", "Chengquan Zhang", "Chi-Yi Tsai", "Chong Luo", "Christian", "Micheloni", "Chunhui Zhang", "Dacheng Tao", "Deepak Gupta", "Dejia Song", "Dong Wang", "Efstratios", "Gavves", "Eunu Yi", "Fahad Shahbaz Khan", "Fangyi Zhang", "Fei Wang", "Fei Zhao", "George De", "Ath", "Goutam Bhat", "Guang-Gui Chen", "Guangting Wang", "Guoxuan Li", "Hakan \u00c7evikalp", "Hao Du", "Haojie", "Zhao", "Hasan Saribas", "Ho Min Jung", "Hongliang Bai", "Hongyuan Yu", "Houwen Peng", "Huchuan", "L\u01d4", "Hui Li", "Jia-Ke Li", "Jianhua Li", "Jianlong Fu", "Jie Chen", "Jie Gao", "Jie Zhao", "Jin Tang", "Jing", "Jingjing Wu", "Jingtuo Liu", "Jinqiao Wang", "Jinqing Qi", "Jinyue Zhang", "John Tsotsos", "Jong Hyuk Jong Hyuk", "Lee", "Joost van de Weijer", "Josef Kittler", "Jun Ha Lee", "Junfei Zhuang", "Kangkai Zhang", "Kangkang", "Wang", "Kenan Dai", "Lei Chen", "Lei Liu", "Leida Guo", "Li Zhang", "Liang Wang", "Liang Wang", "Lichao", "Zhang", "Lijun Wang", "Lijun Zhou", "Linyu Zheng", "Litu Rout", "Luc Van Gool", "Luca Bertinetto", "Martin", "Danelljan", "Matteo Dunnhofer", "Meng Ni", "Min Young Kim", "Ming Tang", "Ming-Hsuan Yang", "Naveen", "Paluru", "Niki Martinel", "Pengfei Xu", "Pengfei Zhang", "Pengkun Zheng", "Pengyu Zhang", "S. PhilipH.", "Torr", "Qi Zhang Qiang Wang", "Qing Guo", "Radu Timofte", "Rama Krishna Sai Subrahmanyam Gorthi", "Richard", "Everson", "Ruize Han", "Ruohan Zhang", "Shan You", "Shaochuan Zhao", "Shengwei Zhao", "Shihu", "Shikun Li", "Shiming Ge", "Shuai Bai", "Shuosen Guan", "Tengfei Xing", "Tianyang Xu", "Tianyu", "Yang", "Ting Zhang", "Tom{\\'a}s Voj{\\'i}r", "Wei Feng", "Wei Hu", "Weizhao Wang", "Wenjie Tang", "Wenjun", "Zeng", "Wenyu Liu", "Xi Chen", "Xi Qiu", "Xiang Bai", "Xiaojun Wu", "Xiaoyun Yang", "Xier", "Xin Li", "Xingyuan Sun", "Xingyu Chen", "Xinmei Tian", "Xuwen Tang", "Xuefeng Zhu", "Yan-ping Huang", "Yanan", "Yanchao Lian", "Yang Gu", "Yang Ming Liu", "Yanjie Chen", "Yi Zhang", "Yinda Xu", "Yingming", "Yingping Li", "Yu Zhou", "Yuan Dong", "Yufei Xu", "Yunhua Zhang", "Yunkun Li", "Zeyu Zhao", "Luo", "Zhaoliang Zhang", "Zhenhua Feng", "Zhenyu He", "Zhichao Song", "Zhihao Chen", "Zhipeng", "Zhirong Wu", "Zhiwei Xiong", "Zhongjian Huang", "Zhu Teng", "Zihan Ni"], "RelatedTopics": ["Computer Science"], "References": ["3c74b636c0f74c1a0cbbd6e165c2760264044971", "53329e5c79c1128c7b252a12b182c472a3413bfa", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "4338f00c11224f1b4056125561927777ab610c9d", "6767812e114c426d45ea83894b156f7906e525cd", "19d6b9725a59f4b624205829d5f03ac893ca1367", "23f8927f996d56f3b5076d8993a70bcfc70182a1", "dd45fe910a0200d43aaa77362f658542f6e175ff", "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7"], "ReferenceCount": 114, "CitationCount": 365}, {"URL": "https://www.semanticscholar.org/paper/The-Sixth-Visual-Object-Tracking-VOT2018-Challenge-Kristan-Leonardis/219e9a4527110baf1feb3df20db12064eeafdfb7", "ID": "219e9a4527110baf1feb3df20db12064eeafdfb7", "Title": "The Sixth Visual Object Tracking VOT2018 Challenge Results", "Abstract": "The Visual Object Tracking challenge VOT2018 is the sixth annual tracker benchmarking activity organized by the VOT initiative; results of over eighty trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The Visual Object Tracking challenge VOT2018 is the sixth annual tracker benchmarking activity organized by the VOT initiative. Results of over eighty trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis and a \u201creal-time\u201d experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. A long-term tracking subchallenge has been introduced to the set of standard VOT sub-challenges. The new subchallenge focuses on long-term tracking properties, namely coping with target disappearance and reappearance. A new dataset has been compiled and a performance evaluation methodology that focuses on long-term tracking capabilities has been adopted. The VOT toolkit has been updated to support both standard short-term and the new long-term tracking subchallenges. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website (http://votchallenge.net).", "PublicationYear": "2018", "Authors": ["Matej Kristan", "Ale{\\vs} Leonardis", "Jiri Matas", "Michael Felsberg", "Roman P. Pflugfelder", "Luka Cehovin Zajc", "Tom{\\'a}s Voj{\\'i}r", "Goutam Bhat", "Alan Luke{\\vz}i{\\vc}", "Abdelrahman Eldesokey", "Gustavo Javier Fernandez", "{\\'A}lvaro Garc{\\'i}a-Mart{\\'i}n", "{\\'A}lvaro Iglesias-Arias", "Aydin Alatan", "Abel Gonzalez-Garcia", "Alfredo Petrosino", "Alireza Memarmoghadam", "Andrea Vedaldi", "Andrej Muhic", "Anfeng He", "Arnold W. M. Smeulders", "Asanka G. Perera", "Bo Li", "Boyu Chen", "Changick Kim", "Changsheng Xu", "Changzhen Xiong", "Cheng Tian", "Chong Luo", "Chong Sun", "Cong Hao", "Daijin Kim", "Deepak Mishra", "Deming Chen", "Dong Wang", "Dongyoon Wee", "Efstratios Gavves", "Erhan Gundogdu", "Erik Velasco-Salido", "Fahad Shahbaz Khan", "Fan Yang", "Fei Zhao", "Feng Li", "Francesco Battistone", "George De Ath", "Gorthi Rama Krishna Sai Subrahmanyam", "Guilherme Sousa Bastos", "Haibin Ling", "Hamed Kiani Galoogahi", "Hankyeol Lee", "Haojie Li", "Haojie Zhao", "Heng Fan", "Honggang Zhang", "Horst Possegger", "Houqiang Li", "Huchuan Lu", "Hui Zhi", "Huiyun Li", "Hyemin Lee", "Hyung Jin Chang", "Isabela Drummond", "Jack Valmadre", "Jaime Spencer Martin", "Javaan Singh Chahl", "Jin Young Choi", "Jing Li", "Jinqiao Wang", "Jinqing Qi", "Jinyoung Sung", "Joakim Johnander", "Jo{\\~a}o F. Henriques", "Jongwon Choi", "Joost van de Weijer", "Jorge Rodr{\\'i}guez Herranz", "Jos{\\'e} Mar{\\'i}a Mart{\\'i}nez Sanchez", "Josef Kittler", "Junfei Zhuang", "Junyu Gao", "Klemen Grm", "Lichao Zhang", "Lijun Wang", "Lingxiao Yang", "Litu Rout", "Liu Si", "Luca Bertinetto", "Lutao Chu", "Manqiang Che", "Mario Edoardo Maresca", "Martin Danelljan", "Ming-Hsuan Yang", "Mohamed H. Abdelpakey", "Mohamed S. Shehata", "Myung Gu Kang", "Namhoon Lee", "Ning Wang", "Ond\u0159ej Mik{\\vs}{\\'i}k", "Payman Moallem", "Pablo Vicente-Mo{\\~n}ivar", "Pedro Senna", "Peixia Li", "Philip H. S. Torr", "Priya Mariam Raju", "Ruihe Qian", "Qiang Wang", "Qin Zhou", "Qing Guo", "Rafael Martin Nieto", "Rama Krishna Sai Subrahmanyam Gorthi", "Ran Tao", "R. Bowden", "Richard M. Everson", "Runling Wang", "Sangdoo Yun", "Seokeon Choi", "Sergio Vivas", "Shuai Bai", "Shuangping Huang", "Sihang Wu", "Simon Hadfield", "Siwen Wang", "Stuart Golodetz", "Ming Tang", "Tianyang Xu", "Tianzhu Zhang", "Tobias Fischer", "Vincenzo Santopietro", "Vitomir {\\vS}truc", "Wei Wang", "Wangmeng Zuo", "Wei Feng", "Wei Wu", "Wei Zou", "Weiming Hu", "Wen-gang Zhou", "Wen Jun Zeng", "Xiaofan Zhang", "Xiaohe Wu", "Xiaojun Wu", "Xinmei Tian", "Yan Li", "Yan Lu", "Yee Wei Law", "Yi Wu", "Y. Demiris", "Yicai Yang", "Yifan Jiao", "Yuhong Li", "Yunhua Zhang", "Yuxuan Sun", "Zheng Zhang", "Zhengyu Zhu", "Zhenhua Feng", "Zhihui Wang", "Zhiqun He"], "RelatedTopics": ["Computer Science"], "References": ["6179ac06f1a8fd1ac6b693b02824948dff438d54", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "19d6b9725a59f4b624205829d5f03ac893ca1367", "4338f00c11224f1b4056125561927777ab610c9d", "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7", "3275944117b43cc44beebe7c82bffc13ec8cb0fa", "9926020dda21874dc7a5ef1511bae6c4cef5ecb9"], "ReferenceCount": 100, "CitationCount": 655}, {"URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2014-Challenge-Kristan-Matas/3c74b636c0f74c1a0cbbd6e165c2760264044971", "ID": "3c74b636c0f74c1a0cbbd6e165c2760264044971", "Title": "The Visual Object Tracking VOT2014 Challenge Results", "Abstract": "The Visual Object Tracking challenge 2014, VOT2014, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance and introduces a new dataset with full annotation of targets by rotated bounding boxes and per-frame attribute. The Visual Object Tracking challenge 2014, VOT2014, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 38 trackers are presented. The number of tested trackers makes VOT 2014 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2014 challenge that go beyond its VOT2013 predecessor are introduced: (i) a new VOT2014 dataset with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2013 evaluation methodology, (iii) a new unit for tracking speed assessment less dependent on the hardware and (iv) the VOT2014 evaluation toolkit that significantly speeds up execution of experiments. The dataset, the evaluation kit as well as the results are publicly available at the challenge website (http://votchallenge.net).", "PublicationYear": "2014", "Authors": ["Matej Kristan", "Juan E. Sala Matas", "Ale{\\vs} Leonardis", "Jiri Matas", "Luka Cehovin", "Georg Nebehay", "Tom{\\'a}s Voj{\\'i}r", "Gustavo Javier Fernandez", "Alan Luke{\\vz}i{\\vc}", "Aleksandar Dimitriev", "Alfredo Petrosino", "Amir Saffari", "Bo Li", "Bohyung Han", "Cherkeng Heng", "Christophe Garcia", "Dominik Pangersic", "Gustav H{\\\"a}ger", "Fahad Shahbaz Khan", "Franc Oven", "Horst Possegger", "Horst Bischof", "Hyeonseob Nam", "Jianke Zhu", "Jijia Li", "Jin Young Choi", "Jinwoo Choi", "Jo{\\~a}o F. Henriques", "Joost van de Weijer", "Jorge Batista", "Karel Lebeda", "Kristoffer {\\\"O}fj{\\\"a}ll", "Kwang Moo Yi", "Lei Qin", "Longyin Wen", "Mario Edoardo Maresca", "Martin Danelljan", "Michael Felsberg", "Ming-Ming Cheng", "Philip H. S. Torr", "Qingming Huang", "R. Bowden", "Sam Hare", "Samantha YueYing Lim", "Seunghoon Hong", "Shengcai Liao", "Simon Hadfield", "S. Li", "Stefan Duffner", "Stuart Golodetz", "Thomas Mauthner", "Vibhav Vineet", "Weiyao Lin", "Yang Li", "Yuankai Qi", "Zhen Lei", "Zhi Heng Niu"], "RelatedTopics": ["Computer Science"], "References": ["15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "4dff84213493bb177dc6bff266a9893538a1f879", "9926020dda21874dc7a5ef1511bae6c4cef5ecb9", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "0b104e517e0440e3bdace01b5f6706c5fa944149", "616b246e332573af1f4859aa91440280774c183a", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "61394599ed0aabe04b724c7ca3a778825c7e776f"], "ReferenceCount": 78, "CitationCount": 518}, {"URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2015-Challenge-Kristan-Leonardis/15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "ID": "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "Title": "The Visual Object Tracking VOT2015 Challenge Results", "Abstract": "The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance and presents a new VOT 2015 dataset twice as large as in VOT2014 with full annotation of targets by rotated bounding boxes and per-frame attribute. The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 predecessor are: (i) a new VOT2015 dataset twice as large as in VOT2014 with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2014 evaluation methodology by introduction of a new performance measure. The dataset, the evaluation kit as well as the results are publicly available at the challenge website.", "PublicationYear": "2015", "Authors": ["Matej Kristan", "Ale{\\vs} Leonardis", "Jiri Matas", "Michael Felsberg", "Roman P. Pflugfelder", "Luka Cehovin Zajc", "Tom{\\'a}s Voj{\\'i}r", "Gustav H{\\\"a}ger", "Alan Luke{\\vz}i{\\vc}", "Abdelrahman Eldesokey", "Gustavo Javier Fernandez", "{\\'A}lvaro Garc{\\'i}a-Mart{\\'i}n", "Andrej Muhic", "Alfredo Petrosino", "Alireza Memarmoghadam", "Andrea Vedaldi", "Antoine Manzanera", "Antoine Tran", "Aydin Alatan", "Bogdan Cosmin Mocanu", "Boyu Chen", "Chang Huang", "Changsheng Xu", "Chong Sun", "Dalong Du", "Dafan Zhang", "Dawei Du", "Deepak Mishra", "Erhan Gundogdu", "Erik Velasco-Salido", "Fahad Shahbaz Khan", "Francesco Battistone", "Gorthi Rama Krishna Sai Subrahmanyam", "Goutam Bhat", "Guan Huang", "Guilherme Sousa Bastos", "Guna Seetharaman", "Hongliang Zhang", "Houqiang Li", "Huchuan Lu", "Isabela Drummond", "Jack Valmadre", "Jae-chan Jeong", "Jaeil Cho", "Jae-Y. Lee", "Jana Noskova", "Jianke Zhu", "Jin Gao", "Jingyu Liu", "Ji-Wan Kim", "Jo{\\~a}o F. Henriques", "Jos{\\'e} Mar{\\'i}a Mart{\\'i}nez Sanchez", "Junfei Zhuang", "Junliang Xing", "Junyu Gao", "Kai Chen", "Kannappan Palaniappan", "Karel Lebeda", "Ke Gao", "Kris Kitani", "Lei Zhang", "Lijun Wang", "Lingxiao Yang", "Longyin Wen", "Luca Bertinetto", "Mahdieh Poostchi", "Martin Danelljan", "Matthias Mueller", "Mengdan Zhang", "Ming-Hsuan Yang", "Nianhao Xie", "Ning Wang", "Ond\u0159ej Mik{\\vs}{\\'i}k", "Payman Moallem", "Pallavi M. Venugopal", "Pedro Senna", "Philip H. S. Torr", "Qiang Wang", "Qifeng Yu", "Qingming Huang", "Rafael Martin Nieto", "R. Bowden", "Risheng Liu", "Ruxandra Tapu", "Simon Hadfield", "Siwei Lyu", "Stuart Golodetz", "Sunglok Choi", "Tianzhu Zhang", "Titus B. Zaharia", "Vincenzo Santopietro", "Wei Zou", "Weiming Hu", "Wenbing Tao", "Wenbo Li", "Wen-gang Zhou", "Xianguo Yu", "Xiao Bian", "Yang Li", "Yifan Xing", "Yingruo Fan", "Zhengyu Zhu", "Zhipeng Zhang", "Zhiqun He"], "RelatedTopics": ["Computer Science"], "References": ["3c74b636c0f74c1a0cbbd6e165c2760264044971", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "4338f00c11224f1b4056125561927777ab610c9d", "4dff84213493bb177dc6bff266a9893538a1f879", "84f911432ba8a3356013b3abfbf1947f1145c953", "91f2b2aeb7e65d0b673ed7e782488b3365027979", "9926020dda21874dc7a5ef1511bae6c4cef5ecb9", "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "c4e7e62b3a3eb100b441674ad3817d9a24239e2a"], "ReferenceCount": 94, "CitationCount": 991}, {"URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2016-Challenge-Kristan-Leonardis/6179ac06f1a8fd1ac6b693b02824948dff438d54", "ID": "6179ac06f1a8fd1ac6b693b02824948dff438d54", "Title": "The Visual Object Tracking VOT2016 Challenge Results", "Abstract": "The Visual Object Tracking challenge VOT2016 goes beyond its predecessors by introducing a new semi-automatic ground truth bounding box annotation methodology and extending the evaluation system with the no-reset experiment. The Visual Object Tracking challenge VOT2016 aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 70 trackers are presented, with a large number of trackers being published at major computer vision conferences and journals in the recent years. The number of tested state-of-the-art trackers makes the VOT 2016 the largest and most challenging benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the Appendix. The VOT2016 goes beyond its predecessors by (i) introducing a new semi-automatic ground truth bounding box annotation methodology and (ii) extending the evaluation system with the no-reset experiment. The dataset, the evaluation kit as well as the results are publicly available at the challenge website (http://votchallenge.net).", "PublicationYear": "2016", "Authors": ["Matej Kristan", "Ale{\\vs} Leonardis", "Jiri Matas", "Michael Felsberg", "Roman P. Pflugfelder", "Luka Cehovin", "Tom{\\'a}s Voj{\\'i}r", "Gustav H{\\\"a}ger", "Alan Luke{\\vz}i{\\vc}", "Gustavo Javier Fernandez", "Abhinav Kumar Gupta", "Alfredo Petrosino", "Alireza Memarmoghadam", "{\\'A}lvaro Garc{\\'i}a-Mart{\\'i}n", "Andr{\\'e}s Sol{\\'i}s Montero", "Andrea Vedaldi", "Andreas Robinson", "Andy Jinhua Ma", "Anton Yuriiovych Varfolomieiev", "A. Aydin Alatan", "Aykut Erdem", "Bernard Ghanem", "Bin Liu", "Bohyung Han", "Brais Mart{\\'i}nez", "Chang-Ming Chang", "Changsheng Xu", "Chong Sun", "Daijin Kim", "Dapeng Chen", "Dawei Du", "Deepak Mishra", "D. Y. Yeung", "Erhan Gundogdu", "Erkut Erdem", "Fahad Shahbaz Khan", "Fatih Murat Porikli", "Fei Zhao", "Filiz Bunyak", "Francesco Battistone", "Gao Zhu", "Giorgio Roffo", "Gorthi Rama Krishna Sai Subrahmanyam", "Guilherme Sousa Bastos", "Guna Seetharaman", "Henry Medeiros", "Hongdong Li", "Honggang Qi", "Horst Bischof", "Horst Possegger", "Huchuan Lu", "Hyemin Lee", "Hyeonseob Nam", "Hyung Jin Chang", "Isabela Drummond", "Jack Valmadre", "Jae-chan Jeong", "Jae Il Cho", "Jae-Y. Lee", "Jianke Zhu", "Jiayi Feng", "Jin Gao", "Jin Young Choi", "Jingjing Xiao", "Ji-Wan Kim", "Jiyeoup Jeong", "Jo{\\~a}o F. Henriques", "Jochen Lang", "Jongwon Choi", "Jos{\\'e} M. Mart{\\'i}nez", "Junliang Xing", "Junyu Gao", "Kannappan Palaniappan", "Karel Lebeda", "Ke Gao", "Krystian Mikolajczyk", "Lei Qin", "Lijun Wang", "Longyin Wen", "Luca Bertinetto", "Madan Kumar Rapuru", "Mahdieh Poostchi", "Mario Edoardo Maresca", "Martin Danelljan", "Matthias Mueller", "Mengdan Zhang", "Michael Arens", "Michel F. Valstar", "Ming Tang", "Mooyeol Baek", "Muhammad Haris Khan", "Naiyan Wang", "Nana Fan", "Noor M. Al-Shakarji", "Ond\u0159ej Mik{\\vs}{\\'i}k", "Osman Akin", "Payman Moallem", "Pedro Senna", "Philip H. S. Torr", "Pong Chi Yuen", "Qingming Huang", "Rafael Mart{\\'i}n-Nieto", "Rengarajan Pelapur", "Richard Bowden", "Robert Lagani{\\`e}re", "R. Stolkin", "Ryan Walsh", "Sebastian Bernd Krah", "Shengkun Li", "Shengping Zhang", "Shizeng Yao", "Simon Hadfield", "Simone Melzi", "Siwei Lyu", "Siyi Li", "Stefan Becker", "Stuart Golodetz", "Sumithra Kakanuru", "Sunglok Choi", "Tao Hu", "Thomas Mauthner", "Tianzhu Zhang", "Tony P. Pridmore", "Vincenzo Santopietro", "Weiming Hu", "Wenbo Li", "Wolfgang H{\\\"u}bner", "Xiangyuan Lan", "Xiaomeng Wang", "Xin Li", "Yang Li", "Y. Demiris", "Yifan Wang", "Yuankai Qi", "Zejian Yuan", "Zexiong Cai", "Zhan Xu", "Zhenyu He", "Zhizhen Chi"], "RelatedTopics": ["Computer Science"], "References": ["15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "6767812e114c426d45ea83894b156f7906e525cd", "4338f00c11224f1b4056125561927777ab610c9d", "91f2b2aeb7e65d0b673ed7e782488b3365027979", "9926020dda21874dc7a5ef1511bae6c4cef5ecb9", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "5bae9822d703c585a61575dced83fa2f4dea1c6d", "6b175816b1f81127f5e2a2fe998df99d62290a1c", "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5"], "ReferenceCount": 110, "CitationCount": 720}, {"URL": "https://www.semanticscholar.org/paper/Performance-Evaluation-Methodology-for-Long-Term-Luke%C5%BEi%C4%8D-Zajc/c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508", "ID": "c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508", "Title": "Performance Evaluation Methodology for Long-Term Single-Object Tracking", "Abstract": "A long-term visual object tracking performance evaluation methodology and a benchmark are proposed and it is shown that these measures generalize the short-term performance measures, thus linking the two tracking problems. A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. Performance measures are designed by following a long-term tracking definition to maximize the analysis probing strength. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors. We show that these measures generalize the short-term performance measures, thus linking the two tracking problems. Furthermore, the new measures are highly robust to temporal annotation sparsity and allow annotation of sequences hundreds of times longer than in the current datasets without increasing manual annotation labor. A new challenging dataset of carefully selected sequences with many target disappearances is proposed. A new tracking taxonomy is proposed to position trackers on the short-term/long-term spectrum. The benchmark contains an extensive evaluation of the largest number of long-term trackers and comparison to state-of-the-art short-term trackers. We analyze the influence of tracking architecture implementations to long-term performance and explore various redetection strategies as well as the influence of visual model update strategies to long-term tracking drift. The methodology is integrated in the VOT toolkit to automate experimental analysis and benchmarking and to facilitate the future development of long-term trackers.", "PublicationYear": "2020", "Authors": ["Alan Luke{\\vz}i{\\vc}", "Luka Cehovin Zajc", "Tom{\\'a}s Voj{\\'i}r", "Jiri Matas", "Matej Kristan"], "RelatedTopics": ["Computer Science"], "References": [], "ReferenceCount": 0, "CitationCount": 20}, {"URL": "https://www.semanticscholar.org/paper/A-thermal-Object-Tracking-benchmark-Berg-Ahlberg/dd45fe910a0200d43aaa77362f658542f6e175ff", "ID": "dd45fe910a0200d43aaa77362f658542f6e175ff", "Title": "A thermal Object Tracking benchmark", "Abstract": "A thermal infrared benchmark according to the Visual Visual Object Tracking (VOT) protocol for evaluation of STSO tracking methods is proposed and it is shown that the ranking of different tracking principles differ between the visual and thermal benchmarks, confirming the need for the new benchmark. Short-term single-object (STSO) tracking in thermal images is a challenging problem relevant in a growing number of applications. In order to evaluate STSO tracking algorithms on visual imagery, there are de facto standard benchmarks. However, we argue that tracking in thermal imagery is different than in visual imagery, and that a separate benchmark is needed. The available thermal infrared datasets are few and the existing ones are not challenging for modern tracking algorithms. Therefore, we hereby propose a thermal infrared benchmark according to the Visual Visual Object Tracking (VOT) protocol for evaluation of STSO tracking methods. The benchmark includes the new LTIR dataset containing 20 thermal image sequences which have been collected from multiple sources and annotated in the format used in the VOT Challenge. In addition, we show that the ranking of different tracking principles differ between the visual and thermal benchmarks, confirming the need for the new benchmark.", "PublicationYear": "2015", "Authors": ["Amanda Berg", "J{\\\"o}rgen Ahlberg", "Michael Felsberg"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["6a699d87bb55477cbe7bfb45b7991b889fd976b6", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "2c76de57b8b1c9e63b1883cbdea9ec8e68ddf493", "201d116761d9d300193df370107f26d7d475023b", "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "c26eaf62a20ebac360148276a1f098d92c7b0738", "d867d7c8cfefe0f5a297a3c613ae6d79c851f4b9", "a8ccbb0981b104cc0f753514cc28c01e5309dc41", "fe2aaad872a2cf08c09dd52ca972f323666306db", "2873de80204743249012f52821419978f4d8b27e"], "ReferenceCount": 22, "CitationCount": 98}, {"URL": "https://www.semanticscholar.org/paper/Long-term-Tracking-in-the-Wild%3A-A-Benchmark-Valmadre-Bertinetto/ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7", "ID": "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7", "Title": "Long-term Tracking in the Wild: A Benchmark", "Abstract": "The OxUvA dataset and benchmark for evaluating single-object tracking algorithms is introduced, offering the community a large and diverse benchmark to enable the design and evaluation of tracking methods ready to be used \u201cin the wild\u201d. We introduce the OxUvA dataset and benchmark for evaluating single-object tracking algorithms. Benchmarks have enabled great strides in the field of object tracking by defining standardized evaluations on large sets of diverse videos. However, these works have focused exclusively on sequences that are just tens of seconds in length and in which the target is always visible. Consequently, most researchers have designed methods tailored to this \u201cshort-term\u201d scenario, which is poorly representative of practitioners\u2019 needs. Aiming to address this disparity, we compile a long-term, large-scale tracking dataset of sequences with average length greater than two minutes and with frequent target object disappearance. The OxUvA dataset is much larger than the object tracking datasets of recent years: it comprises 366 sequences spanning 14 h of video. We assess the performance of several algorithms, considering both the ability to locate the target and to determine whether it is present or absent. Our goal is to offer the community a large and diverse benchmark to enable the design and evaluation of tracking methods ready to be used \u201cin the wild\u201d. The project website is oxuva.net.", "PublicationYear": "2018", "Authors": ["Jack Valmadre", "Luca Bertinetto", "Jo{\\~a}o F. Henriques", "Ran Tao", "Andrea Vedaldi", "Arnold W. M. Smeulders", "Philip H. S. Torr", "Efstratios Gavves"], "RelatedTopics": ["Computer Science"], "References": ["19d6b9725a59f4b624205829d5f03ac893ca1367", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "91f2b2aeb7e65d0b673ed7e782488b3365027979", "703505a00579c0aa67712836acc41d94fa6d6edc", "754504cf01ef3846259783e748b1d3ea52fa2c81", "d3d36c3caa255053877a7e3250d47d906eec81d2", "3275944117b43cc44beebe7c82bffc13ec8cb0fa", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "53329e5c79c1128c7b252a12b182c472a3413bfa"], "ReferenceCount": 39, "CitationCount": 151}, {"URL": "https://www.semanticscholar.org/paper/D3S-%E2%80%93-A-Discriminative-Single-Shot-Segmentation-Luke%C5%BEi%C4%8D-Matas/45512d44f1205bc92775f2e880858b3f23c9f5fd", "ID": "45512d44f1205bc92775f2e880858b3f23c9f5fd", "Title": "D3S \u2013 A Discriminative Single Shot Segmentation Tracker", "Abstract": "Without per-dataset finetuning and trained only for segmentation as the primary output, D3S outperforms all trackers on VOT2016, VOT2018 and GOT-10k benchmarks and performs close to the state-of-the-artTrackers on the TrackingNet. Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker - D3S, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to a broad range of transformations, including non-rigid deformations, the other assuming a rigid object to simultaneously achieve high robustness and online target segmentation. Without per-dataset finetuning and trained only for segmentation as the primary output, D3S outperforms all trackers on VOT2016, VOT2018 and GOT-10k benchmarks and performs close to the state-of-the-art trackers on the TrackingNet. D3S outperforms the leading segmentation tracker SiamMask on video segmentation benchmark and performs on par with top video object segmentation algorithms, while running an order of magnitude faster, close to real-time.", "PublicationYear": "2019", "Authors": ["Alan Luke{\\vz}i{\\vc}", "Jiri Matas", "Matej Kristan"], "RelatedTopics": ["Computer Science"], "References": ["12fae9a2c1ed867997e1ca70eba271b3c741c42f", "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1", "320d05db95ab42ade69294abe46cd1aca6aca602", "c316d5ec14e5768d7eda3d8916bddc1de142a1c2", "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914", "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b", "b3249763ac9ecc4df6ef96721c8c7410e0f0468a", "8b74008565b575f9ab7a0962ca5f6955d64db045", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "4a70c20ad66e5f3bb12fccd84c63ba619053c811"], "ReferenceCount": 52, "CitationCount": 175}, {"URL": "https://www.semanticscholar.org/paper/High-Performance-Visual-Tracking-with-Siamese-Li-Yan/320d05db95ab42ade69294abe46cd1aca6aca602", "ID": "320d05db95ab42ade69294abe46cd1aca6aca602", "Title": "High Performance Visual Tracking with Siamese Region Proposal Network", "Abstract": "The Siamese region proposal network (Siamese-RPN) is proposed which is end-to-end trained off-line with large-scale image pairs for visual object tracking and consists of SiAMESe subnetwork for feature extraction and region proposal subnetwork including the classification branch and regression branch. Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal subnetwork including the classification branch and regression branch. In the inference phase, the proposed framework is formulated as a local one-shot detection task. We can pre-compute the template branch of the Siamese subnetwork and formulate the correlation layers as trivial convolution layers to perform online tracking. Benefit from the proposal refinement, traditional multi-scale test and online fine-tuning can be discarded. The Siamese-RPN runs at 160 FPS while achieving leading performance in VOT2015, VOT2016 and VOT2017 real-time challenges.", "PublicationYear": "2018", "Authors": ["Bo Li", "Junjie Yan", "Wei Wu", "Zheng Zhu", "Xiaolin Hu"], "RelatedTopics": ["Computer Science"], "References": ["29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "1131c53b9baaa740a4deef4c1282821b23d18687", "7ccbb845829234548bfa9b24c61297b4f0cd678e", "5404718135548b01516a668e0c022c5cb22b422e", "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "4f445f3e44f2f2ffb431cf1414c59ccba5a0b27d", "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "dda27eb7ddc4510f94cac0e5134b5d56aa77b075", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"], "ReferenceCount": 40, "CitationCount": 1803}, {"URL": "https://www.semanticscholar.org/paper/An-adaptive-region-growing-algorithm-for-breast-in-Cao-Hao/3c948ca247c6f55ef994400e713412b5f845dd40", "ID": "3c948ca247c6f55ef994400e713412b5f845dd40", "Title": "An adaptive region growing algorithm for breast masses in mammograms", "Abstract": "An adaptive region growing algorithm with hybrid assessment function combined with maximum likelihood analysis and maximum gradient analysis was developed and found that the proposed algorithm obtained segmentation contour more accurately and delineated the tumor body as well as tumor peripheral regions covering typical mass boundaries and some spiculation patterns. This study attempted to accurately segment the mammographic masses and distinguish malignant from benign tumors. An adaptive region growing algorithm with hybrid assessment function combined with maximum likelihood analysis and maximum gradient analysis was developed in this paper. In order to accommodate different situations of masses, the likelihood and the edge gradients of segmented masses were weighted adaptively by the use of information entropy. 106 benign and 110 malignant tumors were included in this study. We found that the proposed algorithm obtained segmentation contour more accurately and delineated the tumor body as well as tumor peripheral regions covering typical mass boundaries and some spiculation patterns. Then the segmented results were evaluated by the classification accuracy. 42 features including age, intensity, shape and texture were extracted from each segmented mass and support vector machine (SVM) was used as a classifier. The classification accuracy was evaluated using the area (Az) under the receiver operating characteristic (ROC) curve. It was found that the maximum likelihood analysis achieved an Az value of 0.835, the maximum gradient analysis got an Az value of 0.932 and the hybrid assessment function performed the best classification result where the value of Az was 0.948. In addition, compared with traditional region growing algorithm, our proposed algorithm is more adaptive and provides a better performance for future works.", "PublicationYear": "2010", "Authors": ["Ying Cao", "Xin Hao", "Xiaoen Zhu", "Shun-ren Xia"], "RelatedTopics": ["Medicine"], "References": ["3f116f1763a3604275b06c6ccf0dcd65910d13b5", "7642ea8a5bd70c3eede1c1c9bf8b666bf4c5c0a3", "5e99438461ae96f4a5816e37a9e01f9d9ae6ab4e", "c909583f2560864a2650dc25dbcd09da8eb96fbd", "e3f3ff00759dca433cf5740b38dd8dce25ee45a0", "a23937d6345c6e707cf17509ec27c76fef4ce7cc", "34c44883a6152c5298f2c452670c1127072400e6", "a277fe4df26e09a6c375e32d77472ae2c9a7632d", "bba978f6deba664527708705d12365bc0f157151", "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb"], "ReferenceCount": 31, "CitationCount": 26}, {"URL": "https://www.semanticscholar.org/paper/Directional-features-for-automatic-tumor-of-images-Buciu-Gacs%C3%A1di/9b5d0a48b0feb156a1270da54d90d0963a3f0404", "ID": "9b5d0a48b0feb156a1270da54d90d0963a3f0404", "Title": "Directional features for automatic tumor classification of mammogram images", "Abstract": "Semantic Scholar extracted view of \\\"Directional features for automatic tumor classification of mammogram images\\\" by I. Buciu et al.", "PublicationYear": "2011", "Authors": ["Ioan Buciu", "Alexandru Gacs{\\'a}di"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["16b9ef18b616b495e32bb9aa0c562c6a39168c65", "34c44883a6152c5298f2c452670c1127072400e6", "09ca54c7866c907641e48b59bc194105f9aacba3", "6de99853193ed9ad9ae36e0994f7a552b546b86a", "2dfb1fd3adfa58a3448251e03b1a5a78239958b3", "e4488ebd82674a981852c66c3138cb0bb9fe6b26", "ef0fe1d3d1b1ac5092374b6bc7533c51f761161d", "ce4e601a216a1d7872c611065d4f865d0b19eddf", "543f1f8bd4ae4d8de56828e4afdeaba14ac849c5", "ea7685f5ee65c4c152478111b5bfcb23a446d358"], "ReferenceCount": 33, "CitationCount": 113}, {"URL": "https://www.semanticscholar.org/paper/Performance-evaluation-of-a-region-growing-for-Rabottino-Mencattini/76389ebb7c1496239e66fd663b0e7e43d391bca9", "ID": "76389ebb7c1496239e66fd663b0e7e43d391bca9", "Title": "Performance evaluation of a region growing procedure for mammographic breast lesion identification", "Abstract": "Semantic Scholar extracted view of \\\"Performance evaluation of a region growing procedure for mammographic breast lesion identification\\\" by G. Rabottino et al.", "PublicationYear": "2011", "Authors": ["Giulia Rabottino", "Arianna Mencattini", "Marcello Salmeri", "Federica Caselli", "Roberto Lojacono"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["5a568905f56d5c424c671757552afc03e70f73fd", "e652b81c4aba8e104c8aee064cc90923293cdb82", "a496b4de4b92d905ec2daaecd9af154ea47481f3", "baac72cbca8efd95e76ea17577e8e90e49fc7275", "37ed2eba228d850b3b34472c216d4ed20e33e151", "e83fdb20beb9908fa6a8b52df03197ba84ef2188", "8d46682acbe8ac27ab8e29163e64f1b3cbb70bb0", "e4488ebd82674a981852c66c3138cb0bb9fe6b26", "04fc0c398508822f3b22a8065a48f17ed69baeb0", "295f223238012947e5ffc1e5a0e7c9bd52807977"], "ReferenceCount": 25, "CitationCount": 25}, {"URL": "https://www.semanticscholar.org/paper/Building-an-ensemble-system-for-diagnosing-masses-Zhang-Tomuro/d0059280e3f69b8fd07ce036e7d2407e3ebcff9e", "ID": "d0059280e3f69b8fd07ce036e7d2407e3ebcff9e", "Title": "Building an ensemble system for diagnosing masses in mammograms", "Abstract": "An ensemble classifier for mammography-detected masses may provide superior performance to any single classifier in distinguishing benign from malignant cases. PurposeClassification of a suspicious mass (region of interest, ROI) in a mammogram as malignant or benign may be achieved using mass shape features. An ensemble system was built for this purpose and tested.MethodsMultiple contours were generated from a single ROI using various parameter settings of the image enhancement functions for the segmentation. For each segmented contour, the mass shape features were computed. For classification, the dataset was partitioned into four subsets based on the patient age (young/old) and the ROI size (large/small). We built an ensemble learning system consisting of four single classifiers, where each classifier is a specialist, trained specifically for one of the subsets. Those specialist classifiers are also an optimal classifier for the subset, selected from several candidate classifiers through preliminary experiment. In this scheme, the final diagnosis (malignant or benign) of an instance is the classification produced by the classifier trained for the subset to which the instance belongs.ResultsThe Digital Database for Screening Mammography (DDSM) from the University of South Florida was used to test the ensemble system for classification of masses, which achieved a 72% overall accuracy. This ensemble of specialist classifiers achieved better performance than single classification (56%).ConclusionAn ensemble classifier for mammography-detected masses may provide superior performance to any single classifier in distinguishing benign from malignant cases.", "PublicationYear": "2012", "Authors": ["Yu Zhang", "Noriko Tomuro", "Jacob D. Furst", "Daniela Stan Raicu"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["995a9f5653e95ff874e39da5d2d0beeb36aaa950", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "7577f9d9beecb8b5f97822cbcb9742f97afa9cd4", "9c4424874d34e511373e6daefd3630faa3921a80", "34c44883a6152c5298f2c452670c1127072400e6", "0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "0db9038edba073a75014870b486981b8b8ed9050", "b5ec7cb440fc82239b940fbe02d21d9e94483d4f", "cc3a4e8bcb49ae31977cc3d99549529596e36fe7", "3e3f7d39b59f67be97ecda8542c04ea141d6e944"], "ReferenceCount": 29, "CitationCount": 47}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-benign-and-malignant-patterns-in-Verma-McLeod/2dfb1fd3adfa58a3448251e03b1a5a78239958b3", "ID": "2dfb1fd3adfa58a3448251e03b1a5a78239958b3", "Title": "Classification of benign and malignant patterns in digital mammograms for the diagnosis of breast cancer", "Abstract": "Semantic Scholar extracted view of \\\"Classification of benign and malignant patterns in digital mammograms for the diagnosis of breast cancer\\\" by B. Verma et al.", "PublicationYear": "2010", "Authors": ["Brijesh K. Verma", "Peter McLeod", "Alan Klevansky"], "RelatedTopics": ["Medicine"], "References": ["34c44883a6152c5298f2c452670c1127072400e6", "5fec51cf2d044c764a049d8455f96869d31f1e99", "cf7396f247441e51071d0a774a3ef7a83da6231a", "9bf32a68edfea8b8c072bcd3ee0d696687bab403", "88d38b88e4890b80373eed7070a2096648c5cf30", "483f0f12feb8ac1c396349e5526a7552b6b067cd", "995a9f5653e95ff874e39da5d2d0beeb36aaa950", "aa792e1a05acccb8811f04adf540835237fb5ffe", "227b786b828240506830fea3660b5dc1de6e2a8e", "fb5989e1fff6024adcc6c3d4d85d43e728b9646d"], "ReferenceCount": 25, "CitationCount": 99}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-benign-and-malignant-masses-based-Tahmasbi-Saki/46c409dd878e643271ef63f1817ded8b57abc01e", "ID": "46c409dd878e643271ef63f1817ded8b57abc01e", "Title": "Classification of benign and malignant masses based on Zernike moments", "Abstract": "Semantic Scholar extracted view of \\\"Classification of benign and malignant masses based on Zernike moments\\\" by Amir Tahmasbi et al.", "PublicationYear": "2011", "Authors": ["Amir Tahmasbi", "Fatemeh Saki", "Shahriar Baradaran Shokouhi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["63a83600a73ffbfd6a58e315a247aa4f3da90a9b", "474ae46626676d01c7b38328c107b1531b181b46", "3e63f9f1323de17e96c4eaffda77b701d138c1f8", "ce1e33c037689acbfd19d4dcfc53021bc59dee2b", "40bbb7667b260bad22b0e2cb34562f57735d67f8", "d98b3a493bdf327f3447e75b4814339e1b436d05", "ea7685f5ee65c4c152478111b5bfcb23a446d358", "802c5bf4c93b795f9f509a3b90efabc501e21c01", "9bf32a68edfea8b8c072bcd3ee0d696687bab403", "603b2f00c9948e63514bdefa4ac2d3357cc2a1dc"], "ReferenceCount": 54, "CitationCount": 247}, {"URL": "https://www.semanticscholar.org/paper/Breast-Cancer-Detection-Using-Neural-Network-Models-Pawar-Patil/342da5d8633aebf27d914a8618e523579a130289", "ID": "342da5d8633aebf27d914a8618e523579a130289", "Title": "Breast Cancer Detection Using Neural Network Models", "Abstract": "Back propagation neural network is the best technique to detect breast cancer, according to results compared with radial basis function network. Breast cancer is the leading cause of death in women. If breast cancer is detected in early stage, then chances of survival are very high. In body new cells take place of old cells by orderly growth as old cells die out. The process of mutation controls the activation of genes in cells. Due to this cells get ability to go on dividing without control and producing cells like it, forming a tumor. This tumor can be of benign or malignant. The benign tumors are not dangerous while malignant tumors are dangerous to health. The unchecked malignant tumors have ability to spread in other parts of body. Breast cancer detection is complex process. So the computer-aided diagnosis of breast cancer helps physician in decision making. The system for breast cancer detection is developed using back propagation neural network and we compare its results with radial basis function network. After comparing we found back propagation neural network is the best technique to detect breast cancer.", "PublicationYear": "2013", "Authors": ["P. S. Pawar", "Divya Patil"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["1945ecc90dc463d65ac113fa0b89679bd8f31718", "cf6fe2d57289af4c401a8f6f006fe243f66d369b", "a8bd26fae7a98d45a8028371b1a3e96fca0ff64d", "c120a2f53a87602a97ba1a594a07305dd5a882eb", "d37bd9a7bc19ce640e33449831181fa3e43f90d2", "1e7c4f513f24c3b82a1138b9f22ed87ed00cbe76", "045310b06e8a3983a363a118cc9dcc3f292970b4", "089a76dbc62a06ad30ae1925530e8733e850268e"], "ReferenceCount": 11, "CitationCount": 27}, {"URL": "https://www.semanticscholar.org/paper/Support-vector-machines-combined-with-feature-for-Akay/fe83150bc326fd62d352cb2993ac91344f195e10", "ID": "fe83150bc326fd62d352cb2993ac91344f195e10", "Title": "Support vector machines combined with feature selection for breast cancer diagnosis", "Abstract": "Semantic Scholar extracted view of \\\"Support vector machines combined with feature selection for breast cancer diagnosis\\\" by M. Akay", "PublicationYear": "2009", "Authors": ["Mehmet Fatih Akay"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["82d5b4635858db58fd38dd829ae5e2c4d13e3e66", "e663fa59a758b945ed0e8e620a52022d617a9b03", "10ea1a358fecfd1623e230df98f11f967490c47a", "5c7dfd541f7eb4b8148c69d9a2974f1d7357d1fa", "456a261579904536364a67207a44660304da5592", "57a29eae9217831f391c2a3206964fddbb162250", "9008cdacbdcff8a218a6928e94fe7c6dfc237b24", "1fda96d554f4e5a21e35bf33b9720141da47664b", "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8", "0d28c0390b21244cc52e9af856249cb601f6b22d"], "ReferenceCount": 24, "CitationCount": 766}, {"URL": "https://www.semanticscholar.org/paper/A-ranklet-based-image-representation-for-mass-in-Masotti/483f0f12feb8ac1c396349e5526a7552b6b067cd", "ID": "483f0f12feb8ac1c396349e5526a7552b6b067cd", "Title": "A ranklet-based image representation for mass classification in digital mammograms.", "Abstract": "A novel nonparametric, orientation-selective, and multiresolution image representation is developed and evaluated, namely a ranklet image representation that discloses to be robust also when tested on radiographic images having gray-level intensity histogram remarkably different from that used for training. Regions of interest (ROIs) found on breast radiographic images are classified as either tumoral mass or normal tissue by means of a support vector machine classifier. Classification features are the coefficients resulting from the specific image representation used to encode each ROI. Pixel and wavelet image representations have already been discussed in one of our previous works. To investigate the possibility of improving classification performances, a novel nonparametric, orientation-selective, and multiresolution image representation is developed and evaluated, namely a ranklet image representation. A dataset consisting of 1000 ROIs representing biopsy-proven tumoral masses (either benign or malignant) and 5000 ROIs representing normal breast tissue is used. ROIs are extracted from the digital database for screening mammography collected by the University of South Florida. Classification performances are evaluated using the area Az under the receiver operating characteristic curve. By achieving Az values of 0.978 +/- 0.003 and 90% sensitivity with a false positive fraction value of 4.5%, experiments demonstrate classification results higher than those reached by the previous image representations. In particular, the improvement on the Az value over that achieved by the wavelet image representation is statistically relevant with the two-tailed p value &lt;0.0001. Besides, owing to the tolerance that the ranklet image representation reveals to variations in the ROIs' gray-level intensity histogram, this approach discloses to be robust also when tested on radiographic images having gray-level intensity histogram remarkably different from that used for training.", "PublicationYear": "2006", "Authors": ["Matteo Masotti"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["adef50946f5336ac951bb37056c0c8de107aa9a7", "3a54399b141999271e49c652979f65fcd968daa9", "f876d2b733ed1e307c81df3008d10ffa60675f0b", "34856bb7b455a317126787076be40f4f57154273", "e764d70b416fa5fee1fd76ed21d64e26ef187bb9", "29dab22d41369fe0af3dd6bca85e0c5aa6859ded", "bba978f6deba664527708705d12365bc0f157151", "38f7c8cfb6b52df515c1cb29a2e42f6673e7a377", "413bb48a77c0730693ea8217d89cab28a686e7a3", "eddad94fd10693fb0cf3340792f11af15232b49c"], "ReferenceCount": 32, "CitationCount": 44}, {"URL": "https://www.semanticscholar.org/paper/Breast-mass-contour-segmentation-algorithm-in-Berber-Alpkocak/a9d0b3485f3091e832f87edb469c350c90cabae1", "ID": "a9d0b3485f3091e832f87edb469c350c90cabae1", "Title": "Breast mass contour segmentation algorithm in digital mammograms", "Abstract": "Semantic Scholar extracted view of \\\"Breast mass contour segmentation algorithm in digital mammograms\\\" by Tolga Berber et al.", "PublicationYear": "2013", "Authors": ["Tolga Berber", "Adil Alpkocak", "P\u0131nar Balc\u0131", "O\u011fuz Dicle"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["6c4aac0941b002d74264b7f702881e85f2eb47a2", "1c26e62c7d9719dcdd652932345090534d661629", "81b568a5899f22f6d8ea7dd2fc31f31f6d423e1a", "728d5be150b5ef7e2b22586f61b7a905b33ee7e6", "103a9fc043d9fcccec9d545a53a76e22dcfe9c3f", "c83e00120d7adcda72ac01b95234134c47cba76a", "07a94891c522d59a1343e6292234aa9d43e89d89", "dda0dc40bc5cb79d5638d8cac955337362e6473e", "2d78c76f2696918bb9457d30e2b9b62c10ccae45", "e71d328440738b2ad8a1937ad6f5c0786c6cc315"], "ReferenceCount": 31, "CitationCount": 70}, {"URL": "https://www.semanticscholar.org/paper/Automatic-Soccer-Video-Analysis-and-Summarization-Ekin-Tekalp/d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f", "ID": "d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f", "Title": "Automatic Soccer Video Analysis and Summarization", "Abstract": "A fully automatic and computationally efficient framework for analysis and summarization of soccer videos using cinematic and object-based features, which includes some novel low-level soccer video processing algorithms, as well as some higher-level algorithms for goal detection, referee detection, and penalty-box detection. We propose a fully automatic and computationally efficient framework for analysis and summarization of soccer videos using cinematic and object-based features. The proposed framework includes some novel low-level soccer video processing algorithms, such as dominant color region detection, robust shot boundary detection, and shot classification, as well as some higher-level algorithms for goal detection, referee detection, and penalty-box detection. The system can output three types of summaries: i) all slow-motion segments in a game, ii) all goals in a game, and iii) slow-motion segments classified according to object-based features. The first two types of summaries are based on cinematic features only for speedy processing, while the summaries of the last type contain higher-level semantics. The proposed framework is efficient, effective, and robust for soccer video processing. It is efficient in the sense that there is no need to compute object-based features when cinematic features are sufficient for the detection of certain events, e.g. goals in soccer. It is effective in the sense that the framework can also employ object-based features when needed to increase accuracy (at the expense of more computation). The efficiency, effectiveness, and the robustness of the proposed framework are demonstrated over a large data set, consisting of more than 13 hours of soccer video, captured at different countries and conditions.", "PublicationYear": "2003", "Authors": ["Ahmet Ekin", "A. Murat Tekalp", "Rajiv Mehrotra"], "RelatedTopics": ["Computer Science"], "References": ["d6151de801659937574c3efe13c2d207e9e2f2cd", "339acc20ebbf3c08c797373f873e4e6b9f2f9c9a", "7b068d9ff88588a15d6d5fa8e7932d4e635cd252", "564649846003db680733697947f974a1ef03c4ea", "5a7571db7df03cca52c48f89595c4abefeb51e5c", "a3a7a3fe0fc54665d5e22461a27e2aa2816666a8", "832f48f5c28956e892e0ece93e2802f4501036ab", "f0bafbf9cf2dfb1fd7e439e2336f1dd3af19478c", "718df880b746a72b02c4ff9f29a8aec06d897d88", "3164b111618ce6ba25c968c50c8fcf27dad5d2a8"], "ReferenceCount": 31, "CitationCount": 926}, {"URL": "https://www.semanticscholar.org/paper/Semantic-analysis-of-soccer-video-using-dynamic-Huang-Shih/d71c84fbaff0d7f2cbcf2f03630e189c58939a4a", "ID": "d71c84fbaff0d7f2cbcf2f03630e189c58939a4a", "Title": "Semantic analysis of soccer video using dynamic Bayesian network", "Abstract": "A semantic analysis system based on Bayesian network (BN) and dynamic Bayesiannetwork (DBN) that can identify the special events in soccer games such as goal event, corner kick event, penaltyKick event, and card event is introduced. Video semantic analysis is formulated based on the low-level image features and the high-level knowledge which is encoded in abstract, nongeometric representations. This paper introduces a semantic analysis system based on Bayesian network (BN) and dynamic Bayesian network (DBN). It is validated in the particular domain of soccer game videos. Based on BN/DBN, it can identify the special events in soccer games such as goal event, corner kick event, penalty kick event, and card event. The video analyzer extracts the low-level evidences, whereas the semantic analyzer uses BN/DBN to interpret the high-level semantics. Different from previous shot-based semantic analysis approaches, the proposed semantic analysis is frame-based for each input frame, it provides the current semantics of the event nodes as well as the hidden nodes. Another contribution is that the BN and DBN are automatically generated by the training process instead of determined by ad hoc. The last contribution is that we introduce a so-called temporal intervening network to improve the accuracy of the semantics output", "PublicationYear": "2006", "Authors": ["Chung-Lin Huang", "Huang-Chia Shih", "Chung-Yuan Chao"], "RelatedTopics": ["Computer Science"], "References": ["d3448a792e771d8cd49a4e0c3b08ae5b3d51e51f", "b5a23310cdc5b492175325ba90af69ecda3dc377", "718df880b746a72b02c4ff9f29a8aec06d897d88", "c51d7cbfb95ee370d1eddb4e0ff03290b8bb479a", "3dcd7ed1905e94b06b0c8f087007f00951b030ab", "d6151de801659937574c3efe13c2d207e9e2f2cd", "54e04284d0d33fabcd7be961ff29af2223638dee", "5a7571db7df03cca52c48f89595c4abefeb51e5c", "c7967ff0c51732110e0e1470975fe0a974fa8a2e", "e19d56ee20fec839338612c2007d67db65351d9d"], "ReferenceCount": 24, "CitationCount": 163}, {"URL": "https://www.semanticscholar.org/paper/Event-Detection-of-Broadcast-Baseball-Videos-Hung-Hsieh/43eb2d80721daa318cc19e4cce405122934e88f2", "ID": "43eb2d80721daa318cc19e4cce405122934e88f2", "Title": "Event Detection of Broadcast Baseball Videos", "Abstract": "An effective and efficient event detection system for broadcast baseball videos that integrates midlevel cues including scoreboard information and shot transition patterns into event classification rules based on a Bayesian Belief Network is presented. This paper presents an effective and efficient event detection system for broadcast baseball videos. It integrates midlevel cues including scoreboard information and shot transition patterns into event classification rules. First, a simple scoreboard detection and recognition scheme is developed to extract the game status from videos. Then, a shot transition classifier is designed to obtain the shot transition patterns, which contains several novel schemes including adaptive playfield segmentation, pitch shot detection, field shot detection, as well as infield/outfield classification. The extracted midlevel cues are used to develop an event classifier based on a Bayesian Belief Network. The network is with low complexity because the number of these cues used is small, which not only improves the generalization performance of the event classifier but also reduces system complexity as well as training efforts. Using the inference results of the network, we further derive a set of classification rules to identify baseball events. The set of rules is stored in a look-up table such that the classification is only a simple table look-up operation. The proposed approach is very simple and computational efficient. More importantly, the simulation results indicate that it identifies ten significant baseball events with 95% of precision rate and 92% of recall rate, which is very promising.", "PublicationYear": "2008", "Authors": ["Mao-Hsiung Hung", "Chaur-Heh Hsieh"], "RelatedTopics": ["Computer Science"], "References": ["d0ec6dee3f7cd0c1571d179d756afc823cda636b", "8268944e509094df7eda14e3963d1add1db87528", "ed9456c605c18aeb9b0aff5eaae4038ef4adb564", "3dcd7ed1905e94b06b0c8f087007f00951b030ab", "e89332600d8abd393bcd8020d69c6a7a3298a966", "d71c84fbaff0d7f2cbcf2f03630e189c58939a4a", "5727fdb06696f92d406adb81459dd2e56da1dfeb", "263eb915898a9e79ff1cb4d234dacd6b2ea72be3", "ce8883dbe8c695d8ef770eefe34e48efe7c0cf64", "ff5c011612174c8fcb9d6a1e901be51f6a3437c7"], "ReferenceCount": 16, "CitationCount": 39}, {"URL": "https://www.semanticscholar.org/paper/Knowledge-Discounted-Event-Detection-in-Sports-Tjondronegoro-Chen/0cca81f3b2928f6d4005e1a8b617960e2fb14d3e", "ID": "0cca81f3b2928f6d4005e1a8b617960e2fb14d3e", "Title": "Knowledge-Discounted Event Detection in Sports Video", "Abstract": "This work proposes a hybrid approach, which integrates statistics into logical rule-based models during highlight detection and pioneered the use of play-break segment as a universal scope of detection and a standard set of features that can be applied for different sports, including soccer, basketball, and Australian football. Automatic events annotation is an essential requirement for constructing an effective sports video summary. Researchers worldwide have actively been seeking the most robust and powerful solutions to detect and classify key events (or highlights) in different sports. Most of the current and widely used approaches have employed rules that model the typical pattern of audiovisual features within particular sport events. These rules are mainly based on manual observation and heuristic knowledge; therefore, machine learning can be used as an alternative. To bridge the gap between the two alternatives, we propose a hybrid approach, which integrates statistics into logical rule-based models during highlight detection. We have also successfully pioneered the use of play-break segment as a universal scope of detection and a standard set of features that can be applied for different sports, including soccer, basketball, and Australian football. The proposed method uses a limited amount of domain knowledge, making this method less subjective and more robust for different sports. An experiment using a large data set of sports video has demonstrated the effectiveness and robustness of the algorithms.", "PublicationYear": "2010", "Authors": ["Dian Tjondronegoro", "Yi-Ping Phoebe Chen"], "RelatedTopics": ["Computer Science"], "References": ["c7bc06203ee09cf2066b47c3ac1fa444dfa8d878", "217478d6a95a5bceef11d7846895b57718d63e73", "ad31e976cfa5cba56b84a2f7e05adceee99366df", "8e0f60b718fa19c2ed10bd93401796683af79512", "cb6742b271ae81baa217d2d6391ead067f6e7018", "cc8756e654c8c3016c1e86189b76fe6b8a08773a", "ba73512ff40f576a4ab6a8f1be6de08256fdf038", "77eba439796f8482a1f36be31dfddbae7536d792", "5a7571db7df03cca52c48f89595c4abefeb51e5c", "5727fdb06696f92d406adb81459dd2e56da1dfeb"], "ReferenceCount": 37, "CitationCount": 90}, {"URL": "https://www.semanticscholar.org/paper/A-semantic-event-detection-approach-and-its-to-in-Haering-Qian/0365c1382924394e200cb627e59cb9c21f8e75bd", "ID": "0365c1382924394e200cb627e59cb9c21f8e75bd", "Title": "A semantic event-detection approach and its application to detecting hunts in wildlife vide", "Abstract": "A three-level video-event detection methodology that can be applied to different events by adapting the classifier at the intermediate level and by specifying a new event model at the highest level is proposed. We propose a three-level video-event detection methodology and apply it to animal-hunt detection in wildlife documentaries. The first level extracts color, texture, and motion features, and detects shot boundaries and moving object blobs. The mid-level employs a neural network to determine the object class of the moving object blobs. This level also generates shot descriptors that combine features from the first level and inferences from the mid-level. The shot descriptors are then used by the domain-specific inference process at the third level to detect video segments that match the user defined event model. The proposed approach has been applied to the detection of hunts in wildlife documentaries. Our method can be applied to different events by adapting the classifier at the intermediate level and by specifying a new event model at the highest level. Event-based video indexing, summarization, and browsing are among the applications of the proposed approach.", "PublicationYear": "2000", "Authors": ["Niels C. Haering", "Richard J. Qian", "M. Ibrahim Sezan"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["e7bd444bbe813273dee084e9efc67d95f411cc19", "93954c1e3cee3039d2b6b53c61ff6137e9e335bd", "3eeebdce6255b997c4ced11d9d45d5bef421b2c6", "54ecdf01c1bbbe8106cd27a35aed672c3564ef34", "3a8ce1bcf4a092761246d99f0cde788f1804577f", "dc185ecd84439165d6cfe90001997cab9b202736", "7d4d58e303e9605c483d9d24a70c7a25864ac3b5", "9895be389b31013b477e3bb48a006ad5c73f3a14", "19c8dc7b4acdeecf092526d767156ac8950c02d8", "edea2f25d705d43ce90f725eed62f7dba6fbd50f"], "ReferenceCount": 44, "CitationCount": 133}, {"URL": "https://www.semanticscholar.org/paper/Integrated-Mining-of-Visual-Features%2C-Speech-and-Tseng-Su/c9edc10d5c22ae62a700c37a41bb0ea22961a0aa", "ID": "c9edc10d5c22ae62a700c37a41bb0ea22961a0aa", "Title": "Integrated Mining of Visual Features, Speech Features, and Frequent Patterns for Semantic Video Annotation", "Abstract": "The proposed approach to semantic video annotation through integrated mining of visual features, speech features, and frequent semantic patterns existing in the video is shown to enhance the performance of annotation substantially in terms of precision, recall, and F-measure. To support effective multimedia information retrieval, video annotation has become an important topic in video content analysis. Existing video annotation methods put the focus on either the analysis of low-level features or simple semantic concepts, and they cannot reduce the gap between low-level features and high-level concepts. In this paper, we propose an innovative method for semantic video annotation through integrated mining of visual features, speech features, and frequent semantic patterns existing in the video. The proposed method mainly consists of two main phases: 1) Construction of four kinds of predictive annotation models, namely speech-association, visual-association, visual-sequential, and statistical models from annotated videos. 2) Fusion of these models for annotating un-annotated videos automatically. The main advantage of the proposed method lies in that all visual features, speech features, and semantic patterns are considered simultaneously. Moreover, the utilization of high-level rules can effectively complement the insufficiency of statistics-based methods in dealing with complex and broad keyword identification in video annotation. Through empirical evaluation on NIST TRECVID video datasets, the proposed approach is shown to enhance the performance of annotation substantially in terms of precision, recall, and F-measure.", "PublicationYear": "2008", "Authors": ["Vincent S. Tseng", "Ja-Hwung Su", "Jhih-Hong Huang", "Chih-Jen Chen"], "RelatedTopics": ["Computer Science"], "References": ["a544b12d39c059a1a9ba7da3d5fe78747c9cabaa", "0d10531bea859670320ff1fbfd882af8dcf9abf3", "e7afd8e942e370e7fdaf3f395492c4aba0b8080b", "30ee51ff3120051bc30d64b2a80cc7edcba7d511", "3a8ce1bcf4a092761246d99f0cde788f1804577f", "fad43474e4fa71eb2527ef30adfa7bb7870baa83", "933faea49491113927c18d6739ed24fc5d8624eb", "ba4e1089e2c5a1c12e9f6c2686e9c8d1870c718e", "09460c5170f5b65e0772cd8d18491accfd9d78d9", "ed7368b4c65d872f6886260271b9b94c2fa2b89b"], "ReferenceCount": 34, "CitationCount": 62}, {"URL": "https://www.semanticscholar.org/paper/Using-Webcast-Text-for-Semantic-Event-Detection-in-Xu-Zhang/90fbd777cf57096e9292601dfe0dbab30198d40f", "ID": "90fbd777cf57096e9292601dfe0dbab30198d40f", "Title": "Using Webcast Text for Semantic Event Detection in Broadcast Sports Video", "Abstract": "This paper presents a novel approach for sports video semantic event detection based on analysis and alignment of Webcast text and broadcast video, and employs a conditional random field model (CRFM) to align text event and video event. Sports video semantic event detection is essential for sports video summarization and retrieval. Extensive research efforts have been devoted to this area in recent years. However, the existing sports video event detection approaches heavily rely on either video content itself, which face the difficulty of high-level semantic information extraction from video content using computer vision and image processing techniques, or manually generated video ontology, which is domain specific and difficult to be automatically aligned with the video content. In this paper, we present a novel approach for sports video semantic event detection based on analysis and alignment of Webcast text and broadcast video. Webcast text is a text broadcast channel for sports game which is co-produced with the broadcast video and is easily obtained from the Web. We first analyze Webcast text to cluster and detect text events in an unsupervised way using probabilistic latent semantic analysis (pLSA). Based on the detected text event and video structure analysis, we employ a conditional random field model (CRFM) to align text event and video event by detecting event moment and event boundary in the video. Incorporation of Webcast text into sports video analysis significantly facilitates sports video semantic event detection. We conducted experiments on 33 hours of soccer and basketball games for Webcast analysis, broadcast video analysis and text/video semantic alignment. The results are encouraging and compared with the manually labeled ground truth.", "PublicationYear": "2008", "Authors": ["Changsheng Xu", "Yifan Zhang", "Guangyu Zhu", "Yong Rui", "Hanqing Lu", "Qingming Huang"], "RelatedTopics": ["Computer Science"], "References": ["7eb16b3e160622fbf58836b2fb884af30a2b19b5", "cc8756e654c8c3016c1e86189b76fe6b8a08773a", "e891530c62ab431de4330693ed5dbda8509802ce", "d993c5d2a62242c9a20550587379c15f6d4ce860", "d0ec6dee3f7cd0c1571d179d756afc823cda636b", "833deab2d9f7bde03848c58b5d8066d153ee60af", "20b253b8846814b5e06007cb337785b963633308", "217478d6a95a5bceef11d7846895b57718d63e73", "99009072d31cf16cd817dffd0aac6b134d71ddb5", "7b29d588cf0d910f867f8eeee3d0a2b0e183e0c8"], "ReferenceCount": 41, "CitationCount": 159}, {"URL": "https://www.semanticscholar.org/paper/Automatic-player-detection%2C-labeling-and-tracking-Liu-Tong/f7b4fcc9dbb97997dc1793d7a366cba274f53134", "ID": "f7b4fcc9dbb97997dc1793d7a366cba274f53134", "Title": "Automatic player detection, labeling and tracking in broadcast soccer video", "Abstract": "Semantic Scholar extracted view of \\\"Automatic player detection, labeling and tracking in broadcast soccer video\\\" by Jia Liu et al.", "PublicationYear": "2009", "Authors": ["Jia Liu", "Xiaofeng Tong", "Wenlong Li", "Tao Wang", "Yimin Zhang", "Hongqi Wang"], "RelatedTopics": ["Computer Science"], "References": ["cc4d03faf65c7fad0eeb345ae0db102a7be3770f", "f12307a3b6d6e12174b31ffb2644108089855f04", "fd294153765faf0851e08a751d3849b4a71e1eb1", "38dd730a7d2466b3bde4674daddecb6532fd3ae3", "dc5181c650b3a7b86989c2d3179fa0f9bcdeb3c3", "197c7b40c4f5ceb6b1d862de0bfc27b57e61d19d", "b46da16dca784e66f600cfa05aa3d9d8bc1dee6d", "f101e675936ea326354ca3c9d4d70699f1a71843", "fb444dc25bab36a8e273ed654d49e3841905e5af", "2c9326ed69e586b08dff3c0da0a2bcab86bbc15e"], "ReferenceCount": 24, "CitationCount": 177}, {"URL": "https://www.semanticscholar.org/paper/Event-detection-in-field-sports-video-using-and-a-Sadlier-O%E2%80%99Connor/8e0f60b718fa19c2ed10bd93401796683af79512", "ID": "8e0f60b718fa19c2ed10bd93401796683af79512", "Title": "Event detection in field sports video using audio-visual features and a support vector Machine", "Abstract": "A novel audio-visual feature-based framework for event detection in broadcast video of multiple different field sports and the results suggest that high event retrieval and content rejection statistics are achievable. In this paper, we propose a novel audio-visual feature-based framework for event detection in broadcast video of multiple different field sports. Features indicating significant events are selected and robust detectors built. These features are rooted in characteristics common to all genres of field sports. The evidence gathered by the feature detectors is combined by means of a support vector machine, which infers the occurrence of an event based on a model generated during a training phase. The system is tested generically across multiple genres of field sports including soccer, rugby, hockey, and Gaelic football and the results suggest that high event retrieval and content rejection statistics are achievable.", "PublicationYear": "2005", "Authors": ["David A. Sadlier", "Noel E. O\u2019Connor"], "RelatedTopics": ["Computer Science"], "References": ["6a9a5667b7595bf06290665f7b32f540e60dbbc3", "5a7571db7df03cca52c48f89595c4abefeb51e5c", "1248d51ccfbcbc89f5682774f5f9f88da4f68611", "e2beed07f3841bc6f97efa2fa65b232d15f6e9d2", "217478d6a95a5bceef11d7846895b57718d63e73", "d203dbaf6047ac6e1cdfecb8b753bd2593f1023b", "c51d7cbfb95ee370d1eddb4e0ff03290b8bb479a", "0ba6ab976e3ec7650df31642ea58759d8bae46f5", "20b253b8846814b5e06007cb337785b963633308", "278dc8bce9b16b135a26a1651db7e3f43eb289ac"], "ReferenceCount": 44, "CitationCount": 255}, {"URL": "https://www.semanticscholar.org/paper/A-Video-Event-Detection-and-Mining-Framework-Guler-Liang/c2f8178ce89a6cc1ad0e1dd5db4bf155d5a80620", "ID": "c2f8178ce89a6cc1ad0e1dd5db4bf155d5a80620", "Title": "A Video Event Detection and Mining Framework", "Abstract": "This work presents two methods for video event detection, namely an expert system (CLIPS) rules based approach and a 2-level Hidden Markov Model built upon split and merge behaviors. We present a video event mining framework that consists of comprehensive set of tools for event detection, annotation, content browsing and a video analysis database. Central to our framework is the video analysis database and the VideoViews database browser that supports both top-down and bottom-up analysis of the video data. to support event mining. We present two methods for video event detection, namely an expert system (CLIPS) rules based approach and a 2-level Hidden Markov Model built upon split and merge behaviors. We devised interfaces for these event detection methods to be operated on the video data in the database for training and detection. We embed scene, object and event data into the video stream as metadata. VideoViews provides interfaces to event detection and video annotation tools. Our video analysis database description scheme represents the structure of the video data from video clips to scenes, objects and their tracks as well as the semantics from simple behaviors to more complex events that may take place over multiple video scenes and/or clips. This framework and the combination of tools enable the users to visualize the raw video data and the processed video information from a number of perspectives facilitating efficient video event mining.", "PublicationYear": "2003", "Authors": ["Sadiye Guler", "Winnie H. Liang", "Ian A. Pushee"], "RelatedTopics": ["Computer Science"], "References": ["ecab8d10ca24b53eca2bf1580e8cd03fe7984676", "1bfe26fac93ad96c81cf1a580b9e7744477f56aa", "518597d91ed49c28f5cf3f0a0b05609568b7e084", "bc4b948b1a0f91525bc3d47e9e192b392bf790ed", "3ff52ba9498b2ac084c9d8bbf637c343679df402", "87cc226aa060db976fbf6ac3a07969b33b544b96", "824aac4970a4d149b35c19a9d2d2dec4c994688e", "18b02beb27288f6bd9d4376ca41e70655a698084", "1c99600451dedd42dcdc02ed6cfcaa81e70e9899", "9fd7f3022db657ef5e9619209962e5525ffdce4e"], "ReferenceCount": 15, "CitationCount": 18}, {"URL": "https://www.semanticscholar.org/paper/A-fast-and-efficient-fuzzy-color-transfer-method-Abadpour-Kasaei/e1dfff8cff33ede3564a35724632bddc5b8619b1", "ID": "e1dfff8cff33ede3564a35724632bddc5b8619b1", "Title": "A fast and efficient fuzzy color transfer method", "Abstract": "A novel fuzzy principle component analysis (PCA) based color transfer method that accomplishes the transformation based on a set of corresponding user-selected regions in images along with a blending ratio parameter set by the user. Each image has its own color content that greatly influences the perception of human observer. Being able to transfer the color content of an image into another image, while preserving other features, (like texture), opens a new horizon in human-perception-based image processing. In this paper, after a brief review on the few efficient works performed in the field, a novel fuzzy principle component analysis (PCA) based color transfer method is proposed. The proposed method accomplishes the transformation based on a set of corresponding user-selected regions in images along with a blending ratio parameter set by the user. Results show more robustness and higher speed when comparing our proposed method with other available approaches.", "PublicationYear": "2004", "Authors": ["Arash Abadpour", "Shohreh Kasaei"], "RelatedTopics": ["Computer Science"], "References": ["05f63bdf9e60d0a299cfe5e8d7ba043904f1fea1", "d5c6edb53dc41f298f145041cd2c53e40e3acf2b", "3fed78dcdcf2588f2f1b34ad6885a60789574203", "4e4504e867e867f8b2bc366b75e036686582e5bf", "b5bd72d8bc9f51dae65c15842f0ab443c3b437e3", "577d19a115f9ef6f002483fcf88adbb3b5479556", "f3a11158e9d8bdfdf07dca756335c084fce0123e", "78b4f65c167185f18b573433e5f3e8814acf656f", "a9407584b7641f70bf0882e495ddef561d0ee62b"], "ReferenceCount": 13, "CitationCount": 44}, {"URL": "https://www.semanticscholar.org/paper/New-Principle-Component-Analysis-Based-Colorizing-Abadpour-Kasaei/d93e4e77e2baba98f1af7f23d47fbf9b46be4df5", "ID": "d93e4e77e2baba98f1af7f23d47fbf9b46be4df5", "Title": "New Principle Component Analysis Based Colorizing Method", "Abstract": "A new dimensionreduction method is proposed for natural color images and approved by both quantitative (PSNR) and subjective tests, based on which a new class of colorizing methods is proposed and two sample formulations are presented. Although many modern imaging systems are still producing grayscale images, colored-images are more preferred for the larger amount of information they are carrying. Computing the grayscale representation of a color image is a straightforward task, while the inverse problem has no objective solution. The search through out literature has not revealed much history of the past works. In this paper, after a brief review of related research, a new dimensionreduction method is proposed for natural color images and approved by both quantitative (PSNR) and subjective tests. Based on it a new class of colorizing methods is proposed and two sample formulations are presented, where the authors are aware of many other formulations available. Subjective test shows dominancy of our proposed method when our method is much faster than others. Our method is leading in face image colorizing where other methods have failed. Such colorization method can be used greatly in medical image processing, surveillance systems, and information visualization.", "PublicationYear": "2004", "Authors": ["Arash Abadpour", "Shohreh Kasaei"], "RelatedTopics": ["Computer Science"], "References": ["d5c6edb53dc41f298f145041cd2c53e40e3acf2b", "ab67b9d0da50e251a4f7e42370540547b891ceb1", "b5bd72d8bc9f51dae65c15842f0ab443c3b437e3", "cc470d34b6d76518ef4435b627ba1ec01ac55c03", "95a057bf3b2b7af6778e30847ad8177191ec43c9", "3cf04e19e55cf6d2d18157c136885a042ab578d1", "577d19a115f9ef6f002483fcf88adbb3b5479556", "8d946c3eb1d1db376a89ad9342282163b5ae0930", "1061dea79f8c5e55bf11f7873b9de109c51cbc67", "f3a11158e9d8bdfdf07dca756335c084fce0123e"], "ReferenceCount": 18, "CitationCount": 6}, {"URL": "https://www.semanticscholar.org/paper/Fast-algorithms-for-color-image-processing-by-Cheng-Hsia/05f63bdf9e60d0a299cfe5e8d7ba043904f1fea1", "ID": "05f63bdf9e60d0a299cfe5e8d7ba043904f1fea1", "Title": "Fast algorithms for color image processing by principal component analysis", "Abstract": "Semantic Scholar extracted view of \\\"Fast algorithms for color image processing by principal component analysis\\\" by Shyi-Chyi Cheng et al.", "PublicationYear": "2003", "Authors": ["Shyi-Chyi Cheng", "Shih-Chang Hsia"], "RelatedTopics": ["Computer Science"], "References": ["03cbb2aff1cb933886edca9ea98161a8896552c5", "94ffa7842b83a4326b7d23a1face2c296edef92c", "fdc9ae0ec9b249b008a9592ddae98881bd46b606", "1e4039217f8f594d8f1be9ca1dd452589dafdcaa", "616388801bd609f9a905f64bbaa08534a4cd3dac", "d367a7305b26d0f6fbe45e85a8ffe8ab4afec718", "91df6a976c1cbed21b67a66d5de81db61ae63f3a", "8a54d38754c216ad26d2c3e61fee980a57a9ad56", "d520e606c8819b465e6eaaad2ee891ac23c42155", "0e90e6853d04c5dc03893c1269320f3828550651"], "ReferenceCount": 14, "CitationCount": 35}, {"URL": "https://www.semanticscholar.org/paper/A-new-FPCA-based-fast-segmentation-method-for-color-Abodpour-Kasaei/0c2ced886708cc3aea4705f8765d152cd3f69cd2", "ID": "0c2ced886708cc3aea4705f8765d152cd3f69cd2", "Title": "A new FPCA-based fast segmentation method for color images", "Abstract": "A general case of clustering is discussed and a general method is proposed and its convergence is proved, and it is proved that the FCM and the FCV methods are special cases of the proposed method. Fuzzy objective function-based clustering methods are proved to be fast tools for classification and segmentation purposes. Unfortunately, most of the available fuzzy clustering methods are using the spherical or ellipsoidal distances, which are proved to result in spurious clusters, when working on color data. In this paper, a general case of clustering is discussed and a general method is proposed and its convergence is proved. Also, it is proved that the FCM and the FCV methods are special cases of the proposed method. Based on the general method, a special case for color image processing is proposed. The clustering method is based on a likelihood measure, and is proved to outperform the Euclidean and the Mahalanobis distances, in color fields. Based on the proposed color clustering method, a new fast fuzzy segmentation method is proposed and is proved to be highly efficient Comparison of the results with the FCM, proves the superiority of the proposed segmentation method.", "PublicationYear": "2004", "Authors": ["A. Abodpour", "Shohreh Kasaei"], "RelatedTopics": ["Computer Science"], "References": ["5ac1bbc582e591e2560d1a3167f30fd5a9073b25", "2377b94096298613d0f06f7c8110a5303bc09f53", "4debea4d29ca203433c830a1dd1c0c1bb4828b6c", "253b74d147ba829b9b1926c478815f1d904f9e36", "1186c8e998b2a1c3dd87e55400929d753877bd19", "1380bcf86538fef43dd2356d71b64523867b58c0", "a34c9af1897c779be9aee293ac43e1dca097a33c", "d738b2654fcdc4569d036fbd958b8151eab4ba19", "fd3828d1465baf3719195ad98971fad66162ce67", "989af4dd904c1958e5f9a6f08f70572259303425"], "ReferenceCount": 41, "CitationCount": 12}, {"URL": "https://www.semanticscholar.org/paper/Linear-color-segmentation-and-its-implementation-Nikolaev-Nikolayev/a2882b8b0c9635d39d15a28138e3f47907f3177b", "ID": "a2882b8b0c9635d39d15a28138e3f47907f3177b", "Title": "Linear color segmentation and its implementation", "Abstract": "Semantic Scholar extracted view of \\\"Linear color segmentation and its implementation\\\" by D. Nikolaev et al.", "PublicationYear": "2004", "Authors": ["Dmitry P. Nikolaev", "Petr P. Nikolayev"], "RelatedTopics": ["Computer Science", "Physics"], "References": ["015e56c1042e0be60154fac7095bcc681a0c2960", "1e48105dd2b6d4a21be627040fa6e2074a576bef", "84818dc24b6efe355ee5bcd7ac1c28473d0e8e3d", "5e3ab08e93e5eb529692825cfedf6d3b6763bd76", "157282748f001bc9876f9eaf1d53b98a6e579f19", "f4145c995bd7fc3415d8a366a2bf25d100d7b9a9", "5924e7dc6c65efc2a7482dadc8f1d3585e6a420d", "794537f1939fad46800d6cf678ea07dc383c4a30", "281b195c5b155c461d679444c3e2aeb06aa7e351", "3a1c431cb819dc5ced519a6be65d6b4a0658aeea"], "ReferenceCount": 32, "CitationCount": 51}, {"URL": "https://www.semanticscholar.org/paper/Multithresholding-of-color-and-gray-level-images-a-Papamarkos-Strouthopoulos/61579369e7b97dec9c699c058edaafcde2817d21", "ID": "61579369e7b97dec9c699c058edaafcde2817d21", "Title": "Multithresholding of color and gray-level images through a neural network technique", "Abstract": "Semantic Scholar extracted view of \\\"Multithresholding of color and gray-level images through a neural network technique\\\" by N. Papamarkos et al.", "PublicationYear": "2000", "Authors": ["Nikos Papamarkos", "Charalambos Strouthopoulos", "Ioannis Andreadis"], "RelatedTopics": ["Computer Science"], "References": ["a050eb794e7cb65207d998371f8f0287e7ed53ab", "42c40ae5648dabf463fb43f24441cf3253782a12", "91343f9ce2e7d702c2ff837830bd35259ff8fd99", "53e4349b6e585426389059c5107a366b8873eb67", "ce1e7aa9fd5ba2f54b342b7cac2625835771daf2", "2c419cfb621051a3a007a4e937a3da22f18653e1", "af7dcf5e823f6e1eaa4aff2afa2912585ea32147", "1d8237039244543cf8bca7cc022cf6c8e39aa260", "ab67b9d0da50e251a4f7e42370540547b891ceb1", "69d3e3535263f1e240920f47ebb462658b3d3761"], "ReferenceCount": 20, "CitationCount": 94}, {"URL": "https://www.semanticscholar.org/paper/Color-Segmentation-Based-on-Separate-Anisotropic-of-Lucchese-Mitra/4a6c5c9b1fb106f7d82508ae593d30e207c8ea45", "ID": "4a6c5c9b1fb106f7d82508ae593d30e207c8ea45", "Title": "Color Segmentation Based on Separate Anisotropic Diffusion of Chromatic and Achromatic Channels", "Abstract": "It is shown how segmentation can benefit from splitting colour signals into chromatic and achromatic channels and separately smoothing them through anisotropic diffusion. The paper presents a new technique for segmenting images only on the basis of colour information. It is shown how segmentation can benefit from splitting colour signals into chromatic and achromatic channels and separately smoothing them through anisotropic diffusion. Operatively, this is accomplished through two independent diffusion processes: one involves only the chromatic information, conveniently embedded in a complex function, while the other affects the lightness information. The results of the two diffusions are separately segmented by k-means clustering techniques and their combination yields the final image partition into homogeneous regions. Some experimental results are reported which verify the effectiveness of the proposed technique.", "PublicationYear": "2001", "Authors": ["Luca Lucchese", "Sanjit K. Mitra"], "RelatedTopics": ["Computer Science"], "References": ["251a7ee2ecd78aff6e83318c92b01a55bf6a762f", "f566985a7df1dcd6af66b019a50338aeea5f1cf2", "3a15aa74d7db2004b8895ee822170231f95a0b6c", "674285f115841d8a237a68e55b4e651cc558bf9d", "fa4dce7d484da0d91d872261e0c41006521e732f", "8854a69749b2a02afbf880a413f77988eaacbfde", "e9e42f0079b6d9ab86857e418a7d5157e381928a", "d077f1a275c922e288cda1e3fa949154316503cf", "a9b9866314054a7c8386bd44362e9034a0690007", "b9ce57274884fa65fb34217b6a79c0f6c78e2721"], "ReferenceCount": 31, "CitationCount": 34}, {"URL": "https://www.semanticscholar.org/paper/Color-information-for-region-segmentation-Ohta-Kanade/ab67b9d0da50e251a4f7e42370540547b891ceb1", "ID": "ab67b9d0da50e251a4f7e42370540547b891ceb1", "Title": "Color information for region segmentation", "Abstract": "Semantic Scholar extracted view of \\\"Color information for region segmentation\\\" by Y. Ohta et al.", "PublicationYear": "1980", "Authors": ["Yuichi Ohta", "Takeo Kanade", "Toshiyuki Sakai"], "RelatedTopics": ["Computer Science"], "References": ["8421556ed9e1b67be2d48de9f47629b4f9a7013b", "b30de454c99b8006db60cd53bea5f9f2d6fc8cd4"], "ReferenceCount": 2, "CitationCount": 998}, {"URL": "https://www.semanticscholar.org/paper/Transferring-color-to-greyscale-images-Welsh-Ashikhmin/d5c6edb53dc41f298f145041cd2c53e40e3acf2b", "ID": "d5c6edb53dc41f298f145041cd2c53e40e3acf2b", "Title": "Transferring color to greyscale images", "Abstract": "This approach attempts to provide a method to help minimize the amount of human labor required for this task by transferring color between a source, color image and a destination, greyscale image by matching luminance and texture information between the images. We introduce a general technique for \\\"colorizing\\\" greyscale images by transferring color between a source, color image and a destination, greyscale image. Although the general problem of adding chromatic values to a greyscale image has no exact, objective solution, the current approach attempts to provide a method to help minimize the amount of human labor required for this task. Rather than choosing RGB colors from a palette to color individual components, we transfer the entire color \\\"mood\\\" of the source to the target image by matching luminance and texture information between the images. We choose to transfer only chromatic information and retain the original luminance values of the target image. Further, the procedure is enhanced by allowing the user to match areas of the two images with rectangular swatches. We show that this simple technique can be successfully applied to a variety of images and video, provided that texture and luminance are sufficiently distinct. The images generated demonstrate the potential and utility of our technique in a diverse set of application domains.", "PublicationYear": "2002", "Authors": ["Tom Welsh", "Michael Ashikhmin", "Klaus Mueller"], "RelatedTopics": ["Computer Science"], "References": ["8d8d0a2d534c3cee59e7e325c07c94d5869a67ca", "923562d216386a88947d40da310d94bbb1376a41", "dd7bf950093fc65f3ae6ad79666ce1077f9dfb2e", "bba3264d6794538381687ad6e151a7f42f3872a9", "f3a11158e9d8bdfdf07dca756335c084fce0123e", "78b4f65c167185f18b573433e5f3e8814acf656f", "a5bca61f72c7eb77bef61ef7e152113ec6cfdff1", "6494de443cc147a9e75041f79ac1e8c4a117b43f", "3906d040f13c45e99ec93693a69cf3cf36d3f99e", "c636437d53514d8f59ed9e7cab165d33b2b86aa2"], "ReferenceCount": 13, "CitationCount": 893}, {"URL": "https://www.semanticscholar.org/paper/GRAYSCALE-IMAGE-MATTING-AND-COLORIZATION-Chen-Wang/ed7e166f65bcecc522c6c4bbb29fcf8048010873", "ID": "ed7e166f65bcecc522c6c4bbb29fcf8048010873", "Title": "GRAYSCALE IMAGE MATTING AND COLORIZATION", "Abstract": "By combining the grayscale image matting algorithm with color transferring techniques, an efficient colorization scheme is proposed, which provides great improvement over existing techniques for some difficult cases, such as human faces or images with confusing luminance distribution. This paper presents a novel approach to grayscale image matting and colorization. The first part of this approach is an efficient grayscale image matting algorithm in Bayesian framework. The foreground and background color distributions, and the alpha\u2019s distribution are modelled with spatially varying sets of Gaussians. The major novelties of this matting algorithm are the introduction of alpha\u2019s distribution and gradient into the Bayesian framework and an efficient optimization scheme. This grayscale image matting algorithm can effectively handle objects with intricate and vision sensitive boundaries, such as hair strands or facial organs. In the second part, by combining the grayscale image matting algorithm with color transferring techniques, an efficient colorization scheme is proposed, which provides great improvement over existing techniques for some difficult cases, such as human faces or images with confusing luminance distribution.", "PublicationYear": "2004", "Authors": ["Tongbo Chen", "Yan Wang", "Volker Schillings", "Christoph Meinel"], "RelatedTopics": ["Computer Science"], "References": ["d5c6edb53dc41f298f145041cd2c53e40e3acf2b", "03b2a8c90b9e5068bb05bfc885588e647f97356d", "61a1c4ae4dbc182e2923c495339466bb0812f53d", "8fd18a0f65134b1abfbb1adf8653ebba63bb2c0e", "923562d216386a88947d40da310d94bbb1376a41", "46c20018841c0ae8226e7cb5d7107ff30742f8f5", "41093fe0f19cb37b239a62adb5f2c0cd058fec83", "64ce3c02fde4157458d84b977dc74a3bd7eda50d", "ec5ece85d618d71bffa9e6d655fe2f38416a4e9d", "69a28cf71d454b06eed2aed3c7a48114ea969455"], "ReferenceCount": 16, "CitationCount": 63}, {"URL": "https://www.semanticscholar.org/paper/Deep-visual-tracking%3A-Review-and-experimental-Li-Wang/26e2ca763087be09e3799ad294302aa91077942d", "ID": "26e2ca763087be09e3799ad294302aa91077942d", "Title": "Deep visual tracking: Review and experimental comparison", "Abstract": "Semantic Scholar extracted view of \\\"Deep visual tracking: Review and experimental comparison\\\" by Peixia Li et al.", "PublicationYear": "2018", "Authors": ["Peixia Li", "D. Wang", "Lijun Wang", "Huchuan Lu"], "RelatedTopics": ["Computer Science"], "References": ["bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0", "bc4cfc075e406f9f5c621fe27a3e0002eec4a8b3", "f546534e4608ca4519be0d27ca6b0e8e76fa11f0", "b2180fc4f5cb46b5b5394487842399c501381d67", "1b3a107739e7f7e05c50999a3d79b8225746f662", "e3c433ab9608d7329f944552ba1721e277a42d74", "c46b08850b9c458704a3ca69172e6a0d40a6cb7f", "552a06c09c49a91956e0bb3a69d7aae688dbcfd0", "6ac3acd8c0cd3d6b234cb2c3f9ca747056c794e0", "28c0b726a0673ccd55ffb7ea002d82d7bee83dcd"], "ReferenceCount": 105, "CitationCount": 445}, {"URL": "https://www.semanticscholar.org/paper/Real-Time-Deep-Tracking-via-Corrective-Domain-Li-Wang/021d0c7013da519b508610064f264c76d768fdf1", "ID": "021d0c7013da519b508610064f264c76d768fdf1", "Title": "Real-Time Deep Tracking via Corrective Domain Adaptation", "Abstract": "This paper proposes to transfer the deep feature, which is learned originally for image classification to the visual tracking domain, via some \u201cgrafted\u201d auxiliary networks, which improves the tracking performance significantly both on accuracy and efficiency. Visual tracking is one of the fundamental problems in computer vision. Recently, some deep-learning-based tracking algorithms have been illustrating record-breaking performances. However, due to the high complexity of neural networks, most deep trackers suffer from low tracking speed and are, thus, impractical in many real-world applications. Some recently proposed deep trackers with smaller network structure achieve high efficiency while at the cost of significant decrease in precision. In this paper, we propose to transfer the deep feature, which is learned originally for image classification to the visual tracking domain. The domain adaptation is achieved via some \u201cgrafted\u201d auxiliary networks, which are trained by regressing the object location in tracking frames. This adaptation improves the tracking performance significantly both on accuracy and efficiency. The yielded deep tracker is real time and also illustrates the state-of-the-art accuracies in the experiment involving two well-adopted benchmarks with more than 100 test videos. Furthermore, the adaptation is also naturally used for introducing the objectness concept into visual tracking. This removes a long-standing target ambiguity in visual tracking tasks, and we illustrate the empirical superiority of the more well-defined task.", "PublicationYear": "2019", "Authors": ["Hanxi Li", "Xinyu Wang", "Fumin Shen", "Yi Li", "Fatih Murat Porikli", "Mingwen Wang"], "RelatedTopics": ["Computer Science"], "References": ["2ac7ab669a56af6ada5cc1459f2c7e93dcdb025a", "b2180fc4f5cb46b5b5394487842399c501381d67", "f24015a365ea2454391c285cd30b8ae723dbb05e", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "084bd219dd239dc4c9a02621a5333d3bc1446566", "2e195a4edeae8d6be0885d7fd9cb7c70f365a326", "1b3a107739e7f7e05c50999a3d79b8225746f662", "9cf3c67529085d31c646091b97be1a1e3dc191f2", "e3c433ab9608d7329f944552ba1721e277a42d74"], "ReferenceCount": 44, "CitationCount": 15}, {"URL": "https://www.semanticscholar.org/paper/An-In-Depth-Analysis-of-Visual-Tracking-with-Neural-Pflugfelder/0a400fd7f0ee28694889baaa4faef150b6912dfa", "ID": "0a400fd7f0ee28694889baaa4faef150b6912dfa", "Title": "An In-Depth Analysis of Visual Tracking with Siamese Neural Networks", "Abstract": "The paper tries to give foundation for tracker design by a formulation of the problem based on the theory of machine learning and by the interpretation of a tracker as a decision function by proposing a novel Lisp-like formalism for a better comparison of trackers. This survey presents a deep analysis of the learning and inference capabilities in nine popular trackers. It is neither intended to study the whole literature nor is it an attempt to review all kinds of neural networks proposed for visual tracking. We focus instead on Siamese neural networks which are a promising starting point for studying the challenging problem of tracking. These networks integrate efficiently feature learning and the temporal matching and have so far shown state-of-the-art performance. In particular, the branches of Siamese networks, their layers connecting these branches, specific aspects of training and the embedding of these networks into the tracker are highlighted. Quantitative results from existing papers are compared with the conclusion that the current evaluation methodology shows problems with the reproducibility and the comparability of results. The paper proposes a novel Lisp-like formalism for a better comparison of trackers. This assumes a certain functional design and functional decomposition of trackers. The paper tries to give foundation for tracker design by a formulation of the problem based on the theory of machine learning and by the interpretation of a tracker as a decision function. The work concludes with promising lines of research and suggests future work.", "PublicationYear": "2017", "Authors": ["Roman P. Pflugfelder"], "RelatedTopics": ["Computer Science"], "References": ["388d29f001411ff80650f80cf197afc440d98b51", "7574b7e5a75fdd338c27af5aeb77ab79460c4437", "26e2ca763087be09e3799ad294302aa91077942d", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "b2180fc4f5cb46b5b5394487842399c501381d67", "ca302b4d7e2d50cb4a4970b78fc237a1294ade40", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "5677e80cd3f3924ff4bbade111d012c313b15d86", "a3a4471e82260f573d240cc34aeff431cf236571", "6683442ae358ae4261fdcde0164f83dd1ccd621b"], "ReferenceCount": 130, "CitationCount": 18}, {"URL": "https://www.semanticscholar.org/paper/Convolutional-Features-for-Correlation-Filter-Based-Danelljan-H%C3%A4ger/311bc4e48838d8e5ef619df3ce0bc598aba788a1", "ID": "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "Title": "Convolutional Features for Correlation Filter Based Visual Tracking", "Abstract": "The results suggest that activations from the first layer provide superior tracking performance compared to the deeper layers, and show that the convolutional features provide improved results compared to standard hand-crafted features. Visual object tracking is a challenging computer vision problem with numerous real-world applications. This paper investigates the impact of convolutional features for the visual tracking problem. We propose to use activations from the convolutional layer of a CNN in discriminative correlation filter based tracking frameworks. These activations have several advantages compared to the standard deep features (fully connected layers). Firstly, they miti-gate the need of task specific fine-tuning. Secondly, they contain structural information crucial for the tracking problem. Lastly, these activations have low dimensionality. We perform comprehensive experiments on three benchmark datasets: OTB, ALOV300++ and the recently introduced VOT2015. Surprisingly, different to image classification, our results suggest that activations from the first layer provide superior tracking performance compared to the deeper layers. Our results further show that the convolutional features provide improved results compared to standard hand-crafted features. Finally, results comparable to state-of-the-art trackers are obtained on all three benchmark datasets.", "PublicationYear": "2015", "Authors": ["Martin Danelljan", "Gustav H{\\\"a}ger", "Fahad Shahbaz Khan", "Michael Felsberg"], "RelatedTopics": ["Computer Science"], "References": ["1b3a107739e7f7e05c50999a3d79b8225746f662", "b2180fc4f5cb46b5b5394487842399c501381d67", "09769e80cdf027db32a1fcb695a1aa0937214763", "f5dbe4550d24d5374d9e10fce44a35b105c7ee07", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "e6824bc799efcf5cb854591474c92cdbb5716e32", "0cae491292feccbc9ad1d864cf8b7144923ce6de", "5677e80cd3f3924ff4bbade111d012c313b15d86", "6270baedeba28001cd1b563a199335720d6e0fe0", "9ea03a9cb11bdc68ac2f56e290c8486868511476"], "ReferenceCount": 42, "CitationCount": 873}, {"URL": "https://www.semanticscholar.org/paper/Good-Features-to-Correlate-for-Visual-Tracking-Gundogdu-Alatan/388d29f001411ff80650f80cf197afc440d98b51", "ID": "388d29f001411ff80650f80cf197afc440d98b51", "Title": "Good Features to Correlate for Visual Tracking", "Abstract": "Extensive performance analysis shows the efficacy of the proposed custom design in the CFB tracking framework, fine-tuning the convolutional parts of a state-of-the-art network and integrating this model to a CFB tracker, which is the top performing one of VOT2016, 18% increase is achieved in terms of expected average overlap. During the recent years, correlation filters have shown dominant and spectacular results for visual object tracking. The types of the features that are employed in this family of trackers significantly affect the performance of visual tracking. The ultimate goal is to utilize the robust features invariant to any kind of appearance change of the object, while predicting the object location as properly as in the case of no appearance change. As the deep learning based methods have emerged, the study of learning features for specific tasks has accelerated. For instance, discriminative visual tracking methods based on deep architectures have been studied with promising performance. Nevertheless, correlation filter based (CFB) trackers confine themselves to use the pre-trained networks, which are trained for object classification problem. To this end, in this manuscript the problem of learning deep fully convolutional features for the CFB visual tracking is formulated. In order to learn the proposed model, a novel and efficient backpropagation algorithm is presented based on the loss function of the network. The proposed learning framework enables the network model to be flexible for a custom design. Moreover, it alleviates the dependency on the network trained for classification. Extensive performance analysis shows the efficacy of the proposed custom design in the CFB tracking framework. By fine-tuning the convolutional parts of a state-of-the-art network and integrating this model to a CFB tracker, which is the top performing one of VOT2016, 18% increase is achieved in terms of expected average overlap, and tracking failures are decreased by 25%, while maintaining the superiority over the state-of-the-art methods in OTB-2013 and OTB-2015 tracking datasets.", "PublicationYear": "2017", "Authors": ["Student Member Ieee Erhan Gundogdu", "Senior Member Ieee A. Ayd\u0131n Alatan", "Aydin Alatan"], "RelatedTopics": ["Computer Science"], "References": ["311bc4e48838d8e5ef619df3ce0bc598aba788a1", "5404718135548b01516a668e0c022c5cb22b422e", "09769e80cdf027db32a1fcb695a1aa0937214763", "1b3a107739e7f7e05c50999a3d79b8225746f662", "5c8a6874011640981e4103d120957802fa28f004", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "f5dbe4550d24d5374d9e10fce44a35b105c7ee07", "084bd219dd239dc4c9a02621a5333d3bc1446566", "000178cd12c8a6e5da8215b6365fae03c20fd18d", "b4035bb1dc4514a72f069d911011ab5845ca1591"], "ReferenceCount": 74, "CitationCount": 154}, {"URL": "https://www.semanticscholar.org/paper/Deep-tracking-with-objectness-Wang-Li/f24015a365ea2454391c285cd30b8ae723dbb05e", "ID": "f24015a365ea2454391c285cd30b8ae723dbb05e", "Title": "Deep tracking with objectness", "Abstract": "The proposed algorithm, termed Deep-Track with Objectness (DTO), naturally combines the state-of-the-art deep-learning-based detectors and trackers, which essentially share a large part of the network. Visual tracking is a fundamental problem in computer vision. However, due to the (sometimes) ambiguous target information given at the first frame, it has also been criticized as less well-posed compared with other tasks with clearly-defined targets, such as object detection and semantic segmentation. In this paper, we try to evaluate the importance of object category in visual tracking by tracking objects with known object types. The proposed algorithm, termed Deep-Track with Objectness (DTO), naturally combines the state-of-the-art deep-learning-based detectors and trackers, which essentially share a large part of the network. In DTO, a deep tracker, which is scale-fixed and sensitive to small translations tracks the object in a relative short lifespan. A deep detector, which is scale-changeable and robust to pose or illumination changes guides the deep tracker in a longer lifespan. As the deep tracker and detector share the main part of their networks, no much extra computation is imposed while the performance gain is significant. We test the proposed algorithm on two well-accepted benchmarks and on both of them, the proposed method increases the tracking accuracies remarkably compared with state-of-the-art visual trackers.", "PublicationYear": "2017", "Authors": ["Xinyu Wang", "Hanxi Li", "Yi Li", "Fatih Murat Porikli", "Mingwen Wang"], "RelatedTopics": ["Computer Science"], "References": ["b2180fc4f5cb46b5b5394487842399c501381d67", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "5c8a6874011640981e4103d120957802fa28f004", "421bf4eeba623f722bf98340d71e3d229881e92d", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "1b3a107739e7f7e05c50999a3d79b8225746f662", "9d57723b4908397654fb1846d37db403d8b2b56a", "d20d7d3490fd970992b3631048c75a8c5fe2e4e3", "084bd219dd239dc4c9a02621a5333d3bc1446566", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"], "ReferenceCount": 23, "CitationCount": 6}, {"URL": "https://www.semanticscholar.org/paper/Learning-Dynamic-Siamese-Network-for-Visual-Object-Guo-Feng/7574b7e5a75fdd338c27af5aeb77ab79460c4437", "ID": "7574b7e5a75fdd338c27af5aeb77ab79460c4437", "Title": "Learning Dynamic Siamese Network for Visual Object Tracking", "Abstract": "This paper proposes dynamic Siamese network, via a fast transformation learning model that enables effective online learning of target appearance variation and background suppression from previous frames, and presents elementwise multi-layer fusion to adaptively integrate the network outputs using multi-level deep features. How to effectively learn temporal variation of target appearance, to exclude the interference of cluttered background, while maintaining real-time response, is an essential problem of visual object tracking. Recently, Siamese networks have shown great potentials of matching based trackers in achieving balanced accuracy and beyond realtime speed. However, they still have a big gap to classification & updating based trackers in tolerating the temporal changes of objects and imaging conditions. In this paper, we propose dynamic Siamese network, via a fast transformation learning model that enables effective online learning of target appearance variation and background suppression from previous frames. We then present elementwise multi-layer fusion to adaptively integrate the network outputs using multi-level deep features. Unlike state-of-theart trackers, our approach allows the usage of any feasible generally- or particularly-trained features, such as SiamFC and VGG. More importantly, the proposed dynamic Siamese network can be jointly trained as a whole directly on the labeled video sequences, thus can take full advantage of the rich spatial temporal information of moving objects. As a result, our approach achieves state-of-the-art performance on OTB-2013 and VOT-2015 benchmarks, while exhibits superiorly balanced accuracy and real-time response over state-of-the-art competitors.", "PublicationYear": "2017", "Authors": ["Qing Guo", "Wei Feng", "Ce Zhou", "Rui Huang", "Liang Wan", "Song Wang"], "RelatedTopics": ["Computer Science"], "References": ["29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "09769e80cdf027db32a1fcb695a1aa0937214763", "c316d5ec14e5768d7eda3d8916bddc1de142a1c2", "5c8a6874011640981e4103d120957802fa28f004", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "0f12a3aaf3851078d93a9bba4e3ebece6d4bcfe5", "3dc60732c1c08165c9d4e7b334ce66e511474bb2", "3d5fe9ef560c08f0c56249360247c7d4b40ce023", "c46b08850b9c458704a3ca69172e6a0d40a6cb7f"], "ReferenceCount": 36, "CitationCount": 653}, {"URL": "https://www.semanticscholar.org/paper/Densely-Connected-Discriminative-Correlation-for-Peng-Liu/1855818c492d5f42dbe14814e4dd9b5733d54790", "ID": "1855818c492d5f42dbe14814e4dd9b5733d54790", "Title": "Densely Connected Discriminative Correlation Filters for Visual Tracking", "Abstract": "A novel densely connected DCFs framework is proposed for visual tracking that incorporates multiple nested DCFs into the deep learning architecture, and then trains the compact network with the data-specific target. Discriminative Correlation Filters (DCFs)-based approaches have recently achieved competitive performance in visual tracking. However, such conventional DCF-based trackers often lack the discriminative ability due to the shallow architecture. As a result, they can hardly tackle drastic appearance variations and easily drift when the target suffers heavy occlusions. To address this issue, a novel densely connected DCFs framework is proposed for visual tracking. We incorporate multiple nested DCFs into the deep learning architecture, and then train the compact network with the data-specific target. Specifically, feature maps and interim response maps are shared and reused throughout the whole network. By doing so, the implicit information carried out by each DCF is fully exploited to enhance the model representation ability during the tracking process. Moreover, a multiscale estimation scheme is developed to account for scale variations. Experimental results on the benchmarks demonstrate that the proposed approach achieves outstanding performance compared to the existing state-of-the-art trackers.", "PublicationYear": "2018", "Authors": ["Cheng Peng", "Fanghui Liu", "Jie Yang", "Nikola Kirilov Kasabov"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["49a5aeefcb257ca92652acf4f875efbad5a2b00d", "09769e80cdf027db32a1fcb695a1aa0937214763", "5c8a6874011640981e4103d120957802fa28f004", "8cc3651488e02d51fa5ae8d3563b346e9e370f5a", "ece7625a346edbc5f6fab541c0c246ec06939121", "0cae491292feccbc9ad1d864cf8b7144923ce6de", "0f12a3aaf3851078d93a9bba4e3ebece6d4bcfe5", "096710211d9e4eb77dc2d0f11a7ff818c8acc5ff", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "000178cd12c8a6e5da8215b6365fae03c20fd18d"], "ReferenceCount": 41, "CitationCount": 4}, {"URL": "https://www.semanticscholar.org/paper/Visual-Tracking-via-Auto-Encoder-Pair-Correlation-Cheng-Zhang/e2e34b202363e4a46a14cd35fd4088d88b2e650e", "ID": "e2e34b202363e4a46a14cd35fd4088d88b2e650e", "Title": "Visual Tracking via Auto-Encoder Pair Correlation Filter", "Abstract": "This paper proposes an auto-encoder pair model for visual tracking which is composed of source domain network and target domain network to help a more accurate localization and improves the tracking speed by using long-term and short-term updating scheme. Robust visual tracking is one of the most challenging problems in computer vision applications. However, the limited training data and the computational complexity have severely affected tracking performance. In this paper, we propose an auto-encoder pair model for visual tracking which is composed of source domain network and target domain network to help a more accurate localization. We adopt the dense circular samples of the object state to increase the number of training samples and prevent model overfitting. Meanwhile, a difference regularization term is also introduced into our framework to penalize the large appearance variations of the object in two domains. The alternating optimization is used to solve the optimization problems. Furthermore, our method alleviates the model update problem and improves the tracking speed by using long-term and short-term updating scheme. In addition, the target domain filter is updated by introducing the updated source domain filter to avoid the object drift. Comprehensive experiments on some challenging benchmarks demonstrate that our approach concurrently improves both tracking accuracy and speed.", "PublicationYear": "2020", "Authors": ["Xu Cheng", "Yifeng Zhang", "Lin Zhou", "Yuhui Zheng"], "RelatedTopics": ["Computer Science"], "References": ["09769e80cdf027db32a1fcb695a1aa0937214763", "b4035bb1dc4514a72f069d911011ab5845ca1591", "7574b7e5a75fdd338c27af5aeb77ab79460c4437", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "6410c97ae03d356e14544c8e95f5367fb7ebb6e6", "b2180fc4f5cb46b5b5394487842399c501381d67", "6683442ae358ae4261fdcde0164f83dd1ccd621b", "7069a994c150b0228c4e471ca48ed55d7646bc62", "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64", "776bc8955e801f6965e85b35d8e2dd6f2f1498ad"], "ReferenceCount": 53, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2017-Challenge-Kristan-Leonardis/53329e5c79c1128c7b252a12b182c472a3413bfa", "ID": "53329e5c79c1128c7b252a12b182c472a3413bfa", "Title": "The Visual Object Tracking VOT2017 Challenge Results", "Abstract": "The Visual Object Tracking challenge VOT2017 is the fifth annual tracker benchmarking activity organized by the VOT initiative. Results of 51 trackers are presented; many are state-of-the-art published at major computer vision conferences or journals in recent years. The evaluation included the standard VOT and other popular methodologies and a new \\\"real-time\\\" experiment simulating a situation where a tracker processes images as if provided by a continuously running sensor. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The VOT2017 goes beyond its predecessors by (i) improving the VOT public dataset and introducing a separate VOT2017 sequestered dataset, (ii) introducing a realtime tracking experiment and (iii) releasing a redesigned toolkit that supports complex experiments. The dataset, the evaluation kit and the results are publicly available at the challenge website1.", "PublicationYear": "2017", "Authors": ["Matej Kristan", "Ale{\\vs} Leonardis", "Jiri Matas", "Michael Felsberg", "Roman P. Pflugfelder", "Luka Cehovin", "Zajc", "Tom{\\'a}s Voj{\\'i}r", "Gustav H{\\\"a}ger", "Alan Luke{\\vz}i{\\vc}", "Abdelrahman Eldesokey", "Gustavo Javier Fernandez", "Andrej Muhic", "Alfredo Petrosino", "Alireza Memarmoghadam", "Andrea", "Vedaldi", "Antoine Manzanera", "Antoine Tran", "A. Aydin Alatan", "Bogdan Cosmin Mocanu", "Boyu Chen", "Chang Huang", "Changsheng Xu", "Chong Sun", "Dalong Du", "David Zhang", "Dawei Du", "Deepak", "Mishra", "Erhan Gundogdu", "Erik Velasco-Salido", "Fahad Shahbaz Khan", "Francesco Battistone", "Gorthi Rama Krishna Sai Subrahmanyam", "Goutam Bhat", "Guan Huang", "Guilherme Sousa Bastos", "Guna", "Seetharaman", "Hongliang Zhang", "Houqiang Li", "Huchuan Lu", "Isabela Drummond", "Jack", "Valmadre", "Jae-chan Jeong", "Jae Il Cho", "Jae-Y. Lee", "Jana Noskova", "Jianke Zhu", "Jin Gao", "Jingyu Liu", "Ji-Wan Kim", "Jo{\\~a}o F. Henriques", "Junfei Zhuang", "Junliang Xing", "Junyu Gao", "Kai Chen", "Kannappan Palaniappan", "Karel Lebeda", "Ke Gao", "Kris Kitani", "Lei", "Zhang", "Lijun Wang", "Lingxiao Yang", "Longyin Wen", "Luca Bertinetto", "Mahdieh Poostchi", "Martin Danelljan", "Matthias Mueller", "Mengdan Zhang", "Ming-Hsuan Yang", "Nianhao Xie", "Ning", "Wang", "Ond\u0159ej Mik{\\vs}{\\'i}k", "Payman Moallem", "M PallaviVenugopal", "Pedro Senna", "Philip H. S. Torr", "Qiang Wang", "Qifeng Yu", "Qingming Huang", "Rafael Mart{\\'i}n-Nieto", "R. Bowden", "Ri-sheng", "Liu", "Ruxandra Tapu", "Simon Hadfield", "Siwei Lyu", "Stuart Golodetz", "Sunglok Choi", "Tianzhu", "Titus B. Zaharia", "Vincenzo Santopietro", "Wei Zou", "Weiming Hu", "Wenbing Tao", "Wenbo", "Li", "Wen-gang Zhou", "Xianguo Yu", "Xiao Bian", "Yang Li", "Yifan Xing", "Yingruo Fan", "Zheng", "Zhu", "Zhipeng Zhang", "Zhiqun He"], "RelatedTopics": ["Computer Science"], "References": ["6179ac06f1a8fd1ac6b693b02824948dff438d54", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "4338f00c11224f1b4056125561927777ab610c9d", "dd45fe910a0200d43aaa77362f658542f6e175ff", "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "91f2b2aeb7e65d0b673ed7e782488b3365027979"], "ReferenceCount": 81, "CitationCount": 120}, {"URL": "https://www.semanticscholar.org/paper/The-Thermal-Infrared-Visual-Object-Tracking-Results-Felsberg-Kristan/4338f00c11224f1b4056125561927777ab610c9d", "ID": "4338f00c11224f1b4056125561927777ab610c9d", "Title": "The Thermal Infrared Visual Object Tracking VOT-TIR2015 Challenge Results", "Abstract": "The Thermal Infrared Visual Object Tracking challenge 2015, VOT-TIR2015, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. The Thermal Infrared Visual Object Tracking challenge 2015, VOT-TIR2015, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. VOT-TIR2015 is the first benchmark on short-term tracking in TIR sequences. Results of 24 trackers are presented. For each participating tracker, a short description is provided in the appendix. The VOT-TIR2015 challenge is based on the VOT2013 challenge, but introduces the following novelties: (i) the newly collected LTIR (Link -- ping TIR) dataset is used, (ii) the VOT2013 attributes are adapted to TIR data, (iii) the evaluation is performed using insights gained during VOT2013 and VOT2014 and is similar to VOT2015.", "PublicationYear": "2015", "Authors": ["Michael Felsberg", "Matej Kristan", "Jiri Matas", "Ale{\\vs} Leonardis", "Roman P. Pflugfelder", "Gustav H{\\\"a}ger", "Amanda Berg", "Abdelrahman Eldesokey", "J{\\\"o}rgen Ahlberg", "Luka Cehovin", "Tom{\\'a}s Voj{\\'i}r", "Alan Luke{\\vz}i{\\vc}", "Gustavo Javier Fernandez", "Alfredo Petrosino", "{\\'A}lvaro Garc{\\'i}a-Mart{\\'i}n", "Andr{\\'e}s Sol{\\'i}s Montero", "Anton Yuriiovych Varfolomieiev", "Aykut Erdem", "Bohyung Han", "Chang-Ming Chang", "Dawei Du", "Erkut Erdem", "Fahad Shahbaz Khan", "Fatih Murat Porikli", "Fei Zhao", "Filiz Bunyak", "Francesco Battistone", "Gao Zhu", "Guna Seetharaman", "Hongdong Li", "Honggang Qi", "Horst Bischof", "Horst Possegger", "Hyeonseob Nam", "Jack Valmadre", "Jianke Zhu", "Jiayi Feng", "Jochen Lang", "Jos{\\'e} Mar{\\'i}a Mart{\\'i}nez Sanchez", "Kannappan Palaniappan", "Karel Lebeda", "Ke Gao", "Krystian Mikolajczyk", "Longyin Wen", "Luca Bertinetto", "Mahdieh Poostchi", "Mario Edoardo Maresca", "Martin Danelljan", "Michael Arens", "Ming Tang", "Mooyeol Baek", "Nana Fan", "Noor M. Al-Shakarji", "Ond\u0159ej Mik{\\vs}{\\'i}k", "Osman Akin", "Philip H. S. Torr", "Qingming Huang", "Rafael Martin Nieto", "Rengarajan Pelapur", "R. Bowden", "Robert Lagani{\\`e}re", "Sebastian Bernd Krah", "Shengkun Li", "Shizeng Yao", "Simon Hadfield", "Siwei Lyu", "Stefan Becker", "Stuart Golodetz", "Tao Hu", "Thomas Mauthner", "Vincenzo Santopietro", "Wenbo Li", "Wolfgang H{\\\"u}bner", "Xin Li", "Yang Li", "Zhan Xu", "Zhenyu He"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "dd45fe910a0200d43aaa77362f658542f6e175ff", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "4dff84213493bb177dc6bff266a9893538a1f879", "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5", "84f911432ba8a3356013b3abfbf1947f1145c953", "0cae491292feccbc9ad1d864cf8b7144923ce6de", "f5dbe4550d24d5374d9e10fce44a35b105c7ee07", "2822a883d149956934a20614d6934c6ddaac6857"], "ReferenceCount": 49, "CitationCount": 136}, {"URL": "https://www.semanticscholar.org/paper/The-Thermal-Infrared-Visual-Object-Tracking-Results-Felsberg-Kristan/6767812e114c426d45ea83894b156f7906e525cd", "ID": "6767812e114c426d45ea83894b156f7906e525cd", "Title": "The Thermal Infrared Visual Object Tracking VOT-TIR2016 Challenge Results", "Abstract": "A significant general improvement of results has been observed, which partly compensate for the more difficult sequences introduced into the dataset in VOT-TIR2016. The Thermal Infrared Visual Object Tracking challenge 2016, VOT-TIR2016, aims at comparing short-term single-object visual trackers that work on thermal infrared (TIR) sequences and do not apply pre-learned models of object appearance. VOT-TIR2016 is the second benchmark on short-term tracking in TIR sequences. Results of 24 trackers are presented. For each participating tracker, a short description is provided in the appendix. The VOT-TIR2016 challenge is similar to the 2015 challenge, the main difference is the introduction of new, more difficult sequences into the dataset. Furthermore, VOT-TIR2016 evaluation adopted the improvements regarding overlap calculation in VOT2016. Compared to VOT-TIR2015, a significant general improvement of results has been observed, which partly compensate for the more difficult sequences. The dataset, the evaluation kit, as well as the results are publicly available at the challenge website.", "PublicationYear": "2016", "Authors": ["Michael Felsberg", "Matej Kristan", "Jiri Matas", "Ale{\\vs} Leonardis", "Roman P. Pflugfelder", "Gustav H{\\\"a}ger", "Amanda Berg", "Abdelrahman Eldesokey", "Jorgen Ahlberg", "Luka Cehovin", "Tom{\\'a}s Voj{\\'i}r", "Alan Luke{\\vz}i{\\vc}", "Gustavo Javier Fernandez", "Alfredo Petrosino", "{\\'A}lvaro Garc{\\'i}a-Mart{\\'i}n", "Andr{\\'e}s Sol{\\'i}s Montero", "Anton Yuriiovych Varfolomieiev", "Aykut Erdem", "Bohyung Han", "Chang-Ming Chang", "Dawei Du", "Erkut Erdem", "Fahad Shahbaz Khan", "Fatih Murat Porikli", "Fei Zhao", "Filiz Bunyak", "Francesco Battistone", "Gao Zhu", "Guna Seetharaman", "Hongdong Li", "Honggang Qi", "Horst Bischof", "Horst Possegger", "Hyeonseob Nam", "Jack Valmadre", "Jianke Zhu", "Jiayi Feng", "Jochen Lang", "Jos{\\'e} Mar{\\'i}a Mart{\\'i}nez Sanchez", "Kannappan Palaniappan", "Karel Lebeda", "Ke Gao", "Krystian Mikolajczyk", "Longyin Wen", "Luca Bertinetto", "Mahdieh Poostchi", "Mario Edoardo Maresca", "Martin Danelljan", "Michael Arens", "Ming Tang", "Mooyeol Baek", "Nana Fan", "Noor M. Al-Shakarji", "Ond\u0159ej Mik{\\vs}{\\'i}k", "Osman Akin", "Philip H. S. Torr", "Qingming Huang", "Rafael Martin Nieto", "Rengarajan Pelapur", "Richard Bowden", "Robert Lagani{\\`e}re", "Sebastian Bernd Krah", "Shengkun Li", "Shizeng Yao", "Simon Hadfield", "Siwei Lyu", "Stefan Becker", "Stuart Golodetz", "Tao-cheng Hu", "Thomas Mauthner", "Vincenzo Santopietro", "Wenbo Li", "Wolfgang H{\\\"u}bner", "Xin Li", "Yang Li", "Zhan Xu", "Zhenyu He"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["4338f00c11224f1b4056125561927777ab610c9d", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "dd45fe910a0200d43aaa77362f658542f6e175ff", "4dff84213493bb177dc6bff266a9893538a1f879", "7c78f89fb80449c862ed28d6253d791675319f9b", "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5", "0708f85ae2721b795db596241b9f944731334805"], "ReferenceCount": 56, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/Long-Term-Visual-Object-Tracking-Benchmark-Moudgil-Gandhi/19d6b9725a59f4b624205829d5f03ac893ca1367", "ID": "19d6b9725a59f4b624205829d5f03ac893ca1367", "Title": "Long-Term Visual Object Tracking Benchmark", "Abstract": "Existing short sequence benchmarks fail to bring out the inherent differences in tracking algorithms which widen up while tracking on long sequences and the accuracy of trackers abruptly drops on challenging long sequences, suggesting the potential need of research efforts in the direction of long-term tracking. We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term tracking performance and train better deep learning architectures (avoiding/reducing augmentation, which may not reflect real world behaviour). We benchmark the dataset on 17 state of the art trackers and rank them according to tracking accuracy and run time speeds. We further present thorough qualitative and quantitative evaluation highlighting the importance of long term aspect of tracking. Our most interesting observations are (a) existing short sequence benchmarks fail to bring out the inherent differences in tracking algorithms which widen up while tracking on long sequences and (b) the accuracy of trackers abruptly drops on challenging long sequences, suggesting the potential need of research efforts in the direction of long-term tracking.", "PublicationYear": "2017", "Authors": ["A. Moudgil", "Vineet Gandhi"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7", "703505a00579c0aa67712836acc41d94fa6d6edc", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "3275944117b43cc44beebe7c82bffc13ec8cb0fa", "1c721511e4c0e21bd264ca71c0d909528511b7ad", "754504cf01ef3846259783e748b1d3ea52fa2c81", "cdafc80c2d68c727756c9a5b528c86389f67b10b", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306"], "ReferenceCount": 47, "CitationCount": 77}, {"URL": "https://www.semanticscholar.org/paper/Performance-Evaluation-Methodology-for-Long-Term-Luke%C5%BEi%C4%8D-Zajc/23f8927f996d56f3b5076d8993a70bcfc70182a1", "ID": "23f8927f996d56f3b5076d8993a70bcfc70182a1", "Title": "Performance Evaluation Methodology for Long-Term Visual Object Tracking", "Abstract": "A long-term visual object tracking performance evaluation methodology and a benchmark are proposed and it is shown that these measures generalize the short-term performance measures, thus linking the two tracking problems. A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. Performance measures are designed by following a long-term tracking definition to maximize the analysis probing strength. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors. We show that these measures generalize the short-term performance measures, thus linking the two tracking problems. Furthermore, the new measures are highly robust to temporal annotation sparsity and allow annotation of sequences hundreds of times longer than in the current datasets without increasing manual annotation labor. A new challenging dataset of carefully selected sequences with many target disappearances is proposed. A new tracking taxonomy is proposed to position trackers on the short-term/long-term spectrum. The benchmark contains an extensive evaluation of the largest number of long-term tackers and comparison to state-of-the-art short-term trackers. We analyze the influence of tracking architecture implementations to long-term performance and explore various re-detection strategies as well as influence of visual model update strategies to long-term tracking drift. The methodology is integrated in the VOT toolkit to automate experimental analysis and benchmarking and to facilitate future development of long-term trackers.", "PublicationYear": "2019", "Authors": ["Alan Luke{\\vz}i{\\vc}", "Luka Cehovin Zajc", "Tom{\\'a}s Voj{\\'i}r", "Jiri Matas", "Matej Kristan"], "RelatedTopics": ["Computer Science"], "References": ["3275944117b43cc44beebe7c82bffc13ec8cb0fa", "19d6b9725a59f4b624205829d5f03ac893ca1367", "ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b", "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "754504cf01ef3846259783e748b1d3ea52fa2c81", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d"], "ReferenceCount": 50, "CitationCount": 6}, {"URL": "https://www.semanticscholar.org/paper/The-Visual-Object-Tracking-VOT2013-Challenge-Kristan-Pflugfelder/4b1a47709d0546e5bc614bf9a521c550e6881d04", "ID": "4b1a47709d0546e5bc614bf9a521c550e6881d04", "Title": "The Visual Object Tracking VOT2013 Challenge Results", "Abstract": "The evaluation protocol of the VOT2013 challenge and the results of a comparison of 27 trackers on the benchmark dataset are presented, offering a more systematic comparison of the trackers. Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) workshop was organized in conjunction with ICCV2013. Researchers from academia as well as industry were invited to participate in the first VOT2013 challenge which aimed at single-object visual trackers that do not apply pre-learned models of object appearance (model-free). Presented here is the VOT2013 benchmark dataset for evaluation of single-object visual trackers as well as the results obtained by the trackers competing in the challenge. In contrast to related attempts in tracker benchmarking, the dataset is labeled per-frame by visual attributes that indicate occlusion, illumination change, motion change, size change and camera motion, offering a more systematic comparison of the trackers. Furthermore, we have designed an automated system for performing and evaluating the experiments. We present the evaluation protocol of the VOT2013 challenge and the results of a comparison of 27 trackers on the benchmark dataset. The dataset, the evaluation tools and the tracker rankings are publicly available from the challenge website (http://votchallenge.net).", "PublicationYear": "2013", "Authors": ["Matej Kristan", "Roman P. Pflugfelder", "Ale{\\vs} Leonardis", "Jiri Matas", "Fatih Murat Porikli", "Luka Cehovin", "Georg Nebehay", "Gustavo Javier Fernandez", "Tom{\\'a}s Voj{\\'i}r", "Adam Gatt", "Ahmad Khajenezhad", "Ahmed Salah El-Din", "Ali Soltani-Farani", "Ali Zarezade", "Alfredo Petrosino", "Anthony Milton", "Behzad Bozorgtabar", "Bo Li", "Chee Seng Chan", "Cherkeng Heng", "Dale A. Ward", "David A. Kearney", "Dorothy Ndedi Monekosso", "Hakki Can Karaimer", "H.R. Rabiee", "Jianke Zhu", "Jin Gao", "Jingjing Xiao", "Junge Zhang", "Junliang Xing", "Kaiqi Huang", "Karel Lebeda", "Lijun Cao", "Mario Edoardo Maresca", "Mei Kuan Lim", "Mohamed ElHelw", "Michael Felsberg", "Paolo Remagnino", "Richard Bowden", "Roland G{\\\"o}cke", "Rustam Stolkin", "Samantha YueYing Lim", "Sara Maher", "S{\\'e}bastien Poullot", "Sebastien C. Wong", "Shin'ichi Satoh", "Weihua Chen", "Weiming Hu", "Xiaoqin Zhang", "Yang Li", "Zhi Heng Niu"], "RelatedTopics": ["Computer Science"], "References": ["2822a883d149956934a20614d6934c6ddaac6857", "882c5e862f2256e10bb7dd74d5bbc984b01489fe", "9926020dda21874dc7a5ef1511bae6c4cef5ecb9", "0b104e517e0440e3bdace01b5f6706c5fa944149", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "bf5e48bcaddc8d8bfb2c5b138efdb90e94f8258f", "9d57723b4908397654fb1846d37db403d8b2b56a", "c63a34ac6a4e049118070e707ca7679fbb132d33"], "ReferenceCount": 55, "CitationCount": 63}, {"URL": "https://www.semanticscholar.org/paper/A-Novel-Performance-Evaluation-Methodology-for-Kristan-Matas/0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "ID": "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "Title": "A Novel Performance Evaluation Methodology for Single-Target Trackers", "Abstract": "The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison and a fully-annotated dataset with per-frame annotations with several visual attributes, which is the largest benchmark to date. This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical differences. A fully-annotated dataset with per-frame annotations with several visual attributes is introduced. The diversity of its visual properties is maximized in a novel way by clustering a large number of videos according to their visual attributes. This makes it the most sophistically constructed and annotated dataset to date. A multi-platform evaluation system allowing easy integration of third-party trackers is presented as well. The proposed evaluation methodology was tested on the VOT2014 challenge on the new dataset and 38 trackers, making it the largest benchmark to date. Most of the tested trackers are indeed state-of-the-art since they outperform the standard baselines, resulting in a highly-challenging benchmark. An exhaustive analysis of the dataset from the perspective of tracking difficulty is carried out. To facilitate tracker comparison a new performance visualization technique is proposed.", "PublicationYear": "2015", "Authors": ["Matej Kristan", "Jiri Matas", "Ale{\\vs} Leonardis", "Tom{\\'a}s Voj{\\'i}r", "Roman P. Pflugfelder", "Gustavo Javier Fernandez", "Georg Nebehay", "Fatih Murat Porikli", "Luka Cehovin"], "RelatedTopics": ["Computer Science"], "References": ["edf6607f0c819390a13e60b722cc40f97359c9c4", "2258e01865367018ed6f4262c880df85b94959f8", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "a52a6cf39054e6f406f67b57cc895e9df1163fc8", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "657c87871e9b8fb6b237d1762c4c5b61433df444", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "681ee0059ed573265847785d110237861458304e", "0cae491292feccbc9ad1d864cf8b7144923ce6de"], "ReferenceCount": 99, "CitationCount": 568}, {"URL": "https://www.semanticscholar.org/paper/Now-you-see-me%3A-evaluating-performance-in-long-term-Luke%C5%BEi%C4%8D-Zajc/3275944117b43cc44beebe7c82bffc13ec8cb0fa", "ID": "3275944117b43cc44beebe7c82bffc13ec8cb0fa", "Title": "Now you see me: evaluating performance in long-term visual tracking", "Abstract": "An extensive evaluation of six long-term and nine short-term state-of-the-art trackers, using new performance measures, suitable for evaluatinglong-term tracking - tracking precision, recall and F-score shows that a good model update strategy and the capability of image-wide re-detection are critical for long- term tracking performance. We propose a new long-term tracking performance evaluation methodology and present a new challenging dataset of carefully selected sequences with many target disappearances. We perform an extensive evaluation of six long-term and nine short-term state-of-the-art trackers, using new performance measures, suitable for evaluating long-term tracking - tracking precision, recall and F-score. The evaluation shows that a good model update strategy and the capability of image-wide re-detection are critical for long-term tracking performance. We integrated the methodology in the VOT toolkit to automate experimental analysis and benchmarking and to facilitate the development of long-term trackers.", "PublicationYear": "2018", "Authors": ["Alan Luke{\\vz}i{\\vc}", "Luka Cehovin Zajc", "Tom{\\'a}s Voj{\\'i}r", "Jiri Matas", "Matej Kristan"], "RelatedTopics": ["Computer Science"], "References": ["19d6b9725a59f4b624205829d5f03ac893ca1367", "754504cf01ef3846259783e748b1d3ea52fa2c81", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d", "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "cdafc80c2d68c727756c9a5b528c86389f67b10b", "0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "a6ee08763d994b1687c594bb9367f8d5cf419113", "d3d36c3caa255053877a7e3250d47d906eec81d2"], "ReferenceCount": 36, "CitationCount": 57}, {"URL": "https://www.semanticscholar.org/paper/Long-Term-Tracking-through-Failure-Cases-Lebeda-Hadfield/9926020dda21874dc7a5ef1511bae6c4cef5ecb9", "ID": "9926020dda21874dc7a5ef1511bae6c4cef5ecb9", "Title": "Long-Term Tracking through Failure Cases", "Abstract": "A visual tracking algorithm, robust to many of the difficulties which often occur in real-world scenes, and addressing long-term stability, enabling the tracker to recover from drift and to provide redetection following object disappearance or occlusion is proposed. Long term tracking of an object, given only a single instance in an initial frame, remains an open problem. We propose a visual tracking algorithm, robust to many of the difficulties which often occur in real-world scenes. Correspondences of edge-based features are used, to overcome the reliance on the texture of the tracked object and improve invariance to lighting. Furthermore we address long-term stability, enabling the tracker to recover from drift and to provide redetection following object disappearance or occlusion. The two-module principle is similar to the successful state-of-the-art long-term TLD tracker, however our approach extends to cases of low-textured objects. Besides reporting our results on the VOT Challenge dataset, we perform two additional experiments. Firstly, results on short-term sequences show the performance of tracking challenging objects which represent failure cases for competing state-of-the-art approaches. Secondly, long sequences are tracked, including one of almost 30000 frames which to our knowledge is the longest tracking sequence reported to date. This tests the re-detection and drift resistance properties of the tracker. All the results are comparable to the state-of-the-art on sequences with textured objects and superior on non-textured objects. The new annotated sequences are made publicly available.", "PublicationYear": "2013", "Authors": ["Karel Lebeda", "Simon Hadfield", "Jiri Matas", "R. Bowden"], "RelatedTopics": ["Computer Science"], "References": ["c63a34ac6a4e049118070e707ca7679fbb132d33", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "00058304b7c51b9dcf837d4125cab0a4b0588aef", "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca", "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c", "fcba52c59e8537e48e747207837cefd04786bd3d", "948a74b25508ab674be06f6a94ca8bc07a082361", "dfa5a0cce66f9e840dd98ac8094434efcc4a9de5", "779220bb5190b976e025dc649b2e9a0e4b3597b9", "ed9839b734c359a84135da5a0dee1085a98795a1"], "ReferenceCount": 17, "CitationCount": 52}, {"URL": "https://www.semanticscholar.org/paper/The-VOT2013-challenge%3A-overview-and-additional-Kristan-Pflugfelder/4dff84213493bb177dc6bff266a9893538a1f879", "ID": "4dff84213493bb177dc6bff266a9893538a1f879", "Title": "The VOT2013 challenge: overview and additional results", "Abstract": "An overview of the VOT2013 challenge is provided, its main results are pointed out, and the additional previously unpublished experiments and results are documented. Visual tracking has attracted a significant attention in the last few decades. The recent surge in the number of publications on tracking-related problems have made it almost impossible to follow the developments in the field. One of the reasons is that there is a lack of commonly accepted annotated data-sets and standardized evaluation protocols that would allow objective comparison of different tracking methods. To address this issue, the Visual Object Tracking (VOT) challenge and workshop was organized in conjunction with ICCV2013. Researchers from academia as well as industry were invited to participate in the first VOT2013 challenge which aimed at single-object visual trackers that do not apply pre-learned models of object appearance (model-free). In this paper we provide an overview of the VOT2013 challenge, point out its main results and document the additional previously unpublished experiments and results.", "PublicationYear": "2014", "Authors": ["Matej Kristan", "Roman P. Pflugfelder", "Ale{\\vs} Leonardis", "Jiri Matas", "Fatih Murat Porikli", "Luka Cehovin", "Georg Nebehay", "Gustavo Javier Fernandez", "Tom{\\'a}s Voj{\\'i}r"], "RelatedTopics": ["Computer Science"], "References": ["3c74b636c0f74c1a0cbbd6e165c2760264044971", "882c5e862f2256e10bb7dd74d5bbc984b01489fe", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "0b104e517e0440e3bdace01b5f6706c5fa944149", "6169efdeca33714833b120152ae591b8a5f159fa", "2822a883d149956934a20614d6934c6ddaac6857", "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "3a9b175324ba11bc0e16c0633912d897b2fac4e2", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc"], "ReferenceCount": 46, "CitationCount": 21}, {"URL": "https://www.semanticscholar.org/paper/Visual-Tracking%3A-an-Experimental-Survey-Smeulders-Chu/5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "ID": "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "Title": "Visual Tracking: an Experimental Survey", "Abstract": "It is demonstrated that trackers can be evaluated objectively by survival curves, Kaplan Meier statistics, and Grubs testing, and it is found that in the evaluation practice the F-score is as effective as the object tracking accuracy (OTA) score. There is a large variety of trackers, which have been proposed in the literature during the last two decades with some mixed success. Object tracking in realistic scenarios is difficult problem, therefore it remains a most active area of research in Computer Vision. A good tracker should perform well in a large number of videos involving illumination changes, occlusion, clutter, camera motion, low contrast, specularities and at least six more aspects. However, the performance of proposed trackers have been evaluated typically on less than ten videos, or on the special purpose datasets. In this paper, we aim to evaluate trackers systematically and experimentally on 315 video fragments covering above aspects. We selected a set of nineteen trackers to include a wide variety of algorithms often cited in literature, supplemented with trackers appearing in 2010 and 2011 for which the code was publicly available. We demonstrate that trackers can be evaluated objectively by survival curves, Kaplan Meier statistics, and Grubs testing. We find that in the evaluation practice the F-score is as effective as the object tracking accuracy (OTA) score. The analysis under a large variety of circumstances provides objective insight into the strengths and weaknesses of trackers. Arnold W. M. Smeulders is with Informatics Institute, University of Amsterdam, The Netherlands and with Centrum Wiskunde & Informatica, Amsterdam, The Netherlands. Dung M. Chu is with Informatics Institute, University of Amsterdam, The Netherlands. Rita Cucchiara and Simone Calderara are with Faculty of Engineering of Modena, University of Modena and Reggio Emilia, Italy. Afshin Dehghan and Mubarak Shah are with School of Electric Engineering and Computer Science, University of Florida, USA. * indicates equal contributions. October 18, 2013 DRAFT Digital Object Indentifier 10.1109/TPAMI.2013.230 0162-8828/13/$31.00 \u00a9 2013 IEEE This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.", "PublicationYear": "2013", "Authors": ["Arnold W. M. Smeulders", "Dung Manh Chu"], "RelatedTopics": ["Computer Science"], "References": ["2258e01865367018ed6f4262c880df85b94959f8", "b762ecb0624005831f2f3d8eb626d53e8eca4b6c", "a52a6cf39054e6f406f67b57cc895e9df1163fc8", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "45e098084c676eee87a71806b7eb7ec03f0410c9", "68cc57640bfd04f697048534f82d16bf10a002ec", "657c87871e9b8fb6b237d1762c4c5b61433df444", "03f9c789ae36196e3e6669c49370b8d48fcf26a2", "da199480427da6b4c3800b11a91ef7f9bbbc90ee"], "ReferenceCount": 110, "CitationCount": 1355}, {"URL": "https://www.semanticscholar.org/paper/Robust-Object-Tracking-with-Online-Multiple-Babenko-Yang/0b104e517e0440e3bdace01b5f6706c5fa944149", "ID": "0b104e517e0440e3bdace01b5f6706c5fa944149", "Title": "Robust Object Tracking with Online Multiple Instance Learning", "Abstract": "It is shown that using Multiple Instance Learning (MIL) instead of traditional supervised learning avoids these problems and can therefore lead to a more robust tracker with fewer parameter tweaks. In this paper, we address the problem of tracking an object in a video given its location in the first frame and no other information. Recently, a class of tracking techniques called \u201ctracking by detection\u201d has been shown to give promising results at real-time speeds. These methods train a discriminative classifier in an online manner to separate the object from the background. This classifier bootstraps itself by using the current tracker state to extract positive and negative examples from the current frame. Slight inaccuracies in the tracker can therefore lead to incorrectly labeled training examples, which degrade the classifier and can cause drift. In this paper, we show that using Multiple Instance Learning (MIL) instead of traditional supervised learning avoids these problems and can therefore lead to a more robust tracker with fewer parameter tweaks. We propose a novel online MIL algorithm for object tracking that achieves superior results with real-time performance. We present thorough experimental results (both qualitative and quantitative) on a number of challenging video clips.", "PublicationYear": "2011", "Authors": ["Boris Babenko", "Ming-Hsuan Yang", "Serge J. Belongie"], "RelatedTopics": ["Computer Science"], "References": ["27d69a2d96600efb66fd907d8287ca3b6e734c59", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "d908f10ca52c19cd98edeef4323fb5619cfcdf9a", "460a435a492107e9c8ec23ae8e79b0420de619e9", "6b1a05759f570f13ebdc5ea7f7a957e41f43203d", "aa6557c658aed10ff303aa90fe8d0952332a43c0", "9c2f13c1fe9d8b894c62b4037491605cf8e45b89", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "b849bfe51138d88f6cae2d602b5e2a42565fb1c7", "38a7ca3f20241c7b310f44538b87e57a79cb6e76"], "ReferenceCount": 49, "CitationCount": 2083}, {"URL": "https://www.semanticscholar.org/paper/The-Pascal-Visual-Object-Classes-Challenge%3A-A-Everingham-Eslami/616b246e332573af1f4859aa91440280774c183a", "ID": "616b246e332573af1f4859aa91440280774c183a", "Title": "The Pascal Visual Object Classes Challenge: A Retrospective", "Abstract": "A review of the Pascal Visual Object Classes challenge from 2008\u20132012 is provided, with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges. The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008\u20132012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community\u2019s progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.", "PublicationYear": "2014", "Authors": ["Mark Everingham", "S. M. Ali Eslami", "Luc Van Gool", "Christopher K. I. Williams", "John M. Winn", "Andrew Zisserman"], "RelatedTopics": ["Computer Science"], "References": ["3a9b175324ba11bc0e16c0633912d897b2fac4e2", "0302bb2d5476540cfb21467473f5eca843caf90b", "2dd55b3bcaf50c1228569d0efe5620a910c1cd07", "5016eaf0f60495eaca9e4b171882adc09e4734b6", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "37e41557932cc0035eab23fd767bde68f6475c3a", "38101fac622a70b78f13625fc6502000b8756d3a", "f4c7ff4b8613f700aa9f89a2c0653b6ffcf658be", "0bca0ca7bb642b747797c17a4899206116fb0b25", "092c275005ae49dc1303214f6d02d134457c7053"], "ReferenceCount": 63, "CitationCount": 5162}, {"URL": "https://www.semanticscholar.org/paper/Incremental-Learning-for-Robust-Visual-Tracking-Ross-Lim/505f48d8236eb25f871da272c2ac2fe4b41ea289", "ID": "505f48d8236eb25f871da272c2ac2fe4b41ea289", "Title": "Incremental Learning for Robust Visual Tracking", "Abstract": "A tracking method that incrementally learns a low-dimensional subspace representation, efficiently adapting online to changes in the appearance of the target, and includes a method for correctly updating the sample mean and a forgetting factor to ensure less modeling power is expended fitting older observations. Abstract\\nVisual tracking, in essence, deals with non-stationary image streams that change over time. While most existing algorithms are able to track objects well in controlled environments, they usually fail in the presence of significant variation of the object\u2019s appearance or surrounding illumination. One reason for such failures is that many algorithms employ fixed appearance models of the target. Such models are trained using only appearance data available before tracking begins, which in practice limits the range of appearances that are modeled, and ignores the large volume of information (such as shape changes or specific lighting conditions) that becomes available during tracking. In this paper, we present a tracking method that incrementally learns a low-dimensional subspace representation, efficiently adapting online to changes in the appearance of the target. The model update, based on incremental algorithms for principal component analysis, includes two important features: a method for correctly updating the sample mean, and a forgetting factor to ensure less modeling power is expended fitting older observations. Both of these features contribute measurably to improving overall tracking performance. Numerous experiments demonstrate the effectiveness of the proposed tracking algorithm in indoor and outdoor environments where the target objects undergo large changes in pose, scale, and illumination.\\n", "PublicationYear": "2008", "Authors": ["David A. Ross", "Jongwoo Lim", "Ruei-Sung Lin", "Ming-Hsuan Yang"], "RelatedTopics": ["Computer Science"], "References": ["fbd1a9f177eabe9817610d6dbbeec368611d89bb", "14ee8cf76e31fdf4381d29c1fb61017beb52f672", "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c", "529afa282ce4bf2e1bd2d862aea01830ec3fd73a", "3731d20583197b98ef1f3c070c592000d572b214", "dafdcbb4c4f1e98c6b7090a1b3d7d8a103a05ace", "7bfe222d83e9dd9117bc4f8508962a01fb0b1626", "dd4bdfc5d3944e3e9573b887635487d4c5f5330f", "1d9cecff0c9c3df2ede822b05d0aa68b8ed35a95", "9c5a0951cea300222834497c8e12ac2be99cd11e"], "ReferenceCount": 35, "CitationCount": 3236}, {"URL": "https://www.semanticscholar.org/paper/Object-tracking%3A-A-survey-Yilmaz-Javed/caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "ID": "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "Title": "Object tracking: A survey", "Abstract": "The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends to discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects. The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends. Object tracking, in general, is a challenging problem. Difficulties in tracking objects can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid object structures, object-to-object and object-to-scene occlusions, and camera motion. Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Typically, assumptions are made to constrain the tracking problem in the context of a particular application. In this survey, we categorize the tracking methods on the basis of the object and motion representations used, provide detailed descriptions of representative methods in each category, and examine their pros and cons. Moreover, we discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects.", "PublicationYear": "2006", "Authors": ["Alper Yilmaz", "Omar Javed", "Mubarak Shah"], "RelatedTopics": ["Computer Science"], "References": ["f33e0aa9940d5fd5db44c122093581cd044ca28b", "dd4bdfc5d3944e3e9573b887635487d4c5f5330f", "1bfe26fac93ad96c81cf1a580b9e7744477f56aa", "5d3e56c19608a32751203ef5367ade3e6e7159d5", "46881a2361be42d2a7fed297b5bfc4ecc10391e3", "7a1da0d5b962a77a76008cb2f283c0606bd962f8", "9c2f13c1fe9d8b894c62b4037491605cf8e45b89", "f51cb4be6e22f7e2b7126c9f2e250071a2351e08", "d14e8f8834cd05ddc10f299fa20b75b52b38fe30", "2557c1ac4879f8b34f263061831ca5577ba9ab68"], "ReferenceCount": 173, "CitationCount": 5572}, {"URL": "https://www.semanticscholar.org/paper/Struck%3A-Structured-Output-Tracking-with-Kernels-Hare-Golodetz/61394599ed0aabe04b724c7ca3a778825c7e776f", "ID": "61394599ed0aabe04b724c7ca3a778825c7e776f", "Title": "Struck: Structured Output Tracking with Kernels", "Abstract": "A framework for adaptive visual object tracking based on structured output prediction that is able to outperform state-of-the-art trackers on various benchmark videos and can easily incorporate additional features and kernels into the framework, which results in increased tracking performance. Adaptive tracking-by-detection methods are widely used in computer vision for tracking arbitrary objects. Current approaches treat the tracking problem as a classification task and use online learning techniques to update the object model. However, for these updates to happen one needs to convert the estimated object position into a set of labelled training examples, and it is not clear how best to perform this intermediate step. Furthermore, the objective for the classifier (label prediction) is not explicitly coupled to the objective for the tracker (estimation of object position). In this paper, we present a framework for adaptive visual object tracking based on structured output prediction. By explicitly allowing the output space to express the needs of the tracker, we avoid the need for an intermediate classification step. Our method uses a kernelised structured output support vector machine (SVM), which is learned online to provide adaptive tracking. To allow our tracker to run at high frame rates, we (a) introduce a budgeting mechanism that prevents the unbounded growth in the number of support vectors that would otherwise occur during tracking, and (b) show how to implement tracking on the GPU. Experimentally, we show that our algorithm is able to outperform state-of-the-art trackers on various benchmark videos. Additionally, we show that we can easily incorporate additional features and kernels into our framework, which results in increased tracking performance.", "PublicationYear": "2016", "Authors": ["Sam Hare", "Stuart Golodetz", "Amir Saffari", "Vibhav Vineet", "Ming-Ming Cheng", "Stephen L. Hicks", "Philip H. S. Torr"], "RelatedTopics": ["Computer Science"], "References": ["0b104e517e0440e3bdace01b5f6706c5fa944149", "421bf4eeba623f722bf98340d71e3d229881e92d", "006f283a50d325840433f4cf6d15876d475bba77", "16e36a4b59e214786737aa4ebc3ba86075b61e49", "b762ecb0624005831f2f3d8eb626d53e8eca4b6c", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "e98cc247b597f6fdba9710fbed719c919f8bf45e", "13141284f1a7e1fe255f5c2b22c09e32f0a4d465", "27d69a2d96600efb66fd907d8287ca3b6e734c59", "236d4de0b1c73217238f370e7d30243c7ee9707a"], "ReferenceCount": 61, "CitationCount": 1677}, {"URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking-with-Proposal-Selection-Hua-Karteek/84f911432ba8a3356013b3abfbf1947f1145c953", "ID": "84f911432ba8a3356013b3abfbf1947f1145c953", "Title": "Online Object Tracking with Proposal Selection", "Abstract": "This paper formulating it as a proposal selection task and making two contributions, introducing novel proposals estimated from the geometric transformations undergone by the object, and building a rich candidate set for predicting the object location. Tracking-by-detection approaches are some of the most successful object trackers in recent years. Their success is largely determined by the detector model they learn initially and then update over time. However, under challenging conditions where an object can undergo transformations, e.g., severe rotation, these methods are found to be lacking. In this paper, we address this problem by formulating it as a proposal selection task and making two contributions. The first one is introducing novel proposals estimated from the geometric transformations undergone by the object, and building a rich candidate set for predicting the object location. The second one is devising a novel selection strategy using multiple cues, i.e., detection score and edgeness score computed from state-of-the-art object edges and motion boundaries. We extensively evaluate our approach on the visual object tracking 2014 challenge and online tracking benchmark datasets, and show the best performance.", "PublicationYear": "2015", "Authors": ["Yang Hua", "Alahari Karteek", "Cordelia Schmid"], "RelatedTopics": ["Computer Science"], "References": ["0b104e517e0440e3bdace01b5f6706c5fa944149", "32e741784688cf4209263666e50bc8187e0b00a0", "c63a34ac6a4e049118070e707ca7679fbb132d33", "61394599ed0aabe04b724c7ca3a778825c7e776f", "b6d31905b671e6d442311c0e275772652df3abb6", "fe2aaad872a2cf08c09dd52ca972f323666306db", "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "1183db5f409e8498d1a0f542703f908275a6dc34", "894767a3911ce9295844579380b4a727f7a2a0bf"], "ReferenceCount": 53, "CitationCount": 104}, {"URL": "https://www.semanticscholar.org/paper/NUS-PRO%3A-A-New-Visual-Tracking-Challenge-Li-Lin/91f2b2aeb7e65d0b673ed7e782488b3365027979", "ID": "91f2b2aeb7e65d0b673ed7e782488b3365027979", "Title": "NUS-PRO: A New Visual Tracking Challenge", "Abstract": "A thorough experimental evaluation of 20 state-of-the-art tracking algorithms is presented with detailed analysis using different metrics and a large-scale database which contains 365 challenging image sequences of pedestrians and rigid objects is proposed. Numerous approaches on object tracking have been proposed during the past decade with demonstrated success. However, most tracking algorithms are evaluated on limited video sequences and annotations. For thorough performance evaluation, we propose a large-scale database which contains 365 challenging image sequences of pedestrians and rigid objects. The database covers 12 kinds of objects, and most of the sequences are captured from moving cameras. Each sequence is annotated with target location and occlusion level for evaluation. A thorough experimental evaluation of 20 state-of-the-art tracking algorithms is presented with detailed analysis using different metrics. The database is publicly available and evaluation can be carried out online for fair assessments of visual tracking algorithms.", "PublicationYear": "2016", "Authors": ["Annan Li", "Min Lin", "Yi Wu", "Ming-Hsuan Yang", "Shuicheng Yan"], "RelatedTopics": ["Computer Science"], "References": ["bfba194dfd9c7c27683082aa8331adc4c5963a0d", "b762ecb0624005831f2f3d8eb626d53e8eca4b6c", "16e58cff042f6d556779431c5dc9dafcf092cbf9", "d908f10ca52c19cd98edeef4323fb5619cfcdf9a", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "0b104e517e0440e3bdace01b5f6706c5fa944149", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "9d57723b4908397654fb1846d37db403d8b2b56a", "b817d78457a2a28e62d343f534fca10b0d020ed8"], "ReferenceCount": 42, "CitationCount": 174}, {"URL": "https://www.semanticscholar.org/paper/Object-Tracking-Benchmark-Wu-Lim/c4c45661501c16064eead6e5d37dcb80d41c7a78", "ID": "c4c45661501c16064eead6e5d37dcb80d41c7a78", "Title": "Object Tracking Benchmark", "Abstract": "An extensive evaluation of the state-of-the-art online object-tracking algorithms with various evaluation criteria is carried out to identify effective approaches for robust tracking and provide potential future research directions in this field. Object tracking has been one of the most important and active research areas in the field of computer vision. A large number of tracking algorithms have been proposed in recent years with demonstrated success. However, the set of sequences used for evaluation is often not sufficient or is sometimes biased for certain types of algorithms. Many datasets do not have common ground-truth object positions or extents, and this makes comparisons among the reported quantitative results difficult. In addition, the initial conditions or parameters of the evaluated tracking algorithms are not the same, and thus, the quantitative results reported in literature are incomparable or sometimes contradictory. To address these issues, we carry out an extensive evaluation of the state-of-the-art online object-tracking algorithms with various evaluation criteria to understand how these methods perform within the same framework. In this work, we first construct a large dataset with ground-truth object positions and extents for tracking and introduce the sequence attributes for the performance analysis. Second, we integrate most of the publicly available trackers into one code library with uniform input and output formats to facilitate large-scale performance evaluation. Third, we extensively evaluate the performance of 31 algorithms on 100 sequences with different initialization settings. By analyzing the quantitative results, we identify effective approaches for robust tracking and provide potential future research directions in this field.", "PublicationYear": "2015", "Authors": ["Yi Wu", "Jongwoo Lim", "Ming-Hsuan Yang"], "RelatedTopics": ["Computer Science"], "References": ["bfba194dfd9c7c27683082aa8331adc4c5963a0d", "a6ee08763d994b1687c594bb9367f8d5cf419113", "16e58cff042f6d556779431c5dc9dafcf092cbf9", "bf5e48bcaddc8d8bfb2c5b138efdb90e94f8258f", "739d084e486702dbdad01d668f77b431228bae9d", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "0b104e517e0440e3bdace01b5f6706c5fa944149", "e13fc55a4dfbf933665e4555dafba558a17f9fa7", "eaf10795a2a34ba6638fd79815d4b81e20eb5955"], "ReferenceCount": 107, "CitationCount": 2803}, {"URL": "https://www.semanticscholar.org/paper/Using-Discriminative-Motion-Context-for-Online-Duffner-Garcia/c4e7e62b3a3eb100b441674ad3817d9a24239e2a", "ID": "c4e7e62b3a3eb100b441674ad3817d9a24239e2a", "Title": "Using Discriminative Motion Context for Online Visual Object Tracking", "Abstract": "An algorithm for online, real-time tracking of arbitrary objects in videos from unconstrained environments based on a particle filter framework using different visual features and motion prediction models is proposed, effectively integrating a discriminative online learning classifier into the model and proposed new method to collect negative training examples for updating the classifier at each video frame. In this paper, we propose an algorithm for online, real-time tracking of arbitrary objects in videos from unconstrained environments. The method is based on a particle filter framework using different visual features and motion prediction models. We effectively integrate a discriminative online learning classifier into the model and propose a new method to collect negative training examples for updating the classifier at each video frame. Instead of taking negative examples only from the surroundings of the object region, or from specific background regions, our algorithm samples the negatives from a contextual motion density function in order to learn to discriminate the target as early as possible from potential distracting image regions. We experimentally show that this learning scheme improves the overall performance of the tracking algorithm. Moreover, we present quantitative and qualitative results on four challenging public data sets that show the robustness of the tracking algorithm with respect to appearance and view changes, lighting variations, partial occlusions, as well as object deformations. Finally, we compare the results with more than 30 state-of-the-art methods using two public benchmarks, showing very competitive results.", "PublicationYear": "2016", "Authors": ["Stefan Duffner", "Christophe Garcia"], "RelatedTopics": ["Computer Science"], "References": ["f9dbc7f2ef8ed42ff3fdc08d12116761fbbb4865", "421bf4eeba623f722bf98340d71e3d229881e92d", "27b6ed73dce051539494100d2dfdaca27d671556", "13141284f1a7e1fe255f5c2b22c09e32f0a4d465", "d11e63d81ca01288ff55a8ae2a9eddba7c9c1f6c", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "3d98b9822e6efc2eec421e0bfd7546fd4ba30407", "1183db5f409e8498d1a0f542703f908275a6dc34", "452e7a99b67efbdca55008d40e859c8156bfab9f", "32e741784688cf4209263666e50bc8187e0b00a0"], "ReferenceCount": 63, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/MOTChallenge-2015%3A-Towards-a-Benchmark-for-Tracking-Leal-Taix%C3%A9-Milan/5bae9822d703c585a61575dced83fa2f4dea1c6d", "ID": "5bae9822d703c585a61575dced83fa2f4dea1c6d", "Title": "MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking", "Abstract": "With MOTChallenge, the work toward a novel multiple object tracking benchmark aimed to address issues of standardization, and the way toward a unified evaluation framework for a more meaningful quantification of multi-target tracking is described. In the recent past, the computer vision community has developed centralized benchmarks for the performance evaluation of a variety of tasks, including generic object and pedestrian detection, 3D reconstruction, optical flow, single-object short-term tracking, and stereo estimation. Despite potential pitfalls of such benchmarks, they have proved to be extremely helpful to advance the state of the art in the respective area. Interestingly, there has been rather limited work on the standardization of quantitative benchmarks for multiple target tracking. One of the few exceptions is the well-known PETS dataset, targeted primarily at surveillance applications. Despite being widely used, it is often applied inconsistently, for example involving using different subsets of the available data, different ways of training the models, or differing evaluation scripts. This paper describes our work toward a novel multiple object tracking benchmark aimed to address such issues. We discuss the challenges of creating such a framework, collecting existing and new data, gathering state-of-the-art methods to be tested on the datasets, and finally creating a unified evaluation system. With MOTChallenge we aim to pave the way toward a unified evaluation framework for a more meaningful quantification of multi-target tracking.", "PublicationYear": "2015", "Authors": ["Laura Leal-Taix{\\'e}", "Anton Milan", "Ian D. Reid", "Stefan Roth", "Konrad Schindler"], "RelatedTopics": ["Computer Science"], "References": ["3e083dc8aeb7983a5cdff146985363d38caf0886", "2258e01865367018ed6f4262c880df85b94959f8", "de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42", "aa574e55ea3401ec9bc500eed990e4f402730d26", "616fda61990097f0401b33dbf01541bd83a939a0", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "695423ede04c7ccf05997c123fd8ab9b94c4a088", "0302bb2d5476540cfb21467473f5eca843caf90b", "5b1e33f60514a307054de5642a13051c1e1438b6", "9b49f70bcaf6e473930681b9a0562f130ae01533"], "ReferenceCount": 58, "CitationCount": 690}, {"URL": "https://www.semanticscholar.org/paper/Robust-visual-tracking-using-template-anchors-Cehovin-Leonardis/6b175816b1f81127f5e2a2fe998df99d62290a1c", "ID": "6b175816b1f81127f5e2a2fe998df99d62290a1c", "Title": "Robust visual tracking using template anchors", "Abstract": "This work proposes decomposing the visual model into several sub-models, each describing the target at a different level of detail, and introduces controlled graduation in estimation of the free parameters to address the problem of self-supervised estimation of a large number of parameters. Deformable part models exhibit excellent performance in tracking non-rigidly deforming targets, but are usually outperformed by holistic models when the target does not deform or in the presence of uncertain visual data. The reason is that part-based models require estimation of a larger number of parameters compared to holistic models and since the updating process is self-supervised, the errors in parameter estimation are amplified with time, leading to a faster accuracy reduction than in holistic models. On the other hand, the robustness of part-based trackers is generally greater than in holistic trackers. We address the problem of self-supervised estimation of a large number of parameters by introducing controlled graduation in estimation of the free parameters. We propose decomposing the visual model into several sub-models, each describing the target at a different level of detail. The sub-models interact during target localization and, depending on the visual uncertainty, serve for cross-sub-model supervised updating. A new tracker is proposed based on this model which exhibits the qualities of part-based as well as holistic models. The tracker is tested on the highly-challenging VOT2013 and VOT2014 benchmarks, outperforming the state-of-the-art.", "PublicationYear": "2016", "Authors": ["Luka Cehovin", "Ale{\\vs} Leonardis", "Matej Kristan"], "RelatedTopics": ["Computer Science"], "References": ["505f48d8236eb25f871da272c2ac2fe4b41ea289", "6c139dc7f1048cdd9240219541ef9d40df75ad31", "13141284f1a7e1fe255f5c2b22c09e32f0a4d465", "8b421c7c42ae7eaa2c5bbf029354192c96b3e23d", "54142ebf7c0c1ae3983feb10cfe135517f720c59", "63b293b346b5f1c04b6716dfb00b8b343e2a1972", "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca", "2cf2cf481ed799ee3cf4851593234c9f00100f3e", "9d57723b4908397654fb1846d37db403d8b2b56a", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb"], "ReferenceCount": 35, "CitationCount": 32}, {"URL": "https://www.semanticscholar.org/paper/Single-Object-Long-term-Tracker-for-Smart-Control-a-Gonz%C3%A1lez-Nieto/f15d5c0a9d2f3678b4c16330da29b3b4511fdef5", "ID": "f15d5c0a9d2f3678b4c16330da29b3b4511fdef5", "Title": "Single Object Long-term Tracker for Smart Control of a PTZ camera", "Abstract": "A single-object long-term tracker that supports high appearance changes in the tracked target, occlusions, and is also capable of recovering a target lost during the tracking process is presented. In this paper, we present a single-object long-term tracker that supports high appearance changes in the tracked target, occlusions, and is also capable of recovering a target lost during the tracking process. The initial motivation was real time automatic speaker tracking by a static camera in order to control a PTZ camera capturing a lecture. The algorithm consists of a novel combination of state-of-the-art techniques. Subjective evaluation, over existing and newly recorded sequences, shows that the tracker is able to overcome the problems and difficulties of long-term tracking in a real lecture. Additionally, in order to further assess the performance of the proposed approach, a comparative evaluation over the VOT2013 dataset is presented.", "PublicationYear": "2014", "Authors": ["Antonio Gonz{\\'a}lez", "Rafael Martin Nieto", "Jes{\\'u}s Besc{\\'o}s", "Jos{\\'e} Mar{\\'i}a Mart{\\'i}nez Sanchez"], "RelatedTopics": ["Computer Science"], "References": ["aefb61185c181edf073dd54045030c406d9205b0", "aff9ed00a2196b4aa7a7968ced25207eb055695c", "2cfa006b33084abe8160b001f9a24944cda25d05", "c63a34ac6a4e049118070e707ca7679fbb132d33", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "e11dab9ddf9ec9b2a0fa35e4b91656ee2ad63aa0", "5f3bda82a3f43cae7deae1dabc7d10ff3dc7a1ae", "bb9535eb9e64cf2c0ec59f550dbfdbde02da76b9", "5cd62c4ace35e93dadb4d69fe76914edd1d331bb", "5254cfffad6e2b4f26dd8d2f32fbd62a6d4354ee"], "ReferenceCount": 35, "CitationCount": 19}, {"URL": "https://www.semanticscholar.org/paper/Comparison-of-infrared-and-visible-imagery-for-with-Gundogdu-Ozkan/6a699d87bb55477cbe7bfb45b7991b889fd976b6", "ID": "6a699d87bb55477cbe7bfb45b7991b889fd976b6", "Title": "Comparison of infrared and visible imagery for object tracking: Toward trackers with superior IR performance", "Abstract": "A novel ensemble based tracking method that is tuned to IR data is proposed that sequentially constructs and maintains a dynamical ensemble of simple correlators and produces tracking decisions by switching among the ensemble correlators depending on the target appearance in a computationally highly efficient manner. The subject of this paper is the visual object tracking in infrared (IR) videos. Our contribution is twofold. First, the performance behaviour of the state-of-the-art trackers is investigated via a comparative study using IR-visible band video conjugates, i.e., video pairs captured observing the same scene simultaneously, to identify the IR specific challenges. Second, we propose a novel ensemble based tracking method that is tuned to IR data. The proposed algorithm sequentially constructs and maintains a dynamical ensemble of simple correlators and produces tracking decisions by switching among the ensemble correlators depending on the target appearance in a computationally highly efficient manner. We empirically show that our algorithm significantly outperforms the state-of-the-art trackers in our extensive set of experiments with IR imagery.", "PublicationYear": "2015", "Authors": ["Erhan Gundogdu", "Huseyin Ozkan", "Huseyin Seckin Demir", "Hamza Ergezer", "Erdem Akagunduz", "S. Kubilay Pakin"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["70c3c9b9a40ca55264e454586dca2a6cf416f6e0", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "c63a34ac6a4e049118070e707ca7679fbb132d33", "421bf4eeba623f722bf98340d71e3d229881e92d", "460a435a492107e9c8ec23ae8e79b0420de619e9", "5616a93e3b8204d340a4d61269d4c4bd8425f0c3", "b7cd6c2234ea8f5b7d75acc454e35158ffbd42d3", "61394599ed0aabe04b724c7ca3a778825c7e776f", "29e1e20323f7cb6c15c6acf5cc6573a2f84e6478"], "ReferenceCount": 25, "CitationCount": 38}, {"URL": "https://www.semanticscholar.org/paper/A-Thermal-Infrared-Video-Benchmark-for-Visual-Wu-Fuller/2c76de57b8b1c9e63b1883cbdea9ec8e68ddf493", "ID": "2c76de57b8b1c9e63b1883cbdea9ec8e68ddf493", "Title": "A Thermal Infrared Video Benchmark for Visual Analysis", "Abstract": "This work publishes a new thermal infrared video benchmark, called TIV, for various visual analysis tasks, which include single object tracking in clutter, multi-object tracking in single or multiple views, analyzing motion patterns of large groups, and censusing wild animals in flight. We hereby publish a new thermal infrared video benchmark, called TIV, for various visual analysis tasks, which include single object tracking in clutter, multi-object tracking in single or multiple views, analyzing motion patterns of large groups, and censusing wild animals in flight. Our data describe real world scenarios, such as bats emerging from their caves in large numbers, a crowded street view during a marathon competition, and students walking through an atrium during class break. We also introduce baseline methods and evaluation protocols for these tasks. Our TIV benchmark enriches and diversifies video data sets available to the research community with thermal infrared footage, which poses new and challenging video analysis problems. We hope the TIV benchmark will help the community to better understand these interesting problems, generate new ideas, and value it as a testbed to compare solutions.", "PublicationYear": "2014", "Authors": ["Zheng Wu", "Nathan W. Fuller", "Diane H. Theriault", "Margrit Betke"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["201d116761d9d300193df370107f26d7d475023b", "dee74a5b8e671909242e05671067eb7add599940", "8c79b44d99b370ac538723d3d22d1f8fa8b396ce", "28d47de5bcfff9ba609337f56a287a4310c2dd44", "2258e01865367018ed6f4262c880df85b94959f8", "f4c7ff4b8613f700aa9f89a2c0653b6ffcf658be", "a34d25e4c53c8261a474af722a631f619cf5a7c3", "d867d7c8cfefe0f5a297a3c613ae6d79c851f4b9", "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "0114a5df2fd5124f435cce3263de90f117b56086"], "ReferenceCount": 21, "CitationCount": 139}, {"URL": "https://www.semanticscholar.org/paper/People-detection-and-tracking-from-aerial-thermal-Portmann-Lynen/201d116761d9d300193df370107f26d7d475023b", "ID": "201d116761d9d300193df370107f26d7d475023b", "Title": "People detection and tracking from aerial thermal views", "Abstract": "A new, publicly available dataset of annotated thermal image sequences, posing a multitude of challenges for people detection and tracking is presented and a new particle filter based framework for tracking people in aerial thermal images is proposed. Detection and tracking of people in visible-light images has been subject to extensive research in the past decades with applications ranging from surveillance to search-and-rescue. Following the growing availability of thermal cameras and the distinctive thermal signature of humans, research effort has been focusing on developing people detection and tracking methodologies applicable to this sensing modality. However, a plethora of challenges arise on the transition from visible-light to thermal images, especially with the recent trend of employing thermal cameras onboard aerial platforms (e.g. in search-and-rescue research) capturing oblique views of the scenery. This paper presents a new, publicly available dataset of annotated thermal image sequences, posing a multitude of challenges for people detection and tracking. Moreover, we propose a new particle filter based framework for tracking people in aerial thermal images. Finally, we evaluate the performance of this pipeline on our dataset, incorporating a selection of relevant, state-of-the-art methods and present a comprehensive discussion of the merits spawning from our study.", "PublicationYear": "2014", "Authors": ["J{\\~A}\u00bcrg Portmann", "Simon Lynen", "Margarita Chli", "Roland Y. Siegwart"], "RelatedTopics": ["Engineering", "Environmental Science", "Computer Science"], "References": ["c26eaf62a20ebac360148276a1f098d92c7b0738", "1b7a5f9b9b18ad42608261f7fc7c4879087e7b8a", "ccbc65d05e753b097a6c6b1ece25624e2ee39d5d", "394b9fed48a08ca7f740b5bc26e9386a2f7a73c0", "5224b79368dba945a9e90506f23a1cfa91f6f404", "34e0ba2daabfa4d3d22913ade8265aff50b5f917", "20a056df333294e2fc34bb170d1a20c64202024c", "7f9844f16b6c011e561ee2afef9157405c1d7e0d", "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63", "e8b12467bdc20bde976750b8a28decdb33246d1d"], "ReferenceCount": 17, "CitationCount": 165}, {"URL": "https://www.semanticscholar.org/paper/Online-Object-Tracking%3A-A-Benchmark-Wu-Lim/bfba194dfd9c7c27683082aa8331adc4c5963a0d", "ID": "bfba194dfd9c7c27683082aa8331adc4c5963a0d", "Title": "Online Object Tracking: A Benchmark", "Abstract": "Large scale experiments are carried out with various evaluation criteria to identify effective approaches for robust tracking and provide potential future research directions in this field. Object tracking is one of the most important components in numerous applications of computer vision. While much progress has been made in recent years with efforts on sharing code and datasets, it is of great importance to develop a library and benchmark to gauge the state of the art. After briefly reviewing recent advances of online object tracking, we carry out large scale experiments with various evaluation criteria to understand how these algorithms perform. The test image sequences are annotated with different attributes for performance evaluation and analysis. By analyzing quantitative results, we identify effective approaches for robust tracking and provide potential future research directions in this field.", "PublicationYear": "2013", "Authors": ["Yi Wu", "Jongwoo Lim", "Ming-Hsuan Yang"], "RelatedTopics": ["Computer Science"], "References": ["caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "2822a883d149956934a20614d6934c6ddaac6857", "0b104e517e0440e3bdace01b5f6706c5fa944149", "237c54150e151e2c9cbfe427219a2ab5864505c6", "2d705458ebae2cb368a6417fe879b2400bf457c9", "a65c76169bdb8479353806556f61bf94fdec7e10", "d908f10ca52c19cd98edeef4323fb5619cfcdf9a", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "e13fc55a4dfbf933665e4555dafba558a17f9fa7", "257cfe2995243b2a5f91a7a423bf2853e1c05420"], "ReferenceCount": 66, "CitationCount": 3673}, {"URL": "https://www.semanticscholar.org/paper/Local-Feature-Based-Person-Detection-and-Tracking-Jungling-Arens/c26eaf62a20ebac360148276a1f098d92c7b0738", "ID": "c26eaf62a20ebac360148276a1f098d92c7b0738", "Title": "Local Feature Based Person Detection and Tracking Beyond the Visible Spectrum", "Abstract": "This work addresses the two tasks of object detection and tracking and introduces an integrated approach to both challenges that combines bottom-up tracking-by-detection techniques with top-down model based strategies on the level of local features. One challenging field in computer vision is the automatic detection and tracking of objects in image sequences. Promising performance of local features and local feature based object detection approaches in the visible spectrum encourage the application of the same principles to data beyond the visible spectrum. Since these dedicated object detectors neither make assumptions on a static background nor a stationary camera, it is reasonable to use these object detectors as a basis for tracking tasks as well. In this work, we address the two tasks of object detection and tracking and introduce an integrated approach to both challenges that combines bottom-up tracking-by-detection techniques with top-down model based strategies on the level of local features. By this combination of detection and tracking in a single framework, we achieve (i) automatic identity preservation in tracking, (ii) a stabilization of object detection, (iii) a reduction of false alarms by automatic verification of tracking results in every step and (iv) tracking through short term occlusions without additional treatment of these situations. Since our tracking approach is solely based on local features it works independently of underlying video-data specifics like color information\u2014making it applicable to both, visible and infrared data. Since the object detector is trainable and the tracking methodology does not make any assumptions on object class specifics, the overall approach is general applicable for any object class. We apply our approach to the task of person detection and tracking in infrared image sequences. For this case we show that our local feature based approach inherently allows for object component classification, i.e., body part detection. To show the usability of our approach, we evaluate the performance of both, person detection and tracking in different real world scenarios, including urban scenarios where the camera is mounted on a moving vehicle.", "PublicationYear": "2011", "Authors": ["Kai Jungling", "Michael Arens"], "RelatedTopics": ["Computer Science"], "References": ["275260b6118b56ee2a3d6bbdf250d0e424b4223c", "e87b897964abb2a093d503ad1ffc956b8129d420", "ccbc65d05e753b097a6c6b1ece25624e2ee39d5d", "49bdd3fb166e0faf7ad1c917aee32c22ebc0f9db", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc", "461efc87636ff4e48323ffcb9f8fdf79cf736fb0", "b6d31905b671e6d442311c0e275772652df3abb6", "c3833f53c947bf89e2c06fd152ca4c7e5a651d6e", "d38345663f133ea519213362ac684e83e24d3464", "91335d9335e4fd06de48d769d1b79eaded4e431b"], "ReferenceCount": 39, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/An-iterative-integrated-framework-for-image-sensor-Torabi-Mass%C3%A9/d867d7c8cfefe0f5a297a3c613ae6d79c851f4b9", "ID": "d867d7c8cfefe0f5a297a3c613ae6d79c851f4b9", "Title": "An iterative integrated framework for thermal-visible image registration, sensor fusion, and people tracking for video surveillance applications", "Abstract": "Semantic Scholar extracted view of \\\"An iterative integrated framework for thermal-visible image registration, sensor fusion, and people tracking for video surveillance applications\\\" by Atousa Torabi et al.", "PublicationYear": "2012", "Authors": ["Atousa Torabi", "Guillaume Mass{\\'e}", "Guillaume-Alexandre Bilodeau"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["3ef7cb18b99007ab8edf92ce13b132e2d033d80c", "78e15870d66399ddd69c0ed453a6ae883843f180", "21616f2e0d4adf6c23cdcd8f8b635fa4f6c1508a", "ae5ce57a03558b4042c4924d2ec5784306a6de56", "70bdddb2e4365e2259cfe7133079a38f2d6afbdf", "cbae29796569bbdfe233212a78c3751947cbf0d2", "59daa7193eaf8d2163885f5c4c9dfc536c03e69d", "d38345663f133ea519213362ac684e83e24d3464", "0cff6baa9493a295c1472b63027ddbae3d86a4da", "bfedd15b5c82f97a7cc97df4754d1f255b58a12a"], "ReferenceCount": 27, "CitationCount": 147}, {"URL": "https://www.semanticscholar.org/paper/Enhanced-Distribution-Field-Tracking-Using-Channel-Felsberg/a8ccbb0981b104cc0f753514cc28c01e5309dc41", "ID": "a8ccbb0981b104cc0f753514cc28c01e5309dc41", "Title": "Enhanced Distribution Field Tracking Using Channel Representations", "Abstract": "This enhanced distribution field tracking method outperforms several state-of-the-art methods on the VOT2013 challenge, which evaluates accuracy, robustness, and speed. Visual tracking of objects under varying lighting conditions and changes of the object appearance, such as articulation and change of aspect, is a challenging problem. Due to its robustness and speed, distribution field tracking is among the state-of-the-art approaches for tracking objects with constant size in grayscale sequences. According to the theory of averaged shifted histograms, distribution fields are an approximation of kernel density estimates. Another, more efficient approximation are channel representations, which are used in the present paper to derive an enhanced computational scheme for tracking. This enhanced distribution field tracking method outperforms several state-of-the-art methods on the VOT2013 challenge, which evaluates accuracy, robustness, and speed.", "PublicationYear": "2013", "Authors": ["Michael Felsberg"], "RelatedTopics": ["Computer Science"], "References": ["bfba194dfd9c7c27683082aa8331adc4c5963a0d", "20402c2004cfb2e9caa433d9ca2fb61ff30b302e", "2cfa006b33084abe8160b001f9a24944cda25d05", "270d3d614f519f4bcc1b4a28f0d3c5bead86a46b", "0b104e517e0440e3bdace01b5f6706c5fa944149", "9b2b3e7460f86d252fa5e0bff6b83fc235fbd73e", "a9ea6b5ea0335aa92c8cab62f5802b5b3606ea90", "eec029c1b57a5b4fc4dab97a84d7e747d1273426", "e07bb324fe689cd8e6f61f045c895c9c1e992f6d", "a35561e15d3270d63574905fca6b44b92ab5ace0"], "ReferenceCount": 25, "CitationCount": 94}, {"URL": "https://www.semanticscholar.org/paper/Robust-object-tracking-via-sparsity-based-model-Zhong-Lu/fe2aaad872a2cf08c09dd52ca972f323666306db", "ID": "fe2aaad872a2cf08c09dd52ca972f323666306db", "Title": "Robust object tracking via sparsity-based collaborative model", "Abstract": "A robust appearance model that exploits both holistic templates and local representations is proposed and the update scheme considers both the latest observations and the original template, thereby enabling the tracker to deal with appearance change effectively and alleviate the drift problem. In this paper we propose a robust object tracking algorithm using a collaborative model. As the main challenge for object tracking is to account for drastic appearance change, we propose a robust appearance model that exploits both holistic templates and local representations. We develop a sparsity-based discriminative classifier (SD-C) and a sparsity-based generative model (SGM). In the S-DC module, we introduce an effective method to compute the confidence value that assigns more weights to the foreground than the background. In the SGM module, we propose a novel histogram-based method that takes the spatial information of each patch into consideration with an occlusion handing scheme. Furthermore, the update scheme considers both the latest observations and the original template, thereby enabling the tracker to deal with appearance change effectively and alleviate the drift problem. Numerous experiments on various challenging videos demonstrate that the proposed tracker performs favorably against several state-of-the-art algorithms.", "PublicationYear": "2012", "Authors": ["Wei Zhong", "Huchuan Lu", "Ming-Hsuan Yang"], "RelatedTopics": ["Computer Science"], "References": ["b762ecb0624005831f2f3d8eb626d53e8eca4b6c", "625e4ee7dce9e6e4183bfebfd8be532172697142", "c4548079b87946c63e9f9a70d6fcc688fb1bdb32", "f317983dfb75ff280d314f9538bb185dc51c6147", "8a2b6f9f4c68262f2b89ef24da48391f7d57b216", "421bf4eeba623f722bf98340d71e3d229881e92d", "9aa63eba69644e45782c9f0bbbaa1cf14d8ace20", "b5e17a0ed14349d6c4066d2408409751f9595e04", "16e36a4b59e214786737aa4ebc3ba86075b61e49", "ebc2edd037e2b3aedc72e22cda3c6d382d650058"], "ReferenceCount": 36, "CitationCount": 1020}, {"URL": "https://www.semanticscholar.org/paper/Particle-Filter-Tracking-of-Camouflaged-Targets-by-Talha-Stolkin/2873de80204743249012f52821419978f4d8b27e", "ID": "2873de80204743249012f52821419978f4d8b27e", "Title": "Particle Filter Tracking of Camouflaged Targets by Adaptive Fusion of Thermal and Visible Spectra Camera Data", "Abstract": "A method for tracking a moving target by fusing bi-modal visual information from a deep infra-red thermal imaging camera and a conventional visible spectrum color camera and adaptively weighting the data fusion process in favor of whichever imaging modality is currently the most discriminating at each successive frame is presented. This paper presents a method for tracking a moving target by fusing bi-modal visual information from a deep infra-red thermal imaging camera and a conventional visible spectrum color camera. The tracking method builds on well-known methods for color-based tracking using particle filtering, but it extends these to handle fusion of color and thermal information when evaluating each particle. The key innovation is a method for continuously relearning local background models for each particle in each imaging modality, comparing these against a model of the foreground object being tracked, and thereby adaptively weighting the data fusion process in favor of whichever imaging modality is currently the most discriminating at each successive frame. The method is evaluated by testing on a variety of extremely challenging video sequences, in which people and other targets are tracked past occlusion, clutter, and distracters causing severe and sustained camouflage conditions in one or both imaging modalities.", "PublicationYear": "2014", "Authors": ["Mohammed Talha", "R. Stolkin"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["954e7e1d0fb187201276a89fb70f18558f32c91d", "4cdc7848bb23f2d43b50950251938bad51090da8", "e11dab9ddf9ec9b2a0fa35e4b91656ee2ad63aa0", "61ac4095650f35458e627015e42f24555441cc4e", "dd4bdfc5d3944e3e9573b887635487d4c5f5330f", "b990e381353a8a12ca3fc57898506a1ae0af913e", "163dcde9f6fe1b7bfbf58a8bd7c06e63ab650cf9", "570502599a26bab7281ce7cbc07eb36bf7b12a51", "0cff6baa9493a295c1472b63027ddbae3d86a4da", "8bd2357955357ba7f09c529273b7b5af15e2f432"], "ReferenceCount": 20, "CitationCount": 60}, {"URL": "https://www.semanticscholar.org/paper/Need-for-Speed%3A-A-Benchmark-for-Higher-Frame-Rate-Galoogahi-Fagg/703505a00579c0aa67712836acc41d94fa6d6edc", "ID": "703505a00579c0aa67712836acc41d94fa6d6edc", "Title": "Need for Speed: A Benchmark for Higher Frame Rate Object Tracking", "Abstract": "This paper proposes the first higher frame rate video dataset (called Need for Speed - NfS) and benchmark for visual object tracking and finds that at higher frame rates, simple trackers such as correlation filters outperform complex methods based on deep networks. In this paper, we propose the first higher frame rate video dataset (called Need for Speed - NfS) and benchmark for visual object tracking. The dataset consists of 100 videos (380K frames) captured with now commonly available higher frame rate (240 FPS) cameras from real world scenarios. All frames are annotated with axis aligned bounding boxes and all sequences are manually labelled with nine visual attributes - such as occlusion, fast motion, background clutter, etc. Our benchmark provides an extensive evaluation of many recent and state-of-the-art trackers on higher frame rate sequences. We ranked each of these trackers according to their tracking accuracy and real-time performance. One of our surprising conclusions is that at higher frame rates, simple trackers such as correlation filters outperform complex methods based on deep networks. This suggests that for practical applications (such as in robotics or embedded vision), one needs to carefully tradeoff bandwidth constraints associated with higher frame rate acquisition, computational costs of real-time analysis, and the required application accuracy. Our dataset and benchmark allows for the first time (to our knowledge) systematic exploration of such issues, and will be made available to allow for further research in this space.", "PublicationYear": "2017", "Authors": ["Hamed Kiani Galoogahi", "Ashton Fagg", "Chen Huang", "Deva Ramanan", "Simon Lucey"], "RelatedTopics": ["Computer Science"], "References": ["204c65df01e958e0331bfdf658a21c55316e2085", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "a6ee08763d994b1687c594bb9367f8d5cf419113", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "f5dbe4550d24d5374d9e10fce44a35b105c7ee07", "47b5e4d564f36bf322c14893b51ae4ecf782b53b"], "ReferenceCount": 42, "CitationCount": 317}, {"URL": "https://www.semanticscholar.org/paper/Long-term-correlation-tracking-Ma-Yang/754504cf01ef3846259783e748b1d3ea52fa2c81", "ID": "754504cf01ef3846259783e748b1d3ea52fa2c81", "Title": "Long-term correlation tracking", "Abstract": "This paper decomposes the task of tracking into translation and scale estimation of objects and shows that the correlation between temporal context considerably improves the accuracy and reliability for translation estimation, and it is effective to learn discriminative correlation filters from the most confident frames to estimate the scale change. In this paper, we address the problem of long-term visual tracking where the target objects undergo significant appearance variation due to deformation, abrupt motion, heavy occlusion and out-of-view. In this setting, we decompose the task of tracking into translation and scale estimation of objects. We show that the correlation between temporal context considerably improves the accuracy and reliability for translation estimation, and it is effective to learn discriminative correlation filters from the most confident frames to estimate the scale change. In addition, we train an online random fern classifier to re-detect objects in case of tracking failure. Extensive experimental results on large-scale benchmark datasets show that the proposed algorithm performs favorably against state-of-the-art methods in terms of efficiency, accuracy, and robustness.", "PublicationYear": "2015", "Authors": ["Chao Ma", "Xiaokang Yang", "Chongyang Zhang", "Ming-Hsuan Yang"], "RelatedTopics": ["Computer Science"], "References": ["1c721511e4c0e21bd264ca71c0d909528511b7ad", "9d57723b4908397654fb1846d37db403d8b2b56a", "32e741784688cf4209263666e50bc8187e0b00a0", "c63a34ac6a4e049118070e707ca7679fbb132d33", "0b104e517e0440e3bdace01b5f6706c5fa944149", "23d17cf651ced54ae538ce994ccb83b7ea2a94d3", "16e36a4b59e214786737aa4ebc3ba86075b61e49", "7069a994c150b0228c4e471ca48ed55d7646bc62", "9ea03a9cb11bdc68ac2f56e290c8486868511476", "caa0fd34e50bb417fae3ee32f667e78fe5b198bc"], "ReferenceCount": 30, "CitationCount": 884}, {"URL": "https://www.semanticscholar.org/paper/Tracking-for-Half-an-Hour-Tao-Gavves/d3d36c3caa255053877a7e3250d47d906eec81d2", "ID": "d3d36c3caa255053877a7e3250d47d906eec81d2", "Title": "Tracking for Half an Hour", "Abstract": "On 10 new half-an-hour videos with city bicycling, sport games etc, the proposed tracker outperforms others by a large margin where the 2010 TLD tracker comes second. Long-term tracking requires extreme stability to the multitude of model updates and robustness to the disappearance and loss of the target as such will inevitably happen. For motivation, we have taken 10 randomly selected OTB-sequences, doubled each by attaching a reversed version and repeated each double sequence 20 times. On most of these repetitive videos, the best current tracker performs worse on each loop. This illustrates the difference between optimization for short-term versus long-term tracking. In a long-term tracker a combined global and local search strategy is beneficial, allowing for recovery from failures and disappearance. Most importantly, the proposed tracker also employs cautious updating, guided by self-quality assessment. The proposed tracker is still among the best on the 20-sec OTB-videos while achieving state-of-the-art on the 100-sec UAV20L benchmark. On 10 new half-an-hour videos with city bicycling, sport games etc, the proposed tracker outperforms others by a large margin where the 2010 TLD tracker comes second.", "PublicationYear": "2017", "Authors": ["Ran Tao", "Efstratios Gavves", "Arnold W. M. Smeulders"], "RelatedTopics": ["Computer Science"], "References": ["1c721511e4c0e21bd264ca71c0d909528511b7ad", "4cbe61862bb95fc99293c24d6e02afcb50a05461", "001d36f857ae634b98e8c629853df324c21f323f", "d20d7d3490fd970992b3631048c75a8c5fe2e4e3", "13141284f1a7e1fe255f5c2b22c09e32f0a4d465", "754504cf01ef3846259783e748b1d3ea52fa2c81", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "c316d5ec14e5768d7eda3d8916bddc1de142a1c2", "c63a34ac6a4e049118070e707ca7679fbb132d33", "70c3c9b9a40ca55264e454586dca2a6cf416f6e0"], "ReferenceCount": 32, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/Fully-Convolutional-Siamese-Networks-for-Object-Bertinetto-Valmadre/29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "ID": "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "Title": "Fully-Convolutional Siamese Networks for Object Tracking", "Abstract": "A basic tracking algorithm is equipped with a novel fully-convolutional Siamese network trained end-to-end on the ILSVRC15 dataset for object detection in video and achieves state-of-the-art performance in multiple benchmarks. The problem of arbitrary object tracking has traditionally been tackled by learning a model of the object\u2019s appearance exclusively online, using as sole training data the video itself. Despite the success of these methods, their online-only approach inherently limits the richness of the model they can learn. Recently, several attempts have been made to exploit the expressive power of deep convolutional networks. However, when the object to track is not known beforehand, it is necessary to perform Stochastic Gradient Descent online to adapt the weights of the network, severely compromising the speed of the system. In this paper we equip a basic tracking algorithm with a novel fully-convolutional Siamese network trained end-to-end on the ILSVRC15 dataset for object detection in video. Our tracker operates at frame-rates beyond real-time and, despite its extreme simplicity, achieves state-of-the-art performance in multiple benchmarks.", "PublicationYear": "2016", "Authors": ["Luca Bertinetto", "Jack Valmadre", "Jo{\\~a}o F. Henriques", "Andrea Vedaldi", "Philip H. S. Torr"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "3dc60732c1c08165c9d4e7b334ce66e511474bb2", "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0", "4f445f3e44f2f2ffb431cf1414c59ccba5a0b27d", "5c8a6874011640981e4103d120957802fa28f004", "e3c433ab9608d7329f944552ba1721e277a42d74", "9ad8c207d66553d0fa7a7cb57c5e1be12896d1d9", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "421bf4eeba623f722bf98340d71e3d229881e92d", "09769e80cdf027db32a1fcb695a1aa0937214763"], "ReferenceCount": 51, "CitationCount": 3330}, {"URL": "https://www.semanticscholar.org/paper/Fast-and-Accurate-Online-Video-Object-Segmentation-Cheng-Tsai/12fae9a2c1ed867997e1ca70eba271b3c741c42f", "ID": "12fae9a2c1ed867997e1ca70eba271b3c741c42f", "Title": "Fast and Accurate Online Video Object Segmentation via Tracking Parts", "Abstract": "This paper proposes a fast and accurate video object segmentation algorithm that can immediately start the segmentation process once receiving the images, and performs favorably against state-of-the-art algorithms in accuracy on the DAVIS benchmark dataset, while achieving much faster runtime performance. Online video object segmentation is a challenging task as it entails to process the image sequence timely and accurately. To segment a target object through the video, numerous CNN-based methods have been developed by heavily finetuning on the object mask in the first frame, which is time-consuming for online applications. In this paper, we propose a fast and accurate video object segmentation algorithm that can immediately start the segmentation process once receiving the images. We first utilize a part-based tracking method to deal with challenging factors such as large deformation, occlusion, and cluttered background. Based on the tracked bounding boxes of parts, we construct a region-of-interest segmentation network to generate part masks. Finally, a similarity-based scoring function is adopted to refine these object parts by comparing them to the visual information in the first frame. Our method performs favorably against state-of-the-art algorithms in accuracy on the DAVIS benchmark dataset, while achieving much faster runtime performance.", "PublicationYear": "2018", "Authors": ["Jingchun Cheng", "Yi-Hsuan Tsai", "Wei-Chih Hung", "Shengjin Wang", "Ming-Hsuan Yang"], "RelatedTopics": ["Computer Science"], "References": ["0d4b8f60be18585a1d199c63199f99c43d10b7de", "1190e0210430e8b743af24cdc43efdeef407b669", "19351b059b2fabafd885322d26a39ed469265654", "ccb9ffa26b28dffc4f7d613821d1a9f0d60ea3f4", "cb1c0d6be4c22c1f18b0ba20dddd93890f17add6", "b2bf41bf5e5e44d746c1cac3edd058d7d346980e", "2f25511948004e9dd4252f7a35dc95556c133b42", "c38dbf0bb5a1615b95dc6d3dbc0733dbcd8cf92e", "a213ec900a4e245f31413dc35c2c2e9ae2f09c88", "203ea8ab1d9c48977be97e6caf3fdbcc84101354"], "ReferenceCount": 47, "CitationCount": 218}, {"URL": "https://www.semanticscholar.org/paper/Fast-Online-Object-Tracking-and-Segmentation%3A-A-Wang-Zhang/d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1", "ID": "d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1", "Title": "Fast Online Object Tracking and Segmentation: A Unifying Approach", "Abstract": "This method improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting their loss with a binary segmentation task, and operates online, producing class-agnostic object segmentation masks and rotated bounding boxes at 55 frames per second. In this paper we illustrate how to perform both visual object tracking and semi-supervised video object segmentation, in real-time, with a single simple approach. Our method, dubbed SiamMask, improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting their loss with a binary segmentation task. Once trained, SiamMask solely relies on a single bounding box initialisation and operates online, producing class-agnostic object segmentation masks and rotated bounding boxes at 55 frames per second. Despite its simplicity, versatility and fast speed, our strategy allows us to establish a new state-of-the-art among real-time trackers on VOT-2018, while at the same time demonstrating competitive performance and the best speed for the semi-supervised video object segmentation task on DAVIS-2016 and DAVIS-2017.", "PublicationYear": "2018", "Authors": ["Qiang Wang", "Li Zhang", "Luca Bertinetto", "Weiming Hu", "Philip H. S. Torr"], "RelatedTopics": ["Computer Science"], "References": ["e8e7eb0ef502d5a456b2d573eb290791e7657b76", "12fae9a2c1ed867997e1ca70eba271b3c741c42f", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "1190e0210430e8b743af24cdc43efdeef407b669", "cb1c0d6be4c22c1f18b0ba20dddd93890f17add6", "3d98b9822e6efc2eec421e0bfd7546fd4ba30407", "4960ab1cef23e5ccd60173725ea280f462164a0e", "320d05db95ab42ade69294abe46cd1aca6aca602", "ccb9ffa26b28dffc4f7d613821d1a9f0d60ea3f4", "4a70c20ad66e5f3bb12fccd84c63ba619053c811"], "ReferenceCount": 78, "CitationCount": 1037}, {"URL": "https://www.semanticscholar.org/paper/UvA-DARE-(Digital-Academic-Repository)-Siamese-for-Tao-Gavves/c316d5ec14e5768d7eda3d8916bddc1de142a1c2", "ID": "c316d5ec14e5768d7eda3d8916bddc1de142a1c2", "Title": "UvA-DARE (Digital Academic Repository) Siamese Instance Search for Tracking", "Abstract": "It turns out that the learned matching function is so powerful that a simple tracker built upon it, coined Siamese INstance search Tracker, SINT, which only uses the original observation of the target from the first frame to reach state-of-the-art performance. In this paper we present a tracker, which is radically different from state-of-the-art trackers: we apply no model updating, no occlusion detection, no combination of trackers, no geometric matching, and still deliver state-of-the-art tracking performance, as demonstrated on the popular online tracking benchmark (OTB) and six very challenging YouTube videos. The presented tracker simply matches the initial patch of the target in the \ufb01rst frame with candidates in a new frame and returns the most similar patch by a learned matching function. The strength of the matching function comes from being extensively trained generically, i.e. , without any data of the target, using a Siamese deep neural network, which we design for tracking. Once learned, the matching function is used as is, without any adapting, to track previously unseen targets. It turns out that the learned matching function is so powerful that a simple tracker built upon it, coined Siamese INstance search Tracker, SINT , which only uses the original observation of the target from the \ufb01rst frame, suf\ufb01ces to reach state-of-the-art performance. Further, we show the proposed tracker even allows for target re-identi\ufb01cation after the target was absent for a complete video shot.", "PublicationYear": "2016", "Authors": ["Ran Tao", "Efstratios Gavves", "Arnold W. M. Smeulders"], "RelatedTopics": ["Computer Science"], "References": ["b2180fc4f5cb46b5b5394487842399c501381d67", "1b3a107739e7f7e05c50999a3d79b8225746f662", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "13141284f1a7e1fe255f5c2b22c09e32f0a4d465", "fe2aaad872a2cf08c09dd52ca972f323666306db", "e3c433ab9608d7329f944552ba1721e277a42d74", "1980ed2beae0e6437eb3d2987a5b4828bb84e939", "61394599ed0aabe04b724c7ca3a778825c7e776f", "b762ecb0624005831f2f3d8eb626d53e8eca4b6c", "e73590fdfd6dab391111bb734053ae24207e2c71"], "ReferenceCount": 58, "CitationCount": 792}, {"URL": "https://www.semanticscholar.org/paper/Object-Tracking-by-Reconstruction-With-Correlation-Kart-Luke%C5%BEi%C4%8D/f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914", "ID": "f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914", "Title": "Object Tracking by Reconstruction With View-Specific Discriminative Correlation Filters", "Abstract": "The proposed long-term RGB-D tracker called OTR \u2013 Object Tracking by Reconstruction performs online 3D target reconstruction to facilitate robust learning of a set of view-specific discriminative correlation filters (DCFs). Standard RGB-D trackers treat the target as a 2D structure, which makes modelling appearance changes related even to out-of-plane rotation challenging. This limitation is addressed by the proposed long-term RGB-D tracker called OTR \u2013 Object Tracking by Reconstruction. OTR performs online 3D target reconstruction to facilitate robust learning of a set of view-specific discriminative correlation filters (DCFs). The 3D reconstruction supports two performance- enhancing features: (i) generation of an accurate spatial support for constrained DCF learning from its 2D projection and (ii) point-cloud based estimation of 3D pose change for selection and storage of view-specific DCFs which robustly localize the target after out-of-view rotation or heavy occlusion. Extensive evaluation on the Princeton RGB-D tracking and STC Benchmarks shows OTR outperforms the state-of-the-art by a large margin.", "PublicationYear": "2018", "Authors": ["Ugur Kart", "Alan Luke{\\vz}i{\\vc}", "Matej Kristan", "J. K{\\\"a}m{\\\"a}r{\\\"a}inen", "Jiri Matas"], "RelatedTopics": ["Computer Science"], "References": ["d10861d377be150b1e03cb942deb8763095de88f", "3f02406b9b59d6f966c735953930fede1d751d0d", "c06ecdf5b149c322db0381adb6b3fd5ccb31a720", "3b75cf84255fce6bdc1fe998761a115437c84c77", "17f2d1221e7a700e26bf8d5c17ca6fec9275439e", "965b01ffc25e643acd16e91dd74ed0d1879f99ec", "ce8c76bfedc5d86faabf0d49dc42a4924f75876d", "70c3c9b9a40ca55264e454586dca2a6cf416f6e0", "8cc3651488e02d51fa5ae8d3563b346e9e370f5a", "487eb86379e979a72ebfef67db6eb8f048d1d258"], "ReferenceCount": 40, "CitationCount": 66}, {"URL": "https://www.semanticscholar.org/paper/TrackingNet%3A-A-Large-Scale-Dataset-and-Benchmark-in-M%C3%BCller-Bibi/8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b", "ID": "8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b", "Title": "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild", "Abstract": "This work presents TrackingNet, the first large-scale dataset and benchmark for object tracking in the wild, which covers a wide selection of object classes in broad and diverse context and provides an extensive benchmark on TrackingNet by evaluating more than 20 trackers. Despite the numerous developments in object tracking, further improvement of current tracking algorithms is limited by small and mostly saturated datasets. As a matter of fact, data-hungry trackers based on deep-learning currently rely on object detection datasets due to the scarcity of dedicated large-scale tracking datasets. In this work, we present TrackingNet, the first large-scale dataset and benchmark for object tracking in the wild. We provide more than 30K videos with more than 14 million dense bounding box annotations. Our dataset covers a wide selection of object classes in broad and diverse context. By releasing such a large-scale dataset, we expect deep trackers to further improve and generalize. In addition, we introduce a new benchmark composed of 500 novel videos, modeled with a distribution similar to our training dataset. By sequestering the annotation of the test set and providing an online evaluation server, we provide a fair benchmark for future development of object trackers. Deep trackers fine-tuned on a fraction of our dataset improve their performance by up to 1.6% on OTB100 and up to 1.7% on TrackingNet Test. We provide an extensive benchmark on TrackingNet by evaluating more than 20 trackers. Our results suggest that object tracking in the wild is far from being solved.", "PublicationYear": "2018", "Authors": ["Matthias M{\\\"u}ller", "Adel Bibi", "Silvio Giancola", "Salman Al-Subaihi", "Bernard Ghanem"], "RelatedTopics": ["Computer Science"], "References": ["5bae9822d703c585a61575dced83fa2f4dea1c6d", "703505a00579c0aa67712836acc41d94fa6d6edc", "4b1a47709d0546e5bc614bf9a521c550e6881d04", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "6179ac06f1a8fd1ac6b693b02824948dff438d54", "ac0d88ca5f75a4a80da90365c28fa26f1a26d4c4", "c4c45661501c16064eead6e5d37dcb80d41c7a78", "3c74b636c0f74c1a0cbbd6e165c2760264044971", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "7574b7e5a75fdd338c27af5aeb77ab79460c4437"], "ReferenceCount": 46, "CitationCount": 559}, {"URL": "https://www.semanticscholar.org/paper/Deformable-Parts-Correlation-Filters-for-Robust-Luke%C5%BEi%C4%8D-Zajc/b3249763ac9ecc4df6ef96721c8c7410e0f0468a", "ID": "b3249763ac9ecc4df6ef96721c8c7410e0f0468a", "Title": "Deformable Parts Correlation Filters for Robust Visual Tracking", "Abstract": "A new formulation of the constellation model with correlation filters that treats the geometric and visual constraints within a single convex cost function and derive a highly efficient optimization for maximum a posteriori inference of a fully connected constellation is presented. Deformable parts models show a great potential in tracking by principally addressing nonrigid object deformations and self occlusions, but according to recent benchmarks, they often lag behind the holistic approaches. The reason is that potentially large number of degrees of freedom have to be estimated for object localization and simplifications of the constellation topology are often assumed to make the inference tractable. We present a new formulation of the constellation model with correlation filters that treats the geometric and visual constraints within a single convex cost function and derive a highly efficient optimization for maximum a posteriori inference of a fully connected constellation. We propose a tracker that models the object at two levels of detail. The coarse level corresponds a root correlation filter and a novel color model for approximate object localization, while the mid-level representation is composed of the new deformable constellation of correlation filters that refine the object location. The resulting tracker is rigorously analyzed on a highly challenging OTB, VOT2014, and VOT2015 benchmarks, exhibits a state-of-the-art performance and runs in real-time.", "PublicationYear": "2016", "Authors": ["Alan Luke{\\vz}i{\\vc}", "Luka {\\vC}ehovin Zajc", "Matej Kristan"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["63b293b346b5f1c04b6716dfb00b8b343e2a1972", "13141284f1a7e1fe255f5c2b22c09e32f0a4d465", "236d4de0b1c73217238f370e7d30243c7ee9707a", "a9448de3265ed9ecdc11c79273aee92daa31f79a", "93a163e4527741fc2027baeaa586d09af12f3a6c", "70c3c9b9a40ca55264e454586dca2a6cf416f6e0", "9d57723b4908397654fb1846d37db403d8b2b56a", "f6f6617ce6270df934403c18517ecfb10d51f438", "e684b61e3bc1a9b34dc52a3c42aaca19e48bcbca", "1183db5f409e8498d1a0f542703f908275a6dc34"], "ReferenceCount": 63, "CitationCount": 109}, {"URL": "https://www.semanticscholar.org/paper/VideoMatch%3A-Matching-based-Video-Object-Hu-Huang/8b74008565b575f9ab7a0962ca5f6955d64db045", "ID": "8b74008565b575f9ab7a0962ca5f6955d64db045", "Title": "VideoMatch: Matching based Video Object Segmentation", "Abstract": "This work develops a novel matching based algorithm for video object segmentation that learns to match extracted features to a provided template without memorizing the appearance of the objects. Video object segmentation is challenging yet important in a wide variety of applications for video analysis. Recent works formulate video object segmentation as a prediction task using deep nets to achieve appealing state-of-the-art performance. Due to the formulation as a prediction task, most of these methods require fine-tuning during test time, such that the deep nets memorize the appearance of the objects of interest in the given video. However, fine-tuning is time-consuming and computationally expensive, hence the algorithms are far from real time. To address this issue, we develop a novel matching based algorithm for video object segmentation. In contrast to memorization based classification techniques, the proposed approach learns to match extracted features to a provided template without memorizing the appearance of the objects. We validate the effectiveness and the robustness of the proposed method on the challenging DAVIS-16, DAVIS-17, Youtube-Objects and JumpCut datasets. Extensive results show that our method achieves comparable performance without fine-tuning and is much more favorable in terms of computational time.", "PublicationYear": "2018", "Authors": ["Yuan-Ting Hu", "Jia-Bin Huang", "Alexander G. Schwing"], "RelatedTopics": ["Computer Science"], "References": ["12fae9a2c1ed867997e1ca70eba271b3c741c42f", "4a70c20ad66e5f3bb12fccd84c63ba619053c811", "1190e0210430e8b743af24cdc43efdeef407b669", "ccb9ffa26b28dffc4f7d613821d1a9f0d60ea3f4", "49b0e4c5558233431d8babc547d2aeac679adc78", "cf56a043577e41e5e33a4722352108660f80258f", "cb1c0d6be4c22c1f18b0ba20dddd93890f17add6", "d710777495f51144c5b9f0a7372d16e3843e1b25", "493670df447aab3b305411c6c352c91eb7021ecb", "e8e7eb0ef502d5a456b2d573eb290791e7657b76"], "ReferenceCount": 62, "CitationCount": 224}, {"URL": "https://www.semanticscholar.org/paper/Efficient-Video-Object-Segmentation-via-Network-Yang-Wang/4a70c20ad66e5f3bb12fccd84c63ba619053c811", "ID": "4a70c20ad66e5f3bb12fccd84c63ba619053c811", "Title": "Efficient Video Object Segmentation via Network Modulation", "Abstract": "This work proposes a novel approach that uses a single forward pass to adapt the segmentation model to the appearance of a specific object and is 70\u00c3\u2014 faster than fine-tuning approaches and achieves similar accuracy. Video object segmentation targets segmenting a specific object throughout a video sequence when given only an annotated first frame. Recent deep learning based approaches find it effective to fine-tune a general-purpose segmentation model on the annotated frame using hundreds of iterations of gradient descent. Despite the high accuracy that these methods achieve, the fine-tuning process is inefficient and fails to meet the requirements of real world applications. We propose a novel approach that uses a single forward pass to adapt the segmentation model to the appearance of a specific object. Specifically, a second meta neural network named modulator is trained to manipulate the intermediate layers of the segmentation network given limited visual and spatial information of the target object. The experiments show that our approach is 70\u00c3\u2014 faster than fine-tuning approaches and achieves similar accuracy. Our model and code have been released at https://github.com/linjieyangsc/video_seg.", "PublicationYear": "2018", "Authors": ["L. Yang", "Yanran Wang", "Xuehan Xiong", "Jianchao Yang", "Aggelos K. Katsaggelos"], "RelatedTopics": ["Computer Science"], "References": ["1190e0210430e8b743af24cdc43efdeef407b669", "49b0e4c5558233431d8babc547d2aeac679adc78", "cb1c0d6be4c22c1f18b0ba20dddd93890f17add6", "ab494d4f2e8f4efb830f15d78cd68ef7f355c76b", "19351b059b2fabafd885322d26a39ed469265654", "9c373b1a7d3a987ceca9d33919725ec4bb290683", "c38dbf0bb5a1615b95dc6d3dbc0733dbcd8cf92e", "72c189a6cfa94e90e4c9275bd50f21df10732a04", "203ea8ab1d9c48977be97e6caf3fdbcc84101354", "05e9e85b5137016c93d042170e82f77bb551a108"], "ReferenceCount": 40, "CitationCount": 304}, {"URL": "https://www.semanticscholar.org/paper/UCT%3A-Learning-Unified-Convolutional-Networks-for-Zhu-Huang/1131c53b9baaa740a4deef4c1282821b23d18687", "ID": "1131c53b9baaa740a4deef4c1282821b23d18687", "Title": "UCT: Learning Unified Convolutional Networks for Real-Time Visual Tracking", "Abstract": "The UCT treats feature extractor and tracking process (ridge regression) both as convolution operation and trains them jointly, enabling learned CNN features are tightly coupled to tracking process and results in superior tracking performance, while maintaining real-time speed. Convolutional neural networks (CNN) based tracking approaches have shown favorable performance in recent benchmarks. Nonetheless, the chosen CNN features are always pre-trained in different task and individual components in tracking systems are learned separately, thus the achieved tracking performance may be suboptimal. Besides, most of these trackers are not designed towards realtime applications because of their time-consuming feature extraction and complex optimization details. In this paper, we propose an end-to-end framework to learn the convolutional features and perform the tracking process simultaneously, namely, a unified convolutional tracker (UCT). Specifically, The UCT treats feature extractor and tracking process (ridge regression) both as convolution operation and trains them jointly, enabling learned CNN features are tightly coupled to tracking process. In online tracking, an efficient updating method is proposed by introducing peak-versus-noise ratio (PNR) criterion, and scale changes are handled efficiently by incorporating a scale branch into network. The proposed approach results in superior tracking performance, while maintaining real-time speed. The standard UCT and UCT-Lite can track generic objects at 41 FPS and 154 FPS without further optimization, respectively. Experiments are performed on four challenging benchmark tracking datasets: OTB2013, OTB2015, VOT2014 and VOT2015, and our method achieves state-of-the-art results on these benchmarks compared with other real-time trackers.", "PublicationYear": "2017", "Authors": ["Zheng Zhu", "Guan Huang", "Wei Zou", "Dalong Du", "Chang Huang"], "RelatedTopics": ["Computer Science"], "References": ["bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "b2180fc4f5cb46b5b5394487842399c501381d67", "2ce63d77eecc35faef85a3b752a314c93a077ac9", "c46b08850b9c458704a3ca69172e6a0d40a6cb7f", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "5c8a6874011640981e4103d120957802fa28f004", "01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c", "09769e80cdf027db32a1fcb695a1aa0937214763"], "ReferenceCount": 49, "CitationCount": 77}, {"URL": "https://www.semanticscholar.org/paper/End-to-End-Flow-Correlation-Tracking-with-Attention-Zhu-Wu/7ccbb845829234548bfa9b24c61297b4f0cd678e", "ID": "7ccbb845829234548bfa9b24c61297b4f0cd678e", "Title": "End-to-End Flow Correlation Tracking with Spatial-Temporal Attention", "Abstract": "The FlowTrack is proposed, which focuses on making use of the rich flow information in consecutive frames to improve the feature representation and the tracking accuracy and is the first work to jointly train flow and tracking task in deep learning framework. Discriminative correlation filters (DCF) with deep convolutional features have achieved favorable performance in recent tracking benchmarks. However, most of existing DCF trackers only consider appearance features of current frame, and hardly benefit from motion and inter-frame information. The lack of temporal information degrades the tracking performance during challenges such as partial occlusion and deformation. In this paper, we propose the FlowTrack, which focuses on making use of the rich flow information in consecutive frames to improve the feature representation and the tracking accuracy. The FlowTrack formulates individual components, including optical flow estimation, feature extraction, aggregation and correlation filters tracking as special layers in network. To the best of our knowledge, this is the first work to jointly train flow and tracking task in deep learning framework. Then the historical feature maps at predefined intervals are warped and aggregated with current ones by the guiding of flow. For adaptive aggregation, we propose a novel spatial-temporal attention mechanism. In experiments, the proposed method achieves leading performance on OTB2013, OTB2015, VOT2015 and VOT2016.", "PublicationYear": "2017", "Authors": ["Zheng Zhu", "Wei Wu", "Wei Zou", "Junjie Yan"], "RelatedTopics": ["Computer Science"], "References": ["0246f6754c38324a837c0ebd1b51976f413f80ad", "311bc4e48838d8e5ef619df3ce0bc598aba788a1", "5404718135548b01516a668e0c022c5cb22b422e", "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64", "1131c53b9baaa740a4deef4c1282821b23d18687", "01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c", "754504cf01ef3846259783e748b1d3ea52fa2c81", "8cc3651488e02d51fa5ae8d3563b346e9e370f5a", "2e7e3b4eb8bc0a7f29ca560b1cceb986a1dcd977", "a87cc499cf101b3697cacc65094b4b6590e0d061"], "ReferenceCount": 61, "CitationCount": 249}, {"URL": "https://www.semanticscholar.org/paper/DCFNet%3A-Discriminant-Correlation-Filters-Network-Wang-Gao/5404718135548b01516a668e0c022c5cb22b422e", "ID": "5404718135548b01516a668e0c022c5cb22b422e", "Title": "DCFNet: Discriminant Correlation Filters Network for Visual Tracking", "Abstract": "This work presents an end-to-end lightweight network architecture, namely DCFNet, to learn the convolutional features and perform the correlation tracking process simultaneously, and treats DCF as a special correlation filter layer added in a Siamese network. Discriminant Correlation Filters (DCF) based methods now become a kind of dominant approach to online object tracking. The features used in these methods, however, are either based on hand-crafted features like HoGs, or convolutional features trained independently from other tasks like image classification. In this work, we present an end-to-end lightweight network architecture, namely DCFNet, to learn the convolutional features and perform the correlation tracking process simultaneously. Specifically, we treat DCF as a special correlation filter layer added in a Siamese network, and carefully derive the backpropagation through it by defining the network output as the probability heatmap of object location. Since the derivation is still carried out in Fourier frequency domain, the efficiency property of DCF is preserved. This enables our tracker to run at more than 60 FPS during test time, while achieving a significant accuracy gain compared with KCF using HoGs. Extensive evaluations on OTB-2013, OTB-2015, and VOT2015 benchmarks demonstrate that the proposed DCFNet tracker is competitive with several state-of-the-art trackers, while being more compact and much faster.", "PublicationYear": "2017", "Authors": ["Qiang Wang", "Jin Gao", "Junliang Xing", "Mengdan Zhang", "Weiming Hu"], "RelatedTopics": ["Computer Science"], "References": ["311bc4e48838d8e5ef619df3ce0bc598aba788a1", "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0", "b2180fc4f5cb46b5b5394487842399c501381d67", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "09769e80cdf027db32a1fcb695a1aa0937214763", "65c9b4b1d49f46b3f8f64a5f617acfc14f85d031", "5c8a6874011640981e4103d120957802fa28f004", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "5b4e50860d61095bb5fb65eaa367b131923917be", "0f12a3aaf3851078d93a9bba4e3ebece6d4bcfe5"], "ReferenceCount": 38, "CitationCount": 313}, {"URL": "https://www.semanticscholar.org/paper/CREST%3A-Convolutional-Residual-Learning-for-Visual-Song-Ma/c2046fc4744a9d358ea7a8e9c21c92fd58df7a64", "ID": "c2046fc4744a9d358ea7a8e9c21c92fd58df7a64", "Title": "CREST: Convolutional Residual Learning for Visual Tracking", "Abstract": "This paper proposes the CREST algorithm to reformulate DCFs as a one-layer convolutional neural network, and applies residual learning to take appearance changes into account to reduce model degradation during online update. Discriminative correlation filters (DCFs) have been shown to perform superiorly in visual tracking. They only need a small set of training samples from the initial frame to generate an appearance model. However, existing DCFs learn the filters separately from feature extraction, and update these filters using a moving average operation with an empirical weight. These DCF trackers hardly benefit from the end-to-end training. In this paper, we propose the CREST algorithm to reformulate DCFs as a one-layer convolutional neural network. Our method integrates feature extraction, response map generation as well as model update into the neural networks for an end-to-end training. To reduce model degradation during online update, we apply residual learning to take appearance changes into account. Extensive experiments on the benchmark datasets demonstrate that our CREST tracker performs favorably against state-of-the-art trackers.", "PublicationYear": "2017", "Authors": ["Yibing Song", "Chao Ma", "Lijun Gong", "Jiawei Zhang", "Rynson W. H. Lau", "Ming-Hsuan Yang"], "RelatedTopics": ["Computer Science"], "References": ["311bc4e48838d8e5ef619df3ce0bc598aba788a1", "1b3a107739e7f7e05c50999a3d79b8225746f662", "b2180fc4f5cb46b5b5394487842399c501381d67", "09769e80cdf027db32a1fcb695a1aa0937214763", "5c8a6874011640981e4103d120957802fa28f004", "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "87283935f0eec5ddc0e5ad3062568df8eb89e7e0", "9ea03a9cb11bdc68ac2f56e290c8486868511476"], "ReferenceCount": 51, "CitationCount": 473}, {"URL": "https://www.semanticscholar.org/paper/Siamese-Instance-Search-for-Tracking-Tao-Gavves/4f445f3e44f2f2ffb431cf1414c59ccba5a0b27d", "ID": "4f445f3e44f2f2ffb431cf1414c59ccba5a0b27d", "Title": "Siamese Instance Search for Tracking", "Abstract": "It turns out that the learned matching function is so powerful that a simple tracker built upon it, coined Siamese INstance search Tracker, SINT, suffices to reach state-of-the-art performance. In this paper we present a tracker, which is radically different from state-of-the-art trackers: we apply no model updating, no occlusion detection, no combination of trackers, no geometric matching, and still deliver state-of-the-art tracking performance, as demonstrated on the popular online tracking benchmark (OTB) and six very challenging YouTube videos. The presented tracker simply matches the initial patch of the target in the first frame with candidates in a new frame and returns the most similar patch by a learned matching function. The strength of the matching function comes from being extensively trained generically, i.e., without any data of the target, using a Siamese deep neural network, which we design for tracking. Once learned, the matching function is used as is, without any adapting, to track previously unseen targets. It turns out that the learned matching function is so powerful that a simple tracker built upon it, coined Siamese INstance search Tracker, SINT, which only uses the original observation of the target from the first frame, suffices to reach state-of-the-art performance. Further, we show the proposed tracker even allows for target re-identification after the target was absent for a complete video shot.", "PublicationYear": "2016", "Authors": ["Ran Tao", "Efstratios Gavves", "Arnold W. M. Smeulders"], "RelatedTopics": ["Computer Science"], "References": ["b2180fc4f5cb46b5b5394487842399c501381d67", "b762ecb0624005831f2f3d8eb626d53e8eca4b6c", "13141284f1a7e1fe255f5c2b22c09e32f0a4d465", "5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb", "1b3a107739e7f7e05c50999a3d79b8225746f662", "fe2aaad872a2cf08c09dd52ca972f323666306db", "61394599ed0aabe04b724c7ca3a778825c7e776f", "505f48d8236eb25f871da272c2ac2fe4b41ea289", "b5e17a0ed14349d6c4066d2408409751f9595e04", "56994ddebc111846dd862ca832479de5692ac9f1"], "ReferenceCount": 61, "CitationCount": 192}, {"URL": "https://www.semanticscholar.org/paper/Faster-R-CNN%3A-Towards-Real-Time-Object-Detection-Ren-He/424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "ID": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "Title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "Abstract": "This work introduces a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals and further merge RPN and Fast R-CNN into a single network by sharing their convolutionAL features. State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available", "PublicationYear": "2015", "Authors": ["Shaoqing Ren", "Kaiming He", "Ross B. Girshick", "Jian Sun"], "RelatedTopics": ["Computer Science"], "References": ["7ffdbc358b63378f07311e883dddacc9faeeaf4b", "a0afd098e7f56ae5e68ee2c95c2566af28064d54", "67fc0ec1d26f334b05fe66d2b7e0767b60fb73b6", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "f075f89b4f4026748cbf2fb9f989a9934c42ee8f", "3ad998a9b2c071c4a1971048f8a2d754530f08e8", "6b8d0df903496699e52b4daee5d1815b7b784cf7", "b07f1d518d08012b9d12eaead0fdb6234e71a680", "1e9b1f6061ef779e3ad0819c2832a29168eaeb9d", "4328ec9d98eff5d7eb70997f76d81b27849f3220"], "ReferenceCount": 48, "CitationCount": 49884}, {"URL": "https://www.semanticscholar.org/paper/Re3-%3A-Real-Time-Recurrent-Regression-Networks-for-Gordon-Farhadi/dda27eb7ddc4510f94cac0e5134b5d56aa77b075", "ID": "dda27eb7ddc4510f94cac0e5134b5d56aa77b075", "Title": "Re3 : Real-Time Recurrent Regression Networks for Object Tracking", "Abstract": "This work presents Re3, a real-time deep object tracker capable of incorporating long-term temporal information into its model, using a recurrent neural network to represent the appearance and motion of the object. Robust object tracking requires knowledge and understanding of the object being tracked: its appearance, its motion, and how it changes over time. A tracker must be able to modify its underlying model and adapt to new observations. We present Re3, a real-time deep object tracker capable of incorporating long-term temporal information into its model. In line with other recent deep learning techniques, we do not train an online tracker. Instead, we use a recurrent neural network to represent the appearance and motion of the object. We train the network offline to learn how an object's appearance and motion may change, letting it track with a single forward pass at test time. This lightweight model is capable of tracking objects at 150 FPS, while attaining competitive results on challenging benchmarks. We also show that our method handles temporary occlusion better than other comparable trackers using experiments that directly measure performance on sequences with occlusion.", "PublicationYear": "2017", "Authors": ["Daniel Gordon", "Ali Farhadi", "Dieter Fox"], "RelatedTopics": ["Computer Science"], "References": ["5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "29d1b9a6e6ff0a4216d10dd31376467d55e788a3", "9ad8c207d66553d0fa7a7cb57c5e1be12896d1d9", "421bf4eeba623f722bf98340d71e3d229881e92d", "9926020dda21874dc7a5ef1511bae6c4cef5ecb9", "61394599ed0aabe04b724c7ca3a778825c7e776f", "c4e7e62b3a3eb100b441674ad3817d9a24239e2a", "e73590fdfd6dab391111bb734053ae24207e2c71", "c63a34ac6a4e049118070e707ca7679fbb132d33", "e3c433ab9608d7329f944552ba1721e277a42d74"], "ReferenceCount": 67, "CitationCount": 49}, {"URL": "https://www.semanticscholar.org/paper/Learning-to-Track-at-100-FPS-with-Deep-Regression-Held-Thrun/5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "ID": "5f0850ec47a17f22ba2611a5cb67a30cb02cf306", "Title": "Learning to Track at 100 FPS with Deep Regression Networks", "Abstract": "This work proposes a method for offline training of neural networks that can track novel objects at test-time at 100 fps, which is significantly faster than previous methods that use neural networks for tracking, which are typically very slow to run and not practical for real-time applications. Machine learning techniques are often used in computer vision due to their ability to leverage large amounts of training data to improve performance. Unfortunately, most generic object trackers are still trained from scratch online and do not benefit from the large number of videos that are readily available for offline training. We propose a method for offline training of neural networks that can track novel objects at test-time at 100 fps. Our tracker is significantly faster than previous methods that use neural networks for tracking, which are typically very slow to run and not practical for real-time applications. Our tracker uses a simple feed-forward network with no online training required. The tracker learns a generic relationship between object motion and appearance and can be used to track novel objects that do not appear in the training set. We test our network on a standard tracking benchmark to demonstrate our tracker's state-of-the-art performance. Further, our performance improves as we add more videos to our offline training set. To the best of our knowledge, our tracker is the first neural-network tracker that learns to track generic objects at 100 fps.", "PublicationYear": "2016", "Authors": ["David Held", "Sebastian Thrun", "Silvio Savarese"], "RelatedTopics": ["Computer Science"], "References": ["b2180fc4f5cb46b5b5394487842399c501381d67", "084bd219dd239dc4c9a02621a5333d3bc1446566", "6b734966d75d5ed9b5d29340a67eb5daffa43e1d", "1b3a107739e7f7e05c50999a3d79b8225746f662", "421bf4eeba623f722bf98340d71e3d229881e92d", "b181771a2ab846bb237479dfe4a687e5f312b4f5", "9cf3c67529085d31c646091b97be1a1e3dc191f2", "bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0", "e3c433ab9608d7329f944552ba1721e277a42d74", "4f445f3e44f2f2ffb431cf1414c59ccba5a0b27d"], "ReferenceCount": 52, "CitationCount": 1155}, {"URL": "https://www.semanticscholar.org/paper/Automatic-segmentation-of-mammographic-masses-using-Kinnard-Lo/3f116f1763a3604275b06c6ccf0dcd65910d13b5", "ID": "3f116f1763a3604275b06c6ccf0dcd65910d13b5", "Title": "Automatic segmentation of mammographic masses using fuzzy shadow and maximum-likelihood analysis", "Abstract": "This study attempted to accurately segment tumors in mammograms using pixel aggregation and region growing techniques combined with maximum likelihood analysis and found the segmented region with the maximum likelihood corresponds to the body of tumor. This study attempted to accurately segment tumors in mammograms. Although this task is considered to be a preprocessing step in a computer analysis program, it plays an important role for further analysis of breast lesions. The region of interest (ROI) was segmented using the pixel aggregation and region growing techniques combined with maximum likelihood analysis. A fast segmentation algorithm has been developed to facilitate the segmentation process. The algorithm repetitively sweeps the ROI horizontally and vertically to aggregate the pixels that have intensifies higher than a threshold. The ROI is then fuzzified by the Gaussian envelope. With each segmented region for a given threshold step in the original ROI, the likelihood function is computed and is comprised of probability density functions inside and outside of the fuzzified ROI. We have implemented this method to test on 90 mammograms. We found the segmented region with the maximum likelihood corresponds to the body of tumor. However, the segmented region with the maximum change of likelihood corresponds to the tumor and it extended margin.", "PublicationYear": "2002", "Authors": ["Lisa M. Kinnard", "Shih-Chung Benedict Lo", "Paul C. Wang", "Matthew T. Freedman", "Mohamed F. Chouikha"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "816deb10419a85444f125056207700c4f1311851", "e7aa02db15ac1c46249be1231b3fa693792844a6", "0c5abfc65c6d8d74ffd2c6490724197e4322a2b9", "7bda4a289f585f8a31d819b963006f6c6918478c", "c3d44f3cbb23519941b9290c93ef442db9129a10", "95962cddd05c9cff112a32f068fc49f7f79ec4e8", "0c408ad1562a3d253caa8b96cb43382e1992f41a", "51f8d113ad4a3aefadcdd061e901262eedac8151", "4aa6aaeb14e5f881100c97cd5d06306f16ab80d0"], "ReferenceCount": 13, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Segmentation-of-mass-in-mammograms-using-a-novel-Xu-Xia/7642ea8a5bd70c3eede1c1c9bf8b666bf4c5c0a3", "ID": "7642ea8a5bd70c3eede1c1c9bf8b666bf4c5c0a3", "Title": "Segmentation of mass in mammograms using a novel intelligent algorithm", "Abstract": "An intelligent algorithm is proposed to improve the performance of mass segmentation on mammograms by using iterative thresholding to extract the suspicious area, as well as the rough regions of those masses matching Model II, and applies a DWT-based technique to locate those massesmatching Model I, which are hidden in the high gray-level intensity and contrast area. In order to improve the performance of mass segmentation on mammograms, an intelligent algorithm is proposed in this paper. It establishes two mass models to characterize the various masses, and the ones in the denser tissue are represented with Model I, while the ones in the fatty tissue are represented with Model II. Then, it uses iterative thresholding to extract the suspicious area, as well as the rough regions of those masses matching Model II, and applies a DWT-based technique to locate those masses matching Model I, which are hidden in the high gray-level intensity and contrast area. A region growing process restricted by Canny edge detection is subsequently used to segment the rough regions of those masses matching Model I, and finally snakes are carried out to find all the mass regions roughly extracted above. Thirty patient cases with 60 mammograms and 107 masses were used for evaluation, and the experimental result has demonstrated the algorithm's better performance over the conventional methods.", "PublicationYear": "2006", "Authors": ["Weidong Xu", "Shun-ren Xia", "Huilong Duan", "Min Xiao"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["ac0ca4295b0622e370c19716071614b6d2d723f9", "ab74c37fd6a7081ce65189b5348222b30bea83a5", "0c5abfc65c6d8d74ffd2c6490724197e4322a2b9", "e01f9f37c0b096990025b9b2861cd05d84ffa665", "6aae39114e7d88ff82f331b6379d5b68e2513bc4", "e2ad29cca43ef504569365ab6484fe26488983ee", "634d09f2716fbd68f9d4298eb5a4a1bceeb07cec", "6d93319d3795a6fac8cc9b4cdaffe7392d5e8f9b", "0c1d091efb7f2f9f33272d94131280220c3e5f72", "9b652efaf193e5a5aae0fbb392f254ab66e0acb5"], "ReferenceCount": 20, "CitationCount": 18}, {"URL": "https://www.semanticscholar.org/paper/Separation-of-malignant-and-benign-masses-using-and-Kinnard-Lo/5e99438461ae96f4a5816e37a9e01f9d9ae6ab4e", "ID": "5e99438461ae96f4a5816e37a9e01f9d9ae6ab4e", "Title": "Separation of malignant and benign masses using maximum-likelihood modeling and neural networks", "Abstract": "It is found that the segmentation method can delineate the tumor body as well as tumor peripheral regions covering typical mass boundaries and some spiculation patterns, which is essential to the analysis of mammographic masses. This study attempted to accurately segment the masses and distinguish malignant from benign tumors. The masses were segmented using a technique that combines pixel aggregation with maximum likelihood analysis. We found that the segmentation method can delineate the tumor body as well as tumor peripheral regions covering typical mass boundaries and some spiculation patterns. We have developed a Multiple Circular Path Convolution Neural Network (MCPCNN) to analyze a set of mass intensity, shape, and texture features for determination of the tumors as malignant or benign. The features were also fed into a conventional neural network for comparison. We also used values obtained from the maximum likelihood values as inputs into a conventional backpropagation neural network. We have tested these methods on 51 mammograms using a grouped Jackknife experiment incorporated with the ROC method. Tumor sizes ranged from 6mm to 3cm. The conventional neural network whose inputs were image features achieved an Az of 0.66. However the MCPCNN achieved an Az value of 0.71. The conventional neural network whose inputs were maximum likelihood values achieved an Az value of 0.84. In addition, the maximum likelihood segmentation method can identify the mass body and boundary regions, which is essential to the analysis of mammographic masses.", "PublicationYear": "2002", "Authors": ["Lisa M. Kinnard", "Shih-Chung Benedict Lo", "Paul C. Wang", "Matthew T. Freedman", "Mohamed F. Chouikha"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["ee30014d4915ffa88578e475a445ae3597b88346", "95962cddd05c9cff112a32f068fc49f7f79ec4e8", "816deb10419a85444f125056207700c4f1311851", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "7bda4a289f585f8a31d819b963006f6c6918478c", "c3d44f3cbb23519941b9290c93ef442db9129a10", "0c5abfc65c6d8d74ffd2c6490724197e4322a2b9", "51f8d113ad4a3aefadcdd061e901262eedac8151", "817cde662af30c7584a4cc869cb3fd979e22b3ea", "8c639b81670f748601e9ef97714bf194e6c2b528"], "ReferenceCount": 21, "CitationCount": 9}, {"URL": "https://www.semanticscholar.org/paper/Automated-detection-of-breast-masses-on-digital-Petrick-Chan/c909583f2560864a2650dc25dbcd09da8eb96fbd", "ID": "c909583f2560864a2650dc25dbcd09da8eb96fbd", "Title": "Automated detection of breast masses on digital mammograms using adaptive density-weighted contrast-enhancement filtering", "Abstract": "This paper presents a novel approach for segmentation of suspicious mass regions in digitized mammograms using a new adaptive density-weighted contrast enhancement (DWCE) filter in conjunction with Laplacian-Gaussian edge detection. This paper presents a novel approach for segmentation of suspicious mass regions in digitized mammograms using a new adaptive density-weighted contrast enhancement (DWCE) filter in conjunction with Laplacian-Gaussian (LG) edge detection. The new algorithm processes a mammogram in two stages. In the first stage the entire mammogram is filtered globally using a DWCE adaptive filter which enhances the local contrast of the image based on its local mean pixel values. The enhanced image is then segmented with an LG edge detector into isolated objects. In the second stage of processing, the DWCE adaptive filter and the edge detector are applied locally to each of the segmented object regions detected in the first stage. The number of objects is then reduced based on morphological features. ROIs are selected from the remaining object set based on the centroid locations of the individual objects. The selected ROIs are then input to either a linear discriminant analysis (LDA) classifier or a convolution neural network (CNN) to further differentiate true-positives and false-positives. In this study ROIs obtained from a set of 84 images were used to train the LDA and CNN classifiers. The DWCE algorithm was then,used to extract ROIs from a set of 84 test images. The trained LDA and CNN classifiers were subsequently applied to the extracted ROIs, and the dependence of the detection system's accuracy on the feature extraction and classification techniques was analyzed.", "PublicationYear": "1995", "Authors": ["Nicholas A. Petrick", "Heang-Ping Chan", "Berkman Sahiner", "Datong Wei", "Mark A. Helvie", "Mitchell M. Goodsitt", "Dorit D. Adler"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["a6a9c3daa459051210cf819e01188731ffe8d7f0", "4a18fe753a3d4f6619928220fb23f7bdd3ba4cff", "3a54399b141999271e49c652979f65fcd968daa9", "9009c9685754346deb93f316144a9da1f70ffcd8", "e85ded860c0d0e56b17abee9b9f8d4d7c726a9a8"], "ReferenceCount": 8, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Improving-mass-detection-by-adaptive-and-multiscale-Li-Qian/e3f3ff00759dca433cf5740b38dd8dce25ee45a0", "ID": "e3f3ff00759dca433cf5740b38dd8dce25ee45a0", "Title": "Improving mass detection by adaptive and multiscale processing in digitized mammograms", "Abstract": "A new CAD mass detection system was developed using adaptive and multi-scale processing methods for improving detection sensitivity/specificity, and its robustness to the variation in mammograms. A new CAD mass detection system was developed using adaptive and multi-scale processing methods for improving detection sensitivity/specificity, and its robustness to the variation in mammograms. The major techniques developed in system design include: (1) image standardization by applying a series of preprocessing to remove extrinsic signal, extract breast area, and normalize the image intensity; (2) multi- mode processing by decomposing image features using directional wavelet transform and non-linear multi-scale representation using anisotropic diffusion; (3) adaptive processing in image segmentation using localized adaptive thresholding and adaptive clustering; and (4) combined `hard'-`soft' classification by using a modified fuzzy decision tree and committee decision-making method. Evaluations and comparisons were taken with a training dataset containing 30 normal and 47 abnormal mammograms with totally 70 masses, and an independent testing dataset consisting of 100 normal images, 39 images with 48 minimal cancers and 25 images with 25 benign masses. A high detection performance of sensitivity TP equals 93% with false positive rate FP equals 3.1 per image and a good generalizability with TP equals 80% and FP equals 2.0 per image are obtained.", "PublicationYear": "1999", "Authors": ["Lihua Li", "Wei Qian", "Laurence P. Clarke", "Robert A. Clark", "Jerry A. Thomas"], "RelatedTopics": ["Medicine", "Engineering", "Computer Science"], "References": ["b2bd0937997521a792f1a0f1c9e4131a54b42ca3", "f876d2b733ed1e307c81df3008d10ffa60675f0b", "ea6d7923148a65372a539e686ec813d05233d5a8", "24298d59444e31b648302f4fa3e4f9fd3672d050", "c6cde20b2c3861c8740fd9092ca30b26d0b002d8", "06cc2b6267a36917bf196be39a7a64393f982023", "5bfaaf486d99b2ebb95a6ac61e760cef0117ebb0", "5ffdae7b278510d0e15dbdc6dfdc4db14e157c20", "19215f07c59f1076a3872a73f48e6ee09c739b93", "5c24e570f7e02e8044e7f2886ea14e4b453e9b68"], "ReferenceCount": 14, "CitationCount": 43}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-Breast-Masses-Using-Selected-and-Mu-Nandi/a23937d6345c6e707cf17509ec27c76fef4ce7cc", "ID": "a23937d6345c6e707cf17509ec27c76fef4ce7cc", "Title": "Classification of Breast Masses Using Selected Shape, Edge-sharpness, and Texture Features with Linear and Kernel-based Classifiers", "Abstract": "Improvement in classification accuracy may be gained by using selected combinations of shape, edge-sharpness, and texture features in breast masses computed from 111 regions in mammograms. Breast masses due to benign disease and malignant tumors related to breast cancer differ in terms of shape, edge-sharpness, and texture characteristics. In this study, we evaluate a set of 22 features including 5 shape factors, 3 edge-sharpness measures, and 14 texture features computed from 111 regions in mammograms, with 46 regions related to malignant tumors and 65 to benign masses. Feature selection is performed by a genetic algorithm based on several criteria, such as alignment of the kernel with the target function, class separability, and normalized distance. Fisher\u2019s linear discriminant analysis, the support vector machine (SVM), and our strict two-surface proximal (S2SP) classifier, as well as their corresponding kernel-based nonlinear versions, are used in the classification task with the selected features. The nonlinear classification performance of kernel Fisher\u2019s discriminant analysis, SVM, and S2SP, with the Gaussian kernel, reached 0.95 in terms of the area under the receiver operating characteristics curve. The results indicate that improvement in classification accuracy may be gained by using selected combinations of shape, edge-sharpness, and texture features.", "PublicationYear": "2008", "Authors": ["Tingting Mu", "Asoke Kumar Nandi", "Rangaraj M. Rangayyan"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["4b55ab8d2d832744d983ea3d840fa8ebe5217578", "73d058d98d2bf051acb24e50464838ea65dff3f4", "c0cdec8e8149ab2e7d185893e3f18eb0089a0f2f", "0e8b00d2b0cdd1627863a87a18e24119812e45f4", "fb518c3f3e487a64ec69f7d1691ef924afb8b8d7", "f8b061df30fa1eb1ca444cedf2e9be9d091120f2", "ac0ca4295b0622e370c19716071614b6d2d723f9", "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb", "6a6c0294803a5a31944d98588f482f7cc11f922e", "26b8feb26bd320ed98d7a5d811acc2b376280c5b"], "ReferenceCount": 61, "CitationCount": 84}, {"URL": "https://www.semanticscholar.org/paper/Approaches-for-automated-detection-and-of-masses-in-Cheng-Shi/34c44883a6152c5298f2c452670c1127072400e6", "ID": "34c44883a6152c5298f2c452670c1127072400e6", "Title": "Approaches for automated detection and classification of masses in mammograms", "Abstract": "Semantic Scholar extracted view of \\\"Approaches for automated detection and classification of masses in mammograms\\\" by Heng-Da Cheng et al.", "PublicationYear": "2006", "Authors": ["Heng-Da Cheng", "Xiangjun Shi", "Rui Min", "Liming Hu", "Xiaopeng Cai", "H. N. Du"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["a88d12a88e711702041bedeb5dfe482af96cc959", "60fc2054898150831abfb17fa6ee82b211d11447", "a79e4c1e3372d6aa0c8142052bef247da697767d", "61d1cc0b6d74e086702bc4b3aee5819cd0001f36", "7ca37e0e86e5bb46152d0a43a19f44c974f7b6b8", "f02218771a8faa4b2d59588a46d0c40bfec95176", "5a568905f56d5c424c671757552afc03e70f73fd", "d337fd6aeaa7e72563e511c5c460db8d7284fe2c", "0aed632e3d576b6ab0945ac17a84cb008aae8ce2", "47aa648be592c851226478f9f1bab692f539e6de"], "ReferenceCount": 208, "CitationCount": 497}, {"URL": "https://www.semanticscholar.org/paper/Mammographic-masses-characterization-based-on-and-Mavroforakis-Georgiou/a277fe4df26e09a6c375e32d77472ae2c9a7632d", "ID": "a277fe4df26e09a6c375e32d77472ae2c9a7632d", "Title": "Mammographic masses characterization based on localized texture and dataset fractal analysis using linear, neural and support vector machine classifiers", "Abstract": "Semantic Scholar extracted view of \\\"Mammographic masses characterization based on localized texture and dataset fractal analysis using linear, neural and support vector machine classifiers\\\" by M. Mavroforakis et al.", "PublicationYear": "2006", "Authors": ["Michael E. Mavroforakis", "Harris V. Georgiou", "Nikos Dimitropoulos", "Dionisis A. Cavouras", "Sergios Theodoridis"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["1c53cbf2a60d7f2df72ce66ff1d09010861b6198", "841e4c4843c6fb70b1b631f471e24bbf1f52f7ae", "c4489eadf3148702292ea59a2d935d3948a1c0b2", "1175e9b80044c0d25b62e4d0e4406797d5d48774", "ffb96e8390c6276528ec9953638133d8b4f24683", "59b5d428a28e7010ce87df770d84ac8ff96514fd", "30e016b2061a70dc89876f3bd5fa12301cbee9d1", "5265070d473215e690115e1cd39480d0bda3ca9b", "cd8888f739a8e6e58a5aa7ea5669bc09d60ac202", "816deb10419a85444f125056207700c4f1311851"], "ReferenceCount": 66, "CitationCount": 128}, {"URL": "https://www.semanticscholar.org/paper/A-novel-featureless-approach-to-mass-detection-in-Campanini-Dongiovanni/bba978f6deba664527708705d12365bc0f157151", "ID": "bba978f6deba664527708705d12365bc0f157151", "Title": "A novel featureless approach to mass detection in digital mammograms based on support vector machines", "Abstract": "A novel approach to mass detection in digital mammograms that chooses not to extract any feature, for the detection of the region of interest; in contrast, this work exploits all the information available on the image to codify the image with redundancy of information. In this work, we present a novel approach to mass detection in digital mammograms. The great variability of the appearance of masses is the main obstacle to building a mass detection method. It is indeed demanding to characterize all the varieties of masses with a reduced set of features. Hence, in our approach we have chosen not to extract any feature, for the detection of the region of interest; in contrast, we exploit all the information available on the image. A multiresolution overcomplete wavelet representation is performed, in order to codify the image with redundancy of information. The vectors of the very-large space obtained are then provided to a first support vector machine (SVM) classifier. The detection task is considered here as a two-class pattern recognition problem: crops are classified as suspect or not, by using this SVM classifier. False candidates are eliminated with a second cascaded SVM. To further reduce the number of false positives, an ensemble of experts is applied: the final suspect regions are achieved by using a voting strategy. The sensitivity of the presented system is nearly 80% with a false-positive rate of 1.1 marks per image, estimated on images coming from the USF DDSM database.", "PublicationYear": "2004", "Authors": ["Renato Campanini", "Danilo Dongiovanni", "Emiro Iampieri", "Nico Lanconelli", "Matteo Masotti", "Giuseppe Palermo", "Alessandro Riccardi", "Matteo Roffilli"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["34856bb7b455a317126787076be40f4f57154273", "ef9d4e735dd0e569a914a16bae165f874e679064", "f1d73520d51a0f19c686d9f4bf7af1db33763a2a", "3e60ffc41d0aebe984222476e1ad374becceeabd", "54c357716234e91f9fb15a7fc5829d1b4549e07c", "6ad785d55427b210bcf71cd85022f16a0324d859", "d1f6890e4b5737182fc89381ef2b6dfd9ec548f7", "e4a65a02428a6c82c6034f194ee894afa324890f", "8706fa1f5aa5721a6c36c8ec088122e08dda20e7", "85a8a97f614b2b6823e035bcc9abcb0f3d27be4d"], "ReferenceCount": 17, "CitationCount": 143}, {"URL": "https://www.semanticscholar.org/paper/Measures-of-acutance-and-shape-for-classification-Rangayyan-El-Faramawy/0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb", "ID": "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb", "Title": "Measures of acutance and shape for classification of breast tumors", "Abstract": "A region-based measure of image edge profile acutance is proposed which characterizes the transition in density of a region of interest (ROI) along normals to the ROI at every boundary pixel and indicates the importance of including lesion edge definition with shape information for classification of tumors. Most benign breast tumors possess well-defined, sharp boundaries that delineate them from surrounding tissues, as opposed to malignant tumors. Computer techniques proposed to date for tumor analysis have concentrated on shape factors of tumor regions and texture measures. While shape measures based on contours of tumor regions can indicate differences in shape complexities between circumscribed and spiculated tumors, they are not designed to characterize the density variations across the boundary of a tumor. Here, the authors propose a region-based measure of image edge profile acutance which characterizes the transition in density of a region of interest (ROI) along normals to the ROI at every boundary pixel. The authors investigate the potential of acutance in quantifying the sharpness of the boundaries of tumors, and propose its application to discriminate between benign and malignant mammographic tumors. In addition, they study the complementary use of various shape factors based upon the shape of the ROI, such as compactness. Fourier descriptors, moments, and chord-length statistics to distinguish between circumscribed and spiculated tumors. Thirty-nine images from the Mammographic Image Analysis Society (MIAS) database and an additional set of 15 local cases were selected for this study. The cases included 16 circumscribed benign, 7 circumscribed malignant, 12 spiculated benign, and 19 spiculated malignant lesions. All diagnoses were proven by pathologic examinations of resected tissue. The contours of the lesions were first marked by an expert radiologist using X-Paint and X-Windows on a SUN-SPARCstation 2 Workstation. For computation of acutance, the ROI boundaries were iteratively approximated using a split/merge and end-point adjustment technique to obtain the best-fitting polygonal approximation. The jackknife method using the Mahalanobis distance measure in the BMDP (Biomedical Programs) package was used for classification of the lesions using acutance and the shape factors as features in various combinations. Acutance alone resulted in a benign/malignant classification accuracy of 95% the MIAS cases. Compactness alone gave a circumscribed/spiculated classification rate of 92.3% with the MIAS cases. Acutance in combination with a moment-based shape measure and a Fourier descriptor-based measure gave four-group classification rate of 95% with the MIAS cases. The results indicate the importance of including lesion edge definition with shape information for classification of tumors, and that the proposed measure of acutance fills this need.", "PublicationYear": "1997", "Authors": ["Rangaraj M. Rangayyan", "N. M. El-Faramawy", "J. E. Leo Desautels", "Onsy Abdel Alim"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["2c13b62db56cd2493b0a5cca029456e88e2ee400", "c67859df1a7a43409479b9d98ad3066263083365", "4a18fe753a3d4f6619928220fb23f7bdd3ba4cff", "057ac70ca12c96e90ccf461a8c6ad2c82e94e787", "747c6002686c66f2ef1b16a6d0142d0439ad050f", "e0f129157f3d08e77334af043bb2368f62b515c2", "5fac84ef49bc6dcc4aeaf6c5623173f8c0e2a531", "8f96c5e5097f8cdefbd2bd27e121d2e80ef68b0e", "e64595d320da91ac2640f7e2794c4fde9920b7c4", "a6a9c3daa459051210cf819e01188731ffe8d7f0"], "ReferenceCount": 49, "CitationCount": 356}, {"URL": "https://www.semanticscholar.org/paper/Breast-Tissue-Classification-Using-Statistical-Of-Sheshadri-Kandaswamy/16b9ef18b616b495e32bb9aa0c562c6a39168c65", "ID": "16b9ef18b616b495e32bb9aa0c562c6a39168c65", "Title": "Breast Tissue Classification Using Statistical Feature Extraction Of Mammograms", "Abstract": "An attempt to classify the breast tissue based on the intensity level of histogram of a mmammogram, which would help a radiologist to detect a normal breast from a cancer affected breast so as to proceed with further investigation. In this paper authors have made an attempt to classify the breast tissue based on the intensity level of histogram of a mmammogram,Statistical features of a mammogram are extrcted using simple image processing techniques.The proposed scheme uses texture models to capture the mammographic appearance within the breast. Parenchymal density patterns are modeled as a statistical distribution of clustered filter responses in a low dimensional space. The statistical features extracted are the mean,standard deviation, smoothness, third moment, uniformity and entropy which signify the important texture features of breast tissue.Based on the values of these features of a digital mammogram, the authors have made an attempt to classify the breast tissue in to four basic categories like fatty, uncompressed fatty, dense and high density. This categorizaton would help a radiologist to detect a normal breast from a cancer affected breast so as to proceed with further investigation.This forms a basic step in the detection of abnormal breast under computer aided detection system. The results obtained out of the proposed technique has been found better compared to the other existing methods. The accuracy of the method has been verified with the ground truth given in the data base( mini-MIAS database) and has obtained accuracy as high as 78% This is a basic step in the development of a CAD for mammo analysis being developed at the department of ECE in support with thePSG Research centre at Coimbatore-India.", "PublicationYear": "2006", "Authors": ["H. S. Sheshadri", "A. Kandaswamy"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["1ac5f398c1eeae7189800c003035dc7248298f93", "6bf47c9319bcf3e78f6a7cbd51145114008403ae", "9e8094dadff2f2ca1893cb339c581b78f4b2f553", "d4f072532690ae1433a2eaf7c7f682ee8df294a7", "81e89f25baed869a690ffc6f93cd0306c58efe14", "375ceb29aaf36e6d25e1dcabc631a1f031620789", "aff87bbf331637722b4210f0133ff190164530d2", "ddf4ce9772c39d30ec90e2435ad39cd965850330"], "ReferenceCount": 11, "CitationCount": 71}, {"URL": "https://www.semanticscholar.org/paper/An-Efficient-Automatic-Mass-Classification-Method-Islam-Ahmadi/09ca54c7866c907641e48b59bc194105f9aacba3", "ID": "09ca54c7866c907641e48b59bc194105f9aacba3", "Title": "An Efficient Automatic Mass Classification Method In Digitized Mammograms Using Artificial Neural Network", "Abstract": "An efficient computer aided mass classification method in digitized mammograms using Artificial Neural Network (ANN), which performs benign-malignant classification on region of interest (ROI) that contains mass. In this paper we present an efficient computer aided mass classification method in digitized mammograms using Artificial Neural Network (ANN), which performs benign-malignant classification on region of interest (ROI) that contains mass. One of the major mammographic characteristics for mass classification is texture. ANN exploits this important factor to classify the mass into benign or malignant. The statistical textural features used in characterizing the masses are mean, standard deviation, entropy, skewness, kurtosis and uniformity. The main aim of the method is to increase the effectiveness and efficiency of the classification process in an objective manner to reduce the numbers of false-positive of malignancies. Three layers artificial neural network (ANN) with seven features was proposed for classifying the marked regions into benign and malignant and 90.91% sensitivity and 83.87% specificity is achieved that is very much promising compare to the radiologist's sensitivity 75%.", "PublicationYear": "2010", "Authors": ["Mohammed J. Islam", "Majid Ahmadi", "Maher A. Sid-Ahmed"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["bea329822e17f3dfc17b97dda091904c35bca7b4", "cd8888f739a8e6e58a5aa7ea5669bc09d60ac202", "7287c033693c0958d3edd47a10c96302546f47da", "26b8feb26bd320ed98d7a5d811acc2b376280c5b", "c83d5d73d123e728df504ebf32c55bcac1155df6", "34c44883a6152c5298f2c452670c1127072400e6", "53de335effbc379eee3a3fcec68df957785a2c7b", "065dd5c3aa1973d94f88bbb6df62b382efe7cdf2", "9c52619bef7ed2b3bd5b6cd7761b0577751ef6c4", "81e89f25baed869a690ffc6f93cd0306c58efe14"], "ReferenceCount": 19, "CitationCount": 57}, {"URL": "https://www.semanticscholar.org/paper/Gabor-wavelet-based-features-for-medical-image-and-Buciu-Gacs%C3%A1di/6de99853193ed9ad9ae36e0994f7a552b546b86a", "ID": "6de99853193ed9ad9ae36e0994f7a552b546b86a", "Title": "Gabor wavelet based features for medical image analysis and classification", "Abstract": "The experimental results indicate that directional properties of Gabor wavelets provided by their orientation are important issues to accurately discriminate mammogram tumor types. Identifying relevant, representative and more important, discriminant image features for analysis and proper image classification purpose is one of the main tasks in image processing and pattern recognition field. In this paper, Gabor wavelets based features are extracted from medical mammogram images representing normal tissues, or benign and malign tumors. Once features are detected, Principal Component Analysis (PCA) is further employed to reduce data dimensionality. To an end, directional properties and frequency spectrum of those features are analyzed with respect to the classification performance by employing multiclass support vector machines as classifier. For comparison, as baseline, PCA was also applied directly to the data set with no feature filtering. The experimental results indicate that directional properties of Gabor wavelets provided by their orientation are important issues to accurately discriminate mammogram tumor types.", "PublicationYear": "2009", "Authors": ["Ioan Buciu", "Alexandru Gacs{\\'a}di"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["ce4e601a216a1d7872c611065d4f865d0b19eddf", "543f1f8bd4ae4d8de56828e4afdeaba14ac849c5", "5e57494f30a08a38006c85f970f405b891c26b28", "16b9ef18b616b495e32bb9aa0c562c6a39168c65", "b1812059bb9c7a0b01b3e2a3edc235bddfba84dd", "ef0fe1d3d1b1ac5092374b6bc7533c51f761161d", "ea7685f5ee65c4c152478111b5bfcb23a446d358", "2adac8e7ad1818d6a1fbc19ecf858581d9a5df9f", "a83195f2353edafa25f9d47f75d7209e57ac4260", "4e01d267ce8e5a7dbc270918c7d111f247c6b6ee"], "ReferenceCount": 14, "CitationCount": 43}, {"URL": "https://www.semanticscholar.org/paper/Mammographic-Images-Enhancement-and-Denoising-for-Mencattini-Salmeri/e4488ebd82674a981852c66c3138cb0bb9fe6b26", "ID": "e4488ebd82674a981852c66c3138cb0bb9fe6b26", "Title": "Mammographic Images Enhancement and Denoising for Breast Cancer Detection Using Dyadic Wavelet Processing", "Abstract": "A novel algorithm for image denoising and enhancement based on dyadic wavelet processing is proposed, which seems to meaningfully improve the diagnosis in the early breast cancer detection with respect to other approaches. Mammography is the most effective method for the early detection of breast diseases. However, the typical diagnostic signs such as microcalcifications and masses are difficult to detect because mammograms are low-contrast and noisy images. In this paper, a novel algorithm for image denoising and enhancement based on dyadic wavelet processing is proposed. The denoising phase is based on a local iterative noise variance estimation. Moreover, in the case of microcalcifications, we propose an adaptive tuning of enhancement degree at different wavelet scales, whereas in the case of mass detection, we developed a new segmentation method combining dyadic wavelet information with mathematical morphology. The innovative approach consists of using the same algorithmic core for processing images to detect both microcalcifications and masses. The proposed algorithm has been tested on a large number of clinical images, comparing the results with those obtained by several other algorithms proposed in the literature through both analytical indexes and the opinions of radiologists. Through preliminary tests, the method seems to meaningfully improve the diagnosis in the early breast cancer detection with respect to other approaches.", "PublicationYear": "2008", "Authors": ["Arianna Mencattini", "Marcello Salmeri", "Roberto Lojacono", "Marco Frigerio", "Federica Caselli"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["8300e6984c505971ab61b7e10974f2f8bdaa3a55", "816deb10419a85444f125056207700c4f1311851", "eafdbae30b97bd43b05c6242b3effd9782ec7ff7", "a77f2b17f27940896d14f776e01cd530d7ea69bc", "c94443c8f95fc03460e5675c0e708455718d0bc3", "55bdc3b1de8ce22d9e9d582c22240fcc39299858", "5ffdae7b278510d0e15dbdc6dfdc4db14e157c20", "f42d06ff2160dae7412c299619c04f63395b784b", "f7ea3fe2ed857119c2c9614a5d07521fb7b7bf62", "4bfd5f3690fb00fa4799f41a499901479ff53615"], "ReferenceCount": 23, "CitationCount": 230}, {"URL": "https://www.semanticscholar.org/paper/Normal-mammogram-classification-based-on-regional-Sun-Babbs/ef0fe1d3d1b1ac5092374b6bc7533c51f761161d", "ID": "ef0fe1d3d1b1ac5092374b6bc7533c51f761161d", "Title": "Normal mammogram classification based on regional analysis", "Abstract": "This paper presents a binary tree classifier based on the use of global features extracted from different levels of a 2-D Quincunx wavelet decomposition of normal and abnormal regional images that is used to classify whether an entire whole-field mammogram is normal. The majority of screening mammograms are normal. It will be beneficial if a detection system is designed to help radiologists readily identify normal regions of mammograms. In this paper, we will present a binary tree classifier based on the use of global features extracted from different levels of a 2-D Quincunx wavelet decomposition of normal and abnormal regional images. This classifier is then used to classify whether an entire whole-field mammogram is normal. This approach is fundamentally different from other approaches that identify a particular abnormality in that is independent of the particular type of abnormality.", "PublicationYear": "2002", "Authors": ["Yajie Sun", "Charles F. Babbs", "Edward J. Delp"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["3c45132198aeb77d3f398fff9c49c78485a0f263", "7c4649551a720fd148a241d31b119c9cd5c83ee6", "a3aa01a396c0a731fd93d9d23802c9b7c9a1a76a", "5d59bbffce8fd98e26727be6edc41a12323658fd", "fea4b238101d56979546c122427d8b02b29cc5d0", "e2ad29cca43ef504569365ab6484fe26488983ee", "da15bf953fd7bab529046c5ba3826e48288f1272", "8a8785628ac316034aeed513bbc8164a43f3e8c4", "8017699564136f93af21575810d557dba1ee6fc6", "8e189096588c953f96dbc1f6a86b3b539d37d780"], "ReferenceCount": 12, "CitationCount": 19}, {"URL": "https://www.semanticscholar.org/paper/An-Evaluation-of-Wavelet-Features-Subsets-for-Ferreira-Borges/ce4e601a216a1d7872c611065d4f865d0b19eddf", "ID": "ce4e601a216a1d7872c611065d4f865d0b19eddf", "Title": "An Evaluation of Wavelet Features Subsets for Mammogram Classification", "Abstract": "Different wavelet bases, variation of the selection strategy for the coefficients, and different metrics are all evaluated with known labelled images, and results shown are promising, and possible lines for future directions are described. This paper is about an evaluation for a feature selection strategy for mammogram classification. An earlier solution to this problem is revisited, which constructed a supervised classifier for two problems in mammogram classification: tumor nature, and tumor geometric type. The approach works by transforming the data of the images in a wavelet basis and by using a minimum subset of representative features of these textures based in a specific threshold (\u03bbT). In this paper different wavelet bases, variation of the selection strategy for the coefficients, and different metrics are all evaluated with known labelled images. This is a suitable solution worth further exploration. For the experiments we have used samples of images labeled by physicians. Results shown are promising, and we describe possible lines for future directions.", "PublicationYear": "2005", "Authors": ["Cristiane Bastos Rocha Ferreira", "D{\\'i}bio Leandro Borges"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["543f1f8bd4ae4d8de56828e4afdeaba14ac849c5", "c1e87c82417dde6126fd0054006515b04860b359", "5e57494f30a08a38006c85f970f405b891c26b28", "b78626ce1a562c05b1c06f9c805e839f9760b9ab", "52b0a2bd718a7f7b168db04a892327b2c0ad60db", "12e5939a80ec59f81214d7e729c577c350af9501", "b471764b7bb35abbcacb3e9f585d2031f4fddff9", "dc5a5cf6aa29ae0847dbd88bcc0ac042a9ee71fb"], "ReferenceCount": 9, "CitationCount": 5}, {"URL": "https://www.semanticscholar.org/paper/Analysis-of-mammogram-classification-using-a-Ferreira-Borges/543f1f8bd4ae4d8de56828e4afdeaba14ac849c5", "ID": "543f1f8bd4ae4d8de56828e4afdeaba14ac849c5", "Title": "Analysis of mammogram classification using a wavelet transform decomposition", "Abstract": "Semantic Scholar extracted view of \\\"Analysis of mammogram classification using a wavelet transform decomposition\\\" by Cristiane Bastos Rocha Ferreira et al.", "PublicationYear": "2003", "Authors": ["Cristiane Bastos Rocha Ferreira", "D{\\'i}bio Leandro Borges"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["c1e87c82417dde6126fd0054006515b04860b359", "5e57494f30a08a38006c85f970f405b891c26b28", "b78626ce1a562c05b1c06f9c805e839f9760b9ab", "7e9bd47e9fa53e8719aba15e4367096317d45f74", "6910d011e4e4854f2ed59f94a9485503b839bff7", "b471764b7bb35abbcacb3e9f585d2031f4fddff9", "b0e137444ec2893ad83cdc8b041c9b0da5155d27", "8a7c1786e260f01a0e2275fe4d5f536797001f6c"], "ReferenceCount": 8, "CitationCount": 118}, {"URL": "https://www.semanticscholar.org/paper/A-study-on-several-Machine-learning-methods-for-of-Wei-Yang/ea7685f5ee65c4c152478111b5bfcb23a446d358", "ID": "ea7685f5ee65c4c152478111b5bfcb23a446d358", "Title": "A study on several Machine-learning methods for classification of Malignant and benign clustered microcalcifications", "Abstract": "This paper investigated several state-of-the-art machine-learning methods for automated classification of clustered microcalcifications (MCs), and formulated differentiation of malignant from benign MCs as a supervised learning problem, and applied these learning methods to develop the classification algorithm. In this paper, we investigate several state-of-the-art machine-learning methods for automated classification of clustered microcalcifications (MCs). The classifier is part of a computer-aided diagnosis (CADx) scheme that is aimed to assisting radiologists in making more accurate diagnoses of breast cancer on mammograms. The methods we considered were: support vector machine (SVM), kernel Fisher discriminant (KFD), relevance vector machine (RVM), and committee machines (ensemble averaging and AdaBoost), of which most have been developed recently in statistical learning theory. We formulated differentiation of malignant from benign MCs as a supervised learning problem, and applied these learning methods to develop the classification algorithm. As input, these methods used image features automatically extracted from clustered MCs. We tested these methods using a database of 697 clinical mammograms from 386 cases, which included a wide spectrum of difficult-to-classify cases. We analyzed the distribution of the cases in this database using the multidimensional scaling technique, which reveals that in the feature space the malignant cases are not trivially separable from the benign ones. We used receiver operating characteristic (ROC) analysis to evaluate and to compare classification performance by the different methods. In addition, we also investigated how to combine information from multiple-view mammograms of the same case so that the best decision can be made by a classifier. In our experiments, the kernel-based methods (i.e., SVM, KFD, and RVM) yielded the best performance (A/sub z/=0.85, SVM), significantly outperforming a well-established, clinically-proven CADx approach that is based on neural network (A/sub z/=0.80).", "PublicationYear": "2005", "Authors": ["Liyang Wei", "Yongyi Yang", "Robert M. Nishikawa", "Yulei Jiang"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["f1d73520d51a0f19c686d9f4bf7af1db33763a2a", "0d8168e66dd34b4039f31cc5f47482262c0be316", "09c937b7a1d4defa5c73ed6ed3c9a467a81e95c4", "c40b2448ca3df1e537ec70c74d13ade646283abb", "f545e9736e3f502548dd3d4fe42f5519c478b55c", "46ef268c227cd2973dfd23ae70cac66c67a10cd3", "770513f9d0c9c6e7085dbbb8187205ff88ab9e11", "ac17350d16c83faf8f74229752ae91d4250ef06e", "eddad94fd10693fb0cf3340792f11af15232b49c", "b4e3eab590270cd3c4f26b037bb0b2cb396e5c9e"], "ReferenceCount": 41, "CitationCount": 312}, {"URL": "https://www.semanticscholar.org/paper/Markov-random-field-for-tumor-detection-in-digital-Li-Kallergi/5a568905f56d5c424c671757552afc03e70f73fd", "ID": "5a568905f56d5c424c671757552afc03e70f73fd", "Title": "Markov random field for tumor detection in digital mammography", "Abstract": "The algorithm was notably successful in the detection of minimal cancers manifested by masses, and an extensive study of the effects of the algorithm's parameters on its sensitivity and specificity was performed in order to optimize the method for a clinical, observer performance study. A technique is proposed for the detection of tumors in digital mammography. Detection is performed in two steps: segmentation and classification. In segmentation, regions of interest are first extracted from the images by adaptive thresholding. A further reliable segmentation is achieved by a modified Markov random field (MRF) model-based method. In classification, the MRF segmented regions are classified into suspicious and normal by a fuzzy binary decision tree based on a series of radiographic, density-related features. A set of normal (50) and abnormal (45) screen/film mammograms were tested. The latter contained 48 biopsy proven, malignant masses of various types and subtlety. The detection accuracy of the algorithm was evaluated by means of a free response receiver operating characteristic curve which shows the relationship between the detection of true positive masses and the number of false positive alarms per image. The results indicated that a 90% sensitivity can be achieved in the detection of different types of masses at the expense of two falsely detected signals per image. The algorithm was notably successful in the detection of minimal cancers manifested by masses &lt;/=10 mm in size. For the 16 such cases in the authors' dataset, a 94% sensitivity was observed with 1.5 false alarms per image. An extensive study of the effects of the algorithm's parameters on its sensitivity and specificity was also performed in order to optimize the method for a clinical, observer performance study.", "PublicationYear": "1995", "Authors": ["Huai-Dong Li", "Maria Kallergi", "Laurence P. Clarke", "Vijay K. Jain", "Robert A. Clark"], "RelatedTopics": ["Medicine"], "References": ["5b40337dcf6c86f31408ff31b878455d32980c8f", "6ac9afd220a448fa6b6fb5a086d1bc85e000a43f", "0c91c5ae82efa4330abe5808da812fcbbecd2359", "057ac70ca12c96e90ccf461a8c6ad2c82e94e787", "20414eee13b6024c430d23e61357d43d4ab2361c", "770513f9d0c9c6e7085dbbb8187205ff88ab9e11", "66cb958c5fe045d9037724f38c5ca7b4728a13f1", "1cf05c619d0f793b97d659aa76b27f6119086a1b", "cca0c1517ede98557b95a1cdd9223e7083ba0ecf", "f0a236b5149cd1642acffcab7920742604bf2fdf"], "ReferenceCount": 31, "CitationCount": 321}, {"URL": "https://www.semanticscholar.org/paper/Performance-Evaluation-of-CADe-Algorithms-in-Wirth/e652b81c4aba8e104c8aee064cc90923293cdb82", "ID": "e652b81c4aba8e104c8aee064cc90923293cdb82", "Title": "Performance Evaluation of CADe Algorithms in Mammography", "Abstract": "Computer-aided detection in breast cancer is the application of computational techniques to the problem of interpreting breast images, usually mammograms, which works by marking a mammogram with marks that indicate regions where the detection algorithm recognizes a suspicious entity that warrants further investigation, thereby complementing the radiologists' interpretation. Mammography plays a central role in the process of detecting abnormalities in breast cancer screening. A mammogram is a x-ray projection of the 3D structures of the breast, obtained by compressing the breast between two plates. Unlike most other x-ray or computed tomography images, mammograms have an inherent \\\"\u0080\u009cfuzzy\\\"\u0080\u009d or diffuse appearance. This is due in part to the superimposition of densities from differing breast tissues, and the differential x-ray attenuation (absorption) characteristics associated with these various tissues. Mammograms are essentially transparencies, where the superposition of structures located in different planes produces ambiguity in the image. For example, two blood vessels in different planes may combine to produce a single masslike structure that can be mistaken for an abnormality. One of the limitations of conventional screening mammography is that the false-negative rate is inappropriately high. This reduced sensitivity is likely due to suboptimal performance in perception of lesions and analysis of perceived findings, with the result being \\\"\u0080\u009cmissed\\\" cancers. Studies suggest that 10-\u0080\u009330% of cancers that could have been detected are in fact missed.\\n\\nDouble reading of mammograms has been advocated as a means of increasing sensitivity. Studies have shown that different readers overlook different findings, and that having more than one person interpret the images from an examination can increase the cancer detection rate as much as 15%. The use of computer prompting to increase the sensitivity in screening has gained increasing attention. Computer-aided detection (CADe) is designed to provide a radiologist with visual prompts on a series of mammograms. It works by marking a mammogram with marks that indicate regions where the detection algorithm recognizes a suspicious entity that warrants further investigation, thereby complementing the radiologists' interpretation. CADe in breast cancer is the application of computational techniques to the problem of interpreting breast images, usually mammograms. CADe, in the purist sense, only really exists for mammography. While computer-aided systems such as CADstream are evolving for modalities, such as magnetic resonance (MR), they usually concentrate more on diagnosis, with limited detection performed by means of temporal analysis.", "PublicationYear": "2006", "Authors": ["Michael A. Wirth"], "RelatedTopics": ["Medicine", "Computer Science"], "References": [], "ReferenceCount": 0, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Algorithms-for-Segmenting-Small-Low-Contrast-in-Bankman-Gatewood/a496b4de4b92d905ec2daaecd9af154ea47481f3", "ID": "a496b4de4b92d905ec2daaecd9af154ea47481f3", "Title": "Algorithms for Segmenting Small Low-Contrast Objects in Images", "Abstract": "This chapter focuses on segmentation algorithms that are especially suited for segmenting small, low-contrast, arbitrarily shaped objects such as microcalcifications in mammograms, which cannot effectively be based on conventional edge detection. One of the signs of early breast cancer is the presence of microcalcification clusters in mammograms. Automated diagnostic aids for detection of breast cancer in mammograms must determine the presence of microcalcification clusters with high enough accuracy to serve as a clinical tool. To do so, the automated system has to process the digitized mammogram with at least three different types of algorithms. The first is segmentation of individual small candidate structures that are separated from the background tissue. The second is extraction of quantitative features from each candidate structure, to represent size, shape, texture, contrast, etc. The third is classification of candidate structures as microcalcification or other tissue, using the feature values, based on automated training against ground truth provided by clinical experts. An optional fourth type of algorithm, enhancement, may also be used as a preprocessing step, depending on the image quality, to reduce the noise level of the image or to increase the contrast of candidate objects before segmentation is applied. In this multistage process, the role of segmentation is essential because the delineation of each candidate object dictates the extracted features, and subsequently their classification. This chapter focuses on segmentation algorithms that are especially suited for segmenting small, low-contrast, arbitrarily shaped objects such as microcalcifications in mammograms.\\n\\nSegmentation algorithms used to separate objects of interest from the image background are primarily based on three different approaches. Some algorithms determine the pixels of the object by comparing their brightness values to either a global or local threshold. The second type of algorithm first determines the edge pixels of the object using a gradient operator, then an edge-linking technique forms a closed contour and labels all pixels within the edge contour. The third approach is to grow a region of contiguous pixels starting from a seed pixel selected inside the object. The segmentation of microcalcifications in mammograms is especially demanding because each microcalcification is a very small, low-contrast object embedded in a nonuniform background that may have significant spatial high-frequency components. An edge detector applied to a mammogram finds edges throughout the image and may also overlook the edges of some microcalcifications due to their low contrast. Segmentation of small, low-contrast objects such as microcalcifications cannot effectively be based on conventional edge detection, especially because linking edge pixels obtained on a mammogram is not practical. Most algorithms reported for segmentation of microcalcifications are based either on thresholding or region growing, with or without enhancement.\\n\\nThe segmentation algorithm suggested in Refs. 1 and 2 compares each pixel to a local threshold computed within a square neighborhood around the pixel. The size of the neighborhood is selected by the user, and the threshold is set as the mean value of pixels in the neighborhood plus their rms value multiplied by a selected coefficient. This threshold represents the highest value that the background pixels in that neighborhood are expected to have. Pixels that have values greater than the threshold are connected to form the segmented region.", "PublicationYear": "2006", "Authors": ["Isaac N. Bankman", "Olga M. B. Gatewood", "William R. Brody", "Tanya Nizialek", "Inpakala Simon", "Irving N. Weinberg"], "RelatedTopics": ["Medicine", "Computer Science"], "References": [], "ReferenceCount": 0, "CitationCount": 5}, {"URL": "https://www.semanticscholar.org/paper/Mass-contour-extraction-in-mammographic-images-for-Rabottino-Mencattini/baac72cbca8efd95e76ea17577e8e90e49fc7275", "ID": "baac72cbca8efd95e76ea17577e8e90e49fc7275", "Title": "Mass contour extraction in mammographic images for breast cancer identification", "Abstract": "This paper describes an effec tive algor for massive les ions segmenta tion based on region \u2013gro wing technique and provides ful l de ta i l s o f the per formance eva lua tion procedure used in this spec i fic context. Abstrac t \u2013 Mammography is the most e ffect ive too l no w avai lab le for an ear ly diagnosis o f breast cancer . Ho wever , the de tec tion of cancer signs in mammograms is a d i ff icul t task o wing to the grea t number o f non patho logical struc tures which are also present in the image. I t has been shown t hat in current breas t cancer screenings 10%\u201325% of the tumors are missed by the radio logis ts . For this reason, a lot o f research is cur rently being done to develop sys tems for Computer Aided Detect ion (CADe). Probably, some causes of the fa lse \u2013negative screening examinat ions are that tumoral masses have varying dimension and ir regular shape, their borders a re o f ten i l l\u2013defined and their contrast i s very lo w, thus making di fficult the discr imination from parenchymal structures . Therefore, in a CADe system a prel iminary segmentat ion procedure has to be implemented in order to separate the mass from background t i ssue. In this way, var ious charac ter i s t ics o f the segmented mass can be evaluated, which may be used in a c lass i f ica t ion s tep to discr iminate patho logi cal and negative cases . In this paper we descr ibe an effec tive algor i thm for massive les ions segmenta tion based on region \u2013gro wing technique and we provide ful l de ta i l s o f the per formance eva lua tion procedure used in this spec i fic context .", "PublicationYear": "2008", "Authors": ["Giulia Rabottino", "Arianna Mencattini", "Marcello Salmeri", "Federica Caselli", "Roberto Lojacono"], "RelatedTopics": ["Medicine"], "References": ["e652b81c4aba8e104c8aee064cc90923293cdb82", "5a568905f56d5c424c671757552afc03e70f73fd", "8d46682acbe8ac27ab8e29163e64f1b3cbb70bb0", "e4488ebd82674a981852c66c3138cb0bb9fe6b26", "e01f9f37c0b096990025b9b2861cd05d84ffa665", "1ecba1c2aa93cb3e659f64a0b28f7c4847c7c3c7", "5cfd7a0de0d6b24114931e2e43fb619c8ca67dad", "e84d936bb711dd38b8870d0832f9458903688a0a", "4aa6aaeb14e5f881100c97cd5d06306f16ab80d0", "ffb96e8390c6276528ec9953638133d8b4f24683"], "ReferenceCount": 16, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Breast-Mass-Segmentation-in-Mammographic-Images-by-Mencattini-Rabottino/37ed2eba228d850b3b34472c216d4ed20e33e151", "ID": "37ed2eba228d850b3b34472c216d4ed20e33e151", "Title": "Breast Mass Segmentation in Mammographic Images by an Effective Region Growing Algorithm", "Abstract": "A module for the segmentation of masses that can be implemented in a complete CADx (Computer Aided Diagnosis) system is proposed and a new version of the region growing algorithm specific for this kind of images is implemented for the constraints on computation time. Breast cancer is the most common cause of death among women and the most effective method for its diagnosis is mammography. However, this kind of analysis is very difficult to interpret and for this reason radiologists miss 20-30% of tumors. We propose a module for the segmentation of masses that can be implemented in a complete CADx (Computer Aided Diagnosis) system. In particular, we implement a new version of the region growing algorithm specific for this kind of images and for the constraints on computation time of this application.", "PublicationYear": "2008", "Authors": ["Arianna Mencattini", "Giulia Rabottino", "Marcello Salmeri", "Roberto Lojacono", "Emanuele Colini"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["a496b4de4b92d905ec2daaecd9af154ea47481f3", "1ecba1c2aa93cb3e659f64a0b28f7c4847c7c3c7", "5a568905f56d5c424c671757552afc03e70f73fd", "4aa6aaeb14e5f881100c97cd5d06306f16ab80d0", "804176b370f99f2dae35f3bb290f3258aa88eba1", "e4488ebd82674a981852c66c3138cb0bb9fe6b26", "8d46682acbe8ac27ab8e29163e64f1b3cbb70bb0", "e01f9f37c0b096990025b9b2861cd05d84ffa665", "e84d936bb711dd38b8870d0832f9458903688a0a", "2a1daf6606a29f8bf9792dd333eac14aa9b76f53"], "ReferenceCount": 12, "CitationCount": 44}, {"URL": "https://www.semanticscholar.org/paper/An-Iris-detector-for-tumoral-masses-identification-Mencattini-Rabottino/e83fdb20beb9908fa6a8b52df03197ba84ef2188", "ID": "e83fdb20beb9908fa6a8b52df03197ba84ef2188", "Title": "An Iris detector for tumoral masses identification in mammograms", "Abstract": "The first step of a CADx (Computer Aided Diagnosis) system that, from the original mammogram, extracts suspicious regions on which the radiologists have to focus their attention. Radiologists that analyze screening mammographic images miss the 10\u201320% of the diagnosis since this kind of images are very difficult to interpret. In this paper, we present the first step of a CADx (Computer Aided Diagnosis) system that, from the original mammogram, extracts suspicious regions on which the radiologists have to focus their attention. The procedure often successes also in case of very low contrast, because it depends only on the orientation of the gradient vectors in the image but not on their amplitude.", "PublicationYear": "2009", "Authors": ["Arianna Mencattini", "Giulia Rabottino", "Marcello Salmeri", "Roberto Lojacono"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["37ed2eba228d850b3b34472c216d4ed20e33e151", "e4a65a02428a6c82c6034f194ee894afa324890f", "295f223238012947e5ffc1e5a0e7c9bd52807977", "c760c07a441fd3c9dcedad75c705ccae1b322c77", "9d2e68f2c0259e953b0c16670614ad2782f83205", "446bc2c47b6b66c7fcc1104043d0a9a9508abec6", "1efbb7c553bb5e4705aee8371d464c4d7a397ee0"], "ReferenceCount": 9, "CitationCount": 11}, {"URL": "https://www.semanticscholar.org/paper/Model-based-detection-of-spiculated-lesions-in-Zwiggelaar-Parr/8d46682acbe8ac27ab8e29163e64f1b3cbb70bb0", "ID": "8d46682acbe8ac27ab8e29163e64f1b3cbb70bb0", "Title": "Model-based detection of spiculated lesions in mammograms", "Abstract": "Semantic Scholar extracted view of \\\"Model-based detection of spiculated lesions in mammograms\\\" by R. Zwiggelaar et al.", "PublicationYear": "1999", "Authors": ["Reyer Zwiggelaar", "Tim C. Parr", "James E. Schumm", "Ian W. Hutt", "Christopher J. Taylor", "Susan M. Astley", "Caroline R. M. Boggis"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["5ad6e60b40dd853870b3cbadfc35e062e1d36e97", "ea6d7923148a65372a539e686ec813d05233d5a8", "169af83152e6bcdac0fcabf5f0897e2eb9212dff", "3a064e8f4bbf5d2af20a43e311033a9bb520e13d", "d4f072532690ae1433a2eaf7c7f682ee8df294a7", "25c77c18bbb0224082d675064aa644cd12025597", "c7c40c212b154f784abd6034d18f279f6acd1f0d", "f4305a7996f618faff4ec968ef883d2769f7fac6", "38194544aa952f0d33ba9ae53df5a0fa6c5e775b", "4141078d162b4396a6fff520aff359f2d9fff0e1"], "ReferenceCount": 39, "CitationCount": 114}, {"URL": "https://www.semanticscholar.org/paper/Digital-Mammography-Maidment/04fc0c398508822f3b22a8065a48f17ed69baeb0", "ID": "04fc0c398508822f3b22a8065a48f17ed69baeb0", "Title": "Digital Mammography", "Abstract": "A feasibility study has been carried out to assess the practicality of using a stepwedge-based technique for measuring breast density from mammograms in the UK National Health Service Breast Screening Programme and to determine whether additional information, relevant to risk, can be collected by questionnaire. . Conventional risk models for the development of breast cancer use inputs such as age, weight, hormonal factors and family history to compute individual breast cancer risk. These are employed in the management of women at high risk. The addition of breast density as an input has been shown to im-prove the accuracy of such models. An improved risk model could facilitate risk-based population screening. However, in order to use breast density in risk models there is a need to employ objective methods for measuring the density. A feasibility study has been carried out to assess the practicality of using a stepwedge-based technique for measuring breast density from mammograms in the UK National Health Service Breast Screening Programme and to determine whether additional information, relevant to risk, can be collected by questionnaire. Preliminary results suggest that it is practical to use such a technique in the screening environment. In a sample of 100 women, the mean density was 27% (range 2 - 81%). A negative trend in breast density was observed with Body Mass Index.", "PublicationYear": "2019", "Authors": ["Andrew D. A. Maidment"], "RelatedTopics": ["Medicine"], "References": ["ecd6e493dcbbd56fb49b68c85f16b968887ee620", "2915e1272c294bb5a7ebbef93d61cb2530c972bc", "829ede025c562a2fa11a52e17958b71d7d1d6597", "47ee5740f809f9a96f93e21852f5b0ab28813821", "5c30d7e455473b80a2427f5da8960f2356749863", "97bab169b371468c4efb54a3b55c03d216eab85f", "3c820ecedf7bdd179717923342bfee0a1f9470d5"], "ReferenceCount": 7, "CitationCount": 219}, {"URL": "https://www.semanticscholar.org/paper/CAD-systems-for-mammography%3A-a-real-opportunity-A-Bazzocchi-Mazzarella/295f223238012947e5ffc1e5a0e7c9bd52807977", "ID": "295f223238012947e5ffc1e5a0e7c9bd52807977", "Title": "CAD systems for mammography: a real opportunity? A review of the literature", "Abstract": "There is still considerable variation among different studies in the level of benefit deriving from CAD, and the role of these systems in clinical practice is still debated, and their real contribution to the overall management of the diagnostic process is not yet clear. AbstractThe introduction of systems for automated reading in\\nmammography has been proposed to improve the sensitivity\\n[computer-aided detection (CADe) systems] and, more recently,\\nthe specificity [computer-aided diagnosis (CADi) systems] of the\\ntest. Only CADe systems have been approved by the U.S. Food\\nand Drug Administration (FDA) and are used in current practice.\\nThese systems are still under discussion. Several studies have\\ndemonstrated that they are beneficial to inexperienced readers and\\nthat, through comparison with the computer, radiologists are led to\\nimprove their performance. However, there is still considerable\\nvariation among different studies in the level of benefit deriving\\nfrom CAD. Therefore the role of these systems in clinical practice\\nis still debated, and their real contribution to the overall\\nmanagement of the diagnostic process is not yet clear.", "PublicationYear": "2007", "Authors": ["Massimo Bazzocchi", "F. Mazzarella", "Chiara del Frate", "F. Girometti", "Chiara Zuiani"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["a24ecd630b5d728e7102b9c457eed605c5252026", "509bed5ac7709e04b6c9a309e679a881bcd674d3", "9ccc5ad7ff35526051f23ba625db01ba15827843", "55f1596a7c8073d8dc675a3e86519fd5f9e1f5d8", "9b6e4cdd91447791204c4ee26daf56be03eb27bb", "f904143d0ad5363c317a669d4624e8f1041e6b03", "e4a65a02428a6c82c6034f194ee894afa324890f", "7972bb4c4e3baf61a561e6324a23165275974019", "9695a3813afe7578f06bfb84a9eb709e2028d9a8", "0c04eef974aeb666c098b20290c35ca6afc30d06"], "ReferenceCount": 80, "CitationCount": 47}, {"URL": "https://www.semanticscholar.org/paper/Characterization-of-mammographic-masses-using-a-and-Delogu-Fantacci/995a9f5653e95ff874e39da5d2d0beeb36aaa950", "ID": "995a9f5653e95ff874e39da5d2d0beeb36aaa950", "Title": "Characterization of mammographic masses using a gradient-based segmentation algorithm and a neural classifier", "Abstract": "Semantic Scholar extracted view of \\\"Characterization of mammographic masses using a gradient-based segmentation algorithm and a neural classifier\\\" by P. Delogu et al.", "PublicationYear": "2007", "Authors": ["Pasquale Delogu", "Maria Evelina Fantacci", "Parnian Kasae", "Alessandra Retico"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["cd8888f739a8e6e58a5aa7ea5669bc09d60ac202", "5341997de2d5e90a07145f731b4edc282c2d3d23", "f8b061df30fa1eb1ca444cedf2e9be9d091120f2", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "36a0514fe9049c501e798a9a60e183efb163e2d2", "475acaf8c5b6f148dd4faabc6a31d7a10605f748", "e83ee765627b856b593f2b2ad1921dc025c6cdac", "1060c5b534e53e213b9e3f9b8a75b54e3639cee8", "06974cd43fb263d178d56a7022082ad42f33557b", "f741202610ed71b1b0de7c68d29ae4ccde3b0bac"], "ReferenceCount": 58, "CitationCount": 84}, {"URL": "https://www.semanticscholar.org/paper/Automated-seeded-lesion-segmentation-on-digital-Kupinski-Giger/71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "ID": "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "Title": "Automated seeded lesion segmentation on digital mammograms", "Abstract": "Two novel lesion segmentation techniques are developed based on a single feature called the radial gradient index (RGI) and one based on simple probabilistic models to segment mass lesions, or other similar nodular structures, from surrounding background. Segmenting lesions is a vital step in many computerized mass-detection schemes for digital (or digitized) mammograms. The authors have developed two novel lesion segmentation techniques-one based on a single feature called the radial gradient index (RGI) and one based on simple probabilistic models to segment mass lesions, or other similar nodular structures, from surrounding background. In both methods a series of image partitions is created using gray-level information as well as prior knowledge of the shape of typical mass lesions. With the former method the partition that maximizes the RGI is selected. In the latter method, probability distributions for gray-levels inside and outside the partitions are estimated, and subsequently used to determine the probability that the image occurred for each given partition. The partition that maximizes this probability is selected as the final lesion partition (contour). The authors tested these methods against a conventional region growing algorithm using a database of biopsy-proven, malignant lesions and found that the new lesion segmentation algorithms more closely match radiologists' outlines of these lesions. At an overlap threshold of 0.30, gray level region growing correctly delineates 62% of the lesions in the authors' database while the RGI and probabilistic segmentation algorithms correctly segment 92% and 96% of the lesions, respectively.", "PublicationYear": "1998", "Authors": ["Matthew A. Kupinski", "Maryellen Lissak Giger"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["5a568905f56d5c424c671757552afc03e70f73fd", "0865dfebfc73dd84b03626db7670677eb372257b", "0aed632e3d576b6ab0945ac17a84cb008aae8ce2", "bae2d8243540c7935d48f316711e6a9181bdee6a", "c27d614e20e4801c85c68157e02a6b6628493b90", "b7ed9856da6b298ac6bac274fda640ee5835e69d", "14614426dbe2a010a37a70810600f52d637d71e8", "dec52b1dd0627bc22dc3e8530c381464633fe8f2", "4c9e8f231a30c2b2647ca3bffafb25fef128d2c4", "64d69c16b283e9f5a448dca1c58eaccbd44fca8f"], "ReferenceCount": 15, "CitationCount": 297}, {"URL": "https://www.semanticscholar.org/paper/Using-BI-RADS-Descriptors-and-Ensemble-Learning-for-Zhang-Tomuro/7577f9d9beecb8b5f97822cbcb9742f97afa9cd4", "ID": "7577f9d9beecb8b5f97822cbcb9742f97afa9cd4", "Title": "Using BI-RADS Descriptors and Ensemble Learning for Classifying Masses in Mammograms", "Abstract": "The results indicate that automatic clinical decision systems can be simplified by focusing on coarse-grained BI-RADS categories without losing any accuracy for classifying masses in mammograms. This paper presents an ensemble learning approach for classifying masses in mammograms as malignant or benign by using Breast Image Report and Data System (BI-RADS) descriptors. We first identify the most important BI-RADS descriptors based on the information gain measure. Then we quantize the fine-grained categories of those descriptors into coarse-grained categories. Finally we apply an ensemble of multiple Machine Learning classification algorithms to produce the final classification. Experimental results showed that using the coarse-grained categories achieved equivalent accuracies compared with using the full fine-grained categories, and moreover the ensemble learning method slightly improved the overall classification. Our results indicate that automatic clinical decision systems can be simplified by focusing on coarse-grained BI-RADS categories without losing any accuracy for classifying masses in mammograms.", "PublicationYear": "2009", "Authors": ["Yu Zhang", "Noriko Tomuro", "Jacob D. Furst", "Daniela Stan Raicu"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["eebe6ee6de642536a49139d50778c03a0fff43dd", "48666ddd437ca7bda95899d2ed1d0ae1ad58c9d0", "34c44883a6152c5298f2c452670c1127072400e6", "9042bbdbb821b1ac65fae49205ce640e0d3a02d3", "267265b02ea294f0013997536480b10aacbc04cf", "4af31c2819d3f2c7f01942f053750ad1a87253db", "004888621a4e4cee56b6633338a89aa036cf5ae5", "e91a15a5c30b9fe47b726d6a6e020abb5eb8cc75", "ff2218b349f89026ffaaccdf807228fa497c04bd", "77898360092fb48f806c312b2bc78f09bef13bc3"], "ReferenceCount": 13, "CitationCount": 12}, {"URL": "https://www.semanticscholar.org/paper/Building-multiple-weak-segmentors-for-strong-mass-Zhang-Tomuro/9c4424874d34e511373e6daefd3630faa3921a80", "ID": "9c4424874d34e511373e6daefd3630faa3921a80", "Title": "Building multiple weak segmentors for strong mass segmentation in mammogram", "Abstract": "The results show that using multiple weak segmentors is an effective method to generate a strong mass segmentation for mammograms, higher than that of any single weak segmentor. This paper proposes to build multiple segmentations for identifying mass contours for a suspicious mass in a mammogram. In this study, by using various parameter settings of the image enhancement functions, we perform multiple segmentations for each suspicious mass (region of interest (ROI)), and multiple mass contours are generated. Each of such segmentations is called a \\\"weak segmentor\\", "PublicationYear": "2011", "Authors": ["Yu Zhang", "Noriko Tomuro", "Jacob D. Furst", "Daniela Stan Raicu"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "b5ec7cb440fc82239b940fbe02d21d9e94483d4f", "0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "b6cae985af240cc8cb6cb89658f5363064840cbd", "1c26e62c7d9719dcdd652932345090534d661629", "31ff030b934db0a40529d0d76c981e012eb52ec0", "37ed2eba228d850b3b34472c216d4ed20e33e151", "e01f9f37c0b096990025b9b2861cd05d84ffa665", "34c44883a6152c5298f2c452670c1127072400e6", "6f8bee74ae6d66582a7cd05a6d9a8d8105193321"], "ReferenceCount": 20, "CitationCount": 2}, {"URL": "https://www.semanticscholar.org/paper/A-dual-stage-method-for-lesion-segmentation-on-Yuan-Giger/0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "ID": "0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "Title": "A dual-stage method for lesion segmentation on digital mammograms.", "Abstract": "This article presents a method for automatic delineation of lesion boundaries on digital mammograms using a geometric active contour model that minimizes an energy function based on the homogeneities inside and outside of the evolving contour. Mass lesion segmentation on mammograms is a challenging task since mass lesions are usually embedded and hidden in varying densities of parenchymal tissue structures. In this article, we present a method for automatic delineation of lesion boundaries on digital mammograms. This method utilizes a geometric active contour model that minimizes an energy function based on the homogeneities inside and outside of the evolving contour. Prior to the application of the active contour model, a radial gradient index (RGI)-based segmentation method is applied to yield an initial contour closer to the lesion boundary location in a computationally efficient manner. Based on the initial segmentation, an automatic background estimation method is applied to identify the effective circumstance of the lesion, and a dynamic stopping criterion is implemented to terminate the contour evolution when it reaches the lesion boundary. By using a full-field digital mammography database with 739 images, we quantitatively compare the proposed algorithm with a conventional region-growing method and an RGI-based algorithm by use of the area overlap ratio between computer segmentation and manual segmentation by an expert radiologist. At an overlap threshold of 0.4, 85% of the images are correctly segmented with the proposed method, while only 69% and 73% of the images are correctly delineated by our previous developed region-growing and RGI methods, respectively. This resulting improvement in segmentation is statistically significant.", "PublicationYear": "2007", "Authors": ["Yading Yuan", "Maryellen Lissak Giger", "Hui Li", "Kenji Suzuki", "Charlene A. Sennett"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["74def17b0d47500107610fcafce5e49eee50b66f", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "b6cae985af240cc8cb6cb89658f5363064840cbd", "475acaf8c5b6f148dd4faabc6a31d7a10605f748", "816deb10419a85444f125056207700c4f1311851", "c4f6a3b7544184b39fbe9da026024ccf80d2adb6", "5a568905f56d5c424c671757552afc03e70f73fd", "cd8888f739a8e6e58a5aa7ea5669bc09d60ac202", "e7aa02db15ac1c46249be1231b3fa693792844a6", "259a9769eb85f791e1f011f2545227e59b949f9b"], "ReferenceCount": 38, "CitationCount": 113}, {"URL": "https://www.semanticscholar.org/paper/A-Modular-Framework-for-Multi-category-feature-in-Ghosh-Ghosh/0db9038edba073a75014870b486981b8b8ed9050", "ID": "0db9038edba073a75014870b486981b8b8ed9050", "Title": "A Modular Framework for Multi category feature selection in Digital mammography", "Abstract": "A canonical GA based modular feature s election approach combined with standard MLP is proposed for multi category feature classification using various ANN classifier-modeling techniques. Many existing researches utilized many different approac hes for recognition in digital mammography using various ANN classifier-modeling techniques. Different types of feature extraction techniques are also used. It has been observed that, beyond a certain point, the inclusion of a dditional features leads to a worse rather than better performance. Moreover , the choice of features to represent the patterns affects several a spects of pattern recognition problem such as accuracy, required learning time and necessary number of samples. A common problem with the multi category feature classification is the conflict between the categories. None of the feasible solutions allow simultaneous optimal solution for all categories. In order to find an optimal solutions the searching space can be divided based on individual category in each sub region and finally merging them through decision spport s ystem. In this paper we propose a canonical GA based modular feature s election approach combined with standard MLP.", "PublicationYear": "2004", "Authors": ["Ranadhir Ghosh", "Moumita Ghosh", "John Yearwood"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["fa1455a3cf860d03a3c15c36d2cc8a5994edfadd", "ac17350d16c83faf8f74229752ae91d4250ef06e", "2a5b31aaefd943b8eb3334fda53311b06f0bdbf5", "50b31977c3c6ca9c95cd6c77e442fea5cb7f73b8", "8b376c6cdd2e668b4db1a54845106f1ae5504fd2", "2a49ba1372671bb34292a420b97efd0568403985", "47ad4e64b71c6ca65b8ece9184a81e744ff43ba7"], "ReferenceCount": 16, "CitationCount": 15}, {"URL": "https://www.semanticscholar.org/paper/Image-enhancement-and-edge-based-mass-segmentation-Zhang-Tomuro/b5ec7cb440fc82239b940fbe02d21d9e94483d4f", "ID": "b5ec7cb440fc82239b940fbe02d21d9e94483d4f", "Title": "Image enhancement and edge-based mass segmentation in mammogram", "Abstract": "Preliminary results show that the contours detected by the novel, edge-based segmentation method outline the shape and boundary of a mass much more closely than the ROI markings made by radiologists. This paper presents a novel, edge-based segmentation method for identifying the mass contour (boundary) for a suspicious mass region (Region of Interest (ROI)) in a mammogram. The method first applies a contrast stretching function to adjust the image contrast, then uses a filtering function to reduce image noise. Next, for each pixel in a ROI, the energy descriptor (one of the Haralick descriptors) is computed from the co-occurrence matrix of the pixel; and the energy texture image of a ROI is obtained. From the energy texture image, the edges in the image are detected; and the mass region is identified from the closed-path edges. Finally, the boundary of the identified mass region is used as the contour of the segmented mass. We applied our method to ROI-marked mammogram images from the Digital Database for Screening Mammography (DDSM). Preliminary results show that the contours detected by our method outline the shape and boundary of a mass much more closely than the ROI markings made by radiologists.", "PublicationYear": "2010", "Authors": ["Yu Zhang", "Noriko Tomuro", "Jacob D. Furst", "Daniela Stan Raicu"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "1c26e62c7d9719dcdd652932345090534d661629", "cc3a4e8bcb49ae31977cc3d99549529596e36fe7", "7a2b18cbb28feecf3496f96452c157ad9680a75b", "6f8bee74ae6d66582a7cd05a6d9a8d8105193321", "a23937d6345c6e707cf17509ec27c76fef4ce7cc", "37ed2eba228d850b3b34472c216d4ed20e33e151", "3fc30d88ef4791577f4382d7fbea233db878fd34", "34c44883a6152c5298f2c452670c1127072400e6"], "ReferenceCount": 18, "CitationCount": 19}, {"URL": "https://www.semanticscholar.org/paper/Performance-assessment-of-mammography-image-Byrd-Zeng/3e3f7d39b59f67be97ecda8542c04ea141d6e944", "ID": "3e3f7d39b59f67be97ecda8542c04ea141d6e944", "Title": "Performance assessment of mammography image segmentation algorithms", "Abstract": "A comprehensive validation analysis is presented to evaluate the performance of three existing mammogram segmentation algorithms against manual segmentation results produced by two expert radiologists, which will significantly help improve early detection of breast cancer. In this paper, we present a comprehensive validation analysis to evaluate the performance of three existing mammogram segmentation algorithms against manual segmentation results produced by two expert radiologists. These studies are especially important for the development of computer-aided cancer detection (CAD) systems, which will significantly help improve early detection of breast cancer. Three typical segmentation methods were implemented and applied to 50 malignant mammography images chosen from the University of South Florida's Digital Database for Screening Mammography (DDSM): (a) region growing combined with maximum likelihood modeling (Kinnard model), (b) an active deformable contour model (snake model), and (c) a standard potential field model (standard model). A comprehensive statistical validation protocol was applied to evaluate the computer and expert outlined segmentation results; both sets of results were examined from the inter- and intra-observer points of view. Experimental results are presented and discussed in this communication", "PublicationYear": "2005", "Authors": ["Kenneth Byrd", "Jianchao Zeng", "Mohamed F. Chouikha"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["623d5d734e70e0af96a42af41e1be5c0f996f935", "f488a621555a288049bb7e43929623202502dac8", "21d2b45cac6952aa8984d5e7585239177e6699c2", "19ed8641daf2499ed3d37156a6dd4e3a7c16da01", "58ee2a3d5e3c9d0f32896e352f6151e5ae77323d", "2b77b2fdb25fb50b8a43344616a3aad74892dd76", "4e9498322979ee4aa286b7aed222240d789efd02", "9394a5d5adcb626128b6a42c8810b9505a3c6487"], "ReferenceCount": 9, "CitationCount": 10}, {"URL": "https://www.semanticscholar.org/paper/Neural-Classification-of-Mass-Abnormalities-with-of-Panchal-Verma/5fec51cf2d044c764a049d8455f96869d31f1e99", "ID": "5fec51cf2d044c764a049d8455f96869d31f1e99", "Title": "Neural Classification of Mass Abnormalities with Different Types of Features in Digital Mammography", "Abstract": "The research work presented in this paper investigates the significance of different types of features using proposed neural network based classification technique to classify mass type of breast abnormalities in digital mammograms into malignant and benign. Early detection of breast abnormalities remains the primary prevention against breast cancer despite the advances in breast cancer diagnosis and treatment. Presence of mass in breast tissues is highly indicative of breast cancer. The research work presented in this paper investigates the significance of different types of features using proposed neural network based classification technique to classify mass type of breast abnormalities in digital mammograms into malignant and benign. 14 gray level based features, four BI-RADS features, patient age feature and subtlety value feature have been explored using the proposed research methodology to attain maximum classification on test dataset. The proposed research technique attained a 91% testing classification rate with a 100% training classification rate on digital mammograms taken from the DDSM benchmark database.", "PublicationYear": "2006", "Authors": ["Rinku Panchal", "Brijesh K. Verma"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["a88d12a88e711702041bedeb5dfe482af96cc959", "4ab901550a39fb62bb9ac872a8b00cc6068c0167", "603b2f00c9948e63514bdefa4ac2d3357cc2a1dc", "92fc92888bc1a5194db419e0d47015975482cbdc", "5fac84ef49bc6dcc4aeaf6c5623173f8c0e2a531", "c1ec2c9f9d2e8914cf6de51e4cef0b15e061b944", "ca6db360c4fe8d73386ca36ec570bd3ef68e3d34", "c5ac9c778de5186dc42e6052bb7f0d28e6b279e5", "cee24fcf9981ce17bf576735af8ae4d7deb73ce8", "7f45255089d20fd54809d00ecd4efd75ca097737"], "ReferenceCount": 17, "CitationCount": 23}, {"URL": "https://www.semanticscholar.org/paper/Neural-Networks-for-the-Classification-of-Benign-in-Verma-Panchal/cf7396f247441e51071d0a774a3ef7a83da6231a", "ID": "cf7396f247441e51071d0a774a3ef7a83da6231a", "Title": "Neural Networks for the Classification of Benign and Malignant Patters in Digital Mammograms", "Abstract": "This chapter presents neural network-based techniques for the classification of microcalcification patterns in digital mammogram patterns into \u2018benign\u2019 and \u2018malignant\u2019. This chapter presents neural network-based techniques for the classification of microcalcification patterns in digital mammograms. Artificial neural network (ANN) applications in digital mammography are mainly focused on feature extraction, feature selection, and classification of micro-calcification patterns into \u2018benign\u2019 and \u2018malignant\u2019. An extensive review of neural network based techniques in digital mammography is presented. Recent developments such as auto-associators and evolutionary neural networks for feature extraction and selection are presented. Experimental results using ANN techniques on a benchmark database are described and analysed. Finally, a comparison of various neural network-based techniques is presented. IDEA GROUP PUBLISHING This paper appears in the publication, Advances in Applied Artificial Intelligence edited by John Fulcher \u00a9 2006, Idea Group Inc. 701 E. Chocolate Avenue, Suite 200, Hershey PA 17033-1240, USA Tel: 717/533-8845; Fax 717/533-8661; URL-http://www.idea-group.com ITB12361", "PublicationYear": "2006", "Authors": ["Brijesh K. Verma", "Rinku Panchal"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["44c3c87c90d795ae9b3bc7c02024cc4390aa64f9", "6a97b8fb5bc80fcaed8f33ae35796d9c93052f43", "3acac684ea95c4735ff16a50babf90bc7fffee43"], "ReferenceCount": 9, "CitationCount": 26}, {"URL": "https://www.semanticscholar.org/paper/A-review-of-computer-aided-diagnosis-of-breast-the-Rangayyan-Ayres/9bf32a68edfea8b8c072bcd3ee0d696687bab403", "ID": "9bf32a68edfea8b8c072bcd3ee0d696687bab403", "Title": "A review of computer-aided diagnosis of breast cancer: Toward the detection of subtle signs", "Abstract": "Semantic Scholar extracted view of \\\"A review of computer-aided diagnosis of breast cancer: Toward the detection of subtle signs\\\" by R. Rangayyan et al.", "PublicationYear": "2007", "Authors": ["Rangaraj M. Rangayyan", "F{\\'a}bio J. Ayres", "J. E. Leo Desautels"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["ad62b724df12fd40169ae8115f5e156adda99283", "e4a65a02428a6c82c6034f194ee894afa324890f", "55f1596a7c8073d8dc675a3e86519fd5f9e1f5d8", "8706fa1f5aa5721a6c36c8ec088122e08dda20e7", "acc3f5d417d18ad994466940e6cfa7289fc9d947", "968157d1264ea1ac6fb33f861c54ed1765ecd2af", "b072abd46ff6abc6c527710c7eef2b00055e4733", "a88d12a88e711702041bedeb5dfe482af96cc959", "52e66cbe0bc8ce5fbdcd8e0d2c309d35f64ed848", "f8ff28e4c2e415cef87cd77254ea03b788f901da"], "ReferenceCount": 118, "CitationCount": 356}, {"URL": "https://www.semanticscholar.org/paper/Computer-Based-Identification-of-Breast-Cancer-R.Acharya-Ng/88d38b88e4890b80373eed7070a2096648c5cf30", "ID": "88d38b88e4890b80373eed7070a2096648c5cf30", "Title": "Computer-Based Identification of Breast Cancer Using Digitized Mammograms", "Abstract": "A comparative approach for classification of three kinds of mammogram namely normal, benign and cancer, using the feedforward architecture neural network classifier and Gaussian mixture model for comparison. High-quality mammography is the most effective technology presently available for breast cancer screening. Efforts to improve mammography focus on refining the technology and improving how it is administered and X-ray films are interpreted. Computer-based intelligent system for identification of the breast cancer can be very useful in diagnosis and its management. This paper presents a comparative approach for classification of three kinds of mammogram namely normal, benign and cancer. The features are extracted from the raw images using the image processing techniques and fed to the two classifiers namely: the feedforward architecture neural network classifier, and Gaussian mixture model (GMM) for comparison.. Our protocol uses, 360 subjects consisting of normal, benign and cancer breast conditions. We demonstrate a sensitivity and specificity of more than 90% for these classifiers.", "PublicationYear": "2008", "Authors": ["Rajendra Acharya U.", "Esaliia Ng", "Y. H. Chang", "J. Yang", "G. J. L. Kaw"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["22ba5733bd3dd85013588ff380d5cc24d84db3eb", "8ea35a2467c81c3a4c1c4f8d74b376d0ce52703c", "ff9e175f75cd2dc165681807eebd1467a60fa949", "5224fa4649ea6a7ba571771b93d168f8c60554f9", "c9ac914ebfd6a59f44e1034ba270a5fdf2a25595", "82136dcf8bc96dfcc4c92d1e67fa4e807e1b92e3", "0c408ad1562a3d253caa8b96cb43382e1992f41a", "01711ec93e11d15af96ea15ef32ec53fc9512bd0", "4e01d267ce8e5a7dbc270918c7d111f247c6b6ee", "56845597b98ceecda99e06fb5ff16cfee42e2cdc"], "ReferenceCount": 23, "CitationCount": 33}, {"URL": "https://www.semanticscholar.org/paper/Automatic-detection-of-clustered-in-digital-using-Halkiotis-Botsis/aa792e1a05acccb8811f04adf540835237fb5ffe", "ID": "aa792e1a05acccb8811f04adf540835237fb5ffe", "Title": "Automatic detection of clustered microcalcifications in digital mammograms using mathematical morphology and neural networks", "Abstract": "Semantic Scholar extracted view of \\\"Automatic detection of clustered microcalcifications in digital mammograms using mathematical morphology and neural networks\\\" by S. Halkiotis et al.", "PublicationYear": "2007", "Authors": ["Stelios Halkiotis", "Taxiarchis Botsis", "Maria Rangoussi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["64603142683647b4678cf1da3d201c04f1e11b7e", "03c79bb15774745569216ad0d002b65391f35b5d", "7f45255089d20fd54809d00ecd4efd75ca097737", "2da129cead8ba0420f28c7880befd02c3688384d", "38f7c8cfb6b52df515c1cb29a2e42f6673e7a377", "4bf55bc218922bf5f01a239f209af57ed9d7f365", "8ea35a2467c81c3a4c1c4f8d74b376d0ce52703c", "caabbebef305ef1b602cf383b6bee45aa92567cb", "a88d12a88e711702041bedeb5dfe482af96cc959", "a0a0fcedd92107cc3f115f323ec0650012654994"], "ReferenceCount": 18, "CitationCount": 116}, {"URL": "https://www.semanticscholar.org/paper/Breast-Cancer-Detection-Based-on-Statistical-Abdalla-Deris/227b786b828240506830fea3660b5dc1de6e2a8e", "ID": "227b786b828240506830fea3660b5dc1de6e2a8e", "Title": "Breast Cancer Detection Based on Statistical Textural Features Classification", "Abstract": "A set of textural features was applied to a set of 120 digital mammographic images, from the Digital Database for Screening Mammography, and these features are used in conjunction with SVMs to detect the breast cancer. Localized textural analysis of breast tissue on mammograms has recently gained considerable attention by researchers studying breast cancer detection. Despite the research progress to solve the problem, detecting breast cancer based on textural features has not been investigated in depth. In this paper we study the breast cancer detection based on statistical texture features using Support Vector Machine (SVM). A set of textural features was applied to a set of 120 digital mammographic images, from the Digital Database for Screening Mammography. These features are then used in conjunction with SVMs to detect the breast cancer. Other linear and non-linear classifiers were also employed to be compared to the SVM performance. SVM was able to achieve better classification accuracy of 82.5%.", "PublicationYear": "2007", "Authors": ["Al Mutaz M. Abdalla", "Safaai B. Deris", "Nazar Zaki", "Doaa Mahmoud Ghoneim"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["2ea9e5cb9f42232f7c37ae8471194fdd95449d2b", "5b54bd1a924084b846bfc5c9e1c11d685621388e", "679b8f442d4bde790e63419eb18918a9495351cb", "d05d402f1a5aabc40c07eda1bd1a235bae7227fc", "6ec7c724aa1d906e9e9f81c58497adddb22175b8", "ea2ea7c6e280c1cfb67ee38ea63a327b1ba3ca36", "6abbd4365170a5e2383d0e70e9fc9fcdf2c29a86", "a40ae6562786c97d554e83715093483e2e331a1e", "4c75b748911ddcd888c5122f7672f69caa5d661f", "bc9bcd12cee527fb4a7dfe2e6edd5e71535cdc9c"], "ReferenceCount": 11, "CitationCount": 27}, {"URL": "https://www.semanticscholar.org/paper/Improved-cancer-detection-using-computer-aided-with-Dean-Ilvento/fb5989e1fff6024adcc6c3d4d85d43e728b9646d", "ID": "fb5989e1fff6024adcc6c3d4d85d43e728b9646d", "Title": "Improved cancer detection using computer-aided detection with diagnostic and screening mammography: prospective study of 104 cancers.", "Abstract": "CAD resulted in detection of more cancers in screening and diagnostic patients, with an increased recall rate but no deterioration in PPV of biopsy. OBJECTIVE\\nThis study prospectively evaluated a computer-aided detection (CAD) device used with diagnostic and screening mammography by assessing cancers detected; tumor sizes, histology, and stage; positive predictive value (PPV) of biopsy recommendation; and recall rates before and after CAD introduction.\\n\\n\\nSUBJECTS AND METHODS\\nInterpretations of 9,520 consecutive mammograms were recorded without and then with CAD for a 28-month period. Cancer detections based on initial radiologist review and additional detections based on CAD findings were noted. Recall rates, tumor size and histology, and PPV of biopsy recommendation before and after the introduction of CAD were compared.\\n\\n\\nRESULTS\\nCancers detected only with CAD assistance were 9.6% of all cancers (10 of 104); screening-detected cancers increased 13.3% with CAD assistance (four in addition to 30 screening-detected cancers). The 95% one-sided confidence boundary using binomial distribution is consistent with at least 5.3% for all cancers and 5.1% for nonpalpable cancers. The greatest impact was on ductal carcinoma in situ, for which CAD increased cancer detection by 14.2% (three added to 21). Similar percentages of cancers were detected only with CAD assistance in both screening (11.4%; 4 of 35) and diagnostic (9.5%; six of 63) studies. Additional cancers were detected using CAD in patients with implants and previous lumpectomy. The additional cancers detected with CAD were smaller (p = 0.01 for all cancers, p = 0.03 for nonpalpable invasive cancer). The screening recall rate increased from 6.2% to 7.8% after CAD, with a decrease in the biopsy rate and a nonsignificant increase in the biopsy PPV from 21.9% to 26.3%.\\n\\n\\nCONCLUSION\\nCAD resulted in detection of more cancers in screening and diagnostic patients, with an increased recall rate but no deterioration in PPV of biopsy. Additional cancers detected were significantly smaller.", "PublicationYear": "2006", "Authors": ["Judy Dean", "Christina Ilvento"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["8706fa1f5aa5721a6c36c8ec088122e08dda20e7", "f88928f7a6de0332abaff25cef87d6f0c28cb7cc", "e4a65a02428a6c82c6034f194ee894afa324890f", "55f1596a7c8073d8dc675a3e86519fd5f9e1f5d8", "fac0de261ff12845f095ac098c734f4efa7dbd26", "632a66f5581d8991f92d3c79324d704f3d3d06a5", "40bfd373950216ff995eddd1be2d70d2bb769e6c", "a2d8143145d20174c3c2487eaf2e8178133b73ae", "e29f94db392e06b27d7620741939df8aa0d06fc3", "87a31a251016da91803ee354d3f43d6e17cc094f"], "ReferenceCount": 31, "CitationCount": 168}, {"URL": "https://www.semanticscholar.org/paper/An-effective-breast-mass-diagnosis-system-using-Tahmasbi-Saki/63a83600a73ffbfd6a58e315a247aa4f3da90a9b", "ID": "63a83600a73ffbfd6a58e315a247aa4f3da90a9b", "Title": "An effective breast mass diagnosis system using Zernike moments", "Abstract": "A novel CADx system for the diagnosis of masses in mammography images is proposed, intensifying the performance of CADx algorithms as well as reducing the false positive rate by utilizing Zernike moments as descriptors of shape and margin characteristics. In this paper, a novel CADx system has been proposed for the diagnosis of masses in mammography images. The objective is intensifying the performance of CADx algorithms as well as reducing the false positive rate by utilizing Zernike moments as descriptors of shape and margin characteristics. The input ROI is segmented manually by expert radiologists. Then, it is subjected to some preprocessing stages such as histogram equalization, translation, and NRL scaling. The outcome of preprocessing stage is two processed images containing co-scaled translated masses. Besides, one of these images represents the shape characteristics of the mass, while the other describes the margin characteristics. Two groups of Zernike moments have been extracted from the preprocessed images and proceeded to the feature selection stage. Each group includes 32 moments with different orders and iterations. Considering the performance of the overall CADx system, the most effective 32 moments have been chosen and applied to a multi-layer Perceptron classifier. The ROC plot and the performance of overall CADx system are analyzed for each group of features. The designed systems yield Az = 0.976 and 0.975 which represent fair sensitivity and fair specificity, respectively. The best achieved FPR is 5.5%.", "PublicationYear": "2010", "Authors": ["Amir Tahmasbi", "Fatemeh Saki", "Shahriar Baradaran Shokouhi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["ea7685f5ee65c4c152478111b5bfcb23a446d358", "34c44883a6152c5298f2c452670c1127072400e6", "6a6c0294803a5a31944d98588f482f7cc11f922e", "72ca0bf7bee745e58a1b0066bc537c4211e7e463", "9c6d488192b0535b032542d16a9d16a423c7a775", "72464133722c922e2185635c57d4527f3ad7bbbb", "3c1a8b740b14e871f69be07112adab67a7193b3a", "9d130db46e078e7996c03735412f2ddb777b9c9d", "64bf1370f1a5b6a0e943142150d8e5021fbb40f8", "7f575e099af94faca1fe9c9f04ab0ee4081c77f0"], "ReferenceCount": 13, "CitationCount": 16}, {"URL": "https://www.semanticscholar.org/paper/Mass-diagnosis-in-mammography-images-using-novel-Tahmasbi-Saki/474ae46626676d01c7b38328c107b1531b181b46", "ID": "474ae46626676d01c7b38328c107b1531b181b46", "Title": "Mass diagnosis in mammography images using novel FTRD features", "Abstract": "In this paper, a novel group of features have been introduced for diagnosing the masses in mammography images and it is shown that the magnitude response of FTRD vectors can be appropriate descriptors of the mass margin. In this paper, a novel group of features have been introduced for diagnosing the masses in mammography images. The goal is increasing the performance of CADx algorithms as well as decreasing computational complexity. The proposed features are proper descriptors of mass margin which are called Fourier Transform of Radial Distance (FTRD). The input ROI has been segmented manually by expert radiologists and subjected to some preprocessing stages. In order to extract the proposed features, the Radial Distance (RD) vectors of masses have been extracted. In addition, the zero padding method has been utilized to equalize the length of the RD vectors. Then, the resulting vectors are transformed to the frequency domain. It is shown that the magnitude response of FTRD vectors can be appropriate descriptors of the mass margin. Furthermore, in order to make a trade-off between the computational complexity and performance of the overall system, several groups of FTRD features with different lengths have been chosen and applied to an MLP classifier. Finally, the ROC curves have been plotted for each group of features and the performances have been evaluated. The most effective system yields an Az which is equal to 0.98. Moreover, the best achieved FPR is 5.56%.", "PublicationYear": "2010", "Authors": ["Amir Tahmasbi", "Fatemeh Saki", "Shahriar Baradaran Shokouhi"], "RelatedTopics": ["Medicine"], "References": ["802c5bf4c93b795f9f509a3b90efabc501e21c01", "f8b061df30fa1eb1ca444cedf2e9be9d091120f2", "d98b3a493bdf327f3447e75b4814339e1b436d05", "6a6c0294803a5a31944d98588f482f7cc11f922e", "34c44883a6152c5298f2c452670c1127072400e6", "7ecef79c3d0752d58a0f286bf425ec1eb42bde07", "2dfb1fd3adfa58a3448251e03b1a5a78239958b3", "227b786b828240506830fea3660b5dc1de6e2a8e", "26c9f47d4356f9b793aafc50e0648a92c4f3f7a4", "64bf1370f1a5b6a0e943142150d8e5021fbb40f8"], "ReferenceCount": 15, "CitationCount": 15}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-Breast-Masses-based-on-Cognitive-Tahmasbi-Saki/3e63f9f1323de17e96c4eaffda77b701d138c1f8", "ID": "3e63f9f1323de17e96c4eaffda77b701d138c1f8", "Title": "Classification of Breast Masses based on Cognitive Resonance", "Abstract": "A trustable mammography Computer Aided-Diagnosis (CADx) system utilizing a new cognitive classifier that primes a knowledge-base developed according to a mammography expert using a special kind of linguistics and grammar formalism. In this pape r, a novel approach has been proposed for mass diagnosis in mammography images. The objective is developing a trustable mammography Computer Aided-Diagnosis (CADx) system utilizing a new cognitive classifier. The input Region of Interest (ROI) is subjected to some preprocessing stages; then, a group of features describing the shape, margin and density characteristics of masses have been extracted. The proposed features are consistent with the evaluations that an expert radiologist takes into account in diagnosis process. The most effective features are selected in the feature selection stage and mapped from the set of real numbers to a set of linguistic terms. The proposed classifier primes a knowledge-base which is developed according to a mammography expert; its rules have been written using a special kind of linguistics and grammar formalism. The semantic comparison of features of the image to the expectations of the knowledge base, called cognitive resonance, leads to the final assessment. Since the output of this system comes with reason, the system is trustable. The best achieved Accuracy and False Positive Rate (FPR) are 87.93% and 10.52%, respectively. More numerical results are reported in the paper.", "PublicationYear": "2012", "Authors": ["Amir Tahmasbi", "Fatemeh Saki", "Abdollah Amirkhani", "Seyed Mohammad Seyedzade", "Shariar B. Shokouhi"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["474ae46626676d01c7b38328c107b1531b181b46", "46c409dd878e643271ef63f1817ded8b57abc01e", "63a83600a73ffbfd6a58e315a247aa4f3da90a9b", "ce1e33c037689acbfd19d4dcfc53021bc59dee2b", "802c5bf4c93b795f9f509a3b90efabc501e21c01", "34c44883a6152c5298f2c452670c1127072400e6", "6a6c0294803a5a31944d98588f482f7cc11f922e", "0937d51456ccf1dff869bc7540b8ace314488400", "c6fbf1dd5f0b48ff01eede7149bb7d5da89d47c9", "2aaa0202c1dfb96d1e946d78b97b81fb18477207"], "ReferenceCount": 14, "CitationCount": 5}, {"URL": "https://www.semanticscholar.org/paper/A-novel-opposition-based-classifier-for-mass-in-Saki-Tahmasbi/ce1e33c037689acbfd19d4dcfc53021bc59dee2b", "ID": "ce1e33c037689acbfd19d4dcfc53021bc59dee2b", "Title": "A novel opposition-based classifier for mass diagnosis in mammography images", "Abstract": "A novel opposition-based classifier has been developed which classifies breast masses into benign and malignant categories and the system which utilizes OWPB learning rule yields a significantly faster training time than BP algorithm while the Az of the resulting CADx system is 0.944. In this paper, a novel opposition-based classifier has been developed which classifies breast masses into benign and malignant categories. An MLP network with a novel learning rule, called Opposite Weighted Back Propagation (OWBP), has been utilized as the classifier. The objective is increasing the convergence rate of MLP learning rules as well as improving the mass diagnostic performance. The input ROI, which is a suspected part of mammogram, is segmented manually by expert radiologists and subjected to some preprocessing stages such as histogram equalization, translation and scaling. Then, a group of features which are appropriate descriptors of mass shape, margin and density have been extracted from the preprocessed ROIs. The proposed features include circularity, Zernike moments, contrast, average gray level, NRL derivatives and SP. The proposed classifier has been trained with both traditional BP and OWBP learning rules and the performance have been evaluated. The system which utilizes OWPB learning rule yields a significantly faster training time than BP algorithm while the Az of the resulting CADx system is 0.944.", "PublicationYear": "2010", "Authors": ["Fatemeh Saki", "Amir Tahmasbi", "Shahriar Baradaran Shokouhi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["5a53d48ecba770309e6cd3e094b39bdb208849c1", "6a6c0294803a5a31944d98588f482f7cc11f922e", "802c5bf4c93b795f9f509a3b90efabc501e21c01", "34c44883a6152c5298f2c452670c1127072400e6", "bbf6942a91f06c054626eb550a9bd0fedf448c25", "9bf32a68edfea8b8c072bcd3ee0d696687bab403", "72464133722c922e2185635c57d4527f3ad7bbbb", "81e89f25baed869a690ffc6f93cd0306c58efe14", "01f702f8b1f9d1314587015f1f038af4d5735e77", "c2d935b98a0ac5f9851840c0e337695dd4ee652d"], "ReferenceCount": 12, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/Feature-Extraction-from-Contours-Shape-for-Tumor-in-Boujelben-Chaabani/40bbb7667b260bad22b0e2cb34562f57735d67f8", "ID": "40bbb7667b260bad22b0e2cb34562f57735d67f8", "Title": "Feature Extraction from Contours Shape for Tumor Analyzing in Mammographic Images", "Abstract": "This paper deals with the problem of shape feature extraction in digital mammograms, particularly the boundary information, and proposes feature vector based in boundary analysis in ameliorating three points of view like RDM, convexity and angular features. The cancer treatment is effective only if it is detected at an early stage. In this context, Mammography is the most efficient method for early detection. Due to the complexity of this last, the distinction of microcalcifications or opacities is very difficult. This paper deals with the problem of shape feature extraction in digital mammograms, particularly the boundary information. In fact, we evaluated the efficiency on boundary information possessed by mass region. We propose feature vector based in boundary analysis in ameliorating three points of view like RDM, convexity and angular features. We use the Digital Database for Screening Mammography \u201cDDSM\u201d for experiments. Some classifiers as Multilayer Perception \u201cMLP\u201d and k-Nearest Neighbours \u201ckNN\u201d are used to distinguish the pathological records from the healthy ones. Using \u201cMLP\u201d classifiers we obtained 94,2% as sensitivity (percentage of pathological ROIs correctly classified). The results in term of specificity (percentage of non-pathological ROIs correctly classified) grows around 97,9% using MLP classifier.", "PublicationYear": "2009", "Authors": ["Atef Boujelben", "Ali Cherif Chaabani", "Hedi Tmar", "Mohamed Abid"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["2d659cbcdf60a76b7ed9de99e721f7f712834b4c", "735fec8e2216e96c46d62de2640f3a6f4e454aa9", "dfff650e5fc09244abf114827e18434d5bddd89e", "16b9ef18b616b495e32bb9aa0c562c6a39168c65", "995a9f5653e95ff874e39da5d2d0beeb36aaa950", "bea329822e17f3dfc17b97dda091904c35bca7b4", "1db7bb353c675d17a63792ff5e610826b60e1a2f", "2b5cb0265cac482551b433ae71a37096706b3278", "0ffefa7d286b24f7c20bedf779cd7bc7d1f64ceb", "bd9eff479fd19ef84e745938734f7dd0b90d380a"], "ReferenceCount": 19, "CitationCount": 16}, {"URL": "https://www.semanticscholar.org/paper/A-Survey-of-Image-Processing-Algorithms-in-Digital-Bo%C5%BEek-Mustra/d98b3a493bdf327f3447e75b4814339e1b436d05", "ID": "d98b3a493bdf327f3447e75b4814339e1b436d05", "Title": "A Survey of Image Processing Algorithms in Digital Mammography", "Abstract": "This chapter gives a survey of image processing algorithms that have been developed for detection of masses and calcifications and an overview of algorithms in each step of the mass detection algorithms is given. Mammography is at present the best available technique for early detection of breast cancer. The most common breast abnormalities that may indicate breast cancer are masses and calcifications. In some cases, subtle signs that can also lead to a breast cancer diagnosis, such as architectural distortion and bilateral asymmetry, are present. Breast abnormalities are defined with wide range of features and may be easily missed or misinterpreted by radiologists while reading large amount of mammographic images provided in screening programs. To help radiologists provide an accurate diagnosis, a computer-aided detection (CADe) and computer-aided diagnosis (CADx) algorithms are being developed. CADe and CADx algorithms help reducing the number of false positives and they assist radiologists in deciding between follow up and biopsy. This chapter gives a survey of image processing algorithms that have been developed for detection of masses and calcifications. An overview of algorithms in each step (segmentation step, feature extraction step, feature selection step, classification step) of the mass detection algorithms is given. Wavelet detection methods and other recently proposed methods for calcification detection are presented. An overview of contrast enhancement and noise equalization methods is given as well as an overview of calcification classification algorithms.", "PublicationYear": "2009", "Authors": ["Jelena Bo{\\vz}ek", "Mario Mustra", "Kresimir Delac", "Mislav Grgic"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["509bed5ac7709e04b6c9a309e679a881bcd674d3", "9bf32a68edfea8b8c072bcd3ee0d696687bab403", "34c44883a6152c5298f2c452670c1127072400e6", "5a568905f56d5c424c671757552afc03e70f73fd", "e4ceac3f5369e0cf668f56e356c4a1eb990f2476", "728d5be150b5ef7e2b22586f61b7a905b33ee7e6", "a88d12a88e711702041bedeb5dfe482af96cc959", "7853c45c105a4b0fe44465842956eafc52effc3a", "d881f4db718b171b3619efb9cba1b66bbb0d5571", "0cac166d49f3f7193b4ef0ba591bc1155aa0a762"], "ReferenceCount": 72, "CitationCount": 105}, {"URL": "https://www.semanticscholar.org/paper/Development-of-tolerant-features-for-of-masses-in-Dom%C3%ADnguez-Nandi/802c5bf4c93b795f9f509a3b90efabc501e21c01", "ID": "802c5bf4c93b795f9f509a3b90efabc501e21c01", "Title": "Development of tolerant features for characterization of masses in mammograms", "Abstract": "Semantic Scholar extracted view of \\\"Development of tolerant features for characterization of masses in mammograms\\\" by A. R. Dom\u00ednguez et al.", "PublicationYear": "2009", "Authors": ["Alfonso Rojas Dom{\\'i}nguez", "Asoke Kumar Nandi"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["35ad1f356614dfd1fa89f11720f00e25546eb996", "f8b061df30fa1eb1ca444cedf2e9be9d091120f2", "7287c033693c0958d3edd47a10c96302546f47da", "e7aa02db15ac1c46249be1231b3fa693792844a6", "ba721e81d2ab8114bc9afcf78f8335c1f6475364", "cd8888f739a8e6e58a5aa7ea5669bc09d60ac202", "995a9f5653e95ff874e39da5d2d0beeb36aaa950", "16f3cb52eb1f374aa037c4080ccbf68d2d7b8cd1", "73d058d98d2bf051acb24e50464838ea65dff3f4", "c0cdec8e8149ab2e7d185893e3f18eb0089a0f2f"], "ReferenceCount": 37, "CitationCount": 44}, {"URL": "https://www.semanticscholar.org/paper/Identification-of-masses-in-digital-mammograms-with-Bovis-Singh/603b2f00c9948e63514bdefa4ac2d3357cc2a1dc", "ID": "603b2f00c9948e63514bdefa4ac2d3357cc2a1dc", "Title": "Identification of masses in digital mammograms with MLP and RBF nets", "Abstract": "The results show recognition rates of 77% correct recognition and an area under the ROC curve value Az of 0.74 are generated on the average recognition rate over these folds on correctly recognising masses and normal regions. We study the identification of masses in digital mammograms using texture analysis. A number of texture measures are calculated for bilateral difference images showing regions of interest. The measurements are made on co-occurrence matrices in four different direction giving a total of seventy features. These features include the ones proposed by Haralick et al. (1973) and Chan et al. (1997). We study a total of 144 breast images from the MIAS database. The dimensionality of the dataset is reduced using principal components analysis (PCA), PCA components are classified using both multilayer perceptron networks using backpropagation (MLP) and radial basis functions based on Gaussian kernels (RBF). The two methods are compared on the same data across a ten fold cross-validation. The results are generated on the average recognition rate over these folds on correctly recognising masses and normal regions. Further analysis is based on the receiver operating characteristic (ROC) plots. The best results show recognition rates of 77% correct recognition and an area under the ROC curve value Az of 0.74.", "PublicationYear": "2000", "Authors": ["Keir Bovis", "Sameer Singh", "Jonathan E. Fieldsend", "Christopher L. Pinder"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["0aed632e3d576b6ab0945ac17a84cb008aae8ce2", "c8c81a85bb3387c897e233173e1a0264e8d3e654", "5b40337dcf6c86f31408ff31b878455d32980c8f", "c3d44f3cbb23519941b9290c93ef442db9129a10", "1fdb62555eb650662dbe2a6f3985d390861597c2", "81e89f25baed869a690ffc6f93cd0306c58efe14", "ef27b45cb523e1e2d0de174500f4d7ea33d42427", "dbc0a468ab103ae29717703d4aa9f682f6a2b664", "6494de443cc147a9e75041f79ac1e8c4a117b43f", "b4fea59b65dfaf8067450e01a3cb413ab2a23c3f"], "ReferenceCount": 14, "CitationCount": 72}, {"URL": "https://www.semanticscholar.org/paper/Breast-Cancer-prediction-based-on-Backpropagation-Azmi-Cob/1945ecc90dc463d65ac113fa0b89679bd8f31718", "ID": "1945ecc90dc463d65ac113fa0b89679bd8f31718", "Title": "Breast Cancer prediction based on Backpropagation Algorithm", "Abstract": "A system that can classify \u201cBreast Cancer Disease\u201d tumor using neural network with Feed-forward Backpropagation Algorithm to classify the tumor from a symptom that causes the breast cancer disease is developed. Breast cancer is the second leading cause of cancer deaths in women worldwide and occurs in nearly one out of eight women. Currently there are three techniques to diagnose breast cancer: mammography, FNA (Fine Needle Aspirate) and surgical biopsy. In this paper, we develop a system that can classify \u201cBreast Cancer Disease\u201d tumor using neural network with Feed-forward Backpropagation Algorithm to classify the tumor from a symptom that causes the breast cancer disease. The main aim of research is to develop more cost-effective and easy-to-use systems for supporting clinicians. For the breast cancer tumor diagnosis problem, experimental results show that the concise models extracted from the network achieve high accuracy rate of on the training data set and on the test data set. Breast cancer tumor database used for this purpose is from the University of Wisconsin (UCI) Machine Learning Repository.", "PublicationYear": "2010", "Authors": ["M. S. Bin Mohd Azmi", "Zaihisma Che Cob"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["ea0b96c5660c5e0d659e439947989d804ce80a22", "d4eb78de55ea28540b5692810e6fd7747847ae9a", "1b5591c9246d78870fd715cdc9c2323d492f332b", "99f6512bb20b18c2140a617b3ff8dcc96cc7c3c4", "e0d6afab5c018636831cf73fc58a45b84e7cd31a", "8d4bf1dbe1a5161946d1effc72d56b2c80d69d67", "d226006338e35829dac6f5ff07fc7b201edbfa7b", "914b546c38ad7927599c7c253fbb330c8d2d9372", "5ad00aade2c34a7a2729b03c37c67853caffce5a", "47c080dd8a5c975d272dd8ad44b86c6e2e93678d"], "ReferenceCount": 16, "CitationCount": 28}, {"URL": "https://www.semanticscholar.org/paper/Breast-cancer-diagnosis-using-Artificial-Neural-Janghel-Shukla/cf6fe2d57289af4c401a8f6f006fe243f66d369b", "ID": "cf6fe2d57289af4c401a8f6f006fe243f66d369b", "Title": "Breast cancer diagnosis using Artificial Neural Network models", "Abstract": "A system for diagnosis, prognosis and prediction of breast cancer using Artificial Neural Network (ANN) models is developed to assist the doctors in diagnosis of the disease. Breast cancer is the second leading cause of cancer deaths worldwide and occurrs in one out of eight women. In this paper we develop a system for diagnosis, prognosis and prediction of breast cancer using Artificial Neural Network (ANN) models. This will assist the doctors in diagnosis of the disease. We implement four models of neural networks namely Back Propagation Algorithm, Radial Basis Function Networks, Learning vector Quantization and Competitive Learning Network Experimental results show that Learning Vector Quantization shows the best performance in the testing data set This is followed in order by CL, MLP and RBFN The high accuracy of the LVQ against the other models indicates its better ability for solving the classificatory problem of Breast Cancer diagnosis.", "PublicationYear": "2010", "Authors": ["Rekh Ram Janghel", "Anupam Shukla", "Ritu Tiwari", "Rahul Kala"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["191692de2ffaadfe24e25be60d9ddcf5ff78b35c", "19856863992fb2c9f8eccb2450656c19104dd8e4", "8511fc42bd8c49260781dece041ebeeb00d98a50", "a0ca66908ed5a5968760932637bf2537d03d3d19", "bd5c89fe5a262301e0e8fa0f4e1bbeeba09b3dc4", "7ead1b044233c56a239b3887197239387e648482", "fdb69eec84299be54f8cc3215e45f46ee784693c", "227b786b828240506830fea3660b5dc1de6e2a8e", "095712770b07fd30653032d550bb214d21db04c7", "2aaa0202c1dfb96d1e946d78b97b81fb18477207"], "ReferenceCount": 20, "CitationCount": 61}, {"URL": "https://www.semanticscholar.org/paper/Breast-cancer-diagnosis-using-a-hybrid-evolutionary-hamdi-Njah/a8bd26fae7a98d45a8028371b1a3e96fca0ff64d", "ID": "a8bd26fae7a98d45a8028371b1a3e96fca0ff64d", "Title": "Breast cancer diagnosis using a hybrid evolutionary neural network classifier", "Abstract": "A hybrid evolutionary neural network classifier (HENC) combining the evolutionary algorithm, which has a powerful global exploration capability, with gradient-based local search method, which can exploit the optimum offspring to develop a diagnostic aid that accurately differentiates malignant from benign pattern is introduced. The important role that mammography is playing in breast cancer detection can be attributed largely to the technical improvements and dedication of radiologists to breast imaging. A lot of work is being done to ensure that these diagnosing steps are becoming smoother, faster and more accurate in classifying whether the abnormalities seen in mammogram images are benign or malignant. This paper takes a step in that direction by introducing a hybrid evolutionary neural network classifier (HENC) combining the evolutionary algorithm, which has a powerful global exploration capability, with gradient-based local search method, which can exploit the optimum offspring to develop a diagnostic aid that accurately differentiates malignant from benign pattern. The computational experiments show that the presented HENC approach can obtain better generalization and much lower computational cost than the existing methods reported recently in the literature using the widely accepted Wisconsin breast cancer diagnosis (WBCD) database with some improvements.", "PublicationYear": "2010", "Authors": ["R. El hamdi", "Mohamed Njah", "Mohamed Chtourou"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["730d7a24bb54e56e00b319fa2473b9cabb04b8ec", "f876d2b733ed1e307c81df3008d10ffa60675f0b", "354342c559561ba8de00ebd8a2348e39c19f9439", "bbbe5535472e8c8e019c72c1dade4eedeef333c3", "45e05ebe6f2ac213cc4a16820cabb798bcf97a71", "5b99587096b2cbfa47d4981968ad532c9165e1fe", "9a65a5b0059bbcfef07a8ffb2e66721696b441d2", "f6b6b33918087c2fc3663d852dc6fe0cd8916f65", "f2424c54967c0b4d58f75e517d1c63e37c47364d", "67ad9b3f3d91b101909297d79b912532446485c0"], "ReferenceCount": 20, "CitationCount": 8}, {"URL": "https://www.semanticscholar.org/paper/A-partially-connected-neural-network-based-approach-Belciug-El-Darzi/c120a2f53a87602a97ba1a594a07305dd5a882eb", "ID": "c120a2f53a87602a97ba1a594a07305dd5a882eb", "Title": "A partially connected neural network-based approach with application to breast cancer detection and recurrence", "Abstract": "This paper assesses the effectiveness of an alternative approach, based on a partially connected neural network, using four significantly different breast cancer datasets for comparison, and finds that this simplified neural network type succeeded in obtaining very good accuracy in comparison with a fullyconnected neural network. The fully connected feed-forward neural networks are commonly used in almost all neural networks applications, since such architecture provides the best generalisation power. However, they need large computing resources and have low speed when they are applied to large databases. The aim of this paper is to assess the effectiveness of an alternative approach, based on a partially connected neural network, using four significantly different breast cancer datasets for comparison. Thus, reducing the computing resource consumption during the classification process, and increasing the speed as well, this simplified neural network type succeeded in obtaining very good accuracy in comparison with a fully connected neural network.", "PublicationYear": "2010", "Authors": ["Smaranda Belciug", "Elia El-Darzi"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["191692de2ffaadfe24e25be60d9ddcf5ff78b35c", "0055d5fedacad05bf16d035bf207c7f72afb3b97", "ea0b96c5660c5e0d659e439947989d804ce80a22", "fdb69eec84299be54f8cc3215e45f46ee784693c", "d559674845eea539dcdaf8bd189eb7b8c4b14046", "237d78c01f6ef48fca5f8091ca042367e5426aa1", "27b9c2dcdffc6e733ba5458bfbe07cdbd7354075", "68e217a9f82b8a8233b31936ddbb5feae1455ad9", "709b4bfc5198336ba5d70da987889a157f695c1e", "07b53067f43ffbd6ad3ef28b620edeba53dce803"], "ReferenceCount": 28, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/Breast-Cancer-Detection-Using-BA-BP-Based-Neural-Khosravi-Addeh/d37bd9a7bc19ce640e33449831181fa3e43f90d2", "ID": "d37bd9a7bc19ce640e33449831181fa3e43f90d2", "Title": "Breast Cancer Detection Using BA-BP Based Neural Networks and Efficient Features", "Abstract": "NA", "PublicationYear": "2011", "Authors": ["Ali Reza Khosravi", "Jalil Addeh", "Javad Ganjipour"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["9f9e95adb4664067f5950c0415e882ec3c1cf08d", "ea03e0d491698154997a3adc794a0c0120863fc2", "4294cd774892f27cebe2d31967e897ec2333f4bf", "a7f5a8fb71f6c939a876dcd2446ea4daeb00408e", "45735a64cf4367b8a2711a34d47efb9797ff1f8c", "e663fa59a758b945ed0e8e620a52022d617a9b03", "30fb9443d77c9c823505c80c25bc17b746061126", "f11a1a8c679f8010cb472a71b239563cced33fe1", "a59d674f054575f28fe4d1b6334d6b0a92fad96e", "1b5591c9246d78870fd715cdc9c2323d492f332b"], "ReferenceCount": 37, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/Fast-Learning-in-Networks-of-Locally-Tuned-Units-Moody-Darken/1e7c4f513f24c3b82a1138b9f22ed87ed00cbe76", "ID": "1e7c4f513f24c3b82a1138b9f22ed87ed00cbe76", "Title": "Fast Learning in Networks of Locally-Tuned Processing Units", "Abstract": "This work proposes a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988). We propose a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988). We consider training such networks in a completely supervised manner, but abandon this approach in favor of a more computationally efficient hybrid learning method which combines self-organized and supervised learning. Our networks learn faster than backpropagation for two reasons: the local representations ensure that only a few units respond to any given input, thus reducing computational overhead, and the hybrid learning rules are linear rather than nonlinear, thus leading to faster convergence. Unlike many existing methods for data analysis, our network architecture and learning rules are truly adaptive and are thus appropriate for real-time use.", "PublicationYear": "1989", "Authors": ["John E. Moody", "Christian J. Darken"], "RelatedTopics": ["Computer Science"], "References": ["7c0ade464620ed604ff58d9ad64bcfa1bc37a86f", "cf895330739ec25aa4077ca375daa2cf3d265215", "d1382a29539b3de419d567f679b5f28cee459a49", "2d7de94252e5040a38ebaaf535841d3500791c79", "0908d52124ec2a31bfe9d966d1374a80919155ad", "089a76dbc62a06ad30ae1925530e8733e850268e", "d564b9ffa5ac79bfb9d53b846eaf53d4f201f8de", "6d981c7637fc39335cf53cfa792a0f8d5b66ec6e", "4d21af3b7c2c971c338818d1ee47c4cef3fc88f3", "68ec8a1e9aea1916e2280489729bab74d5bf6631"], "ReferenceCount": 21, "CitationCount": 4662}, {"URL": "https://www.semanticscholar.org/paper/Neural-Networks%3A-A-Comprehensive-Foundation-Haykin/045310b06e8a3983a363a118cc9dcc3f292970b4", "ID": "045310b06e8a3983a363a118cc9dcc3f292970b4", "Title": "Neural Networks: A Comprehensive Foundation", "Abstract": "Simon Haykin Neural Networks A Comprehensive Foundation Simon S. Haykin neural networks a comprehensive foundation pdf PDF Drive. Simon Haykin Neural Networks A Comprehensive Foundation. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation. Neural Networks Association for Computing Machinery. Book Review Neural Networks A Comprehensive Foundation. Neural Networks A Comprehensive Foundation Pearson. Neural networks a comprehensive foundation. Neural Networks a Comprehensive Foundation AbeBooks. Neural networks a comprehensive foundation solutions. cdn preterhuman net. Neural Networks A Comprehensive Foundation Goodreads. Neural Networks A Comprehensive Foundation Amazon it. Neural Networks A Comprehensive Foundation Amazon co uk. Neural Networks A Comprehensive Foundation 3rd Edition. Neural Networks A Comprehensive Foundation Simon. Neural Networks A Comprehensive Foundation amazon com. Neural networks a comprehensive foundation Academia edu. Neural Networks A Comprehensive Foundation Amazon. neural networks a comprehensive foundation simon haykin. Simon Haykin Neural Networks A Comprehensive Foundation. Neural Networks A comprehensive Foundation 2 ed. Simon haykin neural networks a comprehensive foundation pdf. Buy Neural Networks A Comprehensive Foundation Book. Neural networks a comprehensive foundation 2e book. Neural Networks A Comprehensive Foundation. NEURAL NETWORKS A COMPREHENSIVE FOUNDATION SIMON. Neural Networks a Comprehensive Foundation by Haykin Simon. Neural Networks A Comprehensive Foundation pdf PDF Drive. Neural Networks A Comprehensive Foundation amazon ca. Simon Haykin Neural Networks A Comprehensive Foundation. NEURAL NETWORKS A Comprehensive Foundation PDF. Neural Networks A Comprehensive Foundation pdf PDF Drive. Neural Networks A Comprehensive Foundation by Haykin. Neural Networks A Comprehensive Foundation 3rd Edition. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation. Neural networks a comprehensive foundation Book 1994. Neural Networks A Comprehensive Foundation 2nd Edition. Neural Networks A Comprehensive Foundation S S Haykin. Neural Networks A Comprehensive Foundation International. Neural Networks A Comprehensive Foundation 2 e Pearson. Download Neural Networks A Comprehensive Foundation 2Nd. Neural Networks A comprehensive foundation Aalto", "PublicationYear": "1994", "Authors": ["Simon S. Haykin"], "RelatedTopics": ["Computer Science"], "References": [], "ReferenceCount": 3, "CitationCount": 13205}, {"URL": "https://www.semanticscholar.org/paper/Networks-for-approximation-and-learning-Poggio-Girosi/089a76dbc62a06ad30ae1925530e8733e850268e", "ID": "089a76dbc62a06ad30ae1925530e8733e850268e", "Title": "Networks for approximation and learning", "Abstract": "Regularization theory and a theoretical framework for approximation that leads to a class of three-layer networks called regularization networks are discussed, generalized to a formulation that includes task-dependent clustering and dimensionality reduction. The problem of the approximation of nonlinear mapping, (especially continuous mappings) is considered. Regularization theory and a theoretical framework for approximation (based on regularization techniques) that leads to a class of three-layer networks called regularization networks are discussed. Regularization networks are mathematically related to the radial basis functions, mainly used for strict interpolation tasks. Learning as approximation and learning as hypersurface reconstruction are discussed. Two extensions of the regularization approach are presented, along with the approach's corrections to splines, regularization, Bayes formulation, and clustering. The theory of regularization networks is generalized to a formulation that includes task-dependent clustering and dimensionality reduction. Applications of regularization networks are discussed. &gt;", "PublicationYear": "1990", "Authors": ["Tomaso A. Poggio", "Federico Girosi"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["898c01de58eb3b8e790b60e0fe0db2230d88f15b", "d5558a34dfd1dbb572895664d38fca04029a99cb", "31b5a06273e75f159d5d9e42bc5bdfd7fd4b625e", "4a1b11c68bdc362e60fd49639fa20026e4c00fcc", "1e7c4f513f24c3b82a1138b9f22ed87ed00cbe76", "376ea27808150869d2ed43692ca88f27bfa2430a", "6d981c7637fc39335cf53cfa792a0f8d5b66ec6e", "386cbc45ceb59a7abb844b5078e5c944f17723b4", "b477dd12dd49e44a62c1a303501df5fb6706c7e9", "2b37df7dcaef4766969bad8662a53760fb119ba2"], "ReferenceCount": 78, "CitationCount": 3694}, {"URL": "https://www.semanticscholar.org/paper/Breast-cancer-diagnosis-using-least-square-support-Polat-G%C3%BCnes/82d5b4635858db58fd38dd829ae5e2c4d13e3e66", "ID": "82d5b4635858db58fd38dd829ae5e2c4d13e3e66", "Title": "Breast cancer diagnosis using least square support vector machine", "Abstract": "Semantic Scholar extracted view of \\\"Breast cancer diagnosis using least square support vector machine\\\" by K. Polat et al.", "PublicationYear": "2007", "Authors": ["Kemal Polat", "Salih G{\\\"u}nes"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["e663fa59a758b945ed0e8e620a52022d617a9b03", "19b751327a27a76c170d6c64f92623a2eee8e2f5", "456a261579904536364a67207a44660304da5592", "45e05ebe6f2ac213cc4a16820cabb798bcf97a71", "705edf2f3e27eab231425ae42c656cc960588694", "582f1d88ea6c1b4031f6b93ba9451c304ada1e6b", "f4173359eda4bb1bed79687962af23affa24bc54", "0f5b9b46b43c729d554d4120c4e13828c01f40db", "4b0a63a93b6b1b9c19c83c31f163569320352b3d", "b188eecc76ca241738297f518d7402f823902225"], "ReferenceCount": 19, "CitationCount": 384}, {"URL": "https://www.semanticscholar.org/paper/A-fuzzy-genetic-approach-to-breast-cancer-diagnosis-Pe%C3%B1a-Reyes-Sipper/e663fa59a758b945ed0e8e620a52022d617a9b03", "ID": "e663fa59a758b945ed0e8e620a52022d617a9b03", "Title": "A fuzzy-genetic approach to breast cancer diagnosis", "Abstract": "Semantic Scholar extracted view of \\\"A fuzzy-genetic approach to breast cancer diagnosis\\\" by C. Pe\u00f1a-Reyes et al.", "PublicationYear": "1999", "Authors": ["Carlos Andr{\\'e}s Pe{\\~n}a-Reyes", "Moshe Sipper"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["8d4bf1dbe1a5161946d1effc72d56b2c80d69d67", "6a1b3266d2e68b67c398cce54cbafe83828053f8", "bf0122eab2bf2e3d4739ae7b3ae78e533630907d", "508027c325304dd0a949bca4260f149c982df91b", "637e3728fa5c7a9f0f0eb6f4a144fa1c85beac9c", "1059c6023909fc7c8c9d927571ee2a2b6b9fe502", "e01a22329d3a1b79dadfd8a252b523134a5374e9", "19cfc8d722b56804418f21267d73e82c9d32d146", "53576d61e9c5cedc1a3f57a2e6af2cd45e85b52d", "3578e8d0304a7f3690d1e5b4bbb451076ba123fe"], "ReferenceCount": 41, "CitationCount": 402}, {"URL": "https://www.semanticscholar.org/paper/Two-applications-of-the-LSA-machine-Albrecht-Lappas/10ea1a358fecfd1623e230df98f11f967490c47a", "ID": "10ea1a358fecfd1623e230df98f11f967490c47a", "Title": "Two applications of the LSA machine", "Abstract": "Two applications of a learning algorithm that combines logarithmic simulated annealing with the perceptron algorithm are presented that improve on the results published by Golub et al. (1999) by using the model of self-organising maps. We present two applications of a learning algorithm that combines logarithmic simulated annealing with the perceptron algorithm. The implementation of the learning algorithm is called LSA machine and has been successfully applied already to the classification of liver tissue from CT images. We investigate the performance of the LSA machine on two sets of numerical data: The Wisconsin breast cancer diagnosis (WBCD) database and microarray data published by Golub et al. (1999). The WBCD data consist of 683 samples with 9 input values that are divided into 444 benign cases (positive examples) and 239 malignant cases (negative examples). The LSA machine has been trained on 50% and 75% of the entire sample set, and the test has been performed on the remaining samples. In both cases, we obtain a correct classification close to 99% which is comparable to the best results published on WBCD data. The training set of the microarray data consists of I I samples of acute myeloid leukemia (AML) and 27 samples of acute lymphoblastic leukemia (ALL), each of them with 7129 input values (gene-expression data). For the test, 14 AML samples and 20 ALL samples are used. We obtain a single classification error (which is a ALL test sample) on seven genes only, which improves on the results published by Golub et al. (1999) by using the model of self-organising maps. Our result is competitive to the best results published for support vector machines.", "PublicationYear": "2002", "Authors": ["Andreas Alexander Albrecht", "Georgios Lappas", "Staal Amund Vinterbo", "C. K. P. Wong", "Lucila Ohno-Machado"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["cd10293541f4140b081673bf264632a9c59e6225", "5794141889d0e994c3103b0aaab08a18222c9c43", "606d209492e8374131e9b3bcfb631ea078f987e5", "fb6b4b57f431a0cfbb83bb2af8beab4ee694e94c", "d2cac15e5675bf0d05aa4885f47a233b649b927a", "41c6f229c4b149d502f89ffc386febb24116bd25", "015999a72c70a960e59c51078b09c8f672af0d2c", "456a261579904536364a67207a44660304da5592", "f31fd3e25aea5c6e25c8192a6bcf8b16285f24bf", "4d19272112b50547614479a0c409fca66e3b05f7"], "ReferenceCount": 26, "CitationCount": 51}, {"URL": "https://www.semanticscholar.org/paper/Ensemble-strategies-for-a-medical-diagnostic-A-West-Mangiameli/5c7dfd541f7eb4b8148c69d9a2974f1d7357d1fa", "ID": "5c7dfd541f7eb4b8148c69d9a2974f1d7357d1fa", "Title": "Ensemble strategies for a medical diagnostic decision support system: A breast cancer diagnosis application", "Abstract": "Semantic Scholar extracted view of \\\"Ensemble strategies for a medical diagnostic decision support system: A breast cancer diagnosis application\\\" by David West et al.", "PublicationYear": "2005", "Authors": ["David West", "Paul Mangiameli", "Rohit Rampal", "Vivian L West"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["d3e82192599c6a58cb904fc50c8c6721094c14ca", "235c5a0febd35493dfee553e7c8235ec105f8f6b", "950bc491afa33c2fdcdef9a41b69760f9f338cf7", "6a1b3266d2e68b67c398cce54cbafe83828053f8", "770513f9d0c9c6e7085dbbb8187205ff88ab9e11", "200fc802f57ccfe436b199fef5873f980d2e3f73", "5cb73278d2935d4d6819f39566ede7340f4e0f04", "d664f1111c9718b729bf38937694461e3afa1571", "51f48ecbc1ebcffc3bd49983fcdc3762f681707d", "a7d714f8f87bfc41351eb5ae1e5472f0ebbe0574"], "ReferenceCount": 55, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Generating-concise-and-accurate-classification-for-Setiono/456a261579904536364a67207a44660304da5592", "ID": "456a261579904536364a67207a44660304da5592", "Title": "Generating concise and accurate classification rules for breast cancer diagnosis", "Abstract": "Semantic Scholar extracted view of \\\"Generating concise and accurate classification rules for breast cancer diagnosis\\\" by R. Setiono", "PublicationYear": "2000", "Authors": ["Rudy Setiono"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["bf0122eab2bf2e3d4739ae7b3ae78e533630907d", "e663fa59a758b945ed0e8e620a52022d617a9b03", "637e3728fa5c7a9f0f0eb6f4a144fa1c85beac9c", "bc37101dc273c4aa75ccdefc0f3ee439d28212dd", "7d196ad6907b12ebb24faa57219770917e506493", "0f2ed9d8b32b8c1f8c1124d3ccd3e6814574100c", "9eb8b452b0e037b6563b0b4398506f0b5d6946d7", "82ee6b69dc8ff8338e295b748f0205364dd8ceff", "c5a1a53a7ae61a17b56faf49484d8d79fd6ef8b0", "44e78f23e132ae9dbb4a129622076eed656e60a6"], "ReferenceCount": 25, "CitationCount": 286}, {"URL": "https://www.semanticscholar.org/paper/Comparing-Support-Vector-Machines-with-Gaussian-to-Schh-Sung/57a29eae9217831f391c2a3206964fddbb162250", "ID": "57a29eae9217831f391c2a3206964fddbb162250", "Title": "Comparing Support Vector Machines with Gaussian Kernels to Radial Basis Function Classi", "Abstract": "The results show that on the US postal service database of handwritten digits, the SV machine achieves the highest test accuracy, followed by the hybrid approach, and the SV approach is thus not only theoretically well-founded, but also superior in a practical application. The Support Vector (SV) machine is a novel type of learning machine, based on statistical learning theory, which contains polynomial classi ers, neural networks, and radial basis function (RBF) networks as special cases. In the RBF case, the SV algorithm automatically determines centers, weights and threshold such as to minimize an upper bound on the expected test error. The present study is devoted to an experimental comparison of these machines with a classical approach, where the centers are determined by k{means clustering and the weights are found using error backpropagation. We consider three machines, namely a classical RBF machine, an SV machine with Gaussian kernel, and a hybrid system with the centers determined by the SV method and the weights trained by error backpropagation. Our results show that on the US postal service database of handwritten digits, the SV machine achieves the highest test accuracy, followed by the hybrid approach. The SV approach is thus not only theoretically well{founded, but also superior in a practical application. Copyright c Massachusetts Institute of Technology, 1996 This report describes research done at the Center for Biological and Computational Learning, the Arti cial Intelligence Laboratory of the Massachusetts Institute of Technology, and at AT&T Bell Laboratories (now AT&T Research, and Lucent Technologies Bell Laboratories). Support for the Center is provided in part by a grant from the National Science Foundation under contract ASC{9217041. BS thanks the M.I.T. for hospitality during a three{week visit in March 1995, where this work was started. At the time of the study, BS, CB, and VV were with AT&TBell Laboratories, NJ; KS, FG, PN, and TP were with the Massachusetts Institute of Technology. KS is now with the Department of Information Systems and Computer Science at the National University of Singapore, Lower Kent Ridge Road, Singapore 0511; CB and PN are with Lucent Technologies, Bell Laboratories, NJ; VV is with AT&T Research, NJ. BS was supported by the Studienstiftung des deutschen Volkes; CB was supported by ARPA under ONR contract number N00014-94-C-0186. We thank A. Smola for useful discussions. Please direct correspondence to Bernhard Sch\u007folkopf, bs@mpik-tueb.mpg.de, Max{Planck{Institut f\u007f ur biologische Kybernetik, Spemannstr. 38, 72076 T\u007f ubingen, Germany. Figure 1: A simple 2{dimensional classi cation problem: nd a decision function separating balls from circles. The box, as in all following pictures, depicts the region [ 1; 1].", "PublicationYear": "1997", "Authors": ["Bernhard Schh", "Kah Kay Sung", "Christopher J. C. Burges", "Federico Girosi", "P N I Y Ogi", "Tomaso A. Poggio", "Vladimir Vapnik"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["fed98ea8ecad5034441fd0ac9f728479183e3b9e", "40e5a40ae66d44e6c00d562d068d35db6922715d", "4aaa30769ca49875f45670970130c088136986d1", "7ec8029e5855b6efbac161488a2e68f83298091c", "55590f229e23a8e67af7d6d36f7456a595c251d1", "dd49fda51700d6270472aa931706add576c5ee33", "052b1d8ce63b07fec3de9dbb583772d860b7c769", "a8e8f3c8d4418c8d62e306538c9c1292635e9d27", "9241ea3d8cb85633d314ecb74b31567b8e73f6af", "089a76dbc62a06ad30ae1925530e8733e850268e"], "ReferenceCount": 11, "CitationCount": 1330}, {"URL": "https://www.semanticscholar.org/paper/Training-support-vector-machines%3A-an-application-to-Osuna-Freund/9008cdacbdcff8a218a6928e94fe7c6dfc237b24", "ID": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24", "Title": "Training support vector machines: an application to face detection", "Abstract": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated. We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points.", "PublicationYear": "1997", "Authors": ["Edgar Osuna", "Robert M. Freund", "Federico Girosi"], "RelatedTopics": ["Computer Science"], "References": ["68c4749d9d3f1724aa01778d69a3774c732ca44c", "fed98ea8ecad5034441fd0ac9f728479183e3b9e", "4aaa30769ca49875f45670970130c088136986d1", "f6af749b2b813af20c2f26962249fafdccdc6a1e", "088eb2d102c6bb486f5270d0b2adff76961994cf", "e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6", "2bb1ba70d48561ce8c3fbf59739fabc95e7b3d50", "1cdb510aed4f8b04b73240287da954f9eff39318", "2382359da7a5cae09cd7f675829239306487c757", "09ebd9ad4fa21c0d56433ac57a4cd69e94c72281"], "ReferenceCount": 13, "CitationCount": 2929}, {"URL": "https://www.semanticscholar.org/paper/Support-Vector-Machines-for-3D-Object-Recognition-Pontil-Verri/1fda96d554f4e5a21e35bf33b9720141da47664b", "ID": "1fda96d554f4e5a21e35bf33b9720141da47664b", "Title": "Support Vector Machines for 3D Object Recognition", "Abstract": "The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose, indicating that SVMs are well-suited for aspect-based recognition. Support vector machines (SVMs) have been recently proposed as a new technique for pattern recognition. Intuitively, given a set of points which belong to either of two classes, a linear SVM finds the hyperplane leaving the largest possible fraction of points of the same class on the same side, while maximizing the distance of either class from the hyperplane. The hyperplane is determined by a subset of the points of the two classes, named support vectors, and has a number of interesting theoretical properties. In this paper, we use linear SVMs for 3D object recognition. We illustrate the potential of SVMs on a database of 7200 images of 100 different objects. The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose. The excellent recognition rates achieved in all the performed experiments indicate that SVMs are well-suited for aspect-based recognition.", "PublicationYear": "1998", "Authors": ["Massimiliano Pontil", "Alessandro Verri"], "RelatedTopics": ["Computer Science"], "References": ["9008cdacbdcff8a218a6928e94fe7c6dfc237b24", "68c4749d9d3f1724aa01778d69a3774c732ca44c", "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f", "50899b2355d6908a304bacb5e406f800f3dde558", "57a29eae9217831f391c2a3206964fddbb162250", "5a0f97e889f6fb4b71704f079407a5ef730ad95f", "b0bf5d558220d39698ce96d59ee5772e8e1a0663", "85efeeb25d8e363606d94c8fadaa922ba9b93a37", "239beb3861ceceb4c7c7f229234d97198d5c7697", "fddc5b0b1293d908e18972dd647de6070c1e8ce8"], "ReferenceCount": 17, "CitationCount": 865}, {"URL": "https://www.semanticscholar.org/paper/Transductive-Inference-for-Text-Classification-Joachims/74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8", "ID": "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8", "Title": "Transductive Inference for Text Classification using Support Vector Machines", "Abstract": "An analysis of why Transductive Support Vector Machines are well suited for text classi cation is presented, and an algorithm for training TSVMs, handling 10,000 examples and more is proposed. This paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more.", "PublicationYear": "1999", "Authors": ["Thorsten Joachims"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["40212e9474c3ddf3d8c6ffd13dd3211ec9406c49", "63287d3220fe96d5cbf73067545abbb88cc180a6", "9c4da62e9e89e65ac78ee271e424e8b498053e8c", "c3ebcef26c22a373b6f26a67934213eb0582804e", "04ce064505b1635583fa0d9cc07cac7e9ea993cc", "008abebf4a9404db9050c9d2fbca769f4faf3ca6", "7550a05bf00f7b24aed9c1ac3ef000575388d21c", "b5bf6046f3d0a37fe8e03d6e26b27e07c0a55a76", "094fc15bc058b0d62a661a1460885a9490bdb1bd", "e50a316f97c9a405aa000d883a633bd5707f1a34"], "ReferenceCount": 20, "CitationCount": 3188}, {"URL": "https://www.semanticscholar.org/paper/Feature-selection-for-support-vector-machines-by-of-Fr%C3%B6hlich-Chapelle/0d28c0390b21244cc52e9af856249cb601f6b22d", "ID": "0d28c0390b21244cc52e9af856249cb601f6b22d", "Title": "Feature selection for support vector machines by means of genetic algorithm", "Abstract": "This paper presents a special genetic algorithm, which especially takes into account the existing bounds on the generalization error for support vector machines (SVMs), which is compared to the traditional method of performing cross-validation and to other existing algorithms for feature selection. The problem of feature selection is a difficult combinatorial task in machine learning and of high practical relevance, e.g. in bioinformatics. genetic algorithms (GAs) offer a natural way to solve this problem. In this paper, we present a special genetic algorithm, which especially takes into account the existing bounds on the generalization error for support vector machines (SVMs). This new approach is compared to the traditional method of performing cross-validation and to other existing algorithms for feature selection.", "PublicationYear": "2003", "Authors": ["Holger Fr{\\\"o}hlich", "Olivier Chapelle", "Bernhard Scholkopf"], "RelatedTopics": ["Computer Science"], "References": ["46ba0c8afc9339221076f2b2e497e2a6d9ce6248", "cc821124d2dadc984a4aed5168bb758dd91be3f8", "08b4c61724390f0ba52c711b89121c8dcf7de6c5", "626a5da1bfc0f4b38be27f867f95daa061655f94", "a81cf97778664a960e4f2770bc8c703f8a1afa1b", "2e62d1345b340d5fda3b092c460264b9543bc4b5", "31d0a945d95314e51a970c3f2b588c8f914ccc48", "cbc78c2669eb595c988ab69a6dd4cbabc2421043", "4aaa30769ca49875f45670970130c088136986d1", "5a992baaffc87c7ebf188e27d48935227520e95d"], "ReferenceCount": 74, "CitationCount": 347}, {"URL": "https://www.semanticscholar.org/paper/TESTING-THE-PERFORMANCES-OF-DIFFERENT-IMAGE-FOR-IN-Angelini-Campanini/adef50946f5336ac951bb37056c0c8de107aa9a7", "ID": "adef50946f5336ac951bb37056c0c8de107aa9a7", "Title": "TESTING THE PERFORMANCES OF DIFFERENT IMAGE REPRESENTATIONS FOR MASS CLASSIFICATION IN DIGITAL MAMMOGRAMS", "Abstract": "A mass detection algorithm which does not refer explicitly to shape, border, size, contrast or texture of mammographic suspicious regions is evaluated and the improvement in the Az value with the pixel image representation is statistically significant compared to that obtained with the discrete wavelet and overcomplete wavelet image representations. The classification of tumoral masses and normal breast tissue is targeted. A mass detection algorithm which does not refer explicitly to shape, border, size, contrast or texture of mammographic suspicious regions is evaluated. In the present approach, classification features are embodied by the image representation used to encode suspicious regions. Classification is performed by means of a support vector machine (SVM) classifier. To investigate whether improvements can be achieved with respect to a previously proposed overcomplete wavelet image representation, a pixel and a discrete wavelet image representations are developed and tested. Evaluation is performed by extracting 6000 suspicious regions from the digital database for screening mammography (DDSM) collected by the University of South Florida (USF). More specifically, 1000 regions representing \\nbiopsy-proven tumoral masses (either benign or malignant) and 5000 regions representing normal breast tissue are extracted. Results demonstrate very high performance levels. \\nThe area Az under the receiver operating characteristic (ROC) curve reaches values of 0.973 +/- 0.002, 0.948 +/- 0.004 and 0.956 +/- 0.003 for the pixel, discrete wavelet and overcomplete wavelet image representations, respectively. In particular, the improvement in the Az value with the pixel image representation is statistically significant compared to that obtained with the discrete wavelet and overcomplete wavelet image representations (two-tailed p-value &lt; 0.0001). Additionally, 90% true positive fraction (TPF) values are achieved with false positive fraction (FPF) values of 6%, 11% and 7%, respectively.", "PublicationYear": "2006", "Authors": ["Enrico Angelini", "Renato Campanini", "Emiro Iampieri", "Nico Lanconelli", "Matteo Masotti", "Matteo Roffilli"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["f876d2b733ed1e307c81df3008d10ffa60675f0b", "3a54399b141999271e49c652979f65fcd968daa9", "bba978f6deba664527708705d12365bc0f157151", "ff74c47e8e908b4804e5e87ae89bd07b10ab6216", "ef9d4e735dd0e569a914a16bae165f874e679064", "38f7c8cfb6b52df515c1cb29a2e42f6673e7a377", "47bcbeb612753768c4e102188d87cee9c5479d41", "b88441fcbf2bbfbb8ae89856120c7fa2b959f09c", "87872da9bea7fac5e4b3beb313fc86fa65ce0a7a", "8706fa1f5aa5721a6c36c8ec088122e08dda20e7"], "ReferenceCount": 32, "CitationCount": 32}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-mass-and-normal-breast-tissue-on-Wei-Chan/3a54399b141999271e49c652979f65fcd968daa9", "ID": "3a54399b141999271e49c652979f65fcd968daa9", "Title": "Classification of mass and normal breast tissue on digital mammograms: multiresolution texture analysis.", "Abstract": "It is found that texture features at large pixel distances are important for the classification task and a linear discriminant classifier using the multiresolution texture features can effectively classify masses from normal tissue on mammograms. We investigated the feasibility of using multiresolution texture analysis for differentiation of masses from normal breast tissue on mammograms. The wavelet transform was used to decompose regions of interest (ROIs) on digitized mammograms into several scales. Multiresolution texture features were calculated from the spatial gray level dependence matrices of (1) the original images at variable distances between the pixel pairs, (2) the wavelet coefficients at different scales, and (3) the wavelet coefficients up to certain scale and then at variable distances between the pixel pairs. In this study, 168 ROIs containing biopsy-proven masses and 504 ROIs containing normal parenchyma were used as the data set. The mass ROIs were randomly and equally divided into training and test groups along with corresponding normal ROIs from the same film. Stepwise linear discriminant analysis was used to select optimal features from the multiresolution texture feature space to maximize the separation of mass and normal tissue for all ROIs. We found that texture features at large pixel distances are important for the classification task. The wavelet transform can effectively condense the image information into its coefficients. With texture features based on the wavelet coefficients and variable distances, the area Az under the receiver operating characteristic curve reached 0.89 and 0.86 for the training and test groups, respectively. The results demonstrate that a linear discriminant classifier using the multiresolution texture features can effectively classify masses from normal tissue on mammograms.", "PublicationYear": "1995", "Authors": ["Datona Wei", "Heana Pina Chan", "Mark A. Helvie", "Berkman Sahiner", "Nicholas A. Petrick", "Dorit D. Adler", "Mitchell M. Goodsitt"], "RelatedTopics": ["Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 135}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-mass-and-normal-breast-tissue%3A-a-Sahiner-Chan/f876d2b733ed1e307c81df3008d10ffa60675f0b", "ID": "f876d2b733ed1e307c81df3008d10ffa60675f0b", "Title": "Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images", "Abstract": "The authors' results demonstrate the feasibility of using a convolution neural network for classification of masses and normal tissue on mammograms using a generalized, fast and stable implementation of the CNN. The authors investigated the classification of regions of interest (ROI's) on mammograms as either mass or normal tissue using a convolution neural network (CNN). A CNN is a backpropagation neural network with two-dimensional (2-D) weight kernels that operate on images. A generalized, fast and stable implementation of the CNN was developed. The input images to the CNN were obtained from the ROI's using two techniques. The first technique employed averaging and subsampling. The second technique employed texture feature extraction methods applied to small subregions inside the ROI. Features computed over different subregions were arranged as texture images, which were subsequently used as CNN inputs. The effects of CNN architecture and texture feature parameters on classification accuracy were studied. Receiver operating characteristic (ROC) methodology was used to evaluate the classification accuracy. A data set consisting of 168 ROIs containing biopsy-proven masses and 504 ROI's containing normal breast tissue was extracted from 168 mammograms by radiologists experienced in mammography. This data set was used for training and testing the CNN. With the best combination of CNN architecture and texture feature parameters, the area under the test ROC curve reached 0.87, which corresponded to a true-positive fraction of 90% at a false positive fraction of 31%. The authors' results demonstrate the feasibility of using a CNN for classification of masses and normal tissue on mammograms.", "PublicationYear": "1996", "Authors": ["Berkman Sahiner", "Heang-Ping Chan", "Nicholas A. Petrick", "Datong Wei", "Mark A. Helvie", "Dorit D. Adler", "Mitchell M. Goodsitt"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["3a54399b141999271e49c652979f65fcd968daa9", "f6867839bf43b4c79f740da36a676afd6fdbe112", "c93697b663eb97fbb595c433e3386b56be2f9fc5", "770513f9d0c9c6e7085dbbb8187205ff88ab9e11", "2f4684fff8e020b3e826cb73800dbc97eacdef3f", "8b98632212514b5dc28df528477abc0cd817c338", "bae2d8243540c7935d48f316711e6a9181bdee6a", "38d28411834bb0e328722d04bd812ff1f11ece45", "66cb958c5fe045d9037724f38c5ca7b4728a13f1", "057ac70ca12c96e90ccf461a8c6ad2c82e94e787"], "ReferenceCount": 25, "CitationCount": 430}, {"URL": "https://www.semanticscholar.org/paper/A-novel-approach-to-mass-detection-in-digital-based-Campanini-Bazzani/34856bb7b455a317126787076be40f4f57154273", "ID": "34856bb7b455a317126787076be40f4f57154273", "Title": "A novel approach to mass detection in digital mammography based on Support Vector Machines(SVM)", "Abstract": "A novel approach to mass detection in digital mammograms where no a priori knowledge and no appearance model are used, and a multiresolution overcomplete wavelet representation is achieved, in order to codify the image with redundancy of information. In this paper we present a novel approach to mass detection in digital mammograms. The great variability of the masses appearance is the main obstacle of building a mass detection method. It is indeed demanding to characterize all the varieties of masses with a reduced set of features. Hence, in our approach we decide not to extract any feature, for the detection of the region of interest; on the contrary we exploit all the information available on the image. No a priori knowledge and no appearance model are used. A multiresolution overcomplete wavelet representation is achieved, in order to codify the image with redundancy of information. The vectors of the very-large space obtained are classified by means of an SVM classifier. Training, validation and test are accomplished on images coming from USF DDSM database. The sensitivity of the presented system is 84% with a false-positive rate of 3.1 marks per image.", "PublicationYear": "2003", "Authors": ["Renato Campanini", "Armando Bazzani", "Alessandro Bevilacqua", "Dante Bollini", "Danilo Dongiovanni", "Emiro Iampieri", "Nico Lanconelli", "Alessandro Riccardi", "Matteo Roffilli", "Roberto Tazzoli"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["ef9d4e735dd0e569a914a16bae165f874e679064", "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5", "8213dbed4db44e113af3ed17d6dad57471a0c048", "5451278e1a11cf3f1be28a05f38d36c8641e68f7"], "ReferenceCount": 4, "CitationCount": 24}, {"URL": "https://www.semanticscholar.org/paper/Preliminary-results-of-a-featureless-CAD-system-on-Campanini-Angelini/e764d70b416fa5fee1fd76ed21d64e26ef187bb9", "ID": "e764d70b416fa5fee1fd76ed21d64e26ef187bb9", "Title": "Preliminary results of a featureless CAD system on FFDM images", "Abstract": "The CAD scheme is tested on digital images coming from Giotto Image MD FFDM unit, a mammography system based on an amorphous Selenium detector, with preliminary results presented on a database gathered at two different sites. A novel featureless approach to the detection of masses and microcalcifications has been adopted, based on a Support Vector Machine (SVM) classifier. This method does not rely on any feature extraction task; on the contrary, the algorithm automatically learns to detect the lesions by the examples presented to it during the training phase. Our technique includes a pre-selection step, in which we select the intra-breast areas that will be analyzed. Those regions are then provided to an SVM classifier, trained to recognize suspect masses or microcalcifications. The CAD performance have been already assessed on digitized mammogram freely available on the net (DDSM USF and Nijmegen databases). In this paper we are going to test the CAD scheme on digital images coming from Giotto Image MD FFDM unit, a mammography system based on an amorphous Selenium detector. Images have a spatial resolution equal to 85 um and 13 bit gray-level resolution and have been collected at two different sites: Maggiore Hospital in Bologna (Italy) and Triemli Hospital in Zurich (Switzerland). Preliminary results are presented on a database gathered at these hospitals. The CAD system marked in the FFDM images 19 cancers out of 23, with a false-positive rate of 0.9 marks per image.", "PublicationYear": "2004", "Authors": ["Renato Campanini", "Enrico Angelini", "Danilo Dongiovanni", "Emiro Iampieri", "NicoLanconelli", "Claude Mair-Noack", "Matteo Masotti", "Giuseppe Palermo", "Matteo Roffilli", "Gianni Saguatti", "Omar Schiaratura"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["34856bb7b455a317126787076be40f4f57154273", "f1d73520d51a0f19c686d9f4bf7af1db33763a2a", "bba978f6deba664527708705d12365bc0f157151", "ef9d4e735dd0e569a914a16bae165f874e679064", "6ad785d55427b210bcf71cd85022f16a0324d859", "63bcf405b978707fb0aed6079f8b578de220b3bb"], "ReferenceCount": 6, "CitationCount": 4}, {"URL": "https://www.semanticscholar.org/paper/An-automatic-method-to-discriminate-malignant-from-Brake-Karssemeijer/29dab22d41369fe0af3dd6bca85e0c5aa6859ded", "ID": "29dab22d41369fe0af3dd6bca85e0c5aa6859ded", "Title": "An automatic method to discriminate malignant masses from normal tissue in digital mammograms1", "Abstract": "A number of features were defined that are related to image characteristics that radiologists use to discriminate real lesions from normal tissue that were successful in discriminating tumours from false positive detections in mammography. Specificity levels of automatic mass detection methods in mammography are generally rather low, because suspicious looking normal tissue is often hard to discriminate from real malignant masses. In this work a number of features were defined that are related to image characteristics that radiologists use to discriminate real lesions from normal tissue. An artificial neural network was used to map the computed features to a measure of suspiciousness for each region that was found suspicious by a mass detection method. Two data sets were used to test the method. The first set of 72 malignant cases (132 films) was a consecutive series taken from the Nijmegen screening programme, 208 normal films were added to improve the estimation of the specificity of the method. The second set was part of the new DDSM data set from the University of South Florida. A total of 193 cases (772 films) with 372 annotated malignancies was used. The measure of suspiciousness that was computed using the image characteristics was successful in discriminating tumours from false positive detections. Approximately 75% of all cancers were detected in at least one view at a specificity level of 0.1 false positive per image.", "PublicationYear": "2000", "Authors": ["G M te Brake", "Nico Karssemeijer", "Jan H. C. L. Hendriks"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["a0a0fcedd92107cc3f115f323ec0650012654994", "1ac5f398c1eeae7189800c003035dc7248298f93", "e01f9f37c0b096990025b9b2861cd05d84ffa665", "ea6d7923148a65372a539e686ec813d05233d5a8", "5b40337dcf6c86f31408ff31b878455d32980c8f", "fb2d47d31865291e41f75d5443228cc41f8ef71a", "3a54399b141999271e49c652979f65fcd968daa9", "b301e9c53ffbfa0df00feed1b50c6438d16c0c08", "5bfaaf486d99b2ebb95a6ac61e760cef0117ebb0", "49d148ca8e50d2d153cc66b22c4bf3d8f03355e6"], "ReferenceCount": 25, "CitationCount": 136}, {"URL": "https://www.semanticscholar.org/paper/Automated-detection-of-clustered-on-mammograms%3A-CAD-Ibrahim-Fujita/38f7c8cfb6b52df515c1cb29a2e42f6673e7a377", "ID": "38f7c8cfb6b52df515c1cb29a2e42f6673e7a377", "Title": "Automated detection of clustered microcalcifications on mammograms: CAD system application to MIAS database.", "Abstract": "The detection performance of the automated detection scheme for clustered microcalcifications on mammograms applied to the database of the Mammographic Image Analysis Society (MIAS) in the UK demonstrates that the automated Detection of clustered microCalcifications in the CAD system is reliable as an aid to radiologists. To investigate the detection performance of our automated detection scheme for clustered microcalcifications on mammograms, we applied our computer-aided diagnosis (CAD) system to the database of the Mammographic Image Analysis Society (MIAS) in the UK. Forty-three mammograms from this database were used in this study. In our scheme, the breast regions were firstly extracted by determining the skinline. Histograms of the original images were used to extract the high-density area within the breast region as the segmentation from the fatty area around the skinline. Then the contrast correction technique was employed. Gradient vectors of the image density were calculated on the contrast corrected images. To extract the specific features of the pattern of the microcalcifications, triple-ring filter analysis was employed. A variable-ring filter was used for more accurate detection after the triple-ring filter. The features of the detected candidate areas were then characterized by feature analysis. The areas which satisfied the characteristics and specific terms were classified and displayed as clusters. As a result, the sensitivity was 95.8% with the false-positive rate at 1.8 clusters per image. This demonstrates that the automated detection of clustered microcalcifications in our CAD system is reliable as an aid to radiologists.", "PublicationYear": "1997", "Authors": ["Nazrita Ibrahim", "H. Fujita", "T. Hara", "T. Endo"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["f35fb5da2f03f6ba299b7364766f1dd040dc2115", "c4489eadf3148702292ea59a2d935d3948a1c0b2", "fea4b238101d56979546c122427d8b02b29cc5d0", "81e89f25baed869a690ffc6f93cd0306c58efe14", "2a49ba1372671bb34292a420b97efd0568403985"], "ReferenceCount": 5, "CitationCount": 50}, {"URL": "https://www.semanticscholar.org/paper/A-fast-algorithm-for-intra-breast-segmentation-of-Campanini-Angelini/413bb48a77c0730693ea8217d89cab28a686e7a3", "ID": "413bb48a77c0730693ea8217d89cab28a686e7a3", "Title": "A fast algorithm for intra-breast segmentation of digital mammograms for CAD systems", "Abstract": "A powerful algorithm is presented that performs an intra-breast segmentation from a digital mammogram and by using a combination of different techniques produces a binary map showing the locations of the breast with higher probability of containing a suspect mass. Current CAD systems always demand better performance, both in terms of the best sensitivity-specificity tradeoff and of the processing time. In order to decrease the false positive rate and to increase the time responsiveness of our CAD system, we present a powerful algorithm that performs an intra-breast segmentation. Starting from a digital mammogram and by using a combination of different techniques, the proposed algorithm produces a binary map showing the locations of the breast with higher probability of containing a suspect mass. Experimental trials performed on 317 mammograms show that our algorithm is able to reduce the intra-breast searching area down to 6% of the entire breast area, while maintaining almost the same negative rate. Typical dimension of images is about 2800\u00d72000 pixels at 13 bits of gray level resolution. The set of images was gathered from FFDM units coming from two different hospitals.", "PublicationYear": "2004", "Authors": ["Renato Campanini", "Enrico Angelini", "Emiro Iampieri", "NicoLanconelli", "Matteo Masotti", "Matteo Roffilli", "Omar Schiaratura", "Massimiliano Zanoni"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["491d0dc6ea1d5a5b3ea859b4812a4bc3477a674d", "ef9d4e735dd0e569a914a16bae165f874e679064", "bba978f6deba664527708705d12365bc0f157151", "6494de443cc147a9e75041f79ac1e8c4a117b43f", "78820f823d244ef710fc4c63c5524840c30aa7ea"], "ReferenceCount": 5, "CitationCount": 6}, {"URL": "https://www.semanticscholar.org/paper/Improvement-of-radiologists'-characterization-of-by-Chan-Sahiner/eddad94fd10693fb0cf3340792f11af15232b49c", "ID": "eddad94fd10693fb0cf3340792f11af15232b49c", "Title": "Improvement of radiologists' characterization of mammographic masses by using computer-aided diagnosis: an ROC study.", "Abstract": "CAD may be useful for assisting radiologists in classification of masses and thereby potentially help reduce unnecessary biopsies, as predicted from the improved ROC curves. PURPOSE\\nTo evaluate the effects of computer-aided diagnosis (CAD) on radiologists' classification of malignant and benign masses seen on mammograms.\\n\\n\\nMATERIALS AND METHODS\\nThe authors previously developed an automated computer program for estimation of the relative malignancy rating of masses. In the present study, the authors conducted observer performance experiments with receiver operating characteristic (ROC) methodology to evaluate the effects of computer estimates on radiologists' confidence ratings. Six radiologists assessed biopsy-proved masses with and without CAD. Two experiments, one with a single view and the other with two views, were conducted. The classification accuracy was quantified by using the area under the ROC curve, Az.\\n\\n\\nRESULTS\\nFor the reading of 238 images, the Az value for the computer classifier was 0.92. The radiologists' Az values ranged from 0.79 to 0.92 without CAD and improved to 0.87-0.96 with CAD. For the reading of a subset of 76 paired views, the radiologists' Az values ranged from 0.88 to 0.95 without CAD and improved to 0.93-0.97 with CAD. Improvements in the reading of the two sets of images were statistically significant (P = .022 and .007, respectively). An improved positive predictive value as a function of the false-negative fraction was predicted from the improved ROC curves.\\n\\n\\nCONCLUSION\\nCAD may be useful for assisting radiologists in classification of masses and thereby potentially help reduce unnecessary biopsies.", "PublicationYear": "1999", "Authors": ["Heang-Ping Chan", "Berkman Sahiner", "Mark A. Helvie", "Nicholas A. Petrick", "Marilyn A. Roubidoux", "Todd E. Wilson", "Dorit D. Adler", "Chintana Paramagul", "Joel S. Newman", "S. Sanjay-Gopal"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["ea6d7923148a65372a539e686ec813d05233d5a8", "06974cd43fb263d178d56a7022082ad42f33557b", "25c77c18bbb0224082d675064aa644cd12025597", "24205bd2357eeb3ac6cfcfcb5dca949de0a0bac0", "4a18fe753a3d4f6619928220fb23f7bdd3ba4cff", "7985801d358c788c0f46c60125fcb4eabb7bf408", "fce38045cbe7ea3189d3183f6fef55f64bbf4975", "51f48ecbc1ebcffc3bd49983fcdc3762f681707d", "7bda4a289f585f8a31d819b963006f6c6918478c", "5b39294b50c1461fa8a18fc6c0e8a4aaaf30ef81"], "ReferenceCount": 26, "CitationCount": 286}, {"URL": "https://www.semanticscholar.org/paper/Contour-tracing-for-segmentation-of-mammographic-Elter-Held/6c4aac0941b002d74264b7f702881e85f2eb47a2", "ID": "6c4aac0941b002d74264b7f702881e85f2eb47a2", "Title": "Contour tracing for segmentation of mammographic masses", "Abstract": "A novel approach to segmentation of mammographic masses from the background tissue is presented and outperforms the three state-of-the-art methods based on region growing and dynamic programming. CADx systems have the potential to support radiologists in the difficult task of discriminating benign and malignant mammographic lesions. The segmentation of mammographic masses from the background tissue is an important module of CADx systems designed for the characterization of mass lesions. In this work, a novel approach to this task is presented. The segmentation is performed by automatically tracing the mass' contour in-between manually provided landmark points defined on the mass' margin. The performance of the proposed approach is compared to the performance of implementations of three state-of-the-art approaches based on region growing and dynamic programming. For an unbiased comparison of the different segmentation approaches, optimal parameters are selected for each approach by means of tenfold cross-validation and a genetic algorithm. Furthermore, segmentation performance is evaluated on a dataset of ROI and ground-truth pairs. The proposed method outperforms the three state-of-the-art methods. The benchmark dataset will be made available with publication of this paper and will be the first publicly available benchmark dataset for mass segmentation.", "PublicationYear": "2010", "Authors": ["Matthias Elter", "Christian Held", "T. Wittenberg"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "475acaf8c5b6f148dd4faabc6a31d7a10605f748", "cd8888f739a8e6e58a5aa7ea5669bc09d60ac202", "e7aa02db15ac1c46249be1231b3fa693792844a6", "1448eded35e963c7316f64f9c1b54abe519665fa", "c4f6a3b7544184b39fbe9da026024ccf80d2adb6", "811e70c7690dad7bd7823798ab23243594d04983", "b6cae985af240cc8cb6cb89658f5363064840cbd", "728d5be150b5ef7e2b22586f61b7a905b33ee7e6"], "ReferenceCount": 38, "CitationCount": 18}, {"URL": "https://www.semanticscholar.org/paper/Breast-mass-segmentation-in-mammography-using-plane-Song-Jiang/1c26e62c7d9719dcdd652932345090534d661629", "ID": "1c26e62c7d9719dcdd652932345090534d661629", "Title": "Breast mass segmentation in mammography using plane fitting and dynamic programming.", "Abstract": "Semantic Scholar extracted view of \\\"Breast mass segmentation in mammography using plane fitting and dynamic programming.\\\" by E. Song et al.", "PublicationYear": "2009", "Authors": ["Enmin Song", "Luan Jiang", "Renchao Jin", "Lin Zhang", "Yuan Yuan", "Qiang Li"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["475acaf8c5b6f148dd4faabc6a31d7a10605f748", "0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "cd8888f739a8e6e58a5aa7ea5669bc09d60ac202", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "3a5564bb4ef361f40be1a46d4d574e944e8bbf15", "8a0e80cf734b3021423c994868cdfa4e5c772877", "811e70c7690dad7bd7823798ab23243594d04983", "0aed632e3d576b6ab0945ac17a84cb008aae8ce2", "e7aa02db15ac1c46249be1231b3fa693792844a6", "201576a6e8110d3767206b2666a15c100ffd47ec"], "ReferenceCount": 29, "CitationCount": 52}, {"URL": "https://www.semanticscholar.org/paper/Hybrid-segmentation-of-mass-in-mammograms-using-and-Song-Xu/81b568a5899f22f6d8ea7dd2fc31f31f6d423e1a", "ID": "81b568a5899f22f6d8ea7dd2fc31f31f6d423e1a", "Title": "Hybrid segmentation of mass in mammograms using template matching and dynamic programming.", "Abstract": "Semantic Scholar extracted view of \\\"Hybrid segmentation of mass in mammograms using template matching and dynamic programming.\\\" by E. Song et al.", "PublicationYear": "2010", "Authors": ["Enmin Song", "Shengzhou Xu", "Xiangyang Xu", "Jianye Zeng", "Yihua Lan", "Shenyi Zhang", "Chih-Cheng Hung"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["1c26e62c7d9719dcdd652932345090534d661629", "475acaf8c5b6f148dd4faabc6a31d7a10605f748", "0ff3cefb443e5e0f168d8b3be38435848d8a93a1", "811e70c7690dad7bd7823798ab23243594d04983", "ba55e40a0eb35119ff59bf30675376303e6147f7", "201576a6e8110d3767206b2666a15c100ffd47ec", "8a0e80cf734b3021423c994868cdfa4e5c772877", "1c4b9e5de67233d606f8fe7de7245b2a7070b914", "37cfc1e4739ace79533e9aecd9a80945614ca4ff", "35ad1f356614dfd1fa89f11720f00e25546eb996"], "ReferenceCount": 33, "CitationCount": 38}, {"URL": "https://www.semanticscholar.org/paper/Semiautomatic-segmentation-for-the-computer-aided-Elter-Held/728d5be150b5ef7e2b22586f61b7a905b33ee7e6", "ID": "728d5be150b5ef7e2b22586f61b7a905b33ee7e6", "Title": "Semiautomatic segmentation for the computer aided diagnosis of clustered microcalcifications", "Abstract": "A novel semiautomatic approach that has automatic components but also allows some interaction of the radiologist is proposed with the goal to improve the reliability of microcalcification classification. Screening mammography is recognized as the most effective tool for early breast cancer detection. However, its application in clinical practice shows some of its weaknesses. While clustered microcalcifications are often an early sign of breast cancer, the discrimination of benign from malignant clusters based on their appearance in mammograms is a very difficult task. Hence, it is not surprising that typically only 15% to 30% of breast biopsies performed on calcifications will be positive for malignancy. As this low positive predictive value of mammography regarding the diagnosis of calcification clusters results in many unnecessary biopsies performed on benign calcifications, we propose a novel computer aided diagnosis (CADx) approach with the goal to improve the reliability of microcalcification classification. As effective automatic classification of microcalcification clusters relies on good segmentations of the individual calcification particles, many approaches to the automatic segmentation of individual particles have been proposed in the past. Because none of the fully automatic approaches seem to result in optimal segmentations, we propose a novel semiautomatic approach that has automatic components but also allows some interaction of the radiologist. Based on the resulting segmentations we extract a broad range of features that characterize the morphology and distribution of calcification particles. Using regions of interest containing either benign or malignant clusters extracted from the digital database for screening mammography we evaluate the performance of our approach using a support vector machine and ROC analysis. The resulting ROC performance is very promising and we show that the performance of our semiautomatic segmentation is significantly higher than that of a comparable fully automatic approach.", "PublicationYear": "2008", "Authors": ["Matthias Elter", "Christian Held"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["0baf042687634dc15871a2b9e254e10bc45d9d77", "c1ec2c9f9d2e8914cf6de51e4cef0b15e061b944", "faf922480532df47417f489c2c95719c88d321f2", "0380f8231b7acb7179ffd342133ec045f7cdbf39", "c40b2448ca3df1e537ec70c74d13ade646283abb", "0d8168e66dd34b4039f31cc5f47482262c0be316", "4fd5c66da387aa5c090f35b8e2587007947e4f20", "48666ddd437ca7bda95899d2ed1d0ae1ad58c9d0", "a83195f2353edafa25f9d47f75d7209e57ac4260", "c8c81a85bb3387c897e233173e1a0264e8d3e654"], "ReferenceCount": 35, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Mammogram-retrieval-on-similar-mass-lesions-Wei-Chen/103a9fc043d9fcccec9d545a53a76e22dcfe9c3f", "ID": "103a9fc043d9fcccec9d545a53a76e22dcfe9c3f", "Title": "Mammogram retrieval on similar mass lesions", "Abstract": "Semantic Scholar extracted view of \\\"Mammogram retrieval on similar mass lesions\\\" by Chia-Hung Wei et al.", "PublicationYear": "2012", "Authors": ["Chia-Hung Wei", "Sherry Y. Chen", "Xiaohui Liu"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["16f3cb52eb1f374aa037c4080ccbf68d2d7b8cd1", "cfb3a1635e62ac7d5b41096da7a37c4cea4cb815", "ef4ea8f06303f9cf5bbb0ead82285daf084a8369", "1be08ae74ca6e82b57ea0e1253a83debb5bf45c6", "995a9f5653e95ff874e39da5d2d0beeb36aaa950", "4b87c61abb65986adf66315f17c5cde5985a0593", "35ad1f356614dfd1fa89f11720f00e25546eb996", "07a94891c522d59a1343e6292234aa9d43e89d89", "c8f2bc304c2700655b5c3c19f665d2896af1c413", "34c44883a6152c5298f2c452670c1127072400e6"], "ReferenceCount": 33, "CitationCount": 67}, {"URL": "https://www.semanticscholar.org/paper/Detection-of-masses-in-mammograms-via-statistically-Dom%C3%ADnguez-Nandi/c83e00120d7adcda72ac01b95234134c47cba76a", "ID": "c83e00120d7adcda72ac01b95234134c47cba76a", "Title": "Detection of masses in mammograms via statistically based enhancement, multilevel-thresholding segmentation, and region selection", "Abstract": "Semantic Scholar extracted view of \\\"Detection of masses in mammograms via statistically based enhancement, multilevel-thresholding segmentation, and region selection\\\" by A. R. Dom\u00ednguez et al.", "PublicationYear": "2008", "Authors": ["Alfonso Rojas Dom{\\'i}nguez", "Asoke Kumar Nandi"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["0c5abfc65c6d8d74ffd2c6490724197e4322a2b9", "0aed632e3d576b6ab0945ac17a84cb008aae8ce2", "ac0ca4295b0622e370c19716071614b6d2d723f9", "c24f2b57936ea3cb975b3252ab392a1eb0a644f5", "8d46682acbe8ac27ab8e29163e64f1b3cbb70bb0", "766e0e5e79f0a192a07d89d51c025fc5c01cabf2", "8ea35a2467c81c3a4c1c4f8d74b376d0ce52703c", "7a1974be797dc54232ec51d78d3d4c6f5caeb6f6", "1ac5f398c1eeae7189800c003035dc7248298f93", "e2ad29cca43ef504569365ab6484fe26488983ee"], "ReferenceCount": 27, "CitationCount": 140}, {"URL": "https://www.semanticscholar.org/paper/A-review-of-automatic-mass-detection-and-in-images-Oliver-Freixenet/07a94891c522d59a1343e6292234aa9d43e89d89", "ID": "07a94891c522d59a1343e6292234aa9d43e89d89", "Title": "A review of automatic mass detection and segmentation in mammographic images", "Abstract": "Semantic Scholar extracted view of \\\"A review of automatic mass detection and segmentation in mammographic images\\\" by A. Oliver et al.", "PublicationYear": "2010", "Authors": ["Arnau Oliver", "Jordi Freixenet", "Joan Mart{\\'i}", "Elsa P{\\'e}rez", "Josep Pont", "Erika R. E. Denton", "Reyer Zwiggelaar"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["271920e076976352bd37feb754a66b7dab26ecb1", "c83e00120d7adcda72ac01b95234134c47cba76a", "a984eaf6595d947b9aa5aafcfec19fb09a04486b", "fb4923fc881f8aaf7d11ae350ad796a14ad831f4", "38f4c3d7720d0c985275d79005e2f443ea9994f5", "ddfa7eb9334bab0d507f3b1fab4481af4e619758", "72179ed0b7d7a072e07cee038f7e8b2129061650", "3135b31cab07ba621aa7d82f6a83b635a46fc3b5", "73c6fbcbe472824ebbb460b24e00c9cde7249ef7", "9b62fcaf677d91f16eb3b9c22d713645c465e87b"], "ReferenceCount": 276, "CitationCount": 410}, {"URL": "https://www.semanticscholar.org/paper/Automated-assessment-of-breast-tissue-density-in-Subashini-Ramalingam/dda0dc40bc5cb79d5638d8cac955337362e6473e", "ID": "dda0dc40bc5cb79d5638d8cac955337362e6473e", "Title": "Automated assessment of breast tissue density in digital mammograms", "Abstract": "Semantic Scholar extracted view of \\\"Automated assessment of breast tissue density in digital mammograms\\\" by T. Subashini et al.", "PublicationYear": "2010", "Authors": ["T. S. Subashini", "Vennila Ramalingam", "S. Palanivel"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["26b8feb26bd320ed98d7a5d811acc2b376280c5b", "1ac5f398c1eeae7189800c003035dc7248298f93", "a47b4939945e9139ccbf37e2f232d5c57583b385", "4e4f4428eff699c8963d07995910003cf9ff26c5", "4ec2e5252ee95857f2b2edd2a8339eb8c4fca8a1", "1aae416a0aab94741b07d78f560ca4e566c3a74c", "2e4243b19361809644f0f27d6f8563d42fc7b928", "0fb64930ba2f6e68de53c4c2b73ee7d06e8397d9", "36a044c0e1facc967d5b94cfd8dea299ade30a7d", "7431895d17cc5dda9d84e121887f7a08dafa7dcc"], "ReferenceCount": 43, "CitationCount": 138}, {"URL": "https://www.semanticscholar.org/paper/Multilevel-learning-based-segmentation-of-and-in-Tao-Lo/2d78c76f2696918bb9457d30e2b9b62c10ccae45", "ID": "2d78c76f2696918bb9457d30e2b9b62c10ccae45", "Title": "Multilevel learning-based segmentation of ill-defined and spiculated masses in mammograms.", "Abstract": "The proposed approach could closely delineate the mass body and is capable of including mass margin and its spicule extensions which are considered as key features for breast lesion analyses. PURPOSE\\nA learning-based approach integrating the use of pixel-level statistical modeling and spiculation detection is presented for the segmentation of mammographic masses with ill-defined margins and spiculations.\\n\\n\\nMETHODS\\nThe algorithm involves a multiphase pixel-level classification, using a comprehensive group of features computed from regional intensity, shape, and textures, to generate a mass-conditional probability map (PM). Then, the mass candidate, along with the background clutters consisting of breast fibroglandular and other nonmass tissues, is extracted from the PM by integrating the prior knowledge of shape and location of masses. A multiscale steerable ridge detection algorithm is employed to detect spiculations. Finally, all the object-level findings, including mass candidate, detected spiculations, and clutters, along with the PM, are integrated by graph cuts to generate the final segmentation mask.\\n\\n\\nRESULTS\\nThe method was tested on 54 masses (51 malignant and 3 benign), all with ill-defined margins and irregular shape or spiculations. The ground truth delineations were provided by five experienced radiologists. Area overlapping ratio of 0.689 (\u00b10.160) and 0.540 (\u00b10.164) were obtained for segmenting entire mass and margin portion only, respectively. Williams index of area and contour based measurements indicated that the segmentation results of the algorithm agreed well with the radiologists' delineation.\\n\\n\\nCONCLUSIONS\\nThe proposed approach could closely delineate the mass body. Most importantly, it is capable of including mass margin and its spicule extensions which are considered as key features for breast lesion analyses.", "PublicationYear": "2010", "Authors": ["Yimo Tao", "Shih-Chung Benedict Lo", "Matthew T. Freedman", "Erini Makariou", "Jianhua Xuan"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["a81103a38a147d722070b03ce36a8257f58dcc50", "1448eded35e963c7316f64f9c1b54abe519665fa", "71f98dc5cc9409ceb35f057eb5cbe6ede187a1ba", "816deb10419a85444f125056207700c4f1311851", "e7aa02db15ac1c46249be1231b3fa693792844a6", "1060c5b534e53e213b9e3f9b8a75b54e3639cee8", "2534ddf08d452f908f583eeec6f79b6907145df6", "48bbf086600d1a17a4243e61a7f7bf4b65a3b5c0", "811e70c7690dad7bd7823798ab23243594d04983", "f488a621555a288049bb7e43929623202502dac8"], "ReferenceCount": 25, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/A-comparison-of-two-methods-for-the-segmentation-of-Dubey-Hanmandlu/e71d328440738b2ad8a1937ad6f5c0786c6cc315", "ID": "e71d328440738b2ad8a1937ad6f5c0786c6cc315", "Title": "A comparison of two methods for the segmentation of masses in the digital mammograms", "Abstract": "Semantic Scholar extracted view of \\\"A comparison of two methods for the segmentation of masses in the digital mammograms\\\" by R. Dubey et al.", "PublicationYear": "2010", "Authors": ["R. B. Dubey", "Madasu Hanmandlu", "S. Gupta"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["00a7a58a7087807f9b4b15ecef7139b58ef61a7f", "10a6ff2936644095deb4eb79d8ddc9071586bd86", "78002c425cae0ebc3e5506a242123e0004baaf25", "e6b42bcd6d05e6508d9d71d662cb4ed77c311800", "7de0dfff283e7ec404c053e5ec47a6406241fcfa", "a8f30877da6e2dfbd66223e9e8e1042b3108c147", "7fff5f0812624791c3f235255b4b839027dc28eb", "3a8ebc0de793ff1dbc0d1ec13c06abb6a5cd4feb", "16d84db394be9e5c8c10a08940c2f8c9359c0052", "5cfd7a0de0d6b24114931e2e43fb619c8ca67dad"], "ReferenceCount": 18, "CitationCount": 44}, {"URL": "https://www.semanticscholar.org/paper/Algorithms-and-system-for-segmentation-and-analysis-Xu-Xie/d6151de801659937574c3efe13c2d207e9e2f2cd", "ID": "d6151de801659937574c3efe13c2d207e9e2f2cd", "Title": "Algorithms and system for segmentation and structure analysis in soccer video", "Abstract": "It is shown that low-level features and mid-level view classes can be combined to extract more information about the game, via the example of detecting grass orientation in the field, and the best result in segmentation is 86.5%. In this paper, we present a novel system and effective algorithms for soccer video segmentation. The output, about whether the ball is in play, reveals high-level structure of the content. The first step is to classify each sample frame into 3 kinds of view using a unique domain-specific feature, grass-area-ratio. Here the grass value and classification rules are learned and automatically adjusted to each new clip. Then heuristic rules are used in processing the view label sequence, and obtain play/break status of the game. The results provide good basis for detailed content analysis in next step. We also show that low-level features and mid-level view classes can be combined to extract more information about the game, via the example of detecting grass orientation in the field. The results are evaluated under different metrics intended for different applications; the best result in segmentation is 86.5%.", "PublicationYear": "2001", "Authors": ["Peng Xu", "Lexing Xie", "Shih-Fu Chang", "Ajay Divakaran", "Anthony Vetro", "Huifang Sun"], "RelatedTopics": ["Computer Science"], "References": ["0d76d2a2e200920a386e6ca5f8e8d0b12106b3eb", "89b52ef051679634365a0f646e18b59537b396d6", "564649846003db680733697947f974a1ef03c4ea", "5a7571db7df03cca52c48f89595c4abefeb51e5c", "b00a09f37de0d17dd631913ecf55617a38e43e51"], "ReferenceCount": 6, "CitationCount": 267}, {"URL": "https://www.semanticscholar.org/paper/Framework-for-tracking-and-analysis-of-soccer-video-Ekin-Tekalp/339acc20ebbf3c08c797373f873e4e6b9f2f9c9a", "ID": "339acc20ebbf3c08c797373f873e4e6b9f2f9c9a", "Title": "Framework for tracking and analysis of soccer video", "Abstract": "A complete framework for automatic analysis of soccer video by using domain specific information, which enables development of more effective low-level processing algorithms for high-level scene understanding, which perform nearly in real time. In this paper, we present a complete framework for automatic analysis of soccer video by using domain specific information. In the proposed framework, following shot boundary detection, soccer shots are classified into 3 classes using the ratio of grass-colored pixels in a frame, and the size and number of soccer objects detected in a shot. These classes are long shots, in-field medium shots, and others, such as out-of-field of close-up shots. The long shots and in-field medium shots are further processed to analyze their semantic content. We observe that different low-level processing algorithms may be required to process different shot classes. For example, we introduce different tracking algorithms for the long shots and in- field medium shots. Furthermore, frame registration onto a reference field model is not usually applicable to in-field medium shots, because the field lines may not be visible. The proposed framework enables development of more effective low-level processing algorithms for high-level scene understanding, which perform nearly in real time. The results show the increased accuracy and efficiency of the proposed methods.", "PublicationYear": "2002", "Authors": ["Ahmet Ekin", "A. Murat Tekalp"], "RelatedTopics": ["Computer Science"], "References": ["d6151de801659937574c3efe13c2d207e9e2f2cd", "18f45272373ad42f00a6ce1941743e8a76c50a59", "f0bafbf9cf2dfb1fd7e439e2336f1dd3af19478c", "9bbafe9be7636af04ead3ab81173d4846cb43749", "1a60192ca9a4053aeb9df986b655d05072605d70", "321ef79f7f62826de13d010b9aed65d800d361ef", "610d95b4c978bb49f0b301e075f73108804128bc", "ecc23e5a7902460572d5144664acae27469cf79a", "2ab46391005cea85fa5c204b6e77a9c870fdbaed", "cfcaae349544212c93e3cb8ad16e95351048bfc9"], "ReferenceCount": 11, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Event-detection-and-summarization-in-American-video-Li-Sezan/7b068d9ff88588a15d6d5fa8e7932d4e635cd252", "ID": "7b068d9ff88588a15d6d5fa8e7932d4e635cd252", "Title": "Event detection and summarization in American football broadcast video", "Abstract": "A framework for event detection and summary generation in football broadcast video is proposed, which proposes both deterministic and probabilistic approaches to the detection of the plays and an audio-based hierarchical summarization method. We propose a framework for event detection and summary generation in football broadcast video. First, we formulate summarization as a play detection problem, with play being defined as the most basic segment of time during which the ball is being played. Then we propose both deterministic and probabilistic approaches to the detection of the plays. The detected plays are concatenated to generate a compact, time-compressed summary of the original video. Such a summary is complete in the sense that it contains every meaningful action of the underlying game, and it also servers as a much better starting point for higher-level summarization and other analyses than the original video does. Based on the summary, we also propose an audio-based hierarchical summarization method. Experimental results show the proposed methods work very well on consumer grade platforms.", "PublicationYear": "2001", "Authors": ["Baoxin Li", "Ibrahim Sezan"], "RelatedTopics": ["Computer Science"], "References": ["5a7571db7df03cca52c48f89595c4abefeb51e5c", "5727fdb06696f92d406adb81459dd2e56da1dfeb", "dc075e9210e4a235f32e3668449cc06af010ef13", "5138a7d65d6875191572291f3458b4de149b4d2a", "f0bafbf9cf2dfb1fd7e439e2336f1dd3af19478c", "65c4ef6d26039cde31872249d11cada9da08e6aa", "a577d37d7bf3d408ee68fd1434820323f39d6812", "012e6ed77fb00a8bc1ab024a01eb19311cf69479", "a647faec7abe85792a2804c94884f33f1854c5a4", "19be3a664ba3c1cfbd4e9dbeb0287f1e635db4fb"], "ReferenceCount": 18, "CitationCount": 73}, {"URL": "https://www.semanticscholar.org/paper/Automatic-parsing-of-TV-soccer-programs-Gong-Sin/564649846003db680733697947f974a1ef03c4ea", "ID": "564649846003db680733697947f974a1ef03c4ea", "Title": "Automatic parsing of TV soccer programs", "Abstract": "The proposed system can classify a sequence of soccer frames into various play categories, such as shot at left goal, top left corner kick play in right penalty area, in midfield, etc, based on a priori model comprising four major components: a soccer court, a ball, the players and the motion vectors. While automatic parsing of general video images are difficult or nearly impossible, parsing a specific type of video image can be achieved if the video structure can be explicitly identified and its model can be constructed. The paper presents ongoing work on using domain knowledge to parse content of soccer video programs. The proposed system can classify a sequence of soccer frames into various play categories, such as shot at left goal, top left corner kick play in right penalty area, in midfield, etc, based on a priori model comprising four major components: a soccer court, a ball, the players and the motion vectors. Approaches in applying the model for parsing soccer programs are presented in detail. Experimental results are included to evaluate the performance of the system.", "PublicationYear": "1995", "Authors": ["Yihong Gong", "Lim Teck Sin", "Chua Hock Chuan", "HongJiang Zhang", "Masao Sakauchi"], "RelatedTopics": ["Computer Science"], "References": ["05edc783def10174ca1d9952deb444f1e1c5baa1", "28726944aebed6b3d88935e55c9f228bf4d9bfe5", "14e39eafc656ae89a13ef9d5e1515da3e2b22daf", "e8dfb5fb0c8739b6f439909676a2193d95dbc8ff", "257ff5ae00fb89e0f51b8d5c15ee25db409ccf32"], "ReferenceCount": 6, "CitationCount": 389}, {"URL": "https://www.semanticscholar.org/paper/Structure-analysis-of-sports-video-using-domain-Zhong-Chang/5a7571db7df03cca52c48f89595c4abefeb51e5c", "ID": "5a7571db7df03cca52c48f89595c4abefeb51e5c", "Title": "Structure analysis of sports video using domain models", "Abstract": "This paper presents an effective framework for scene detection and structure analysis for sports videos, using tennis and baseball as examples, and combines domain-specific knowledge, supervised machine learning techniques, and automatic feature analysis at multiple levels. In this paper, we present an effective framework for scene detection and structure analysis for sports videos, using tennis and baseball as examples. Sports video can be characterized by its predictable temporal syntax, recurrent events with consistent features, and a fixed number of views. Our approach combines domain-specific knowledge, supervised machine learning techniques, and automatic feature analysis at multiple levels. Real time processing performance is achieved by utilizing compressed-domain processing techniques. High accuracy in view recognition is achieved by using compressed-domain global features as prefilters and object-level refined analysis in the latter verification stage. Applications include high-level structure browsing/navigation, highlight generation, and mobile media filtering.", "PublicationYear": "2001", "Authors": ["Di Zhong", "Shih-Fu Chang"], "RelatedTopics": ["Computer Science"], "References": ["89b52ef051679634365a0f646e18b59537b396d6", "edea2f25d705d43ce90f725eed62f7dba6fbd50f", "3a135e884734a3319d38dd37adfde0d9b1811204", "0dc563175e6a1c3ffba3ad2cfb641a02b079fc34", "1ed3cfa7adfd16a78482d61340201226a4311f5e"], "ReferenceCount": 5, "CitationCount": 200}, {"URL": "https://www.semanticscholar.org/paper/Shot-boundary-detection%3A-unraveled-and-resolved-Hanjalic/a3a7a3fe0fc54665d5e22461a27e2aa2816666a8", "ID": "a3a7a3fe0fc54665d5e22461a27e2aa2816666a8", "Title": "Shot-boundary detection: unraveled and resolved?", "Abstract": "A conceptual solution to the shot-boundary detection problem is presented in the form of a statistical detector that is based on minimization of the average detection-error probability and the performance of the detector is demonstrated regarding two most widely used types of shot boundaries: hard cuts and dissolves. Partitioning a video sequence into shots is the first step toward video-content analysis and content-based video browsing and retrieval. A video shot is defined as a series of interrelated consecutive frames taken contiguously by a single camera and representing a continuous action in time and space. As such, shots are considered to be the primitives for higher level content analysis, indexing, and classification. The objective of this paper is twofold. First, we analyze the shot-boundary detection problem in detail and identify major issues that need to be considered in order to solve this problem successfully. Then, we present a conceptual solution to the shot-boundary detection problem in which all issues identified in the previous step are considered. This solution is provided in the form of a statistical detector that is based on minimization of the average detection-error probability. We model the required statistical functions using a robust metric for visual content discontinuities (based on motion compensation) and take into account all (a priori) knowledge that we found relevant to shot-boundary detection. This knowledge includes the shot-length distribution, visual discontinuity patterns at shot boundaries, and characteristic temporal changes of visual features around a boundary. Major advantages of the proposed detector are its robust and sequence-independent performance, while there is also the possibility to detect different types of shot boundaries simultaneously. We demonstrate the performance of our detector regarding two most widely used types of shot boundaries: hard cuts and dissolves.", "PublicationYear": "2002", "Authors": ["Alan Hanjalic"], "RelatedTopics": ["Computer Science"], "References": ["1ee66e6ff219e4314560d06cb7c3c96450e36623", "cc72512d6a39eca67fe85ea2efd552b33281ddc0", "73944042356f44098f678af5e1d471cdb0ce38fd", "9b86450906df4c767c376576984c9f2337de1ad5", "d34700fdcacdde01be530c6b3bf473c80d98137e", "e661a5aec01035005b66233372d507457bfeae81", "de8587c1e68de0e628488425bed742562d30f901", "7ce734075160712eadc2efeda3e6ca0b73c80ffa", "10c8691e23dffadab19c39fb9245496efbf75b2a", "e37e7533b1689127f5eb151694f4add687767f96"], "ReferenceCount": 32, "CitationCount": 552}, {"URL": "https://www.semanticscholar.org/paper/Identifying-sports-videos-using-replay%2C-text%2C-and-Kobla-DeMenthon/832f48f5c28956e892e0ece93e2802f4501036ab", "ID": "832f48f5c28956e892e0ece93e2802f4501036ab", "Title": "Identifying sports videos using replay, text, and camera motion features", "Abstract": "The extraction of features that enable identification of sports videos directly from the compressed domain of MPEG video, including detecting the presence of action replays, determining the amount of scene text in vide, and calculating various statistics on camera and/or object motion are discussed. Automated classification of digital video is emerging as an important piece of the puzzle in the design of content management systems for digital libraries. The ability to classify videos into various classes such as sports, news, movies, or documentaries, increases the efficiency of indexing, browsing, and retrieval of video in large databases. In this paper, we discuss the extraction of features that enable identification of sports videos directly from the compressed domain of MPEG video. These features include detecting the presence of action replays, determining the amount of scene text in vide, and calculating various statistics on camera and/or object motion. The features are derived from the macroblock, motion,and bit-rate information that is readily accessible from MPEG video with very minimal decoding, leading to substantial gains in processing speeds. Full-decoding of selective frames is required only for text analysis. A decision tree classifier built using these features is able to identify sports clips with an accuracy of about 93 percent.", "PublicationYear": "1999", "Authors": ["Vikrant Kobla", "Daniel DeMenthon", "David S. Doermann"], "RelatedTopics": ["Computer Science"], "References": ["96840df6de2afaf6ede9e788c0eb54a9171d1aab", "19c8dc7b4acdeecf092526d767156ac8950c02d8", "08f0a418746e4d8db571e66938d88981737990cf", "bc8b866cc58e82e6413367c8d770ef681e5abe66", "3cbd5989b55aa67cc1349c096e1daa5ec54518e3", "67fe6f4553bc9da70d908b29457225574e2b08f0", "bd2d7b28c1ea306efafa36fba9be3fad113c0535", "ddcb017450dcbb1075e16d619b08610f181355f7", "3e247d882400b35d052b19914b3d225ce1dca340", "03b6cb3e889925dee99ed9ef7d1220b0e0f53580"], "ReferenceCount": 11, "CitationCount": 71}]