[{"URL": "https://www.semanticscholar.org/paper/Spatial-Aware-Dictionary-Learning-for-Hyperspectral-Soltani-Farani-Rabiee/5ca94050fcf3382b50ec44629c0dda80c8843558", "ID": "5ca94050fcf3382b50ec44629c0dda80c8843558", "Title": "Spatial-Aware Dictionary Learning for Hyperspectral Image Classification", "Abstract": "A structured dictionary-based model for hyperspectral data that incorporates both spectral and contextual characteristics of spectral samples and is capable of finding representations that may effectively be used for classification of multispectral resolution samples is presented. This paper presents a structured dictionary-based model for hyperspectral data that incorporates both spectral and contextual characteristics of spectral samples. The idea is to partition the pixels of a hyperspectral image into a number of spatial neighborhoods called contextual groups and to model the pixels inside a group as members of a common subspace. That is, each pixel is represented using a linear combination of a few dictionary elements learned from the data, but since pixels inside a contextual group are often made up of the same materials, their linear combinations are constrained to use common elements from the dictionary. To this end, dictionary learning is carried out with a joint sparse regularizer to induce a common sparsity pattern in the sparse coefficients of a contextual group. The sparse coefficients are then used for classification using a linear support vector machine. Experimental results on a number of real hyperspectral images confirm the effectiveness of the proposed representation for hyperspectral image classification. Moreover, experiments with simulated multispectral data show that the proposed model is capable of finding representations that may effectively be used for classification of multispectral resolution samples.", "PublicationYear": "2013", "Authors": ["Ali Soltani-Farani", "Hamid R. Rabiee", "Seyyed Abbas Hosseini"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["4a5ff537ed30b7810d463483eba83c55d9fe51d9", "15f7662fadf686beae8ce704ee9b48262ac62237", "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b", "f5f963d7872625c75f43d422f3c4cf7d70d2de7d", "f6e92c66ba553d6ae1d52e94f83278ede73c696f", "2b07d0bfcbc64b8cefa2d5d7b84a3dd13b6d7b51", "7c997a648976fb9df320c6ca332c9dc155820454", "c5389f0d9751ce9cd39160320ef17ae968a79edf", "41f426e2dc5b4944148014d9c86d20fdd21dc968", "2badd8953397d757693859918cf9318fe7ec5e3b"], "ReferenceCount": 67, "CitationCount": 122}, {"URL": "https://www.semanticscholar.org/paper/Multiresolution-Knowledge-Distillation-for-Anomaly-Salehi-Sadjadi/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d", "ID": "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d", "Title": "Multiresolution Knowledge Distillation for Anomaly Detection", "Abstract": "This work proposes to use the \\\"distillation\\\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle anomaly detection and localization. Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the \\\"distillation\\\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks\u2019 intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert\u2019s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.", "PublicationYear": "2020", "Authors": ["Mohammadreza Salehi", "Niousha Sadjadi", "Soroosh Baselizadeh", "Mohammad Hossein Rohban", "Hamid R. Rabiee"], "RelatedTopics": ["Computer Science"], "References": ["4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "5db790198b9acf4e5efe350acdd814238fcacaa7", "0535625be630c6a67f4c244ebf3aa61ad088fc70", "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "41747cbdbed84762dfbfc305254c97021279dc6e", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "8381157eae4fbf8908d0312a9642f8e69e944449", "d9d7ab13ce305ccee309c989a2341d72b1252070", "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d"], "ReferenceCount": 62, "CitationCount": 213}, {"URL": "https://www.semanticscholar.org/paper/A-Hybrid-Deep-Learning-Architecture-for-Mobile-Osia-Shamsabadi/6f0685d61328f0f90972fe822258d574b74e9c7a", "ID": "6f0685d61328f0f90972fe822258d574b74e9c7a", "Title": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics", "Abstract": "This article presents a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics, and shows that by using Siamese fine-tuning and at a small processing cost, this approach can greatly reduce the level of unnecessary, potentially sensitive information in the personal data. Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user\u2019s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.", "PublicationYear": "2017", "Authors": ["Seyed Ali Osia", "Ali Shahin Shamsabadi", "Sina Sajadmanesh", "Ali Taheri", "Kleomenis Katevas", "Hamid R. Rabiee", "Nicholas D. Lane", "Hamed Haddadi"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["65c8a794830f9a11aa0b9ab682f3b6256be67185", "6c20cd584e7258056840eb88437d69731000bb0f", "60951974d24dd83e288117b0cd217af6a5d34178", "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "8a5d0579590465494c9aba58a857af43b190b6a6", "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "187a78ebfe654e9c1d3e8d070c8845a49c1d1a42", "5a7a7dfea3674d4e0474f7fdd596951da44babe4", "7fcb90f68529cbfab49f471b54719ded7528d0ef", "405006da005398279bdf7c3423d47aa0951c5391"], "ReferenceCount": 70, "CitationCount": 203}, {"URL": "https://www.semanticscholar.org/paper/Novel-dataset-for-fine-grained-abnormal-behavior-in-Rabiee-Haddadnia/c626a9d75dfd73e26cf30793d5ef71527cd9fa95", "ID": "c626a9d75dfd73e26cf30793d5ef71527cd9fa95", "Title": "Novel dataset for fine-grained abnormal behavior understanding in crowd", "Abstract": "This work presents a novel crowd dataset which contains around 45,000 video clips which annotated by one of the five different fine-grained abnormal behavior categories and evaluated two state-of-the-art methods on this dataset, showing that this dataset can be effectively used as a benchmark for fine- grained abnormality detection. Despite the huge research on crowd on behavior understanding in visual surveillance community, lack of publicly available realistic datasets for evaluating crowd behavioral interaction led not to have a fair common test bed for researchers to compare the strength of their methods in the real scenarios. This work presents a novel crowd dataset contains around 45,000 video clips which annotated by one of the five different fine-grained abnormal behavior categories. We also evaluated two state-of-the-art methods on our dataset, showing that our dataset can be effectively used as a benchmark for fine-grained abnormality detection. The details of the dataset and the results of the baseline methods are presented in the paper.", "PublicationYear": "2016", "Authors": ["Hamid R. Rabiee", "Javad Haddadnia", "Hossein Mousavi", "Maziyar Kalantarzadeh", "Moin Nabi", "Vittorio Murino"], "RelatedTopics": ["Computer Science"], "References": ["3950b335fd77d6f025cdf29e9733ee92189b6a9b", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "fd52349a019d928cd9b09c2f6a8a689f174bbbf2", "655b1f83ef218ee6a030b5541d2865bc6599e6d9", "c3113eaad326a955ba96c11b7b65d0c065fb2054", "27839232387db332bdc9024d014a6d1bc47c35eb", "5194cbd51f9769ab25260446b4fa17204752e799", "02a98118ce990942432c0147ff3c0de756b4b76a", "e65ec773059770c45da16bb9ce638d24870b1adf", "84af83ff6412a756df58b6436f0d2e3c049e1f12"], "ReferenceCount": 26, "CitationCount": 50}, {"URL": "https://www.semanticscholar.org/paper/Deep-Private-Feature-Extraction-Ossia-Taheri/e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da", "ID": "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da", "Title": "Deep Private-Feature Extraction", "Abstract": "The log-rank privacy is introduced and utilize, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy trade-off. We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model which is trained and evaluated based on information theoretic constraints. Using the selective exchange of information between a user's device and a service provider, DPFE enables the user to prevent certain sensitive information from being shared with a service provider, while allowing them to extract approved information using their model. We introduce and utilize the log-rank privacy, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy trade-off. We then implement and evaluate the performance of DPFE on smartphones to understand its complexity, resource demands, and efficiency trade-offs. Our results on benchmark image datasets demonstrate that under moderate resource utilization, DPFE can achieve high accuracy for primary tasks while preserving the privacy of sensitive information.", "PublicationYear": "2018", "Authors": ["Seyed Ali Ossia", "Ali Taheri", "Ali Shahin Shamsabadi", "Kleomenis Katevas", "Hamed Haddadi", "Hamid R. Rabiee"], "RelatedTopics": ["Computer Science"], "References": ["6cefb70f4668ee6c0bf0c18ea36fd49dd60e8365", "bc3f84ae122815aba616a310ae22abf216864b85", "44a97f4eaaefaf5338f8aed2913d5debb2459f7e", "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "e6050e19c82ac215194cc311016094b71f57b17d", "65c8a794830f9a11aa0b9ab682f3b6256be67185", "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "53969301953b5e3d908a057f95d29eef2f11970f", "3625202d710db29ee117f7502d86901f50f92e1c"], "ReferenceCount": 63, "CitationCount": 77}, {"URL": "https://www.semanticscholar.org/paper/Learning-Sparse-Codes-for-Hyperspectral-Imagery-Charles-Olshausen/15f7662fadf686beae8ce704ee9b48262ac62237", "ID": "15f7662fadf686beae8ce704ee9b48262ac62237", "Title": "Learning Sparse Codes for Hyperspectral Imagery", "Abstract": "This work modified an existing unsupervised learning approach and applied it to HSI data to learn an optimal sparse coding dictionary, which improves the performance of a supervised classification algorithm, both in terms of the classifier complexity and generalization from very small training sets. The spectral features in hyperspectral imagery (HSI) contain significant structure that, if properly characterized, could enable more efficient data acquisition and improved data analysis. Because most pixels contain reflectances of just a few materials, we propose that a sparse coding model is well-matched to HSI data. Sparsity models consider each pixel as a combination of just a few elements from a larger dictionary, and this approach has proven effective in a wide range of applications. Furthermore, previous work has shown that optimal sparse coding dictionaries can be learned from a dataset with no other a priori information (in contrast to many HSI \u201cendmember\u201d discovery algorithms that assume the presence of pure spectra or side information). We modified an existing unsupervised learning approach and applied it to HSI data (with significant ground truth labeling) to learn an optimal sparse coding dictionary. Using this learned dictionary, we demonstrate three main findings: 1) the sparse coding model learns spectral signatures of materials in the scene and locally approximates nonlinear manifolds for individual materials; 2) this learned dictionary can be used to infer HSI-resolution data with very high accuracy from simulated imagery collected at multispectral-level resolution, and 3) this learned dictionary improves the performance of a supervised classification algorithm, both in terms of the classifier complexity and generalization from very small training sets.", "PublicationYear": "2011", "Authors": ["Adam S. Charles", "Bruno A. Olshausen", "Christopher J. Rozell"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["1141a9135c41f969a379c5372bee85126d0f3988", "00582be58da554cc66c91d23924b24487912abf7", "41f426e2dc5b4944148014d9c86d20fdd21dc968", "d7bd1659967cfe584e420b5e70109b5901072aa0", "21e654600e75f2663caf23733695a119582e54a1", "273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "d9919fd10760699c7e482bc941298670d8d77837", "10ad2ec4ebcbecd4b2ddd3e88f9b125caf50a2fc", "f6e0fb4c77906bc23fe59a8f848ce62ba9687181", "6ffc3965342faf3be2cd73e1ea15ca2569a7dd92"], "ReferenceCount": 57, "CitationCount": 196}, {"URL": "https://www.semanticscholar.org/paper/Learning-Discriminative-Sparse-Representations-for-Castrodad-Xing/5ef1bc90ee5ca4e474972bf6f43eb0751e09093b", "ID": "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b", "Title": "Learning Discriminative Sparse Representations for Modeling, Source Separation, and Mapping of Hyperspectral Imagery", "Abstract": "Results when the data have been significantly undersampled and then reconstructed are presented, still retaining high-performance classification, showing the potential role of compressive sensing and sparse modeling techniques in efficient acquisition/transmission missions for hyperspectral imagery. A method is presented for subpixel modeling, mapping, and classification in hyperspectral imagery using learned block-structured discriminative dictionaries, where each block is adapted and optimized to represent a material in a compact and sparse manner. The spectral pixels are modeled by linear combinations of subspaces defined by the learned dictionary atoms, allowing for linear mixture analysis. This model provides flexibility in source representation and selection, thus accounting for spectral variability, small-magnitude errors, and noise. A spatial-spectral coherence regularizer in the optimization allows pixel classification to be influenced by similar neighbors. We extend the proposed approach for cases for which there is no knowledge of the materials in the scene, unsupervised classification, and provide experiments and comparisons with simulated and real data. We also present results when the data have been significantly undersampled and then reconstructed, still retaining high-performance classification, showing the potential role of compressive sensing and sparse modeling techniques in efficient acquisition/transmission missions for hyperspectral imagery.", "PublicationYear": "2011", "Authors": ["Alexey Castrodad", "Zhengming Xing", "John B. Greer", "Edward Bosch", "Lawrence Carin", "Guillermo Sapiro"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["41f426e2dc5b4944148014d9c86d20fdd21dc968", "ec892e36c16feffdea169dbec97ecdc412778a02", "074354a7d114c43dfba60663a536cec947f8ff08", "dbd75566afe8034c8d1db0cad623f3730d1c5e97", "0337e7041779082330ac74cf74aebe79fddb38d2", "79ff2db16cb2c64883a581bf7f6641795263ae8c", "e616132691824d6eec92b0eb4560b286d732582b", "46f447a8dbb68ea4d2793a8c5d9abfd3c622c144", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "4a1042d7a216008eaae4d17d478f93029ef69a4f"], "ReferenceCount": 69, "CitationCount": 129}, {"URL": "https://www.semanticscholar.org/paper/Sparse-Demixing-of-Hyperspectral-Images-Greer/f5f963d7872625c75f43d422f3c4cf7d70d2de7d", "ID": "f5f963d7872625c75f43d422f3c4cf7d70d2de7d", "Title": "Sparse Demixing of Hyperspectral Images", "Abstract": "Sparse demixing (SD) is introduced, which is a method that is similar to orthogonal matching pursuit, for calculating sparse abundances in the LMM for hyperspectral images, and it is demonstrated that SD outperforms an existing L1 demixed algorithm, which it is proved to depend adversely on the angles between endmembers. In the LMM for hyperspectral images, all the image spectra lie on a high-dimensional simplex with corners called endmembers. Given a set of endmembers, the standard calculation of fractional abundances with constrained least squares typically identifies the spectra as combinations of most, if not all, endmembers. We assume instead that pixels are combinations of only a few endmembers, yielding abundance vectors that are sparse. We introduce sparse demixing (SD), which is a method that is similar to orthogonal matching pursuit, for calculating these sparse abundances. We demonstrate that SD outperforms an existing L1 demixing algorithm, which we prove to depend adversely on the angles between endmembers. We combine SD with dictionary learning methods to calculate automatically endmembers for a provided set of spectra. Applying it to an airborne visible/infrared imaging spectrometer image of Cuprite, NV, yields endmembers that compare favorably with signatures from the USGS spectral library.", "PublicationYear": "2012", "Authors": ["John B. Greer"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["1af8b1059d5104fa2bb418b5de327ae652bce36a", "deeeda3e9d352de048b3d23fedeeb32e9ad94124", "954c621a5be1193166e9c610e8323eff942da0a7", "dd489b78bbb2fb45a07d5af2586287639146b9ff", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "bf131254f1c3e24092c448e71c12e96949f7a7ed", "d9919fd10760699c7e482bc941298670d8d77837", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "5d6d531585ca65a41367550b959bf792d8ae26fc", "a16ddf440077328c3e147cc703e8a0fe96d17622"], "ReferenceCount": 35, "CitationCount": 71}, {"URL": "https://www.semanticscholar.org/paper/Hyperspectral-unmixingwith-sparse-group-lasso-Iordache-Bioucas-Dias/f6e92c66ba553d6ae1d52e94f83278ede73c696f", "ID": "f6e92c66ba553d6ae1d52e94f83278ede73c696f", "Title": "Hyperspectral unmixingwith sparse group lasso", "Abstract": "The potential of the sparse group lasso technique in solving hyperspectral unmixing problems, when the spectral signatures appear in groups, has the potential to yield better results than the standard sparse regression approach. Sparse unmixing has been recently introduced as a mechanism to characterize mixed pixels in remotely sensed hyperspectral images. It assumes that the observed image signatures can be expressed in the form of linear combinations of a number of pure spectral signatures known in advance (e.g., spectra collected on the ground by a field spectroradiometer). Unmixing then amounts to finding the optimal subset of signatures in a (potentially very large) spectral library that can best model each mixed pixel in the scene. In available spectral libraries, it is observed that the spectral signatures appear organized in groups (e.g. different alterations of a single mineral in the U.S. Geological Survey spectral library). In this paper, we explore the potential of the sparse group lasso technique in solving hyperspectral unmixing problems. Our introspection in this work is that, when the spectral signatures appear in groups, this technique has the potential to yield better results than the standard sparse regression approach. Experimental results with both synthetic and real hyperspectral data are given to investigate this issue.", "PublicationYear": "2011", "Authors": ["Marian-Daniel Iordache", "Jos{\\'e} M. Bioucas-Dias", "Antonio J. Plaza"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["41f426e2dc5b4944148014d9c86d20fdd21dc968", "6ffc3965342faf3be2cd73e1ea15ca2569a7dd92", "284cdfef6ed51904ec840077a2f2710e635f78fe", "3a1b983a87a4116803fff779ecf1cd11a4b07539", "7236864d8c2f62defea559465462c43a4b4b6b47", "63c53e35b25e09a3432e4f4dd786f5d539304f30", "b2148e57be50122e569941e835208326e76ba79b", "c8430c5d13834e46631960469d86f7ed4577b0e2", "915df1a8dda45221204f3ecbf70b07d8b34d7ba8", "b5e853572b2f3134acafa76d5ae80b9f28c7dca8"], "ReferenceCount": 13, "CitationCount": 34}, {"URL": "https://www.semanticscholar.org/paper/Total-Variation-Spatial-Regularization-for-Sparse-Iordache-Bioucas-Dias/2b07d0bfcbc64b8cefa2d5d7b84a3dd13b6d7b51", "ID": "2b07d0bfcbc64b8cefa2d5d7b84a3dd13b6d7b51", "Title": "Total Variation Spatial Regularization for Sparse Hyperspectral Unmixing", "Abstract": "The total variation (TV) regularization to the classical sparse regression formulation is included, thus exploiting the spatial-contextual information present in the hyperspectral images and developing a new algorithm called sparse unmixing via variable splitting augmented Lagrangian and TV. Spectral unmixing aims at estimating the fractional abundances of pure spectral signatures (also called endmembers) in each mixed pixel collected by a remote sensing hyperspectral imaging instrument. In recent work, the linear spectral unmixing problem has been approached in semisupervised fashion as a sparse regression one, under the assumption that the observed image signatures can be expressed as linear combinations of pure spectra, known a priori and available in a library. It happens, however, that sparse unmixing focuses on analyzing the hyperspectral data without incorporating spatial information. In this paper, we include the total variation (TV) regularization to the classical sparse regression formulation, thus exploiting the spatial-contextual information present in the hyperspectral images and developing a new algorithm called sparse unmixing via variable splitting augmented Lagrangian and TV. Our experimental results, conducted with both simulated and real hyperspectral data sets, indicate the potential of including spatial information (through the TV term) on sparse unmixing formulations for improved characterization of mixed pixels in hyperspectral imagery.", "PublicationYear": "2012", "Authors": ["Marian-Daniel Iordache", "Jos{\\'e} M. Bioucas-Dias", "Antonio J. Plaza"], "RelatedTopics": ["Environmental Science", "Computer Science", "Engineering"], "References": ["41f426e2dc5b4944148014d9c86d20fdd21dc968", "f76d44cba31df357c8fa184b488d34ce9fb1fe9c", "4a1042d7a216008eaae4d17d478f93029ef69a4f", "15f7662fadf686beae8ce704ee9b48262ac62237", "78bd5b068dd4be59e40fc642abd3b190d8636a2f", "f02cfba39160a2a5f7fe6d701bab5fb621728246", "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b", "a16ddf440077328c3e147cc703e8a0fe96d17622", "6acdf90e0d1d32480292cab70fdd75214ff22ef4", "6ffc3965342faf3be2cd73e1ea15ca2569a7dd92"], "ReferenceCount": 72, "CitationCount": 609}, {"URL": "https://www.semanticscholar.org/paper/Semi-Supervised-Graph-Based-Hyperspectral-Image-Camps-Valls-Marsheva/7c997a648976fb9df320c6ca332c9dc155820454", "ID": "7c997a648976fb9df320c6ca332c9dc155820454", "Title": "Semi-Supervised Graph-Based Hyperspectral Image Classification", "Abstract": "The introduction of the composite-kernel framework drastically improves results, and the new fast formulation ranks almost linearly in the computational cost, rather than cubic as in the original method, thus allowing the use of this method in remote-sensing applications. This paper presents a semi-supervised graph-based method for the classification of hyperspectral images. The method is designed to handle the special characteristics of hyperspectral images, namely, high-input dimension of pixels, low number of labeled samples, and spatial variability of the spectral signature. To alleviate these problems, the method incorporates three ingredients, respectively. First, being a kernel-based method, it combats the curse of dimensionality efficiently. Second, following a semi-supervised approach, it exploits the wealth of unlabeled samples in the image, and naturally gives relative importance to the labeled ones through a graph-based methodology. Finally, it incorporates contextual information through a full family of composite kernels. Noting that the graph method relies on inverting a huge kernel matrix formed by both labeled and unlabeled samples, we originally introduce the Nystro umlm method in the formulation to speed up the classification process. The presented semi-supervised-graph-based method is compared to state-of-the-art support vector machines in the classification of hyperspectral data. The proposed method produces better classification maps, which capture the intrinsic structure collectively revealed by labeled and unlabeled points. Good and stable accuracy is produced in ill-posed classification problems (high dimensional spaces and low number of labeled samples). In addition, the introduction of the composite-kernel framework drastically improves results, and the new fast formulation ranks almost linearly in the computational cost, rather than cubic as in the original method, thus allowing the use of this method in remote-sensing applications.", "PublicationYear": "2007", "Authors": ["Gustau Camps-Valls", "Tatyana V. Bandos Marsheva", "Dengyong Zhou"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["fe1fed99da2ddb76b07cb636fe30fb673869c469", "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "2badd8953397d757693859918cf9318fe7ec5e3b", "282cb3c00f517146a81029f4e05e93958024c0eb", "ad086d2e679f54a4a866183b0f4c27d9fc47861f", "7b22587b518d406e81e10c74719696e439fef2a4", "3e32b4775f3aeff0e1eaf37cc46771376a0c8d08", "c57a50f79bf2e8174b76aed1ccabc53e9e966256", "14b64bb5af95367883abd2b95d95979f87bcd5f0", "2ee856d5b6acc20f1313943d77374b37826ff97f"], "ReferenceCount": 56, "CitationCount": 584}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-hyperspectral-data-from-urban-on-Benediktsson-Palmason/c5389f0d9751ce9cd39160320ef17ae968a79edf", "ID": "c5389f0d9751ce9cd39160320ef17ae968a79edf", "Title": "Classification of hyperspectral data from urban areas based on extended morphological profiles", "Abstract": "A method based on mathematical morphology for preprocessing of the hyperspectral data is proposed, using opening and closing morphological transforms to isolate bright and dark structures in images, where bright/dark means brighter/darker than the surrounding features in the images. Classification of hyperspectral data with high spatial resolution from urban areas is investigated. A method based on mathematical morphology for preprocessing of the hyperspectral data is proposed. In this approach, opening and closing morphological transforms are used in order to isolate bright (opening) and dark (closing) structures in images, where bright/dark means brighter/darker than the surrounding features in the images. A morphological profile is constructed based on the repeated use of openings and closings with a structuring element of increasing size, starting with one original image. In order to apply the morphological approach to hyperspectral data, principal components of the hyperspectral imagery are computed. The most significant principal components are used as base images for an extended morphological profile, i.e., a profile based on more than one original image. In experiments, two hyperspectral urban datasets are classified. The proposed method is used as a preprocessing method for a neural network classifier and compared to more conventional classification methods with different types of statistical computations and feature extraction.", "PublicationYear": "2005", "Authors": ["J{\\'o}n Atli Benediktsson", "Jon Aevar Palmason", "Johannes R. Sveinsson"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["ed4f21d6fd4ea0cd2decba6f126cf05e9d7c1326", "ead23f99658e2370d3c20428635c4d90e71cfb69", "554006f9a6fb65441208956464e54bfb470916d5", "3f4a398762ae9cf721361d8c6b5a020be9dc5ef1", "f306d6e22c997cd2de22cd0ad00b9612a5701c87", "5e85f4cefa96286387a9717e3260111d64d7e2ae", "c69db8cf4a77466e8a8b52fcc2ef1ca0e503764c", "eb925519b2cea6f75158f26ba57e70eee7c139f9", "e52e9bfe2932765ac6d8b1ac9ada313f98b4d08f", "a9add89c424065562b6cf8c7e9ded69af8429cd8"], "ReferenceCount": 31, "CitationCount": 1272}, {"URL": "https://www.semanticscholar.org/paper/Sparse-Unmixing-of-Hyperspectral-Data-Iordache-Bioucas-Dias/41f426e2dc5b4944148014d9c86d20fdd21dc968", "ID": "41f426e2dc5b4944148014d9c86d20fdd21dc968", "Title": "Sparse Unmixing of Hyperspectral Data", "Abstract": "The experimental results, conducted using both simulated and real hyperspectral data sets collected by the NASA Jet Propulsion Laboratory's Airborne Visible Infrared Imaging Spectrometer and spectral libraries publicly available from the U.S. Geological Survey, indicate the potential of SR techniques in the task of accurately characterizing the mixed pixels using the library spectra. Linear spectral unmixing is a popular tool in remotely sensed hyperspectral data interpretation. It aims at estimating the fractional abundances of pure spectral signatures (also called as endmembers) in each mixed pixel collected by an imaging spectrometer. In many situations, the identification of the end-member signatures in the original data set may be challenging due to insufficient spatial resolution, mixtures happening at different scales, and unavailability of completely pure spectral signatures in the scene. However, the unmixing problem can also be approached in semisupervised fashion, i.e., by assuming that the observed image signatures can be expressed in the form of linear combinations of a number of pure spectral signatures known in advance (e.g., spectra collected on the ground by a field spectroradiometer). Unmixing then amounts to finding the optimal subset of signatures in a (potentially very large) spectral library that can best model each mixed pixel in the scene. In practice, this is a combinatorial problem which calls for efficient linear sparse regression (SR) techniques based on sparsity-inducing regularizers, since the number of endmembers participating in a mixed pixel is usually very small compared with the (ever-growing) dimensionality (and availability) of spectral libraries. Linear SR is an area of very active research, with strong links to compressed sensing, basis pursuit (BP), BP denoising, and matching pursuit. In this paper, we study the linear spectral unmixing problem under the light of recent theoretical results published in those referred to areas. Furthermore, we provide a comparison of several available and new linear SR algorithms, with the ultimate goal of analyzing their potential in solving the spectral unmixing problem by resorting to available spectral libraries. Our experimental results, conducted using both simulated and real hyperspectral data sets collected by the NASA Jet Propulsion Laboratory's Airborne Visible Infrared Imaging Spectrometer and spectral libraries publicly available from the U.S. Geological Survey, indicate the potential of SR techniques in the task of accurately characterizing the mixed pixels using the library spectra. This opens new perspectives for spectral unmixing, since the abundance estimation process no longer depends on the availability of pure spectral signatures in the input data nor on the capacity of a certain endmember extraction algorithm to identify such pure signatures.", "PublicationYear": "2011", "Authors": ["Marian-Daniel Iordache", "Jos{\\'e} M. Bioucas-Dias", "Antonio J. Plaza"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "23d92dc4598dd7dfa78560f187fa75524584c038", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "a70157e7089b12b5cc8f0c5603f6970bbb0dadad", "6ba3b3b9122ab0e663af6186267a8c81a1dd661e", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "5d6d531585ca65a41367550b959bf792d8ae26fc", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "6ffc3965342faf3be2cd73e1ea15ca2569a7dd92"], "ReferenceCount": 50, "CitationCount": 913}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-hyperspectral-remote-sensing-with-Melgani-Bruzzone/2badd8953397d757693859918cf9318fe7ec5e3b", "ID": "2badd8953397d757693859918cf9318fe7ec5e3b", "Title": "Classification of hyperspectral remote sensing images with support vector machines", "Abstract": "This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines by understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces and concludes that SVMs are a valid and effective alternative to conventional pattern recognition approaches. This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines (SVMs). First, we propose a theoretical discussion and experimental analysis aimed at understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces. Then, we assess the effectiveness of SVMs with respect to conventional feature-reduction-based approaches and their performances in hypersubspaces of various dimensionalities. To sustain such an analysis, the performances of SVMs are compared with those of two other nonparametric classifiers (i.e., radial basis function neural networks and the K-nearest neighbor classifier). Finally, we study the potentially critical issue of applying binary SVMs to multiclass problems in hyperspectral data. In particular, four different multiclass strategies are analyzed and compared: the one-against-all, the one-against-one, and two hierarchical tree-based strategies. Different performance indicators have been used to support our experimental studies in a detailed and accurate way, i.e., the classification accuracy, the computational time, the stability to parameter setting, and the complexity of the multiclass architecture. The results obtained on a real Airborne Visible/Infrared Imaging Spectroradiometer hyperspectral dataset allow to conclude that, whatever the multiclass strategy adopted, SVMs are a valid and effective alternative to conventional pattern recognition approaches (feature-reduction procedures combined with a classification method) for the classification of hyperspectral remote sensing data.", "PublicationYear": "2004", "Authors": ["Farid Melgani", "Lorenzo Bruzzone"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["a240da170041b9aa798b512160ba9712bf82a56e", "5b92c12e80e82e2302c6f2570f415bbc26f966b0", "b821c3afbb404766ff2c768fa363803b8d256434", "b9ddc16cd2449e93d44c1c5360dcf765b91de099", "f83b85d8daa4ee370982842a809b5c8dba63b645", "75a963eff4fd7809694d2225b62db7569f1e1b93", "5355e8c7359b8dadb970099dcd6fa951fa5ef3b7", "c94dec3fc99c4a653afb935d00246f788689c341", "ea82a3b3f8940c7e8f949d78639792ac345d09fd", "7dd9820b13754f05ae3f7f771fc8b2d7f4691c06"], "ReferenceCount": 52, "CitationCount": 3545}, {"URL": "https://www.semanticscholar.org/paper/Deep-Semi-Supervised-Anomaly-Detection-Ruff-Vandermeulen/4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "ID": "4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "Title": "Deep Semi-Supervised Anomaly Detection", "Abstract": "This work presents Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection, and introduces an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy the anomalous distribution, which can serve as a theoretical interpretation for the method. Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "PublicationYear": "2019", "Authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G{\\\"o}rnitz", "Alexander Binder", "Emmanuel M{\\\"u}ller", "Klaus-Robert M{\\\"u}ller", "M. Kloft"], "RelatedTopics": ["Computer Science"], "References": ["f5a951b9596be0df5ad7ede180b405c9e97a65c9", "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed", "2d8c97db4bae00ff243d122b957091a236a697a7", "ca4edb65a0664804e4819c5c809d0dfba9bdb2df", "a2e667e4382aaa8e02a17d0522c1a910790ab65b", "f076e4355c0facf111716dcab2837803367dd2d8", "6af440915b8a0718c93be1cf61905e41e620484a", "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "5db790198b9acf4e5efe350acdd814238fcacaa7", "0535625be630c6a67f4c244ebf3aa61ad088fc70"], "ReferenceCount": 88, "CitationCount": 387}, {"URL": "https://www.semanticscholar.org/paper/Deep-Anomaly-Detection-Using-Geometric-Golan-El-Yaniv/5db790198b9acf4e5efe350acdd814238fcacaa7", "ID": "5db790198b9acf4e5efe350acdd814238fcacaa7", "Title": "Deep Anomaly Detection Using Geometric Transformations", "Abstract": "The main idea behind the scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images, which generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We consider the problem of anomaly detection in images, and present a new detection technique. Given a sample of images, all known to belong to a \\\"normal\\\" class (e.g., dogs), we show how to train a deep neural model that can detect out-of-distribution images (i.e., non-dog objects). The main idea behind our scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images. The auxiliary expertise learned by the model generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We present extensive experiments using the proposed detector, which indicate that our algorithm improves state-of-the-art methods by a wide margin.", "PublicationYear": "2018", "Authors": ["Izhak Golan", "Ran El-Yaniv"], "RelatedTopics": ["Computer Science"], "References": ["6af440915b8a0718c93be1cf61905e41e620484a", "3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "547c854985629cfa9404a5ba8ca29367b5f8c25f", "c72e91b2e5c103f529510fa15a156d61c5633da1", "10a498003e9204f5fc1328e706510a37e514d8c7", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "061146b1d7938d7a8dae70e3531a00fceb3c78e8", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "d612d7c21d4130a457968273d79c2c2f6946953d"], "ReferenceCount": 45, "CitationCount": 512}, {"URL": "https://www.semanticscholar.org/paper/GANomaly%3A-Semi-Supervised-Anomaly-Detection-via-Ak%C3%A7ay-Atapour-Abarghouei/0535625be630c6a67f4c244ebf3aa61ad088fc70", "ID": "0535625be630c6a67f4c244ebf3aa61ad088fc70", "Title": "GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training", "Abstract": "This work introduces a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space and shows the model efficacy and superiority over previous state-of-the-art approaches. Anomaly detection is a classical problem in computer vision, namely the determination of the normal from the abnormal when datasets are highly biased towards one class (normal) due to the insufficient sample size of the other class (abnormal). While this can be addressed as a supervised learning problem, a significantly more challenging problem is that of detecting the unknown/unseen anomaly case that takes us instead into the space of a one-class, semi-supervised learning paradigm. We introduce such a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space. Employing encoder-decoder-encoder sub-networks in the generator network enables the model to map the input image to a lower dimension vector, which is then used to reconstruct the generated output image. The use of the additional encoder network maps this generated image to its latent representation. Minimizing the distance between these images and the latent vectors during training aids in learning the data distribution for the normal samples. As a result, a larger distance metric from this learned data distribution at inference time is indicative of an outlier from that distribution - an anomaly. Experimentation over several benchmark datasets, from varying domains, shows the model efficacy and superiority over previous state-of-the-art approaches.", "PublicationYear": "2018", "Authors": ["Samet Ak\u00e7ay", "Amir Atapour-Abarghouei", "T. Breckon"], "RelatedTopics": ["Computer Science"], "References": ["e399a626ba21fafb19b3661603ec9724058e951b", "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "39b8f34e71553622bb16b547211d0d769563c61d", "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "571b0750085ae3d939525e62af510ee2cee9d5ea", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "86ee1835a56722b76564119437070782fc90eb19", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "e163a2e89c136cb4442e34c72f7173a0ff46dc79"], "ReferenceCount": 55, "CitationCount": 999}, {"URL": "https://www.semanticscholar.org/paper/MVTec-AD-%E2%80%94-A-Comprehensive-Real-World-Dataset-for-Bergmann-Fauser/3aa681914a7da79f7d7293f51a058eefe61c8bb7", "ID": "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "Title": "MVTec AD \u2014 A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection", "Abstract": "This work introduces the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories, and conducts a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolved neural networks. The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the \ufb01eld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the \ufb01rst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.", "PublicationYear": "2019", "Authors": ["Paul Bergmann", "Michael Fauser", "David Sattlegger", "Carsten Steger"], "RelatedTopics": ["Computer Science"], "References": ["6af440915b8a0718c93be1cf61905e41e620484a", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "2d8c97db4bae00ff243d122b957091a236a697a7", "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "732c21998e251d64cd58b6a86886ee5907efeaa5", "9c24454b071bc8e96ea46c5064a7bddf07cca464", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "5d90f06bb70a0a3dced62413346235c02b1aa086"], "ReferenceCount": 29, "CitationCount": 742}, {"URL": "https://www.semanticscholar.org/paper/Uninformed-Students%3A-Student-Teacher-Anomaly-With-Bergmann-Fauser/41747cbdbed84762dfbfc305254c97021279dc6e", "ID": "41747cbdbed84762dfbfc305254c97021279dc6e", "Title": "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings", "Abstract": "A powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images by trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.", "PublicationYear": "2019", "Authors": ["Paul Bergmann", "Michael Fauser", "David Sattlegger", "Carsten Steger"], "RelatedTopics": ["Computer Science"], "References": ["3aa681914a7da79f7d7293f51a058eefe61c8bb7", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "2910bec6d4de87e22be5119cef3c488d2ae50e2a", "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6", "6af440915b8a0718c93be1cf61905e41e620484a", "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "317c172f314f8cb634f7569ed5bf3ae7dd25c313", "67b9c2b376a01d8757dc6d704be450d1c46c4ced"], "ReferenceCount": 37, "CitationCount": 373}, {"URL": "https://www.semanticscholar.org/paper/Deep-Autoencoding-Gaussian-Mixture-Model-for-Zong-Song/dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "ID": "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "Title": "Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection", "Abstract": "A Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised anomaly detection, which significantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement based on the standard F1 score. Unsupervised anomaly detection on multior high-dimensional data is of great importance in both fundamental machine learning research and industrial applications, for which density estimation lies at the core. Although previous approaches based on dimensionality reduction followed by density estimation have made fruitful progress, they mainly suffer from decoupled model learning with inconsistent optimization goals and incapability of preserving essential information in the low-dimensional space. In this paper, we present a Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised anomaly detection. Our model utilizes a deep autoencoder to generate a low-dimensional representation and reconstruction error for each input data point, which is further fed into a Gaussian Mixture Model (GMM). Instead of using decoupled two-stage training and the standard Expectation-Maximization (EM) algorithm, DAGMM jointly optimizes the parameters of the deep autoencoder and the mixture model simultaneously in an end-to-end fashion, leveraging a separate estimation network to facilitate the parameter learning of the mixture model. The joint optimization, which well balances autoencoding reconstruction, density estimation of latent representation, and regularization, helps the autoencoder escape from less attractive local optima and further reduce reconstruction errors, avoiding the need of pre-training. Experimental results on several public benchmark datasets show that, DAGMM significantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement based on the standard F1 score.", "PublicationYear": "2018", "Authors": ["Bo Zong", "Qi Song", "Martin Renqiang Min", "Wei Cheng", "Cristian Lumezanu", "Dae-ki Cho", "Haifeng Chen"], "RelatedTopics": ["Computer Science"], "References": ["60d4ec78a673119420bee41268672a8f8669bb31", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "10a498003e9204f5fc1328e706510a37e514d8c7", "aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "33a832399927971f144dee7fee50c0bcc5e1e659", "3eeb8b5d5ee2db86fa359ec479b730a793d5971e", "ca9f84c3922004ec6133aa9c2048ceeb17702fee", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "8080c7954944e4e293028768e7dcbaead190c85e"], "ReferenceCount": 34, "CitationCount": 1211}, {"URL": "https://www.semanticscholar.org/paper/Anomaly-Detection-with-Robust-Deep-Autoencoders-Zhou-Paffenroth/2b75ba7f75170b73d913c515cc0deefef6c88f5f", "ID": "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "Title": "Anomaly Detection with Robust Deep Autoencoders", "Abstract": "Novel extensions to deep autoencoders are demonstrated which not only maintain a deep autenkocoders' ability to discover high quality, non-linear features but can also eliminate outliers and noise without access to any clean training data. Deep autoencoders, and other deep neural networks, have demonstrated their effectiveness in discovering non-linear features across many problem domains. However, in many real-world problems, large outliers and pervasive noise are commonplace, and one may not have access to clean training data as required by standard deep denoising autoencoders. Herein, we demonstrate novel extensions to deep autoencoders which not only maintain a deep autoencoders' ability to discover high quality, non-linear features but can also eliminate outliers and noise without access to any clean training data. Our model is inspired by Robust Principal Component Analysis, and we split the input data X into two parts, $X = L_{D} + S$, where $L_{D}$ can be effectively reconstructed by a deep autoencoder and $S$ contains the outliers and noise in the original data X. Since such splitting increases the robustness of standard deep autoencoders, we name our model a \\\"Robust Deep Autoencoder (RDA)\\\". Further, we present generalizations of our results to grouped sparsity norms which allow one to distinguish random anomalies from other types of structured corruptions, such as a collection of features being corrupted across many instances or a collection of instances having more corruptions than their fellows. Such \\\"Group Robust Deep Autoencoders (GRDA)\\\" give rise to novel anomaly detection approaches whose superior performance we demonstrate on a selection of benchmark problems.", "PublicationYear": "2017", "Authors": ["Chong Zhou", "Randy Clinton Paffenroth"], "RelatedTopics": ["Computer Science"], "References": ["357733cc76e31a499a27ba2da8612174aafb3213", "00af02c2cb48920af477115e870a42ac4f8a3834", "fbb38946334941292800a82c99c0dc4feb0cb882", "843959ffdccf31c6694d135fad07425924f785b1", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "ec7e0ceea8f79735742ea671b3c37148cae9f22c", "a2017ec2c60d542af5e9993176ba68f89529dbce", "195d0a8233a7a46329c742eaff56c276f847fadc", "2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35", "a4cec122a08216fe8a3bc19b22e78fbaea096256"], "ReferenceCount": 27, "CitationCount": 1026}, {"URL": "https://www.semanticscholar.org/paper/Adversarially-Learned-One-Class-Classifier-for-Sabokrou-Khalooei/8381157eae4fbf8908d0312a9642f8e69e944449", "ID": "8381157eae4fbf8908d0312a9642f8e69e944449", "Title": "Adversarially Learned One-Class Classifier for Novelty Detection", "Abstract": "The results on MNIST and Caltech-256 image datasets, along with the challenging UCSD Ped2 dataset for video anomaly detection illustrate that the proposed method learns the target class effectively and is superior to the baseline and state-of-the-art methods. Novelty detection is the process of identifying the observation(s) that differ in some respect from the training observations (the target class). In reality, the novelty class is often absent during training, poorly sampled or not well defined. Therefore, one-class classifiers can efficiently model such problems. However, due to the unavailability of data from the novelty class, training an end-to-end deep network is a cumbersome task. In this paper, inspired by the success of generative adversarial networks for training deep models in unsupervised and semi-supervised settings, we propose an end-to-end architecture for one-class classification. Our architecture is composed of two deep networks, each of which trained by competing with each other while collaborating to understand the underlying concept in the target class, and then classify the testing samples. One network works as the novelty detector, while the other supports it by enhancing the inlier samples and distorting the outliers. The intuition is that the separability of the enhanced inliers and distorted outliers is much better than deciding on the original samples. The proposed framework applies to different related applications of anomaly and outlier detection in images and videos. The results on MNIST and Caltech-256 image datasets, along with the challenging UCSD Ped2 dataset for video anomaly detection illustrate that our proposed method learns the target class effectively and is superior to the baseline and state-of-the-art methods.", "PublicationYear": "2018", "Authors": ["M. Sabokrou", "Mohammad Khalooei", "Mahmood Fathy", "Ehsan Adeli"], "RelatedTopics": ["Computer Science"], "References": ["e399a626ba21fafb19b3661603ec9724058e951b", "571b0750085ae3d939525e62af510ee2cee9d5ea", "5d666e2761bbac7d8e0ac724280d20fd24d71a6b", "a7fae7dba0db74cc21a7c7b70157fe601784b681", "6f68ce1e03c56c186256dac689a21f6405ae8d96", "8388f1be26329fa45e5807e968a641ce170ea078", "9eb1b16fbd4786eaac91f308d75609b9321868ce", "9d5290fadb7625862a966e0330bd0f9e111fc99d", "6259b02912cebc224f3a2b1324e811a152a0177d", "60fef33549f57f5cbb6712a510c3a444ab682429"], "ReferenceCount": 52, "CitationCount": 579}, {"URL": "https://www.semanticscholar.org/paper/Iterative-energy-based-projection-on-a-normal-data-Dehaene-Frigo/d9d7ab13ce305ccee309c989a2341d72b1252070", "ID": "d9d7ab13ce305ccee309c989a2341d72b1252070", "Title": "Iterative energy-based projection on a normal data manifold for anomaly localization", "Abstract": "This paper proposes a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoen coder's loss function, augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder's loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.", "PublicationYear": "2020", "Authors": ["David Dehaene", "Oriel Frigo", "S{\\'e}bastien Combrexelle", "Pierre Eline"], "RelatedTopics": ["Computer Science"], "References": ["06fad023ef0274e7d6727ecbd1ef46887a6806df", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d", "9c24454b071bc8e96ea46c5064a7bddf07cca464", "061146b1d7938d7a8dae70e3531a00fceb3c78e8", "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa"], "ReferenceCount": 29, "CitationCount": 107}, {"URL": "https://www.semanticscholar.org/paper/Attention-Guided-Anomaly-Localization-in-Images-Venkataramanan-Peng/211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d", "ID": "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d", "Title": "Attention Guided Anomaly Localization in Images", "Abstract": "This work proposes Convolutional Adversarial Variational autoencoder with Guided Attention (CAVGA), which localizes the anomaly with a convolutional latent variable to preserve the spatial information and outperforms state-of-the-art anomaly localization methods on several datasets. Anomaly localization is an important problem in computer vision which involves localizing anomalous regions within images with applications in industrial inspection, surveillance, and medical imaging. This task is challenging due to the small sample size and pixel coverage of the anomaly in real-world scenarios. Most prior works need to use anomalous training images to compute a class-specific threshold to localize anomalies. Without the need of anomalous training images, we propose Convolutional Adversarial Variational autoencoder with Guided Attention (CAVGA), which localizes the anomaly with a convolutional latent variable to preserve the spatial information. In the unsupervised setting, we propose an attention expansion loss where we encourage CAVGA to focus on all normal regions in the image. Furthermore, in the weakly-supervised setting we propose a complementary guided attention loss, where we encourage the attention map to focus on all normal regions while minimizing the attention map corresponding to anomalous regions in the image. CAVGA outperforms the state-of-the-art (SOTA) anomaly localization methods on MVTec Anomaly Detection (MVTAD), modified ShanghaiTech Campus (mSTC) and Large-scale Attention based Glaucoma (LAG) datasets in the unsupervised setting and when using only 2% anomalous images in the weakly-supervised setting. CAVGA also outperforms SOTA anomaly detection methods on the MNIST, CIFAR-10, Fashion-MNIST, MVTAD, mSTC and LAG datasets.", "PublicationYear": "2019", "Authors": ["Shashanka Venkataramanan", "Kuan-Chuan Peng", "Rajat Vikram Singh", "Abhijit Mahalanobis"], "RelatedTopics": ["Computer Science"], "References": ["0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b", "39972fb3a9cbac1e25b2c096e3e28bba2eee7aa4", "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "8a6acba7fb2aad1299fcf35701417e063d410ed4", "d9d7ab13ce305ccee309c989a2341d72b1252070", "3aa681914a7da79f7d7293f51a058eefe61c8bb7", "3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "4c1abd8969fc1c360f50373f6552bcfb3cc408b7", "97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f"], "ReferenceCount": 65, "CitationCount": 149}, {"URL": "https://www.semanticscholar.org/paper/Replacement-AutoEncoder%3A-A-Privacy-Preserving-for-Malekzadeh-Clegg/65c8a794830f9a11aa0b9ab682f3b6256be67185", "ID": "65c8a794830f9a11aa0b9ab682f3b6256be67185", "Title": "Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data Analysis", "Abstract": "This paper introduces Replacement AutoEncoder, a novel feature-learning algorithm which learns how to transform discriminative features of multi-variate time-series that correspond to sensitive inferences, into some features that have been more observed in non-sensitive inferences to protect users' privacy. An increasing number of sensors on mobile, Internet of things (IoT), and wearable devices generate time-series measurements of physical activities. Though access to the sensory data is critical to the success of many beneficial applications such as health monitoring or activity recognition, a wide range of potentially sensitive information about the individuals can also be discovered through access to sensory data and this cannot easily be protected using traditional privacy approaches. In this paper, we propose a privacy-preserving sensing framework for managing access to time-series data in order to provide utility while protecting individuals' privacy. We introduce Replacement AutoEncoder, a novel feature-learning algorithm which learns how to transform discriminative features of multi-variate time-series that correspond to sensitive inferences, into some features that have been more observed in non-sensitive inferences, to protect users' privacy. This efficiency is achieved by defining a user-customized objective function for deep autoencoders. Replacement will not only eliminate the possibility of recognition sensitive inferences, it also eliminates the possibility of detecting the occurrence of them, that is the main weakness of other approaches such as filtering or randomization. We evaluate the efficacy of the algorithm with an activity recognition task in a multi-sensing environment using extensive experiments on three benchmark datasets. We show that it can retain the recognition accuracy of state-of-the-art techniques while simultaneously preserving the privacy of sensitive information. Finally, we utilize the GANs for detecting the occurrence of replacement, after releasing data, and show that this can be done only if the adversarial network is trained on the users' original data.", "PublicationYear": "2017", "Authors": ["M. Malekzadeh", "Richard G. Clegg", "Hamed Haddadi"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["6f0685d61328f0f90972fe822258d574b74e9c7a", "36051962fdcfa536c3cc1cd27b17649d84a8cf09", "818e1e81b9bf13f4803934b15f4f6b3cb9251658", "7dee8c690e23585f0beffa3c81933f8691b06a73", "017d615afa48eea38ae741d0071c4781dc0d1024", "6065090377b440bbf5dc02ede58aeaa7d7811f5c", "ffc77622fca7aa46de7ef7ded3031e31c3bacce4", "b3de61ce1665d7f8b5ddc344289b7a4e18f015f6", "08c71fe89af5f168b373e92b44a7cf9d1755fb8c", "2009b05a29eb78f915f1a1f6178151dc6c93871c"], "ReferenceCount": 46, "CitationCount": 65}, {"URL": "https://www.semanticscholar.org/paper/Can-Deep-Learning-Revolutionize-Mobile-Sensing-Lane-Georgiev/6c20cd584e7258056840eb88437d69731000bb0f", "ID": "6c20cd584e7258056840eb88437d69731000bb0f", "Title": "Can Deep Learning Revolutionize Mobile Sensing?", "Abstract": "Preliminary answers to how the field of mobile sensing can best make use of advances in deep learning towards robust and efficient sensor inference are provided by prototyping a low-power Deep Neural Network inference engine that exploits both the CPU and DSP of a mobile device SoC. Sensor-equipped smartphones and wearables are transforming a variety of mobile apps ranging from health monitoring to digital assistants. However, reliably inferring user behavior and context from noisy and complex sensor data collected under mobile device constraints remains an open problem, and a key bottleneck to sensor app development. In recent years, advances in the field of deep learning have resulted in nearly unprecedented gains in related inference tasks such as speech and object recognition. However, although mobile sensing shares many of the same data modeling challenges, we have yet to see deep learning be systematically studied within the sensing domain. If deep learning could lead to significantly more robust and efficient mobile sensor inference it would revolutionize the field by rapidly expanding the number of sensor apps ready for mainstream usage. In this paper, we provide preliminary answers to this potentially game-changing question by prototyping a low-power Deep Neural Network (DNN) inference engine that exploits both the CPU and DSP of a mobile device SoC. We use this engine to study typical mobile sensing tasks (e.g., activity recognition) using DNNs, and compare results to learning techniques in more common usage. Our early findings provide illustrative examples of DNN usage that do not overburden modern mobile hardware, while also indicating how they can improve inference accuracy. Moreover, we show DNNs can gracefully scale to larger numbers of inference classes and can be flexibly partitioned across mobile and remote resources. Collectively, these results highlight the critical need for further exploration as to how the field of mobile sensing can best make use of advances in deep learning towards robust and efficient sensor inference.", "PublicationYear": "2015", "Authors": ["Nicholas D. Lane", "Petko Georgiev"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["6ea35942b5c5a4fa2e0e72b9cf059052b6995b22", "5cdb93d0edef0483e7e7f41c1bbdbe38543581d0", "64ac4e5bb92a2de48edb56a3be3d63cfb03b6cd2", "8674a529943dec8eefd539517b73a513a5dc5a54", "104974b6c48147a96739ff8a63e14befe8115020", "5ed68f0d6d477c96201cb06d95b61689fa739956", "6ca8fa3ba89ed69128c7f6f03e07f3aa42446596", "80f6139c1de8fbf819afa29764a6c39a208fcf41", "376dfa43778847987e2e3ac17e4df12418091956", "72e93aa6767ee683de7f001fa72f1314e40a8f35"], "ReferenceCount": 27, "CitationCount": 261}, {"URL": "https://www.semanticscholar.org/paper/A-Privacy-Preserving-Deep-Learning-Approach-for-Mao-Feng/60951974d24dd83e288117b0cd217af6a5d34178", "ID": "60951974d24dd83e288117b0cd217af6a5d34178", "Title": "A Privacy-Preserving Deep Learning Approach for Face Recognition with Edge Computing", "Abstract": "This paper utilizes the differentially private mechanism to enable the privacy-preserving edge based training of DNN face recognition models, and shows that the mechanism is capable of training models in different scenarios, e.g., from scratch, or through finetuning over existed models. Deep convolutional neural networks (DNNs) have brought significant performance improvements to face recognition. However the training can hardly be carried out on mobile devices because the training of these models requires much computational power. An individual user with the demand of deriving DNN models from her own datasets usually has to outsource the training procedure onto a cloud or edge server. However this outsourcing method violates privacy because it exposes the users\u2019 data to curious service providers. In this paper, we utilize the differentially private mechanism to enable the privacy-preserving edge based training of DNN face recognition models. During the training, DNN is split between the user device and the edge server in a way that both private data and model parameters are protected, with only a small cost of local computations. We show that our mechanism is capable of training models in different scenarios, e.g., from scratch, or through finetuning over existed models.", "PublicationYear": "2018", "Authors": ["Yunlong Mao", "Jinghao Feng", "Fengyuan Xu", "Sheng Zhong"], "RelatedTopics": ["Computer Science"], "References": ["f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "44a97f4eaaefaf5338f8aed2913d5debb2459f7e", "6f0685d61328f0f90972fe822258d574b74e9c7a", "82e66c4832386cafcec16b92ac88088ffd1a1bc9", "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "db0cc2f21b20cbc0ab8946090967399c25709614", "d1b9a3b11e6c9571a1553556f82b605b2b4baec3", "162ea969d1929ed180cc6de9f0bf116993ff6e06", "35f4dbc11805ad58a730d23d9032aa7ec1c679ce", "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d"], "ReferenceCount": 16, "CitationCount": 61}, {"URL": "https://www.semanticscholar.org/paper/Privacy-preserving-deep-learning-Shokri-Shmatikov/f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "ID": "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "Title": "Privacy-preserving deep learning", "Abstract": "This paper presents a practical system that enables multiple parties to jointly learn an accurate neural-network model for a given objective without sharing their input datasets, and exploits the fact that the optimization algorithms used in modern deep learning, namely, those based on stochastic gradient descent, can be parallelized and executed asynchronously. Deep learning based on artificial neural networks is a very popular approach to modeling, classifying, and recognizing complex data such as images, speech, and text. The unprecedented accuracy of deep learning methods has turned them into the foundation of new AI-based services on the Internet. Commercial companies that collect user data on a large scale have been the main beneficiaries of this trend since the success of deep learning techniques is directly proportional to the amount of data available for training. Massive data collection required for deep learning presents obvious privacy issues. Users' personal, highly sensitive data such as photos and voice recordings is kept indefinitely by the companies that collect it. Users can neither delete it, nor restrict the purposes for which it is used. Furthermore, centrally kept data is subject to legal subpoenas and extrajudicial surveillance. Many data owners-for example, medical institutions that may want to apply deep learning methods to clinical records-are prevented by privacy and confidentiality concerns from sharing the data and thus benefitting from large-scale deep learning. In this paper, we present a practical system that enables multiple parties to jointly learn an accurate neural-network model for a given objective without sharing their input datasets. We exploit the fact that the optimization algorithms used in modern deep learning, namely, those based on stochastic gradient descent, can be parallelized and executed asynchronously. Our system lets participants train independently on their own datasets and selectively share small subsets of their models' key parameters during training. This offers an attractive point in the utility/privacy tradeoff space: participants preserve the privacy of their respective data while still benefitting from other participants' models and thus boosting their learning accuracy beyond what is achievable solely on their own inputs. We demonstrate the accuracy of our privacy-preserving deep learning on benchmark datasets.", "PublicationYear": "2015", "Authors": ["R. Shokri", "Vitaly Shmatikov"], "RelatedTopics": ["Computer Science"], "References": ["6f2632d3569223056c040899b5891980288539d8", "763afb9dc8650101be06053e2eb612d9e3a1ce18", "006cb500fd0b25200e12eb5a024756aea3d569ed", "b57c54350769ffa59ff57f79ee5aad918844d298", "c1d36203276052765afbc8d9cd822ba5d0384627", "a188d2ac0d10bdd4d4a04c92cdc76523e11c155c", "34f25a8704614163c4095b3ee2fc969b60de4698", "8fe09c5c88c3dd0700051c48fd917ac480436a4c", "19c40cc8456950acc93553591f4a79b138bbeaf0", "f8558a09553fc35415b271019be9f7d44354073e"], "ReferenceCount": 60, "CitationCount": 1899}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-in-Mobile-and-Wireless-Networking%3A-A-Zhang-Patras/8a5d0579590465494c9aba58a857af43b190b6a6", "ID": "8a5d0579590465494c9aba58a857af43b190b6a6", "Title": "Deep Learning in Mobile and Wireless Networking: A Survey", "Abstract": "This paper bridges the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas, and provides an encyclopedic review of mobile and Wireless networking research based on deep learning, which is categorize by different domains. The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper, we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research.", "PublicationYear": "2018", "Authors": ["Chaoyun Zhang", "Paul Patras", "Hamed Haddadi"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["992983bd9faa6846f143a9080a41ccbb442553e9", "7e739a65f5d5e8fa724322a832ef1de2aa614996", "d246989d6839a91f38b7fa97d1ee67545d636db6", "7c4af74191488ecfc5f7963f8d6af483c1ba548b", "d53533b4f24504ecb04612a0d08c46db966caa2f", "30e28b272f7ad1ca82a2d68d4f0fdd575d6e31b2", "959497916e2aef85172c5664a0496f3a12622384", "d7896d6be118386a1f76f389210ca4e3a87b0d4a", "d4de528645fdfc6d954364a8e6eeeed9480ccfa2", "d67e2f60c55884e34fa8e2a154ae12b5983c90e7"], "ReferenceCount": 581, "CitationCount": 1104}, {"URL": "https://www.semanticscholar.org/paper/SecureML%3A-A-System-for-Scalable-Privacy-Preserving-Mohassel-Zhang/2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "ID": "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "Title": "SecureML: A System for Scalable Privacy-Preserving Machine Learning", "Abstract": "This paper presents new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method, and implements the first privacy preserving system for training neural networks. Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.", "PublicationYear": "2017", "Authors": ["Payman Mohassel", "Yupeng Zhang"], "RelatedTopics": ["Computer Science"], "References": ["f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "a188d2ac0d10bdd4d4a04c92cdc76523e11c155c", "c80d112ce59c72f943dc7b3e56e4c77dc3af1146", "1f996f3ed94538d5cea66c1cb6ef3adfed9cdd24", "d24c81f1e2904ba6ec3f341161865ef93247855b", "a09dcece804c6cd11fd3f0025dda7d327121ae67", "0eefa33a1ad9118ba91a2e4a88e555b453a952f1", "c82910284f31c4f13ce58a31ecef0e4c32d2396a", "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "78f6f52a2e5f836fb4c24902be11ca3b81982847"], "ReferenceCount": 42, "CitationCount": 1411}, {"URL": "https://www.semanticscholar.org/paper/Sparsification-and-Separation-of-Deep-Learning-for-Bhattacharya-Lane/187a78ebfe654e9c1d3e8d070c8845a49c1d1a42", "ID": "187a78ebfe654e9c1d3e8d070c8845a49c1d1a42", "Title": "Sparsification and Separation of Deep Learning Layers for Constrained Resource Inference on Wearables", "Abstract": "This paper proposes SparseSep, a new approach that leverages the sparsification of fully connected layers and separation of convolutional kernels to reduce the resource requirements of popular deep learning algorithms, and allows large-scale DNNs and CNNs to run efficiently on mobile and embedded hardware with only minimal impact on inference accuracy. Deep learning has revolutionized the way sensor data are analyzed and interpreted. The accuracy gains these approaches offer make them attractive for the next generation of mobile, wearable and embedded sensory applications. However, state-of-the-art deep learning algorithms typically require a significant amount of device and processor resources, even just for the inference stages that are used to discriminate high-level classes from low-level data. The limited availability of memory, computation, and energy on mobile and embedded platforms thus pose a significant challenge to the adoption of these powerful learning techniques. In this paper, we propose SparseSep, a new approach that leverages the sparsification of fully connected layers and separation of convolutional kernels to reduce the resource requirements of popular deep learning algorithms. As a result, SparseSep allows large-scale DNNs and CNNs to run efficiently on mobile and embedded hardware with only minimal impact on inference accuracy. We experiment using SparseSep across a variety of common processors such as the Qualcomm Snapdragon 400, ARM Cortex M0 and M3, and Nvidia Tegra K1, and show that it allows inference for various deep models to execute more efficiently; for example, on average requiring 11.3 times less memory and running 13.3 times faster on these representative platforms.", "PublicationYear": "2016", "Authors": ["Sourav Bhattacharya", "Nicholas D. Lane"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["c76559037bdafef208da9e3fc38eb68a08cdfa2f", "6c20cd584e7258056840eb88437d69731000bb0f", "9cdd742261c9f07887354622f79ade8226d625c7", "d594839932b3ec17b2f0e30f00d1095937eabf74", "d5b4721c8188269b120d3d06149a04435753e755", "22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd", "e7bf9803705f2eb608db1e59e5c7636a3f171916", "604e5b979a35b76e86643293b9130e465af3332b", "a4cec122a08216fe8a3bc19b22e78fbaea096256", "021fc345d40d3e6332cd2ef276e2eaa5e71102e4"], "ReferenceCount": 57, "CitationCount": 218}, {"URL": "https://www.semanticscholar.org/paper/ZOE%3A-A-Cloud-less-Dialog-enabled-Continuous-Sensing-Lane-Georgiev/5a7a7dfea3674d4e0474f7fdd596951da44babe4", "ID": "5a7a7dfea3674d4e0474f7fdd596951da44babe4", "Title": "ZOE: A Cloud-less Dialog-enabled Continuous Sensing Wearable Exploiting Heterogeneous Computation", "Abstract": "A match-box sized collar- or lapel-worn sensor that pushes the boundary of wearables in an important set of new directions, ZOE aims to perform multiple deep sensor inferences that span key aspects of everyday life on continuously sensed data; while also offering this data not only within conventional analytics but also through a speech dialog system that is able to answer impromptu casual questions from users. The wearable revolution, as a mass-market phenomenon, has finally arrived. As a result, the question of how wearables should evolve over the next 5 to 10 years is assuming an increasing level of societal and commercial importance. A range of open design and system questions are emerging, for instance: How can wearables shift from being largely health and fitness focused to tracking a wider range of life events? What will become the dominant methods through which users interact with wearables and consume the data collected? Are wearables destined to be cloud and/or smartphone dependent for their operation? Towards building the critical mass of understanding and experience necessary to tackle such questions, we have designed and implemented ZOE - a match-box sized (49g) collar- or lapel-worn sensor that pushes the boundary of wearables in an important set of new directions. First, ZOE aims to perform multiple deep sensor inferences that span key aspects of everyday life (viz. personal, social and place information) on continuously sensed data; while also offering this data not only within conventional analytics but also through a speech dialog system that is able to answer impromptu casual questions from users. (Am I more stressed this week than normal?) Crucially, and unlike other rich-sensing or dialog supporting wearables, ZOE achieves this without cloud or smartphone support - this has important side-effects for privacy since all user information can remain on the device. Second, ZOE incorporates the latest innovations in system-on-a-chip technology together with a custom daughter-board to realize a three-tier low-power processor hierarchy. We pair this hardware design with software techniques that manage system latency while still allowing ZOE to remain energy efficient (with a typical lifespan of 30 hours), despite its high sensing workload, small form-factor, and need to remain responsive to user dialog requests.", "PublicationYear": "2015", "Authors": ["Nicholas D. Lane", "Petko Georgiev", "Cecilia Mascolo", "Ying Gao"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["856c1fc2bae151215ce3dacf06c4a003b5a129b1", "eadfeaf5e0a3947029a0a373aa1f923ad83454fe", "19704fa35fdc2eae04cd45158df706e59dd3693d", "158dad9eaa0461e6e5d404ea91de7a547640cb7d", "64ac4e5bb92a2de48edb56a3be3d63cfb03b6cd2", "647134685bf254f07cf1a87eeb5d3344c19e37c8", "6ea35942b5c5a4fa2e0e72b9cf059052b6995b22", "d29e208f57c96cac901cde1955e4e62a96b4da81", "672f12e4ee015308a240f32d6766fccfabd75bfc", "f3b18830659ad634016682d7d498d020f04a9449"], "ReferenceCount": 62, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Federated-Learning%3A-Strategies-for-Improving-Konecn%C3%BD-McMahan/7fcb90f68529cbfab49f471b54719ded7528d0ef", "ID": "7fcb90f68529cbfab49f471b54719ded7528d0ef", "Title": "Federated Learning: Strategies for Improving Communication Efficiency", "Abstract": "Two ways to reduce the uplink communication costs are proposed: structured updates, where the user directly learns an update from a restricted space parametrized using a smaller number of variables, e.g. either low-rank or a random mask; and sketched updates, which learn a full model update and then compress it using a combination of quantization, random rotations, and subsampling. Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. We consider learning algorithms for this setting where on each round, each client independently computes an update to the current model based on its local data, and communicates this update to a central server, where the client-side updates are aggregated to compute a new global model. The typical clients in this setting are mobile phones, and communication efficiency is of the utmost importance. In this paper, we propose two ways to reduce the uplink communication costs: structured updates, where we directly learn an update from a restricted space parametrized using a smaller number of variables, e.g. either low-rank or a random mask; and sketched updates, where we learn a full model update and then compress it using a combination of quantization, random rotations, and subsampling before sending it to the server. Experiments on both convolutional and recurrent networks show that the proposed methods can reduce the communication cost by two orders of magnitude.", "PublicationYear": "2016", "Authors": ["Jakub Konecn{\\'y}", "H. B. McMahan", "Felix X. Yu", "Peter Richt{\\'a}rik", "Ananda Theertha Suresh", "Dave Bacon"], "RelatedTopics": ["Computer Science"], "References": ["561269a24f2f2a06409109723a8ab93a01696efc", "8b419080cd37bdc30872b76f405ef6a93eae3304", "d1dbf643447405984eeef098b1b320dee0b3b8a7", "614ec0fe23fe21235126cc5c92ccf5a739a3ae32", "3127190433230b3dc1abd0680bb58dced4bcd90e", "25fb5a6abcd88ee52bdb3165b844c941e90eb9bf", "51fb0ad908794c6127c51420c3924dfcc601b570", "9d72c286f24a51e24ae9e80e957d1f999baee17b", "edc2e4e6308d7dfce586cb8a4441c704f8f8d41b", "c7c512090ebe83cc8947404984b300aca30e9793"], "ReferenceCount": 26, "CitationCount": 3557}, {"URL": "https://www.semanticscholar.org/paper/Advanced-Media-Based-Smart-Big-Data-on-Intelligent-Psannis-Stergiou/405006da005398279bdf7c3423d47aa0951c5391", "ID": "405006da005398279bdf7c3423d47aa0951c5391", "Title": "Advanced Media-Based Smart Big Data on Intelligent Cloud Systems", "Abstract": "The proposed encoding algorithm outperforms the conventional HEVC standard which demonstrated by the performance evaluations and could be used and integrated into HEVC, as a Smart Big Data, without violating the standard. Today's advanced media technology preaches an enthralling time that will enormously bear on daily life. Moreover, the rapid raise of wireless communications and networking will ultimately bring advanced media to our lives anytime, anywhere, and on any device. According to the National Institute of Standards and Technology (NIST), Cloud Computing (CC) is a scheme for enabling convenient, on-demand network access to a shared pool of configurable computing pores (for example networks, applications, storage, servers, and services) which could be promptly foresighted and delivered with minimal management effort or service provider interaction. This paper proposed an efficient algorithm for advanced scalable Media-basedSmart Big Data (3D, Ultra HD) on Intelligent Cloud Computing systems. The proposed encoding algorithmoutperforms the conventional HEVC standard which demonstrated by the performance evaluations. In order to ratify the proposed approach, in addition, a relative study has been carried out. The proposed method could be used and integrated into HEVC, as a Smart Big Data, without violating the standard.", "PublicationYear": "2019", "Authors": ["Kostas E. Psannis", "Christos L. Stergiou", "Brij Bhooshan Gupta"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["fdd709a6f33f7cfc46c7827ab69e786ba4a392e5", "fb18e87bdfa27b3bc7a9d9337f02cd6b66d0c372", "2a3ebc6d371a55a926fdd15e1ee1bdc32ec05f0e", "eaabf1c38e6b4925a21eae1658971f2cc3ada14f", "7dfd49a28b3eff74e29fd11aeecd1e9802c5c95a", "44180d8de71036962383b4b074d475b767ddd95a", "ef5ff2c100eff7adbf3335c82e0bd55b0f4f2890", "6da3d71dc601fd9cd6b4e84bc947de5474c5873b", "39c140bf1aaa2f3ea4f532aedff84c659e8dbcd7", "c0ac47e65ecdd066e2021470d605574f73a2925b"], "ReferenceCount": 69, "CitationCount": 100}, {"URL": "https://www.semanticscholar.org/paper/Data-driven-crowd-analysis-in-videos-Rodriguez-Sivic/3950b335fd77d6f025cdf29e9733ee92189b6a9b", "ID": "3950b335fd77d6f025cdf29e9733ee92189b6a9b", "Title": "Data-driven crowd analysis in videos", "Abstract": "A new crowd analysis algorithm powered by behavior priors that are learned on a large database of crowd videos gathered from the Internet that performs like state-of-the-art methods for tracking people having common crowd behaviors and outperforms the methods when the tracked individual behaves in an unusual way. In this work we present a new crowd analysis algorithm powered by behavior priors that are learned on a large database of crowd videos gathered from the Internet. The algorithm works by first learning a set of crowd behavior priors off-line. During testing, crowd patches are matched to the database and behavior priors are transferred. We adhere to the insight that despite the fact that the entire space of possible crowd behaviors is infinite, the space of distinguishable crowd motion patterns may not be all that large. For many individuals in a crowd, we are able to find analogous crowd patches in our database which contain similar patterns of behavior that can effectively act as priors to constrain the difficult task of tracking an individual in a crowd. Our algorithm is data-driven and, unlike some crowd characterization methods, does not require us to have seen the test video beforehand. It performs like state-of-the-art methods for tracking people having common crowd behaviors and outperforms the methods when the tracked individual behaves in an unusual way.", "PublicationYear": "2011", "Authors": ["Mikel D. Rodriguez", "Josef Sivic", "Ivan Laptev", "Jean-Yves Audibert"], "RelatedTopics": ["Computer Science"], "References": ["db2e05ccd1d6d106ee8816bf65c655f250f7206c", "1e5e70f77a9957bc6fdfa9748dc4739657933dc4", "ed01c2706c1dd05de8664bee1e42a628a49480ad", "cae331ed80dfaa78fabd0014ad0e88f94151cdb5", "9e147ee02392169f5716d0774f02b7df27f8ce1c", "c4c5b3995f14fcb85affde0164addbbd4d962914", "07d61392606dade00c08704e78f1c19b66d75261", "7c6bb7a6d68c4c5fe6c33e9e2b5852ea7fcb17d9", "6d0db7dc45147d5d5680a0918fc1a1e23b0124d2", "17d65b2f276bc3b92f4a92567becc4fe41ffcb69"], "ReferenceCount": 33, "CitationCount": 228}, {"URL": "https://www.semanticscholar.org/paper/Anomaly-detection-in-crowded-scenes-Mahadevan-Li/9d3f0d47449c7db37d1bae3b70db2928610a8db7", "ID": "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "Title": "Anomaly detection in crowded scenes", "Abstract": "A novel framework for anomaly detection in crowded scenes is presented and the proposed representation is shown to outperform various state of the art anomaly detection techniques. A novel framework for anomaly detection in crowded scenes is presented. Three properties are identified as important for the design of a localized video representation suitable for anomaly detection in such scenes: 1) joint modeling of appearance and dynamics of the scene, and the abilities to detect 2) temporal, and 3) spatial abnormalities. The model for normal crowd behavior is based on mixtures of dynamic textures and outliers under this model are labeled as anomalies. Temporal anomalies are equated to events of low-probability, while spatial anomalies are handled using discriminant saliency. An experimental evaluation is conducted with a new dataset of crowded scenes, composed of 100 video sequences and five well defined abnormality categories. The proposed representation is shown to outperform various state of the art anomaly detection techniques.", "PublicationYear": "2010", "Authors": ["Vijay Mahadevan", "Wei-Xin Li", "Viral Bhalodia", "Nuno Vasconcelos"], "RelatedTopics": ["Computer Science"], "References": ["2e269d2ee60db6d09a514c4748e3fdf9202917f9", "08f99af9f5d6d351201ee4563e407bf37bc164fd", "bec61be907d309d1797daab46236b66d41380c54", "c3113eaad326a955ba96c11b7b65d0c065fb2054", "38d4b5a464652a4afb4f043f141976f5c71c1e6b", "eac7287d7ef69252358c1fbddedf123e11012370", "8a916608e81eea5d7494e577c8563cae44a1b8c6", "731a2844c5af6b072d3b404ecabbb488cdad9d46", "86078efdd0d1bbfaf4b7f821e973f607429751fc", "c4c5b3995f14fcb85affde0164addbbd4d962914"], "ReferenceCount": 22, "CitationCount": 1348}, {"URL": "https://www.semanticscholar.org/paper/Crowd-motion-monitoring-using-tracklet-based-Mousavi-Nabi/fd52349a019d928cd9b09c2f6a8a689f174bbbf2", "ID": "fd52349a019d928cd9b09c2f6a8a689f174bbbf2", "Title": "Crowd motion monitoring using tracklet-based commotion measure", "Abstract": "A novel measure to capture the commotion of a crowd motion for the task of abnormality detection in crowd allows to detect abnormality adaptively (i.e. context dependent) with no training cost. Abnormal detection in crowd is a challenging vision task due to the scarcity of real-world training examples and the lack of a clear definition of abnormality. To tackle these challenges, we propose a novel measure to capture the commotion of a crowd motion for the task of abnormality detection in crowd. The unsupervised nature of the proposed measure allows to detect abnormality adaptively (i.e. context dependent) with no training cost. The extensive experiments on three different levels (e.g. pixel, frame and video) show the superiority of the proposed approach compared to the state of the arts.", "PublicationYear": "2015", "Authors": ["Hossein Mousavi", "Moin Nabi", "Hamed Kiani Galoogahi", "Alessandro Perina", "Vittorio Murino"], "RelatedTopics": ["Computer Science"], "References": ["c7ae0a6974e2bf7c304e7c24331e109ebe5c65c8", "655b1f83ef218ee6a030b5541d2865bc6599e6d9", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "84af83ff6412a756df58b6436f0d2e3c049e1f12", "91d6f04df29112811121e4d5416776ac974709df", "ddb3de7a51958a00bb4d8fabd029317c60cd5927", "9c9aa8a9c83a6f2aeea58b49850fa01e513972a7", "5194cbd51f9769ab25260446b4fa17204752e799", "5d7e40ca3dcafea355f75f8b65df78ff5b654ba3", "c266fc51bf6d769057de606a980988c50fc8b99e"], "ReferenceCount": 21, "CitationCount": 40}, {"URL": "https://www.semanticscholar.org/paper/Analyzing-Tracklets-for-the-Detection-of-Abnormal-Mousavi-Mohammadi/655b1f83ef218ee6a030b5541d2865bc6599e6d9", "ID": "655b1f83ef218ee6a030b5541d2865bc6599e6d9", "Title": "Analyzing Tracklets for the Detection of Abnormal Crowd Behavior", "Abstract": "A novel video descriptor, referred to as Histogram of Oriented Tracklets, for recognizing abnormal situation in crowded scenes is presented, which quantized orientation and magnitude in a 2-dimensional histogram which encodes the motion patterns expected in each cuboid. This paper presents a novel video descriptor, referred to as Histogram of Oriented Tracklets, for recognizing abnormal situation in crowded scenes. Unlike standard approaches that use optical flow, which estimates motion vectors only from two successive frames, we built our descriptor over long-range motion trajectories which is called tracklets in the literature. Following the standard procedure, we divided video sequences in spatio-temporal cuboids within which we collected statistics on the tracklets passing through them. In particular, we quantized orientation and magnitude in a 2-dimensional histogram which encodes the motion patterns expected in each cuboid. We classify frames as normal and abnormal by using Latent Dirichlet Allocation and Support Vector Machines. We evaluated the effectiveness of the proposed descriptors on three datasets: UCSD, Violence in Crowds and UMN. The experiments demonstrated (i) very promising results in abnormality detection, (ii) setting new state-of-the-art on two of them, and (iii) outperforming former descriptors based on the optical flow, dense trajectories and the social force model.", "PublicationYear": "2015", "Authors": ["Hossein Mousavi", "Sadegh Mohammadi", "Alessandro Perina", "Ryad Chellali", "Vittorio Murino"], "RelatedTopics": ["Computer Science"], "References": ["aba7b76c300db4159592ee2933d8796176d1e737", "5194cbd51f9769ab25260446b4fa17204752e799", "c3113eaad326a955ba96c11b7b65d0c065fb2054", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "aae932cf9c2434f52b03991fcab050a61a960d48", "c266fc51bf6d769057de606a980988c50fc8b99e", "ce9edb785f28c81bd7c2864940ed001429178e1e", "eeaba0abdc26a89d8b9e3750db344c45d3460e7c", "731a2844c5af6b072d3b404ecabbb488cdad9d46", "5f6065ef5104f20f473dfc1a8504f3b6868eb584"], "ReferenceCount": 27, "CitationCount": 116}, {"URL": "https://www.semanticscholar.org/paper/Abnormal-crowd-behavior-detection-using-social-Mehran-Oyama/c3113eaad326a955ba96c11b7b65d0c065fb2054", "ID": "c3113eaad326a955ba96c11b7b65d0c065fb2054", "Title": "Abnormal crowd behavior detection using social force model", "Abstract": "A novel method to detect and localize abnormal behaviors in crowd videos using Social Force model and it is shown that the social force approach outperforms similar approaches based on pure optical flow. In this paper we introduce a novel method to detect and localize abnormal behaviors in crowd videos using Social Force model. For this purpose, a grid of particles is placed over the image and it is advected with the space-time average of optical flow. By treating the moving particles as individuals, their interaction forces are estimated using social force model. The interaction force is then mapped into the image plane to obtain Force Flow for every pixel in every frame. Randomly selected spatio-temporal volumes of Force Flow are used to model the normal behavior of the crowd. We classify frames as normal and abnormal by using a bag of words approach. The regions of anomalies in the abnormal frames are localized using interaction forces. The experiments are conducted on a publicly available dataset from University of Minnesota for escape panic scenarios and a challenging dataset of crowd videos taken from the web. The experiments show that the proposed method captures the dynamics of the crowd behavior successfully. In addition, we have shown that the social force approach outperforms similar approaches based on pure optical flow.", "PublicationYear": "2009", "Authors": ["Ramin Mehran", "Alexis Oyama", "Mubarak Shah"], "RelatedTopics": ["Computer Science"], "References": ["54cf4e85cea0f6f1ec8b3fa318cb2c488a5a7f79", "279196c4d96053a6083ceae2bb3600059564f9a1", "db2e05ccd1d6d106ee8816bf65c655f250f7206c", "c4c5b3995f14fcb85affde0164addbbd4d962914", "f6461ce6d9c12248227845da006e98c0bd4b33b0", "cf898df551678088b304e0beb32725556f043fcf", "50c794f5c24b4f423bfadd52629e8d94ce672625", "f129124da1d10b1a4b33e2dc7e01d6a4349886e7", "b03420aa079b8d4c5332f369b21dc997723e23db", "3921f459a9ee26827963abc4abf013b4cc9cbd32"], "ReferenceCount": 31, "CitationCount": 1660}, {"URL": "https://www.semanticscholar.org/paper/Detecting-Abnormal-Behavioral-Patterns-in-Crowd-Mousavi-Galoogahi/27839232387db332bdc9024d014a6d1bc47c35eb", "ID": "27839232387db332bdc9024d014a6d1bc47c35eb", "Title": "Detecting Abnormal Behavioral Patterns in Crowd Scenarios", "Abstract": "This Chapter presents a framework for the the task of abnormality detection in crowded scenes based on the analysis of trajectories, build up upon a novel video descriptor, called Histogram of Oriented Tracklets, based on mid-level features extracted from long-range motion trajectories called tracklets. This Chapter presents a framework for the the task of abnormality detection in crowded scenes based on the analysis of trajectories, build up upon a novel video descriptor, called Histogram of Oriented Tracklets. Unlike standard approaches that employ low level motion features, e.g. optical flow, to form video descriptors, we propose to exploit mid-level features extracted from long-range motion trajectories called tracklets, which have been successfully applied for action modeling and video analysis. Following standard procedure, a video sequence is divided into spatio-temporal cuboids within which we collect statistics of the tracklets passing through them. Specifically, tracklets orientation and magnitude are quantized in a two-dimensional histogram which encodes the actual motion patterns in each cuboid. These histograms are then fed into machine learning models (e.g., Latent Dirichlet allocation and Support Vector Machines) to detect abnormal behaviors in video sequences. The evaluation of the proposed descriptor on different datasets, namely UCSD, BEHAVE, UMN and Violence in Crowds, yields compelling results in abnormality detection, by setting new state-of-the-art and outperforming former descriptors based on the optical flow, dense trajectories and social force models.", "PublicationYear": "2016", "Authors": ["Hossein Mousavi", "Hamed Kiani Galoogahi", "Alessandro Perina", "Vittorio Murino"], "RelatedTopics": ["Computer Science"], "References": ["655b1f83ef218ee6a030b5541d2865bc6599e6d9", "c3113eaad326a955ba96c11b7b65d0c065fb2054", "8984c1adee4e862f64732c3306a7ebda3745d756", "5194cbd51f9769ab25260446b4fa17204752e799", "84af83ff6412a756df58b6436f0d2e3c049e1f12", "ce9edb785f28c81bd7c2864940ed001429178e1e", "dadd2e6846c620f2664d7cb80ece113912730052", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "a605a375d0803794adee9eac225011d294dfbada", "aba7b76c300db4159592ee2933d8796176d1e737"], "ReferenceCount": 52, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Violent-flows%3A-Real-time-detection-of-violent-crowd-Hassner-Itcher/5194cbd51f9769ab25260446b4fa17204752e799", "ID": "5194cbd51f9769ab25260446b4fa17204752e799", "Title": "Violent flows: Real-time detection of violent crowd behavior", "Abstract": "A novel approach to real-time detection of breaking violence in crowded scenes by considers statistics of how flow-vector magnitudes change over time, using the VIolent Flows descriptor. Although surveillance video cameras are now widely used, their effectiveness is questionable. Here, we focus on the challenging task of monitoring crowded events for outbreaks of violence. Such scenes require a human surveyor to monitor multiple video screens, presenting crowds of people in a constantly changing sea of activity, and to identify signs of breaking violence early enough to alert help. With this in mind, we propose the following contributions: (1) We describe a novel approach to real-time detection of breaking violence in crowded scenes. Our method considers statistics of how flow-vector magnitudes change over time. These statistics, collected for short frame sequences, are represented using the VIolent Flows (ViF) descriptor. ViF descriptors are then classified as either violent or non-violent using linear SVM. (2) We present a unique data set of real-world surveillance videos, along with standard benchmarks designed to test both violent/non-violent classification, as well as real-time detection accuracy. Finally, (3) we provide empirical tests, comparing our method to state-of-the-art techniques, and demonstrating its effectiveness.", "PublicationYear": "2012", "Authors": ["Tal Hassner", "Yossi Itcher", "Orit Kliper-Gross"], "RelatedTopics": ["Computer Science"], "References": ["53964e0ccc0412e2fbb2cdf3483e1f383208febe", "25d7a9cc63fe4a6578fadd369277d45c46dfb781", "cac8e12c0b45dcb27e207c70bc83a0f92d5d2017", "02a98118ce990942432c0147ff3c0de756b4b76a", "2110c7f72e7153f73199dd217f87bc6d79d87fb2", "aca29d7bbbf54078f842c8ca1d75d8d8c68191d2", "84723996c3536088b0d3b4a99a9bdbfea6767b27", "1e5e70f77a9957bc6fdfa9748dc4739657933dc4", "86078efdd0d1bbfaf4b7f821e973f607429751fc", "e332ae93ff5348a3e95a7b41a80c5ed80f18ccd3"], "ReferenceCount": 34, "CitationCount": 415}, {"URL": "https://www.semanticscholar.org/paper/Learning-realistic-human-actions-from-movies-Laptev-Marszalek/02a98118ce990942432c0147ff3c0de756b4b76a", "ID": "02a98118ce990942432c0147ff3c0de756b4b76a", "Title": "Learning realistic human actions from movies", "Abstract": "A new method for video classification that builds upon and extends several recent ideas including local space-time features,space-time pyramids and multi-channel non-linear SVMs is presented and shown to improve state-of-the-art results on the standard KTH action dataset. The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. Our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. We evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. Using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. We present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear SVMs. The method is shown to improve state-of-the-art results on the standard KTH action dataset by achieving 91.8% accuracy. Given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. We finally apply the method to learning and classifying challenging action classes in movies and show promising results.", "PublicationYear": "2008", "Authors": ["Ivan Laptev", "Marcin Marszalek", "Cordelia Schmid", "Benjamin Rozenfeld"], "RelatedTopics": ["Computer Science"], "References": ["c6cd1a1c1e6bde8e06120c431d4e816e4d67f249", "0eefe92e151cca891de7dcc1ad9b70b8ef42b086", "b480f6a3750b4cebaf1db205692c8321d45926a2", "ab1632b7277eea8d65b8d5b2e0ac07bfd63dff87", "2b7e019719972384ed99501cf50b8eac5e51a925", "d4ed0b69a2e9a3d75ac13c4ff43044fea9b5df6e", "c8d905b121e3e1f27d1f72195e27b7c8ac1a4386", "124d967683544973581f951ee93b3f7c069e3ced", "10c8691e23dffadab19c39fb9245496efbf75b2a", "804db97075c4e371177e5bfffe8012de237ae44d"], "ReferenceCount": 32, "CitationCount": 3773}, {"URL": "https://www.semanticscholar.org/paper/Crowd-Analysis-and-Its-Applications-Sjarif-Shamsuddin/e65ec773059770c45da16bb9ce638d24870b1adf", "ID": "e65ec773059770c45da16bb9ce638d24870b1adf", "Title": "Crowd Analysis and Its Applications", "Abstract": "This study presents the state of art of crowd analysis, taxonomy of the common approach of the crowd analysis and it can be useful to researchers and would serve as a good introduction related to the field undertaken. Crowd is a unique group of individual or something involves community or society. The phenomena of the crowd are very familiar in a variety of research discipline such as sociology, civil and physic. Nowadays, it becomes the most active-oriented research and trendy topic in computer vision. Traditionally, three processing steps involve in crowd analysis, and these include pre-processing, object detection and event/behavior recognition. Meanwhile, the common process for analysis in video sequence of crowd information extraction consists of Pre-Processing, Object Tracking, and Event/Behavior Recognition. In terms of behavior detection, the crowd density estimation, crowd motion detection, crowd tracking and crowd behavior recognition are adopted. In this paper, we give the general framework and taxonomy of pattern in detecting abnormal behavior in a crowd scene. This study presents the state of art of crowd analysis, taxonomy of the common approach of the crowd analysis and it can be useful to researchers and would serve as a good introduction related to the field undertaken.", "PublicationYear": "2011", "Authors": ["Nilam Nur Amir Sjarif", "Siti Mariyam Hj. Shamsuddin", "Siti Zaiton Mohd Hashim", "Siti Sophiayati Yuhaniz"], "RelatedTopics": ["Computer Science"], "References": ["7acf5502f9fe06bb455d00820f5dc0f3b097b791", "e298919adf82aed62b2375c96005397797f966e8", "daa84f3160e0a71d9820f9961382ffbc5b811dbd", "92f07e826f44ed5b4d0fa243c9b7f30a158a841a", "52f63f6d444c1d192e02a7b407aad1ebe908c388", "c115ac8cba0d479f57e317da06c5a694b935a804", "54cf4e85cea0f6f1ec8b3fa318cb2c488a5a7f79", "0c3bcf947000ed82d3da6d8a7d5c29baf26e629f", "c3113eaad326a955ba96c11b7b65d0c065fb2054", "1e5e70f77a9957bc6fdfa9748dc4739657933dc4"], "ReferenceCount": 26, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Abnormality-Detection-with-Improved-Histogram-of-Mousavi-Nabi/84af83ff6412a756df58b6436f0d2e3c049e1f12", "ID": "84af83ff6412a756df58b6436f0d2e3c049e1f12", "Title": "Abnormality Detection with Improved Histogram of Oriented Tracklets", "Abstract": "This paper proposes to initialize salient points in each frame instead of the first frame, as the HOT does, and replaces the naive count-based histogramming by the richer statistics of crowd movement (i.e., motion distribution), which yields compelling results in abnormality detection. Recently the histogram of oriented tracklets (HOT) was shown to be an efficient video representation for abnormality detection and achieved state-of-the-arts on the available datasets. Unlike standard video descriptors that mainly employ low level motion features, e.g. optical flow, the HOT descriptor simultaneously encodes magnitude and orientation of tracklets as a mid-level representation over crowd motions. However, extracting tracklets in HOT suffers from poor salient point initialization and tracking drift in the presence of occlusion. Moreover, count-based HOT histogramming does not properly take into account the motion characteristics of abnormal motions. This paper extends the HOT by addressing these drawbacks introducing an enhanced version of HOT, named Improved HOT. First, we propose to initialize salient points in each frame instead of the first frame, as the HOT does. Second, we replace the naive count-based histogramming by the richer statistics of crowd movement (i.e., motion distribution). The evaluation of the Improved HOT on different datasets, namely UCSD, BEHAVE and UMN, yields compelling results in abnormality detection, by outperforming the original HOT and the state-of-the-art descriptors based on optical flow, dense trajectories and the social force models.", "PublicationYear": "2015", "Authors": ["Hossein Mousavi", "Moin Nabi", "Hamed Kiani Galoogahi", "Alessandro Perina", "Vittorio Murino"], "RelatedTopics": ["Computer Science"], "References": ["655b1f83ef218ee6a030b5541d2865bc6599e6d9", "a605a375d0803794adee9eac225011d294dfbada", "fd52349a019d928cd9b09c2f6a8a689f174bbbf2", "aae932cf9c2434f52b03991fcab050a61a960d48", "731a2844c5af6b072d3b404ecabbb488cdad9d46", "5194cbd51f9769ab25260446b4fa17204752e799", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "c9cd94cf620d6b20c5deca1ce0b88aefd256cf55", "86078efdd0d1bbfaf4b7f821e973f607429751fc", "ae37774ff871575b7799411bf87f42eb52634390"], "ReferenceCount": 29, "CitationCount": 43}, {"URL": "https://www.semanticscholar.org/paper/Privacy-Preserving-Deep-Inference-for-Rich-User-on-Ossia-Shamsabadi/6cefb70f4668ee6c0bf0c18ea36fd49dd60e8365", "ID": "6cefb70f4668ee6c0bf0c18ea36fd49dd60e8365", "Title": "Privacy-Preserving Deep Inference for Rich User Data on The Cloud", "Abstract": "This paper presents a hybrid approach for breaking down large, complex deep models for cooperative, privacy-preserving analytics by breaking down the popular deep architectures and fine-tune them in a particular way, and evaluates the privacy benefits of this approach based on the information exposed to the cloud service. Deep neural networks are increasingly being used in a variety of machine learning applications applied to rich user data on the cloud. However, this approach introduces a number of privacy and efficiency challenges, as the cloud operator can perform secondary inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger, and more complicated models. In this paper, we present a hybrid approach for breaking down large, complex deep models for cooperative, privacy-preserving analytics. We do this by breaking down the popular deep architectures and fine-tune them in a particular way. We then evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also asses the local inference cost of different layers on a modern handset for mobile applications. Our evaluations show that by using certain kind of fine-tuning and embedding techniques and at a small processing costs, we can greatly reduce the level of information available to unintended tasks applied to the data feature on the cloud, and hence achieving the desired tradeoff between privacy and performance.", "PublicationYear": "2017", "Authors": ["Seyed Ali Ossia", "Ali Shahin Shamsabadi", "Ali Taheri", "Kleomenis Katevas", "Hamid R. Rabiee", "Nicholas D. Lane", "Hamed Haddadi"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["125f7b539e89cd0940ff89c231902b1d4023b3ba", "081651b38ff7533550a3adfc1c00da333a8fe86c", "14d9be7962a4ec5a6e55755f4c7588ea00793652", "4ca3b996d888d7178dbbf9855bb2ab253bdfa43d", "cfaae9b6857b834043606df3342d8dc97524aa9d", "3625202d710db29ee117f7502d86901f50f92e1c", "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "187a78ebfe654e9c1d3e8d070c8845a49c1d1a42", "123d00c6a664ea6d4da57d0d89d980dd02347c79", "e9a986c8ff6c2f381d026fe014f6aaa865f34da7"], "ReferenceCount": 58, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Comments-on-%E2%80%9CDropping-Activation-Outputs-with-Deep-Tan-Li/bc3f84ae122815aba616a310ae22abf216864b85", "ID": "bc3f84ae122815aba616a310ae22abf216864b85", "Title": "Comments on \u201cDropping Activation Outputs with Localized First-Layer Deep Network for Enhancing User Privacy and Data Security\u201d", "Abstract": "It is proved that the DAO first layer, in fact, can generally be inverted, and hence fails to preserve privacy, and also provides a countermeasure against the privacy vulnerabilities that are examined. Inference based on deep learning models is usually implemented by exposing sensitive user data to the outside models, which of course gives rise to acute privacy concerns. To deal with these concerns, Dong et al. recently proposed an approach, namely the dropping-activation-outputs (DAO) first layer. This approach was claimed to be a non-invertible transformation, such that the privacy of user data could not be compromised. However, In this paper, we prove that the DAO first layer, in fact, can generally be inverted, and hence fails to preserve privacy. We also provide a countermeasure against the privacy vulnerabilities that we examined.", "PublicationYear": "2018", "Authors": ["Xinrui Tan", "Hongjia Li", "Liming Wang", "Zhen Xu"], "RelatedTopics": ["Computer Science"], "References": ["53969301953b5e3d908a057f95d29eef2f11970f", "586533aa9687a99cb011f9113467c761715ea1de", "6c9a5f7eb3590290545e383baf743e5aa742de0c", "6257bd89b3d4cc6c3e071692e5e3f58e13fac14f", "fc2057499fcc5dfe61316f1722db7837971a9c94", "9d0959c438e2947cf4604d9e23ef0f03269047dd", "b7b915d508987b73b61eccd2b237e7ed099a2d29", "9e6060316394393c226b5c86ce51b06c4c75bee1", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "38f35dd624cd1cf827416e31ac5e0e0454028eca"], "ReferenceCount": 27, "CitationCount": 6}, {"URL": "https://www.semanticscholar.org/paper/Deep-Models-Under-the-GAN%3A-Information-Leakage-from-Hitaj-Ateniese/44a97f4eaaefaf5338f8aed2913d5debb2459f7e", "ID": "44a97f4eaaefaf5338f8aed2913d5debb2459f7e", "Title": "Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning", "Abstract": "It is shown that a distributed, federated, or decentralized deep learning approach is fundamentally broken and does not protect the training sets of honest participants. Deep Learning has recently become hugely popular in machine learning for its ability to solve end-to-end learning systems, in which the features and the classifiers are learned simultaneously, providing significant improvements in classification accuracy in the presence of highly-structured and large databases. Its success is due to a combination of recent algorithmic breakthroughs, increasingly powerful computers, and access to significant amounts of data. Researchers have also considered privacy implications of deep learning. Models are typically trained in a centralized manner with all the data being processed by the same training algorithm. If the data is a collection of users' private data, including habits, personal pictures, geographical positions, interests, and more, the centralized server will have access to sensitive information that could potentially be mishandled. To tackle this problem, collaborative deep learning models have recently been proposed where parties locally train their deep learning structures and only share a subset of the parameters in the attempt to keep their respective training sets private. Parameters can also be obfuscated via differential privacy (DP) to make information extraction even more challenging, as proposed by Shokri and Shmatikov at CCS'15. Unfortunately, we show that any privacy-preserving collaborative deep learning is susceptible to a powerful attack that we devise in this paper. In particular, we show that a distributed, federated, or decentralized deep learning approach is fundamentally broken and does not protect the training sets of honest participants. The attack we developed exploits the real-time nature of the learning process that allows the adversary to train a Generative Adversarial Network (GAN) that generates prototypical samples of the targeted training set that was meant to be private (the samples generated by the GAN are intended to come from the same distribution as the training data). Interestingly, we show that record-level differential privacy applied to the shared parameters of the model, as suggested in previous work, is ineffective (i.e., record-level DP is not designed to address our attack).", "PublicationYear": "2017", "Authors": ["Briland Hitaj", "Giuseppe Ateniese", "Fernando P{\\'e}rez-Cruz"], "RelatedTopics": ["Computer Science"], "References": ["f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "8b419080cd37bdc30872b76f405ef6a93eae3304", "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "6065090377b440bbf5dc02ede58aeaa7d7811f5c", "819167ace2f0caae7745d2f25a803979be5fbfae", "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e", "a4cec122a08216fe8a3bc19b22e78fbaea096256", "9b618fa0cd834f7c4122c8e53539085e06922f8c", "3127190433230b3dc1abd0680bb58dced4bcd90e"], "ReferenceCount": 103, "CitationCount": 1065}, {"URL": "https://www.semanticscholar.org/paper/DEEProtect%3A-Enabling-Inference-based-Access-Control-Liu-Chakraborty/e6050e19c82ac215194cc311016094b71f57b17d", "ID": "e6050e19c82ac215194cc311016094b71f57b17d", "Title": "DEEProtect: Enabling Inference-based Access Control on Mobile Sensing Applications", "Abstract": "DDEProtect is presented, a framework that enables a novel form of inference control, in which mobile apps with access to sensor data are limited (provably) in their ability to make inferences about user's sensitive data and behavior, and provides provable privacy guarantees with up to 8x improvement in utility. Personal sensory data is used by context-aware mobile applications to provide utility. However, the same data can also be used by an adversary to make sensitive inferences about a user thereby violating her privacy. \\nWe present DEEProtect, a framework that enables a novel form of inference control, in which mobile apps with access to sensor data are limited (provably) in their ability to make inferences about user's sensitive data and behavior. DEEProtect adopts a two-layered privacy strategy. First, it leverages novel autoencoder techniques to perform data minimization and limits the amount of information being shared; the learning network is used to derive a compact representation of sensor data consisting only of features relevant to authorized utility-providing inferences. Second, DEEProtect obfuscates the previously learnt features, thereby providing an additional layer of protection against sensitive inferences. Our framework supports both conventional as well as a novel relaxed notion of local differential privacy that enhances utility. Through theoretical analysis and extensive experiments using real-world datasets, we demonstrate that when compared to existing approaches DEEProtect provides provable privacy guarantees with up to 8x improvement in utility. Finally, DEEProtect shares obfuscated but raw sensor data reconstructed from the perturbed features, thus requiring no changes to the existing app interfaces.", "PublicationYear": "2017", "Authors": ["Changchang Liu", "Supriyo Chakraborty", "Prateek Mittal"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["dc289b7889bd48962e5ab8e07981491056755ad7", "017d615afa48eea38ae741d0071c4781dc0d1024", "6c20cd584e7258056840eb88437d69731000bb0f", "f594689291ddf723f58cb42942e0af9284eea9eb", "19a452b3f915c298de8848b80f7b377979d2e49d", "e06e6a177d5df77cb3d9aeb66b379f2f3a93c05f", "d918908d20057705f5bf5fdb0d3219137c6c0cb0", "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "f8844f2065931290520c9044d0ee2c9ef6381079", "6eb259f2ff2dafd0ed10ccfd16a25b46e71d3575"], "ReferenceCount": 102, "CitationCount": 24}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-with-Differential-Privacy-Abadi-Chu/e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "ID": "e9a986c8ff6c2f381d026fe014f6aaa865f34da7", "Title": "Deep Learning with Differential Privacy", "Abstract": "This work develops new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy, and demonstrates that deep neural networks can be trained with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality. Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.", "PublicationYear": "2016", "Authors": ["Mart{\\'i}n Abadi", "Andy Chu", "Ian J. Goodfellow", "H. B. McMahan", "Ilya Mironov", "Kunal Talwar", "Li Zhang"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["fae3819ea63c7ae9eef2398fa938e84fe0c10317", "6065090377b440bbf5dc02ede58aeaa7d7811f5c", "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "8c23ea0ed7badd70a8e26dcea73f2d673cc0c74d", "2e99b1868621e47cb89ba8e0f72a5b9d87acb991", "b57c54350769ffa59ff57f79ee5aad918844d298", "a1f83d89a3a8ab74f8968f5b875a8d8f98bb9475", "54d22f1c5a776ca4324497593b3c193f0abb2179", "d1b9a3b11e6c9571a1553556f82b605b2b4baec3", "dade3d81749385e08ec0f163c806308c94b56f32"], "ReferenceCount": 63, "CitationCount": 4399}, {"URL": "https://www.semanticscholar.org/paper/Dropping-Activation-Outputs-With-Localized-Deep-for-Dong-Wu/53969301953b5e3d908a057f95d29eef2f11970f", "ID": "53969301953b5e3d908a057f95d29eef2f11970f", "Title": "Dropping Activation Outputs With Localized First-Layer Deep Network for Enhancing User Privacy and Data Security", "Abstract": "This paper proposed a new architecture for deep network in which users do not reveal their original data to the model, and achieves the desirable privacy protection requirement and demonstrated several advantages over the traditional approach with encryption/decryption. Deep learning methods can play a crucial role in anomaly detection, prediction, and supporting decision making for applications like personal health-care, pervasive body sensing, and so on. However, current architecture of deep networks suffers the privacy issue that users need to give out their data to the model (typically hosted in a server or a cluster on Cloud) for training or prediction. This problem is getting more severe for those sensitive health-care or medical data (e.g., fMRI or body sensors measures like EEG signals). In addition to this, there is also a security risk of leaking these data during the data transmission from user to the model (especially when it is through the Internet). Targeting at these issues, in this paper, we proposed a new architecture for deep network in which users do not reveal their original data to the model. In our method, feed-forward propagation and data encryption are combined into one process: we migrate the first layer of deep network to users\u2019 local devices and apply the activation functions locally, and then use the \u201cdropping activation output\u201d method to make the output non-invertible. The resulting approach is able to make model prediction without accessing users\u2019 sensitive raw data. The experiment conducted in this paper showed that our approach achieves the desirable privacy protection requirement and demonstrated several advantages over the traditional approach with encryption/decryption.", "PublicationYear": "2017", "Authors": ["Hao Dong", "Chao Wu", "Zhen Wei", "Yike Guo"], "RelatedTopics": ["Computer Science"], "References": ["586533aa9687a99cb011f9113467c761715ea1de", "6257bd89b3d4cc6c3e071692e5e3f58e13fac14f", "9d0959c438e2947cf4604d9e23ef0f03269047dd", "9e6060316394393c226b5c86ce51b06c4c75bee1", "3c623c08329e129e784a5d03f7606ec8feba3a28", "fc2057499fcc5dfe61316f1722db7837971a9c94", "34f25a8704614163c4095b3ee2fc969b60de4698", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6", "abd1c342495432171beb7ca8fd9551ef13cbd0ff"], "ReferenceCount": 29, "CitationCount": 27}, {"URL": "https://www.semanticscholar.org/paper/DeepSecure%3A-Scalable-Provably-Secure-Deep-Learning-Rouhani-Riazi/3625202d710db29ee117f7502d86901f50f92e1c", "ID": "3625202d710db29ee117f7502d86901f50f92e1c", "Title": "DeepSecure: Scalable Provably-Secure Deep Learning", "Abstract": "The DeepSecure framework is the first to empower accurate and scalable DL analysis of data generated by distributed clients without sacrificing the security to maintain efficiency and introduces a set of novel low-overhead pre-processing techniques which further reduce the GC overall runtime in the context of DL. This paper presents DeepSecure, the an scalable and provably secure Deep Learning (DL) framework that is built upon automated design, efficient logic synthesis, and optimization methodologies. DeepSecure targets scenarios in which neither of the involved parties including the cloud servers that hold the DL model parameters or the delegating clients who own the data is willing to reveal their information. Our framework is the first to empower accurate and scalable DL analysis of data generated by distributed clients without sacrificing the security to maintain efficiency. The secure DL computation in DeepSecure is performed using Yao's Garbled Circuit (GC) protocol. We devise GC-optimized realization of various components used in DL. Our optimized implementation achieves up to 58-fold higher throughput per sample compared with the best prior solution. In addition to the optimized GC realization, we introduce a set of novel low-overhead pre-processing techniques which further reduce the GC overall runtime in the context of DL. Our extensive evaluations demonstrate up to two orders-of-magnitude additional runtime improvement achieved as a result of our pre-processing methodology.", "PublicationYear": "2017", "Authors": ["Bita Darvish Rouhani", "M. Sadegh Riazi", "Farinaz Koushanfar"], "RelatedTopics": ["Computer Science"], "References": ["5a9aebb4c6836595bd8d38a06b19197e1ea02a69", "87d605ed72a452818633b397a54b4bd659b039e0", "18f5d7663632c92c84f89151823dff2120ae43cf", "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "d4a8ecf10852322d5a162ba1a58687e9f5c16a19", "e6cc1a7258e5009604c4b33f460a60ebfeefb028", "646913a2c744da069dd85ccbbed34588362f7537", "a632cb9f83bd161d548e4db2ec04aa3370d82c8d", "65ab89409b00a98769c865e7de12347e86e9ebf1", "8b60f152247a1df551ac7fd29251d23256dafb04"], "ReferenceCount": 49, "CitationCount": 330}, {"URL": "https://www.semanticscholar.org/paper/Sparse-coding-for-spectral-signatures-in-images-Charles-Olshausen/1141a9135c41f969a379c5372bee85126d0f3988", "ID": "1141a9135c41f969a379c5372bee85126d0f3988", "Title": "Sparse coding for spectral signatures in hyperspectral images", "Abstract": "This work applies a sparse approximation model to sample hyperspectral data and shows that unsupervised learning techniques learn a dictionary that contains a meaningful spectral decomposition for hyperspectrals imagery, and forms local approximations to the nonlinear manifold structure present in the actual data. The growing use of hyperspectral imagery lead us to seek automated algorithms for extracting useful information about the scene. Recent work in sparse approximation has shown that unsupervised learning techniques can use example data to determine an efficient dictionary with few a priori assumptions. We apply this model to sample hyperspectral data and show that these techniques learn a dictionary that: 1) contains a meaningful spectral decomposition for hyperspectral imagery, 2) admit representations that are useful in determining properties and classifying materials in the scene, and 3) forms local approximations to the nonlinear manifold structure present in the actual data.", "PublicationYear": "2010", "Authors": ["Adam S. Charles", "Bruno A. Olshausen", "Christopher J. Rozell"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["d7bd1659967cfe584e420b5e70109b5901072aa0", "21e654600e75f2663caf23733695a119582e54a1", "5d6d531585ca65a41367550b959bf792d8ae26fc", "dbd75566afe8034c8d1db0cad623f3730d1c5e97", "954c621a5be1193166e9c610e8323eff942da0a7", "539346f7f35f83875d9e86851010ee35d1a47e69", "8012c4a1e2ca663f1a04e80cbb19631a00cbab27", "9af121fbed84c3484ab86df8f17f1f198ed790a0", "7cd400437a5f99c6cf7fdbb5ff00e6c722dda00e", "5acfb2abca580a40f2f6890371c2387527dfefc0"], "ReferenceCount": 12, "CitationCount": 10}, {"URL": "https://www.semanticscholar.org/paper/Discriminative-sparse-representations-in-imagery-Castrodad-Xing/00582be58da554cc66c91d23924b24487912abf7", "ID": "00582be58da554cc66c91d23924b24487912abf7", "Title": "Discriminative sparse representations in hyperspectral imagery", "Abstract": "It is shown that highly accurate material classification from hyperspectral imagery (HSI) can be obtained with these models, even when the data is reconstructed from a very small percentage of the original image samples. Recent advances in sparse modeling and dictionary learning for discriminative applications show high potential for numerous classification tasks. In this paper, we show that highly accurate material classification from hyperspectral imagery (HSI) can be obtained with these models, even when the data is reconstructed from a very small percentage of the original image samples. The proposed supervised HSI classification is performed using a measure that accounts for both reconstruction errors and sparsity levels for sparse representations based on class-dependent learned dictionaries. Combining the dictionaries learned for the different materials, a linear mixing model is derived for sub-pixel classification. Results with real hyperspectral data cubes are shown both for urban and non-urban terrain.", "PublicationYear": "2010", "Authors": ["Alexey Castrodad", "Zhengming Xing", "John B. Greer", "Edward Bosch", "Lawrence Carin", "Guillermo Sapiro"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["9d65ba8bb20ae6dd001b9833c525c279dfe18916", "0a072cbdee54b83c8df43a431065f009d2cd2e70", "5d6d531585ca65a41367550b959bf792d8ae26fc", "2d7c320c01aae86dc3b0e267109423deb6422fbc", "b11f559432f453fb801befe5e43768a97855c8ca", "79ff2db16cb2c64883a581bf7f6641795263ae8c", "8c13717c7995af03eebf11f696cc5250375063d5", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "f6e0fb4c77906bc23fe59a8f848ce62ba9687181", "6bffeb5fe36c3ccdbf1dd680f4fc63262baf1a31"], "ReferenceCount": 18, "CitationCount": 25}, {"URL": "https://www.semanticscholar.org/paper/Exploiting-manifold-geometry-in-hyperspectral-Bachmann-Ainsworth/d7bd1659967cfe584e420b5e70109b5901072aa0", "ID": "d7bd1659967cfe584e420b5e70109b5901072aa0", "Title": "Exploiting manifold geometry in hyperspectral imagery", "Abstract": "A new algorithm for exploiting the nonlinear structure of hyperspectral imagery is developed and compared against the de facto standard of linear mixing, and it is demonstrated that the new manifold representation provides better separation of spectrally similar classes than one of the standard linear mixing models. A new algorithm for exploiting the nonlinear structure of hyperspectral imagery is developed and compared against the de facto standard of linear mixing. This new approach seeks a manifold coordinate system that preserves geodesic distances in the high-dimensional hyperspectral data space. Algorithms for deriving manifold coordinates, such as isometric mapping (ISOMAP), have been developed for other applications. ISOMAP guarantees a globally optimal solution, but is computationally practical only for small datasets because of computational and memory requirements. Here, we develop a hybrid technique to circumvent ISOMAP's computational cost. We divide the scene into a set of smaller tiles. The manifolds derived from the individual tiles are then aligned and stitched together to recomplete the scene. Several alignment methods are discussed. This hybrid approach exploits the fact that ISOMAP guarantees a globally optimal solution for each tile and the presumed similarity of the manifold structures derived from different tiles. Using land-cover classification of hyperspectral imagery in the Virginia Coast Reserve as a test case, we show that the new manifold representation provides better separation of spectrally similar classes than one of the standard linear mixing models. Additionally, we demonstrate that this technique provides a natural data compression scheme, which dramatically reduces the number of components needed to model hyperspectral data when compared with traditional methods such as the minimum noise fraction transform.", "PublicationYear": "2005", "Authors": ["Charles M. Bachmann", "Thomas L. Ainsworth", "Robert A. Fusina"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["8a40240815bb72fad80a19650a2510ad2f796bdb", "23d92dc4598dd7dfa78560f187fa75524584c038", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "a5a22bfc36ad97aa4a1642fb12cbc07b3c1830e9", "8c2c14045438fe739eca0f4a827bd2be0464ebde", "d000e714aba108ee6d4572d4e4013ad4364053ba", "0d67e02aa81c3fadb1f1cb77afcbf06c905ac033", "6e4dd8d34a79e7ab063c0f242d39555290474eb2", "919edb1b70631b042a1d03c22f5ebb7b1762515f", "38296d45c1007097f7d0ee83a488f7df77ee24d5"], "ReferenceCount": 43, "CitationCount": 439}, {"URL": "https://www.semanticscholar.org/paper/Sparse-demixing-Greer/21e654600e75f2663caf23733695a119582e54a1", "ID": "21e654600e75f2663caf23733695a119582e54a1", "Title": "Sparse demixing", "Abstract": "This work combines this sparse demixing algorithm with dictionary learning methods to automatically calculate endmembers for a provided set of spectra, and applies this method to an AVIRIS image of Cuprite, NV, for which it is applied to compare the authors' endmembers with spectral signatures from the USGS spectral library. The linear mixture model for hyperspectral images assumes that all the image spectra lie on a high-dimensional simplex with corners called endmembers. Given the set of endmembers, one typically calculates fractional abundances for each pixel using constrained least squares. This method likely reconstructs the spectra as combinations of most, if not all, the endmembers. We instead assume that pixels are combinations of only a few of the endmembers, yielding sparse abundance vectors. We introduce a new method, similar to Matching Pursuit (MP) from the signal processing literature, to calculate these sparse abundances. We combine this sparse demixing algorithm with dictionary learning methods to automatically calculate endmembers for a provided set of spectra. We apply our method to an AVIRIS image of Cuprite, NV, for which we compare our endmembers with spectral signatures from the USGS spectral library.", "PublicationYear": "2010", "Authors": ["John B. Greer"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["954c621a5be1193166e9c610e8323eff942da0a7", "5d6d531585ca65a41367550b959bf792d8ae26fc", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "f9d22746bca7353e242ec226eb781ce825da11e0", "5498056718088d6de432974c573ee8079847d5ce", "8a40240815bb72fad80a19650a2510ad2f796bdb", "f6e0fb4c77906bc23fe59a8f848ce62ba9687181", "2210a7157565422261b03cf2cdf4e91b583df5a0", "8012c4a1e2ca663f1a04e80cbb19631a00cbab27", "684732677d91a93b115f57e8d671ef7f5f13ee14"], "ReferenceCount": 14, "CitationCount": 16}, {"URL": "https://www.semanticscholar.org/paper/Spatial-spectral-endmember-extraction-by-operations-Plaza-Mart%C3%ADnez/273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "ID": "273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "Title": "Spatial/spectral endmember extraction by multidimensional morphological operations", "Abstract": "A new automated method that performs unsupervised pixel purity determination and endmember extraction from multidimensional datasets; this is achieved by using both spatial and spectral information in a combined manner. Spectral mixture analysis provides an efficient mechanism for the interpretation and classification of remotely sensed multidimensional imagery. It aims to identify a set of reference signatures (also known as endmembers) that can be used to model the reflectance spectrum at each pixel of the original image. Thus, the modeling is carried out as a linear combination of a finite number of ground components. Although spectral mixture models have proved to be appropriate for the purpose of large hyperspectral dataset subpixel analysis, few methods are available in the literature for the extraction of appropriate endmembers in spectral unmixing. Most approaches have been designed from a spectroscopic viewpoint and, thus, tend to neglect the existing spatial correlation between pixels. This paper presents a new automated method that performs unsupervised pixel purity determination and endmember extraction from multidimensional datasets; this is achieved by using both spatial and spectral information in a combined manner. The method is based on mathematical morphology, a classic image processing technique that can be applied to the spectral domain while being able to keep its spatial characteristics. The proposed methodology is evaluated through a specifically designed framework that uses both simulated and real hyperspectral data.", "PublicationYear": "2002", "Authors": ["Antonio J. Plaza", "Pablo Mart{\\'i}nez", "Rosa M. P{\\'e}rez", "Javier Plaza"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["bdace6d060f58cc5167f2a3130987d3e8f264c33", "4d3e9019eedec5e69864dcc2c814a0dff8cea826", "f06fe7d9c42a70a62bbd25794705298b521a9297", "595625865c3bfdad58e1f7eaf7c6c9884f62a98c", "954c621a5be1193166e9c610e8323eff942da0a7", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "e6334789ec6d43664f8f164a462461a4408243ba", "9745f1f3ec226d5d45f95ff06713b6e990f7d62c", "093acb100307827bccf99031f4c50d26a049f1f4", "d8c7b197b7a927e6adb7ad79921af1063ddd14cb"], "ReferenceCount": 50, "CitationCount": 558}, {"URL": "https://www.semanticscholar.org/paper/Constrained-Nonnegative-Matrix-Factorization-for-Jia-Qian/d9919fd10760699c7e482bc941298670d8d77837", "ID": "d9919fd10760699c7e482bc941298670d8d77837", "Title": "Constrained Nonnegative Matrix Factorization for Hyperspectral Unmixing", "Abstract": "Two inherent characteristics of hyperspectral data, piecewise smoothness of spectral data and sparseness of abundance fraction of every material, are introduced to nonnegative matrix factorization (NMF) and the gradient-based optimization algorithm is presented and the monotonic convergence of the algorithm is proved. Hyperspectral unmixing is a process to identify the constituent materials and estimate the corresponding fractions from the mixture. During the last few years, nonnegative matrix factorization (NMF), as a suitable candidate for the linear spectral mixture model, has been applied to unmix hyperspectral data. Unfortunately, the local minima caused by the nonconvexity of the objective function makes the solution nonunique, thus only the nonnegativity constraint is not sufficient enough to lead to a well-defined problem. Therefore, in this paper, two inherent characteristics of hyperspectral data, piecewise smoothness (both temporal and spatial) of spectral data and sparseness of abundance fraction of every material, are introduced to NMF. The adaptive potential function from discontinuity adaptive Markov random field model is used to describe the smoothness constraint while preserving discontinuities in spectral data. At the same time, two NMF algorithms, nonsmooth NMF and NMF with sparseness constraint, are used to quantify the degree of sparseness of material abundances. A gradient-based optimization algorithm is presented, and the monotonic convergence of the algorithm is proved. Three important facts are exploited in our method: First, both the spectra and abundances are nonnegative; second, the variation of the material spectra and abundance images is piecewise smooth in wavelength and spatial spaces, respectively; third, the abundance distribution of each material is almost sparse in the scene. Experiments using synthetic and real data demonstrate that the proposed algorithm provides an effective unsupervised technique for hyperspectral unmixing.", "PublicationYear": "2009", "Authors": ["Sen Jia", "Yun-tao Qian"], "RelatedTopics": ["Environmental Science"], "References": ["ec892e36c16feffdea169dbec97ecdc412778a02", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "804519f49feee4d2bfafdc0db6d0d10f7f3ebf0c", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "73fc67a0d7b8bfc3398853ad51a6b239b4637141", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "f1e34d38ca4a7b6867c1d0e0eb3a3893b5105447", "5b82d8b2c7dcb6d46f02a9de0a5b791b50889333"], "ReferenceCount": 43, "CitationCount": 368}, {"URL": "https://www.semanticscholar.org/paper/On-the-decomposition-of-Mars-hyperspectral-data-by-Moussaoui-Hauksd%C3%B3ttir/10ad2ec4ebcbecd4b2ddd3e88f9b125caf50a2fc", "ID": "10ad2ec4ebcbecd4b2ddd3e88f9b125caf50a2fc", "Title": "On the decomposition of Mars hyperspectral data by ICA and Bayesian positive source separation", "Abstract": "Semantic Scholar extracted view of \\\"On the decomposition of Mars hyperspectral data by ICA and Bayesian positive source separation\\\" by S. Moussaoui et al.", "PublicationYear": "2008", "Authors": ["Sa{\\\"i}d Moussaoui", "Hafrun Hauksd{\\'o}ttir", "Fr{\\'e}d{\\'e}ric Schmidt", "Christian Jutten", "Jocelyn Chanussot", "David Brie", "Sylvain Dout{\\'e}", "J{\\'o}n Atli Benediktsson"], "RelatedTopics": ["Environmental Science", "Physics"], "References": ["9ac8c92bc2713b861bae9c60dae8a097e0e12d3a", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "24c6cd2b5aaea15f07cf6ff01f1e562b3743b807", "8506e08dd4c5e70d84c6e5ccf56efb1609378dcf", "1446797a3ef1a0b5e1cd0228716fcb0bedbd2bfb", "96a1effa4be3f8caa88270d6d258de418993d2e7", "2e73081ed096c62c073b3faa1b3b80aab89998c5", "db2eaf591ef3aff9a06b7d8bb3778f277e02fb4e", "dc247a8ab0e7065af03fed960efa9841a1beb5e9", "eb748dc1113f56171d2d5249dc8efee7b45a4a5a"], "ReferenceCount": 52, "CitationCount": 157}, {"URL": "https://www.semanticscholar.org/paper/K-SVD-%3A-An-Algorithm-for-Designing-of-Overcomplete-Aharon-Elad/f6e0fb4c77906bc23fe59a8f848ce62ba9687181", "ID": "f6e0fb4c77906bc23fe59a8f848ce62ba9687181", "Title": "K-SVD : An Algorithm for Designing of Overcomplete Dictionaries for Sparse Representation", "Abstract": "A novel algorithm for adapting dictionaries in order to achieve sparse signal representations, K-SVD, an iterative method that alternates between sparse coding of the examples based on the current dictionary, and a process of updating the dictionary atoms to better fit the data. In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a pre-specified set of linear transforms, or by adapting the dictionary to a set of training signals. Both these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method \u2013 the K-SVD algorithm \u2013 generalizing the K-Means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary, and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results on both synthetic tests and in applications on real image data.", "PublicationYear": "2005", "Authors": ["Michal Aharon", "Michael Elad", "Alfred Marcel Bruckstein", "Y. Katz"], "RelatedTopics": ["Computer Science"], "References": ["83b522f4bfa5db7f7d34f839475af7d078107634", "306de9c553695822ae9e6de044b6856baf0cce7d", "5a09a81393b824bf7b2efe38e2049c3dc9941293", "17e7cca7e795d8ba1fa9d2c88bf2675c2d6ddfe8", "7236864d8c2f62defea559465462c43a4b4b6b47", "1d9ef403969035e022b1b61c7dc513ffe189f031", "42d906c733f273109c0ed716a5ef6e2a379beb26", "46ee0292a71fa86a9e2f9d691da5f0f1cf281f83", "4ed0700119ed281d210897117863fa290d383cd0", "6cf9b027aa09d042dd13fd9ae848d902240b3d34"], "ReferenceCount": 47, "CitationCount": 6773}, {"URL": "https://www.semanticscholar.org/paper/Alternating-direction-algorithms-for-constrained-to-Bioucas-Dias-Figueiredo/6ffc3965342faf3be2cd73e1ea15ca2569a7dd92", "ID": "6ffc3965342faf3be2cd73e1ea15ca2569a7dd92", "Title": "Alternating direction algorithms for constrained sparse regression: Application to hyperspectral unmixing", "Abstract": "Two new algorithms to efficiently solve convex optimization problems, based on the alternating direction method of multipliers, a method from the augmented Lagrangian family, are introduced and are shown to outperform off-the-shelf methods in terms of speed and accuracy. Convex optimization problems are common in hyperspectral unmixing. Examples are the constrained least squares (CLS) problem used to compute the fractional abundances in a linear mixture of known spectra, the constrained basis pursuit (CBP) to find sparse (i.e., with a small number of terms) linear mixtures of spectra, selected from large libraries, and the constrained basis pursuit denoising (CBPDN), which is a generalization of BP to admit modeling errors. In this paper, we introduce two new algorithms to efficiently solve these optimization problems, based on the alternating direction method of multipliers, a method from the augmented Lagrangian family. The algorithms are termed SUnSAL (sparse unmixing by variable splitting and augmented Lagrangian) and C-SUnSAL (constrained SUnSAL). C-SUnSAL solves the CBP and CBPDN problems, while SUnSAL solves CLS as well as a more general version thereof, called constrained sparse regression (CSR). C-SUnSAL and SUnSAL are shown to outperform off-the-shelf methods in terms of speed and accuracy.", "PublicationYear": "2010", "Authors": ["Jos{\\'e} M. Bioucas-Dias", "M{\\'a}rio A. T. Figueiredo"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["bbe98a57d7d86cce82b9fdfa8c18be55806be3ef", "c96d322ad45e5f412d20cf85b1d97b2c33267d53", "0337e7041779082330ac74cf74aebe79fddb38d2", "68fc329577638519eae5c0fbf5c76d12c4b061a9", "b830ba166a6c56706ae6299792f0894e4f36ca12", "cd88b3665a0533b72833929c1b8635622c693ea2", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "7141358d398741486b9714719044f8b24b6e15e8", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b", "23d92dc4598dd7dfa78560f187fa75524584c038"], "ReferenceCount": 25, "CitationCount": 568}, {"URL": "https://www.semanticscholar.org/paper/Spectral-and-Spatial-Complexity-Based-Hyperspectral-Jia-Qian/ec892e36c16feffdea169dbec97ecdc412778a02", "ID": "ec892e36c16feffdea169dbec97ecdc412778a02", "Title": "Spectral and Spatial Complexity-Based Hyperspectral Unmixing", "Abstract": "A complexity-based BSS algorithm is introduced, which studies the complexity of sources instead of the independence, and a strict theoretic interpretation is given, showing that the complexity- based BSS is very suitable for hyperspectral unmixing. Hyperspectral unmixing, which decomposes pixel spectra into a collection of constituent spectra, is a preprocessing step for hyperspectral applications like target detection and classification. It can be considered as a blind source separation (BSS) problem. Independent component analysis, which is a widely used method for performing BSS, models a mixed pixel as a linear mixture of its constituent spectra weighted by the correspondent abundance fractions (sources). The sources are assumed to be independent and stationary. However, in many instances, this assumption is not valid. In this paper, a complexity-based BSS algorithm is introduced, which studies the complexity of sources instead of the independence. We extend the 1-D temporal complexity, which is called complexity pursuit that was proposed by Stone, to the 2-D spatial complexity, which is named spatial complexity BSS (SCBSS), to describe the spatial autocorrelation of each abundance fraction. Further, the temporal complexity of spectrum is combined into SCBSS to account for the spectral smoothness, which is termed spectral and spatial complexity BSS. More importantly, a strict theoretic interpretation is given, showing that the complexity-based BSS is very suitable for hyperspectral unmixing. Experimental results on synthetic and real hyperspectral data demonstrate the advantages of the proposed two algorithms with respect to other methods.", "PublicationYear": "2007", "Authors": ["Sen Jia", "Yun-tao Qian"], "RelatedTopics": ["Engineering", "Environmental Science"], "References": ["d0a1744f8e1c5259a8cf8b2bb489ee511b3efea7", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "44cb48ed3c114a0072ac8061319c58dae85054ff", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "23d92dc4598dd7dfa78560f187fa75524584c038", "25f7a27a2c8bb01df6937952645844ccc4dff89e", "8d5a3a134e3340b1754d5608080d9b213c56dd8b", "094a5970dd5d4fac36fa00b81ced669cb208a74b", "265cc4dfcbb7d7de5d17f66f419440144b72ed68"], "ReferenceCount": 60, "CitationCount": 132}, {"URL": "https://www.semanticscholar.org/paper/Generalization-of-Subpixel-Analysis-for-Data-With-Chen-Jia/074354a7d114c43dfba60663a536cec947f8ff08", "ID": "074354a7d114c43dfba60663a536cec947f8ff08", "Title": "Generalization of Subpixel Analysis for Hyperspectral Data With Flexibility in Spectral Similarity Measures", "Abstract": "A unified subpixel mapping framework that models the unmixing process as a best match of the unknown pixel's spectrum to a weighted sum of the endmembers' spectra is proposed and sequential quadratic programming is introduced to solve the nonlinear optimization problem encountered in the implementation of this framework. Several spectral unmixing techniques have been developed for subpixel mapping using hyperspectral data in the past two decades, among which the fully constrained least squares method based on the linear spectral mixture model (LSMM) has been widely accepted. However, the shortage of this method is that the Euclidean spectral distance measure is used, and therefore, it is sensitive to the magnitude of the spectra. While other spectral matching criteria are available, such as spectral angle mapping (SAM) and spectral information divergence (SID), the current unmixing algorithm is unable to be extended to these measures. In this paper, we propose a unified subpixel mapping framework that models the unmixing process as a best match of the unknown pixel's spectrum to a weighted sum of the endmembers' spectra. We introduce sequential quadratic programming to solve the nonlinear optimization problem encountered in the implementation of this framework. The main feature of this proposed method is that it is not restricted to any particular similarity measures. Experiments were conducted with both simulated and Hyperion data. The tests demonstrated the proposed framework's advantage in accommodating various spectral similarity measures and provided performance comparisons of the Euclidean distance measure with other spectral matching criteria including SAM, spectral correlation measure, and SID.", "PublicationYear": "2009", "Authors": ["Jin Chen", "Xiuping Jia", "Wei Yang", "Bunkei Matsushita"], "RelatedTopics": ["Engineering", "Environmental Science"], "References": ["5f05187f894c0b7acf6fad415ccf8960d225528a", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "1ddbc9dc1a7095ec8a77c899fdcc9e63b57f719f", "184e378a7006900299a394c9699528f04196ba00", "eac326f0a2c9dc78fb4a0bda042cbddbfb8e1ebb", "dc39d8988ecebbb53c1e8e39dfd6e022e59475af", "b7db214102ac230ba0299f4b00108116b137f885", "4e46d913a5d4a0a1e484403bab7639d209adee43", "30ccafd67833412ab6d248992e16f7ed8fbaee62", "fa8f12b9356d3610a97db9c11c312d13773559a9"], "ReferenceCount": 22, "CitationCount": 61}, {"URL": "https://www.semanticscholar.org/paper/Improved-Manifold-Coordinate-Representations-of-Bachmann-Ainsworth/dbd75566afe8034c8d1db0cad623f3730d1c5e97", "ID": "dbd75566afe8034c8d1db0cad623f3730d1c5e97", "Title": "Improved Manifold Coordinate Representations of Large-Scale Hyperspectral Scenes", "Abstract": "This paper improves the scaling performance of isometric mapping (ISOMAP) and achieve full-scene global manifold coordinates while removing artifacts generated by the original methods. In recent publications, we have presented a data-driven approach to representing the nonlinear structure of hyperspectral imagery using manifold coordinates. The approach relies on graph methods to derive geodesic distances on the high-dimensional hyperspectral data manifold. From these distances, a set of intrinsic manifold coordinates that parameterizes the data manifold is derived. Scaling the solution relied on divide-conquer-and-merge strategies for the manifold coordinates because of the computational and memory scaling of the geodesic coordinate calculations. In this paper, we improve the scaling performance of isometric mapping (ISOMAP) and achieve full-scene global manifold coordinates while removing artifacts generated by the original methods. The CPU time of the enhanced ISOMAP approach scales as O(Nlog 2(N)), where N is the number of samples, while the memory requirement is bounded by O(Nlog(N)). Full hyperspectral scenes of O(10 6) samples or greater are obtained via a reconstruction algorithm, which allows insertion of large numbers of samples into a representative \\\"backbone\\\" manifold obtained for a smaller but representative set of O(105) samples. We provide a classification example using a coastal hyperspectral scene to illustrate the approach", "PublicationYear": "2006", "Authors": ["Charles M. Bachmann", "Thomas L. Ainsworth", "Robert A. Fusina"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["fcf2c9455c4c2057cdf7d11a023b86989f8a4b30", "d7bd1659967cfe584e420b5e70109b5901072aa0", "1f74b16e9c8c8dc26c5eedcade3cb9a6abdcd552", "a94fcf1a75918720f203544839ce30e93fd95a2f", "09bc4152d7d9a4b59ba6ec4188230884fda50261", "1f4e4c729011cf935702477b144ef495fdc27a30", "c1b4a2a8cc8f8daaf070b87de9e1986e8cd9a8ab", "8a40240815bb72fad80a19650a2510ad2f796bdb", "ed3c324be93f30797e0f71d5f5fb5417cdd790bc", "d6d25bbdac6e52a0a9e3c21992f7e9bbc9a0f012"], "ReferenceCount": 56, "CitationCount": 164}, {"URL": "https://www.semanticscholar.org/paper/Hyperspectral-unmixing-algorithm-via-dependent-Nascimento-Bioucas-Dias/0337e7041779082330ac74cf74aebe79fddb38d2", "ID": "0337e7041779082330ac74cf74aebe79fddb38d2", "Title": "Hyperspectral unmixing algorithm via dependent component analysis", "Abstract": "This method decomposes a hyperspectral images into a collection of reflectance (or radiance) spectra of the materials present in the scene and the corresponding abundance fractions at each pixel, thus enforcing the constraints on abundance fractions imposed by the acquisition process. This paper introduces a new method to blindly unmix hyperspectral data, termed dependent component analysis (DECA). This method decomposes a hyperspectral images into a collection of reflectance (or radiance) spectra of the materials present in the scene (end member signatures) and the corresponding abundance fractions at each pixel. DECA assumes that each pixel is a linear mixture of the end-members signatures weighted by the correspondent abundance fractions. These abundances are modeled as mixtures of Dirichlet densities, thus enforcing the constraints on abundance fractions imposed by the acquisition process, namely non-negativity and constant sum. The mixing matrix is inferred by a generalized expectation-maximization (GEM) type algorithm. This method overcomes the limitations of unmixing methods based on independent component analysis (ICA) and on geometrical based approaches. The effectiveness of the proposed method is illustrated using simulated data based on U.S.G.S. laboratory spectra and real hyperspectral data collected by the AVIRIS sensor over Cuprite, Nevada.", "PublicationYear": "2007", "Authors": ["Jos{\\'e} M. P. Nascimento", "Jos{\\'e} M. Bioucas-Dias"], "RelatedTopics": ["Engineering", "Environmental Science"], "References": ["1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "954c621a5be1193166e9c610e8323eff942da0a7", "45f2bd821d663e07d11bf8d4371a7fb4f0fa5e2c", "8eb1de1d4c09b4c60be7ee272564de003d0ade14", "efd13aa38e7b2ade54336f9afe10fbf79ab442a2", "b8e1d91a1c3a9b5c4920f5d00a3a01151ce4bbb3", "0a17e44059fcbbe8a7282be7bd07f32314d4b420", "2358f08255fc3eca3e79f83fb5edbbd2f45ffb05"], "ReferenceCount": 15, "CitationCount": 69}, {"URL": "https://www.semanticscholar.org/paper/Dictionary-learning-and-sparse-coding-for-Sprechmann-Sapiro/79ff2db16cb2c64883a581bf7f6641795263ae8c", "ID": "79ff2db16cb2c64883a581bf7f6641795263ae8c", "Title": "Dictionary learning and sparse coding for unsupervised clustering", "Abstract": "A clustering framework within the sparse modeling and dictionary learning setting is introduced, and a novel measurement for the quality of the sparse representation is used, inspired by the robustness of the \u21131 regularization term in sparse coding. A clustering framework within the sparse modeling and dictionary learning setting is introduced in this work. Instead of searching for the set of centroid that best fit the data, as in k-means type of approaches that model the data as distributions around discrete points, we optimize for a set of dictionaries, one for each cluster, for which the signals are best reconstructed in a sparse coding manner. Thereby, we are modeling the data as the of union of learned low dimensional subspaces, and data points associated to subspaces spanned by just a few atoms of the same learned dictionary are clustered together. Using learned dictionaries makes this method robust and well suited to handle large datasets. The proposed clustering algorithm uses a novel measurement for the quality of the sparse representation, inspired by the robustness of the \u21131 regularization term in sparse coding. We first illustrate this measurement with examples on standard image and speech datasets in the supervised classification setting, showing with a simple approach its discriminative power and obtaining results comparable to the state-of-the-art. We then conclude with experiments for fully unsupervised clustering on extended standard datasets and texture images, obtaining excellent performance.", "PublicationYear": "2010", "Authors": ["Pablo Sprechmann", "Guillermo Sapiro"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["cf80cc34528273d8fbe17783efe802a6509e1562", "63140301f88a0c5223f92afbf2acfec9e537f6be", "5facbc5bd594f4faa0524d871d49ba6a6e956e17", "9bf757c9e2b6e759382d059f618a6a1586e67574", "e64a9960734215e2b1866ea3cb723ffa5585ac14", "9d65ba8bb20ae6dd001b9833c525c279dfe18916", "0a072cbdee54b83c8df43a431065f009d2cd2e70", "f1f63a129866a80644ff9abc119e17e2ca5c4e4e", "74227090d23c958f601ad05369fad587e3b546f1", "b715cd5222110b50ca6cea267f4eb5a7d012cddc"], "ReferenceCount": 19, "CitationCount": 136}, {"URL": "https://www.semanticscholar.org/paper/Recent-Advances-in-Techniques-for-Hyperspectral-Plaza-Benediktsson/e616132691824d6eec92b0eb4560b286d732582b", "ID": "e616132691824d6eec92b0eb4560b286d732582b", "Title": "Recent Advances in Techniques for Hyperspectral Image Processing", "Abstract": "Semantic Scholar extracted view of \\\"Recent Advances in Techniques for Hyperspectral Image Processing\\\" by A. Plaza et al.", "PublicationYear": "2009", "Authors": ["Antonio J. Plaza", "J{\\'o}n Atli Benediktsson", "Joseph W. Boardman", "Jason Brazile", "Lorenzo Bruzzone", "Gustau Camps-Valls", "Jocelyn Chanussot", "Mathieu Fauvel", "Paolo Gamba", "Anthony J. Gualtieri", "Mattia Marconcini", "James C. Tilton", "Giovanna Trianni"], "RelatedTopics": ["Environmental Science", "Physics", "Materials Science", "Engineering"], "References": ["23d92dc4598dd7dfa78560f187fa75524584c038", "a99ff8f2b3a076ec3e8c7ebb8576b51c20d2cff8", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "c5389f0d9751ce9cd39160320ef17ae968a79edf", "b61fecab91089f9ab5e9bce0b3aa9093e3571167", "954c621a5be1193166e9c610e8323eff942da0a7", "906a83577692bcbebfe0bd48d6484c9da1d99830", "d36383bd7dab0fb0c8f3733416d9f26bf74fe74c"], "ReferenceCount": 76, "CitationCount": 1524}, {"URL": "https://www.semanticscholar.org/paper/Bathymetric-retrieval-from-manifold-coordinate-of-Bachmann-Ainsworth/46f447a8dbb68ea4d2793a8c5d9abfd3c622c144", "ID": "46f447a8dbb68ea4d2793a8c5d9abfd3c622c144", "Title": "Bathymetric retrieval from manifold coordinate representations of hyperspectral imagery", "Abstract": "This paper analyzes the accuracy of manifold coordinate representations as a reduced representation of a hyperspectral look-up table for bathymetry retrieval using data acquired by the PHILLS hyperspectrals over the Indian River lagoon Florida in 2004. In this paper we examine the accuracy of manifold coordinate representations as a reduced representation of a hyperspectral look-up table for bathymetry retrieval. The approach is based on the extraction of a reduced dimensionality representation in manifold coordinates of a sufficiently large representative set of hyperspectral imagery [4]. The manifold coordinates are derived from a scalable version [4] of the isometric mapping (ISOMAP) algorithm [12] [11]. In the present work and in [5], these coordinates are used to establish an interpolating look-up table for bathymet- ric retrieval by associating the representative data with ground truth data, in this case from a LIDAR estimate in the representative area. The compression of look-up tables could also readily be applied to look-up tables generated by forward radiative transfer models [9]. In this paper, we analyze the approach using data acquired by the PHILLS [6] hyperspectral camera over the Indian River lagoon Florida in 2004. Within a few months of the PHILLS overflights, SHOALS LIDAR data was obtained for a portion of this lagoon, principally covering the beach zone and in some in stances portions of contiguous river channels.", "PublicationYear": "2007", "Authors": ["Charles M. Bachmann", "Thomas L. Ainsworth"], "RelatedTopics": ["Environmental Science"], "References": ["a94fcf1a75918720f203544839ce30e93fd95a2f", "09bc4152d7d9a4b59ba6ec4188230884fda50261", "dbd75566afe8034c8d1db0cad623f3730d1c5e97", "d7bd1659967cfe584e420b5e70109b5901072aa0", "d33d284c02c4c564538f9e359fde14194ad84e50", "8d1c7122547b7452ce19df0b8f02874f2c949dc6", "3537fcd0ff99a3b3cb3d279012df826358420556", "e8f676bc0332bfbbe4d60cf8ef919afa3e48f1c8", "df83034e88557e1e2c7f9d268d90b19762312847"], "ReferenceCount": 11, "CitationCount": 19}, {"URL": "https://www.semanticscholar.org/paper/Fully-constrained-least-squares-linear-spectral-for-Heinz-Chang/47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "ID": "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "Title": "Fully constrained least squares linear spectral mixture analysis method for material quantification in hyperspectral imagery", "Abstract": "The authors present a fully constrained least squares (FCLS) linear spectral mixture analysis method for material quantification, where no closed form can be derived for this method and an efficient algorithm is developed to yield optimal solutions. Linear spectral mixture analysis (LSMA) is a widely used technique in remote sensing to estimate abundance fractions of materials present in an image pixel. In order for an LSMA-based estimator to produce accurate amounts of material abundance, it generally requires two constraints imposed on the linear mixture model used in LSMA, which are the abundance sum-to-one constraint and the abundance nonnegativity constraint. The first constraint requires the sum of the abundance fractions of materials present in an image pixel to be one and the second imposes a constraint that these abundance fractions be nonnegative. While the first constraint is easy to deal with, the second constraint is difficult to implement since it results in a set of inequalities and can only be solved by numerical methods. Consequently, most LSMA-based methods are unconstrained and produce solutions that do not necessarily reflect the true abundance fractions of materials. In this case, they can only be used for the purposes of material detection, discrimination, and classification, but not for material quantification. The authors present a fully constrained least squares (FCLS) linear spectral mixture analysis method for material quantification. Since no closed form can be derived for this method, an efficient algorithm is developed to yield optimal solutions. In order to further apply the designed algorithm to unknown image scenes, an unsupervised least squares error (LSE)-based method is also proposed to extend the FCLS method in an unsupervised manner.", "PublicationYear": "2001", "Authors": ["Daniel C. Heinz", "Chein-I. Chang"], "RelatedTopics": ["Environmental Science"], "References": ["b764048b9270289ead83a711dcb1a71e2377d884", "c175c1fa4037a21986e052bfff4483fb6315212c", "eac326f0a2c9dc78fb4a0bda042cbddbfb8e1ebb", "09ab7445113a7ceb2ba284e71c35f02e47001dad", "fb6f38560aa90d5f44d08a2b453ae740d28b4d6c", "d7f0e513a2241cee7dbfbffc6191d8d458222c3a", "34973c84d9356f35059a4adb1f8060a17cba2e6d", "c78a1b5c930f81ea8d9380fb5f9e0f1c96471e35", "dfadb3653d434f926f293b8eb7b773532b12b143", "c5f4d4f29dff1547d7fe8374cc5fc6e631cc7621"], "ReferenceCount": 39, "CitationCount": 1633}, {"URL": "https://www.semanticscholar.org/paper/Minimum-Dispersion-Constrained-Nonnegative-Matrix-Huck-Guillaume/4a1042d7a216008eaae4d17d478f93029ef69a4f", "ID": "4a1042d7a216008eaae4d17d478f93029ef69a4f", "Title": "Minimum Dispersion Constrained Nonnegative Matrix Factorization to Unmix Hyperspectral Data", "Abstract": "The derived algorithm, called MiniDisCo, is shown to be particularly robust to the presence of flat spectra, to a possible a priori overestimation of the number of endmembers, or if the amount of observed spectral pixels is low. This paper considers the problem of unsupervised spectral unmixing for hyperspectral image analysis. Each observed pixel is assumed to be a noisy linear mixture of pure material spectra, namely, endmembers. The mixing coefficients, usually called abundances, are constrained to positive and summed to unity. The proposed unmixing approach is based on the nonnegative matrix factorization (NMF) framework, which considers the physical constraints of the problem, including the positivity of the endmember spectra and abundances. However, the basic NMF formulation has degenerated solutions and suffers from nonconvexity limitations. We consider here a regularization function, called dispersion, which favors the solution such that the endmember spectra have minimum variances. Such a solution encourages the recovered spectra to be flat, preserving the possible spectral singularities (peaks and sharp variations). The regularized criterion is minimized with a projected gradient (PG) scheme, and we propose a new step-size estimation technique to fasten the PG convergence. The derived algorithm is called MiniDisCo, for minimum dispersion constrained NMF. We experimentally compare MiniDisCo with the recently proposed algorithm. It is shown to be particularly robust to the presence of flat spectra, to a possible a priori overestimation of the number of endmembers, or if the amount of observed spectral pixels is low. In addition, experiments show that the considered regularization correctly overcomes the degeneracy and nonconvexity problems, leading to satisfactory unmixing accuracy. We include a comparative analysis of a real-world scene.", "PublicationYear": "2010", "Authors": ["Alexis Huck", "Mireille Guillaume", "Jacques Blanc-Talon"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["d9919fd10760699c7e482bc941298670d8d77837", "0337e7041779082330ac74cf74aebe79fddb38d2", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b", "24a862c1ce346e435d6e6225e36f6a32f185258a", "074354a7d114c43dfba60663a536cec947f8ff08", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "d0aa80264988c937d3909edd4c3a8615e5daf49f", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6"], "ReferenceCount": 41, "CitationCount": 129}, {"URL": "https://www.semanticscholar.org/paper/Endmember-extraction-in-hyperspectral-images-using-Nguyen-Tran/1af8b1059d5104fa2bb418b5de327ae652bce36a", "ID": "1af8b1059d5104fa2bb418b5de327ae652bce36a", "Title": "Endmember extraction in hyperspectral images using l-1 minimization and linear complementary programming", "Abstract": "A new approach to endmember extraction is proposed, which takes advantage of the sparsity property of the linear representation of HSI's spectral vector, which results in a constrained quadratic programming which can be solved effectively using the Linear Complementary Programming (LCP). Endmember extraction in Hyperspectral Images (HSI) is a critical step for target detection and abundance estimation. In this paper, we propose a new approach to endmember extraction, which takes advantage of the sparsity property of the linear representation of HSI's spectral vector. Sparsity is measured by the l0 norm of the abundance vector. It is also well known that l1 norm well resembles l0 in boosting sparsity while keeping the minimization problem convex and tractable. By adding the l1 norm term to the objective function, we result in a constrained quadratic programming which can be solved effectively using the Linear Complementary Programming (LCP). Unlike existing methods which require expensive computations in each iteration, LCP only requires pivoting steps, which are extremely simple and efficient for the un-mixing problem, since the number of signatures in the reconstructing basis is reasonably small. Preliminary experiments of the proposed methods for both supervised and unsupervised abundance decomposition showed competitive results as compared to LS-based method like Fully Constrained Least Square (FCLS). Furthermore, combination of our unsupervised decomposition with anomaly detection makes a decent target detection algorithm as compared to methods which require prior information of target and background signatures.", "PublicationYear": "2010", "Authors": ["Dzung T. Nguyen", "Trac D. Tran", "Chiman Kwan", "Bulent Ayhan"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "5d6d531585ca65a41367550b959bf792d8ae26fc", "8eb1de1d4c09b4c60be7ee272564de003d0ade14", "6bd906765e974a1a3e8381189d86d64379c28513", "bf6bf50d1b2d1a81d23f84c3cacd1ac509270a55", "d2958dc046f74144f8f64913612c24bac3268f1b", "d8c0f0a243070ba05883befce0095a633186dd53", "e7321ab0f3be0b29aaf5f073fd7de7da5fed2f92", "cc79e154ee8cf75e8d132f497b64f7c10c380bcd", "58485dfbff2f56c202de4b085285cd95e995df04"], "ReferenceCount": 11, "CitationCount": 15}, {"URL": "https://www.semanticscholar.org/paper/Implementation-Strategies-for-Hyperspectral-Using-Schmidt-Schmidt/deeeda3e9d352de048b3d23fedeeb32e9ad94124", "ID": "deeeda3e9d352de048b3d23fedeeb32e9ad94124", "Title": "Implementation Strategies for Hyperspectral Unmixing Using Bayesian Source Separation", "Abstract": "The implementation strategy that allows one to apply Bayesian positive source separation algorithms on a full hyperspectral image, as it is typical in earth and planetary science, is introduced and the effects of pixel selection and the impact of such sampling on the relevance of the estimated component spectra and abundance maps, as well as on the computation times. Bayesian positive source separation (BPSS) is a useful unsupervised approach for hyperspectral data unmixing, where numerical nonnegativity of spectra and abundances has to be ensured, such as in remote sensing. Moreover, it is sensible to impose a sum-to-one (full additivity) constraint to the estimated source abundances in each pixel. Even though nonnegativity and full additivity are two necessary properties to get physically interpretable results, the use of BPSS algorithms has so far been limited by high computation time and large memory requirements due to the Markov chain Monte Carlo calculations. An implementation strategy that allows one to apply these algorithms on a full hyperspectral image, as it is typical in earth and planetary science, is introduced. The effects of pixel selection and the impact of such sampling on the relevance of the estimated component spectra and abundance maps, as well as on the computation times, are discussed. For that purpose, two different data sets have been used: a synthetic one and a real hyperspectral image from Mars.", "PublicationYear": "2010", "Authors": ["Fr{\\'e}d{\\'e}ric Schmidt", "Albrecht Schmidt", "Erwan Tr{\\'e}guier", "Ma{\\\"e}l Guiheneuf", "Sa{\\\"i}d Moussaoui", "Nicolas Dobigeon"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["0337e7041779082330ac74cf74aebe79fddb38d2", "ec892e36c16feffdea169dbec97ecdc412778a02", "23d92dc4598dd7dfa78560f187fa75524584c038", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "10ad2ec4ebcbecd4b2ddd3e88f9b125caf50a2fc", "d9919fd10760699c7e482bc941298670d8d77837", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "c5f0ffa5ee91caa6d79be29045bfa1c3752866b5", "d09a4f6a700c05f7ad69a9e401e2fb84ff1fd6b1", "25f7a27a2c8bb01df6937952645844ccc4dff89e"], "ReferenceCount": 54, "CitationCount": 67}, {"URL": "https://www.semanticscholar.org/paper/N-FINDR%3A-an-algorithm-for-fast-autonomous-spectral-Winter/954c621a5be1193166e9c610e8323eff942da0a7", "ID": "954c621a5be1193166e9c610e8323eff942da0a7", "Title": "N-FINDR: an algorithm for fast autonomous spectral end-member determination in hyperspectral data", "Abstract": "A method based upon the geometry of convex sets is proposed to find a unique set ofpurest pixels in an image, based on the fact that in N spectral dimensions, the N-volume contained by a simplex formed of the purest pixels is larger than any other volume formed from any other combination of pixels. The analysis of hyperspectral data sets requires the determination of certain basis spectra called 'end-members.' Once these spectra are found, the image cube can be 'unmixed' into the fractional abundance of each material in each pixel. There exist several techniques for accomplishing the determination of the end-members, most of which involve the intervention of a trained geologist. Often these-end-members are assumed to be present in the image, in the form of pure, or unmixed, pixels. In this paper a method based upon the geometry of convex sets is proposed to find a unique set of purest pixels in an image. The technique is based on the fact that in N spectral dimensions, the N-volume contained by a simplex formed of the purest pixels is larger than any other volume formed from any other combination of pixels. The algorithm works by 'inflating' a simplex inside the data, beginning with a random set of pixels. For each pixel and each end-member, the end-member is replaced with the spectrum of the pixel and the volume is recalculated. If it increases, the spectrum of the new pixel replaces that end-member. This procedure is repeated until no more replacements are done. This algorithm successfully derives end-members in a synthetic data set, and appears robust with less than perfect data. Spectral end-members have been extracted for the AVIRIS Cuprite data set which closely match reference spectra, and resulting abundance maps match published mineral maps.", "PublicationYear": "1999", "Authors": ["Michael E. Winter"], "RelatedTopics": ["Environmental Science", "Computer Science", "Geology"], "References": ["8a40240815bb72fad80a19650a2510ad2f796bdb", "7d54d6f5ffb51ab8f4e68b23e73895eee6bc1cd4"], "ReferenceCount": 3, "CitationCount": 1673}, {"URL": "https://www.semanticscholar.org/paper/Joint-Bayesian-Endmember-Extraction-and-Linear-for-Dobigeon-Moussaoui/dd489b78bbb2fb45a07d5af2586287639146b9ff", "ID": "dd489b78bbb2fb45a07d5af2586287639146b9ff", "Title": "Joint Bayesian Endmember Extraction and Linear Unmixing for Hyperspectral Imagery", "Abstract": "A Gibbs sampler is proposed to overcome the complexity of evaluating the resulting posterior distribution and estimates the unknown parameters using these generated samples using the joint Bayesian estimator. This paper studies a fully Bayesian algorithm for endmember extraction and abundance estimation for hyperspectral imagery. Each pixel of the hyperspectral image is decomposed as a linear combination of pure endmember spectra following the linear mixing model. The estimation of the unknown endmember spectra is conducted in a unified manner by generating the posterior distribution of abundances and endmember parameters under a hierarchical Bayesian model. This model assumes conjugate prior distributions for these parameters, accounts for nonnegativity and full-additivity constraints, and exploits the fact that the endmember proportions lie on a lower dimensional simplex. A Gibbs sampler is proposed to overcome the complexity of evaluating the resulting posterior distribution. This sampler generates samples distributed according to the posterior distribution and estimates the unknown parameters using these generated samples. The accuracy of the joint Bayesian estimator is illustrated by simulations conducted on synthetic and real AVIRIS images.", "PublicationYear": "2009", "Authors": ["Nicolas Dobigeon", "Sa{\\\"i}d Moussaoui", "Martial Coulon", "Jean-Yves Tourneret", "Alfred O. Hero"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["cd88b3665a0533b72833929c1b8635622c693ea2", "0337e7041779082330ac74cf74aebe79fddb38d2", "e321facb5b7d796197140e3cfceb439b2da9522f", "23d92dc4598dd7dfa78560f187fa75524584c038", "5d75cb202a7576c318685fab6fbb905768a6e6e3", "804519f49feee4d2bfafdc0db6d0d10f7f3ebf0c", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b"], "ReferenceCount": 69, "CitationCount": 344}, {"URL": "https://www.semanticscholar.org/paper/Vertex-component-analysis%3A-a-fast-algorithm-to-data-Nascimento-Bioucas-Dias/26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "ID": "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "Title": "Vertex component analysis: a fast algorithm to unmix hyperspectral data", "Abstract": "A new method for unsupervised endmember extraction from hyperspectral data, termed vertex component analysis (VCA), which competes with state-of-the-art methods, with a computational complexity between one and two orders of magnitude lower than the best available method. Given a set of mixed spectral (multispectral or hyperspectral) vectors, linear spectral mixture analysis, or linear unmixing, aims at estimating the number of reference substances, also called endmembers, their spectral signatures, and their abundance fractions. This paper presents a new method for unsupervised endmember extraction from hyperspectral data, termed vertex component analysis (VCA). The algorithm exploits two facts: (1) the endmembers are the vertices of a simplex and (2) the affine transformation of a simplex is also a simplex. In a series of experiments using simulated and real data, the VCA algorithm competes with state-of-the-art methods, with a computational complexity between one and two orders of magnitude lower than the best available method.", "PublicationYear": "2005", "Authors": ["Jos{\\'e} M. P. Nascimento", "Jos{\\'e} M. Bioucas-Dias"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["23d92dc4598dd7dfa78560f187fa75524584c038", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "77f964d83ed93648b17585df764ae914c60890be", "273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "093acb100307827bccf99031f4c50d26a049f1f4", "34973c84d9356f35059a4adb1f8060a17cba2e6d", "678ddfa79d0db8528d2deb4b52dc3b9118165708", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "b7137c928d5531fce2c8873c18a5aa0db2bd132c", "954c621a5be1193166e9c610e8323eff942da0a7"], "ReferenceCount": 66, "CitationCount": 2305}, {"URL": "https://www.semanticscholar.org/paper/Spectral-Unmixing-With-Negative-and-Superunity-for-Duran-Petrou/bf131254f1c3e24092c448e71c12e96949f7a7ed", "ID": "bf131254f1c3e24092c448e71c12e96949f7a7ed", "Title": "Spectral Unmixing With Negative and Superunity Abundances for Subpixel Anomaly Detection", "Abstract": "The unmixing spectral linear model without the nonnegativity constraint is used to distinguish between false anomalies corresponding to pure substances and real man-made anomalies. We propose a low false alarm methodology to determine anomalies in hyperspectral data. The method is based on the assumptions that the linear mixing model is valid and that, due to the resolution of the image, most pixels are mixtures of common substances, of which pure pixels (not mixtures) are rare. In the first stage of the algorithm, the classes associated with the background, which are the dominant classes in the image, are found by clustering the image pixels. The resulting clusters may be considered as representatives of the background classes in the image. In order to determine the anomalous pixels, a threshold may be applied to the distance between the pixel spectrum and the cluster centers. However, pixels corresponding to anomalies and pure substances will both show high distances. If we consider that the background classes are themselves most likely mixtures of other materials, the pixels within the convex hull formed by the background classes will have positive fractions that are smaller than one. The pure substances, however, will be outside such a convex hull and will show negative or superunity fractions. Pixels with such mixing proportions are explained as linear combinations of the background classes and, therefore, as not true anomalies. Pixels corresponding to anomalies, however, when expressed as linear combinations of the background classes, show high residual error even with negative and superunity mixing proportions. We use the unmixing spectral linear model without the nonnegativity constraint to distinguish between false anomalies corresponding to pure substances and real man-made anomalies.", "PublicationYear": "2009", "Authors": ["Olga Duran", "Maria Petrou"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["4387cb3899b7512e597c9af4b49018777f239805", "5c02667a8435d42cda3f41de13a30b30eb7dfe3f", "fde9b2c2872a427c48226eaf4b6ae972e2b92fa2", "95a97cd4d7ecd8b8a2d84577eebb5541077f46aa", "c66131f9a33245166258530f328e409d91f5e4cb", "0411eb52aed92f2e8e99551518f802d6e2729cf1", "e545da6ce36abcc9b6065f27176dd82f3ea9ef6b", "0eeee7e67842a9037a3dd4438a16d3cc944bc064", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "595625865c3bfdad58e1f7eaf7c6c9884f62a98c"], "ReferenceCount": 20, "CitationCount": 33}, {"URL": "https://www.semanticscholar.org/paper/Spectral-unmixing-Keshava-Mustard/70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "ID": "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "Title": "Spectral unmixing", "Abstract": "The outputs of spectral unmixing, endmember, and abundance estimates are important for identifying the material composition of mixtures and the applicability of models and techniques is highly dependent on the variety of circumstances and factors that give rise to mixed pixels. Spectral unmixing using hyperspectral data represents a significant step in the evolution of remote decompositional analysis that began with multispectral sensing. It is a consequence of collecting data in greater and greater quantities and the desire to extract more detailed information about the material composition of surfaces. Linear mixing is the key assumption that has permitted well-known algorithms to be adapted to the unmixing problem. In fact, the resemblance of the linear mixing model to system models in other areas has permitted a significant legacy of algorithms from a wide range of applications to be adapted to unmixing. However, it is still unclear whether the assumption of linearity is sufficient to model the mixing process in every application of interest. It is clear, however, that the applicability of models and techniques is highly dependent on the variety of circumstances and factors that give rise to mixed pixels. The outputs of spectral unmixing, endmember, and abundance estimates are important for identifying the material composition of mixtures.", "PublicationYear": "2002", "Authors": ["Nirmal Keshava", "John F. Mustard"], "RelatedTopics": ["Environmental Science"], "References": ["c175c1fa4037a21986e052bfff4483fb6315212c", "564f5b0b74f751b90952bceec3a447a2aad46db6", "01142cd1d10dfa8066883143b2e91f52aca73ea1", "46e527f606ac56ec4316d5c1657b45d6ff1f7879", "eaf3b06bf3be5beffc34170b953e0996e08496d9", "ac2c1084720b12d139156261fe2280f26ee1ffb7", "31f29c9293fa0a91f1f7232f3af7cd4ddc019df2", "81c5df1f31c8c74bab1b9d1cb13be106fec73f79", "80b86a441ca58a06b318166b7bb247264aa02dd7", "6ae00ebd3a91c0667c79c39035b5163025bcfcad"], "ReferenceCount": 25, "CitationCount": 2120}, {"URL": "https://www.semanticscholar.org/paper/L1-unmixing-and-its-application-to-hyperspectral-Guo-Wittman/5d6d531585ca65a41367550b959bf792d8ae26fc", "ID": "5d6d531585ca65a41367550b959bf792d8ae26fc", "Title": "L1 unmixing and its application to hyperspectral image enhancement", "Abstract": "The L1 unmixing model and fast computational approaches based on Bregman iteration are discussed, which are used to produce a higher resolution hyperspectral image in which each pixel is driven towards a \\\"pure\\\" material. Because hyperspectral imagery is generally low resolution, it is possible for one pixel in the image to contain several materials. The process of determining the abundance of representative materials in a single pixel is called spectral unmixing. We discuss the L1 unmixing model and fast computational approaches based on Bregman iteration. We then use the unmixing information and Total Variation (TV) minimization to produce a higher resolution hyperspectral image in which each pixel is driven towards a \\\"pure\\\" material. This method produces images with higher visual quality and can be used to indicate the subpixel location of features.", "PublicationYear": "2009", "Authors": ["Zhaohui Guo", "Todd Wittman", "S. Osher"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["8bebc76f5bc7e055566f268a2ffbafd89eeae82f", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "4fcab776dc0db499d168825b86a3da098277421e", "8ed095c7846ffdfa6ce531a79ceb51466fadf4f5", "fe2332604f708d58e535249ad829f71ffd28e36d", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "e6334789ec6d43664f8f164a462461a4408243ba", "954c621a5be1193166e9c610e8323eff942da0a7", "a70157e7089b12b5cc8f0c5603f6970bbb0dadad", "4d3e9019eedec5e69864dcc2c814a0dff8cea826"], "ReferenceCount": 23, "CitationCount": 152}, {"URL": "https://www.semanticscholar.org/paper/A-Convex-Analysis-Based-Minimum-Volume-Enclosing-Chan-Chi/a16ddf440077328c3e147cc703e8a0fe96d17622", "ID": "a16ddf440077328c3e147cc703e8a0fe96d17622", "Title": "A Convex Analysis-Based Minimum-Volume Enclosing Simplex Algorithm for Hyperspectral Unmixing", "Abstract": "This paper incorporates convex analysis and Craig's criterion to develop a minimum-volume enclosing simplex (MVES) formulation for hyperspectral unmixing, and provides a non-heuristic guarantee of the MVES problem formulation, where the existence of pure pixels is proved to be a sufficient condition for MVES to perfectly identify the true endmembers. Hyperspectral unmixing aims at identifying the hidden spectral signatures (or endmembers) and their corresponding proportions (or abundances) from an observed hyperspectral scene. Many existing hyperspectral unmixing algorithms were developed under a commonly used assumption that pure pixels exist. However, the pure-pixel assumption may be seriously violated for highly mixed data. Based on intuitive grounds, Craig reported an unmixing criterion without requiring the pure-pixel assumption, which estimates the endmembers by vertices of a minimum-volume simplex enclosing all the observed pixels. In this paper, we incorporate convex analysis and Craig's criterion to develop a minimum-volume enclosing simplex (MVES) formulation for hyperspectral unmixing. A cyclic minimization algorithm for approximating the MVES problem is developed using linear programs (LPs), which can be practically implemented by readily available LP solvers. We also provide a non-heuristic guarantee of our MVES problem formulation, where the existence of pure pixels is proved to be a sufficient condition for MVES to perfectly identify the true endmembers. Some Monte Carlo simulations and real data experiments are presented to demonstrate the efficacy of the proposed MVES algorithm over several existing hyperspectral unmixing methods.", "PublicationYear": "2009", "Authors": ["Tsung-Han Chan", "Chong-Yung Chi", "Yu-Min Huang", "Wing-Kin Ma"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["6ba3b3b9122ab0e663af6186267a8c81a1dd661e", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "954c621a5be1193166e9c610e8323eff942da0a7", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b", "093acb100307827bccf99031f4c50d26a049f1f4", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "dd489b78bbb2fb45a07d5af2586287639146b9ff", "8d5a3a134e3340b1754d5608080d9b213c56dd8b", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe"], "ReferenceCount": 52, "CitationCount": 400}, {"URL": "https://www.semanticscholar.org/paper/Imaging-spectroscopy%3A-Earth-and-planetary-remote-Clark-Swayze/284cdfef6ed51904ec840077a2f2710e635f78fe", "ID": "284cdfef6ed51904ec840077a2f2710e635f78fe", "Title": "Imaging spectroscopy: Earth and planetary remote sensing with the USGS Tetracorder and expert systems", "Abstract": "A new system that is effective at material identification and mapping: a set of algorithms within an expert system decision-making framework that is called Tetracorder, which can be used to study both terrestrial and planetary science problems. [1]\u00a0Imaging spectroscopy is a tool that can be used to spectrally identify and spatially map materials based on their specific chemical bonds. Spectroscopic analysis requires significantly more sophistication than has been employed in conventional broadband remote sensing analysis. We describe a new system that is effective at material identification and mapping: a set of algorithms within an expert system decision-making framework that we call Tetracorder. The expertise in the system has been derived from scientific knowledge of spectral identification. The expert system rules are implemented in a decision tree where multiple algorithms are applied to spectral analysis, additional expert rules and algorithms can be applied based on initial results, and more decisions are made until spectral analysis is complete. Because certain spectral features are indicative of specific chemical bonds in materials, the system can accurately identify and map those materials. In this paper we describe the framework of the decision making process used for spectral identification, describe specific spectral feature analysis algorithms, and give examples of what analyses and types of maps are possible with imaging spectroscopy data. We also present the expert system rules that describe which diagnostic spectral features are used in the decision making process for a set of spectra of minerals and other common materials. We demonstrate the applications of Tetracorder to identify and map surface minerals, to detect sources of acid rock drainage, and to map vegetation species, ice, melting snow, water, and water pollution, all with one set of expert system rules. Mineral mapping can aid in geologic mapping and fault detection and can provide a better understanding of weathering, mineralization, hydrothermal alteration, and other geologic processes. Environmental site assessment, such as mapping source areas of acid mine drainage, has resulted in the acceleration of site cleanup, saving millions of dollars and years in cleanup time. Imaging spectroscopy data and Tetracorder analysis can be used to study both terrestrial and planetary science problems. Imaging spectroscopy can be used to probe planetary systems, including their atmospheres, oceans, and land surfaces.", "PublicationYear": "2003", "Authors": ["Roger N. Clark", "Gregg Alan Swayze", "Keith Eric Livo", "Raymond F. Kokaly", "Stephen J. Sutley", "James B. Dalton", "Robert R. McDougal", "Carol A. Gent"], "RelatedTopics": ["Environmental Science", "Computer Science", "Physics", "Geology"], "References": ["f9acdaafa31a142e898e3b1815fa423557c193d7", "742efbe99f5dea6e1e2d3fc7ab5f69c8a22dab01", "64eb2af669f5efaefe1c189bb74e297b99212171", "849784c9d1fe958928f043a9d65701089622836d", "935761cef190bb05ba594d7b1c176165a6581ec9", "5522204532bda6bbc89e8a12d23fe88c1ba67f54", "28b004d775a55f8f8ca1c0c4c638ec3ca03fe673", "b97b023c881571285e163908866a5af022956020", "0b5099a095d9a76c431ea4214a705aeb14db8330", "ad446e9da2067fff70483a724827ba3720f42800"], "ReferenceCount": 51, "CitationCount": 754}, {"URL": "https://www.semanticscholar.org/paper/An-Augmented-Lagrangian-Approach-to-the-Constrained-Afonso-Bioucas-Dias/3a1b983a87a4116803fff779ecf1cd11a4b07539", "ID": "3a1b983a87a4116803fff779ecf1cd11a4b07539", "Title": "An Augmented Lagrangian Approach to the Constrained Optimization Formulation of Imaging Inverse Problems", "Abstract": "This paper proposes a new efficient algorithm to handle one class of constrained problems (often known as basis pursuit denoising) tailored to image recovery applications and shows that the proposed algorithm is a strong contender for the state-of-the-art. We propose a new fast algorithm for solving one of the standard approaches to ill-posed linear inverse problems (IPLIP), where a (possibly nonsmooth) regularizer is minimized under the constraint that the solution explains the observations sufficiently well. Although the regularizer and constraint are usually convex, several particular features of these problems (huge dimensionality, nonsmoothness) preclude the use of off-the-shelf optimization tools and have stimulated a considerable amount of research. In this paper, we propose a new efficient algorithm to handle one class of constrained problems (often known as basis pursuit denoising) tailored to image recovery applications. The proposed algorithm, which belongs to the family of augmented Lagrangian methods, can be used to deal with a variety of imaging IPLIP, including deconvolution and reconstruction from compressive observations (such as MRI), using either total-variation or wavelet-based (or, more generally, frame-based) regularization. The proposed algorithm is an instance of the so-called alternating direction method of multipliers, for which convergence sufficient conditions are known; we show that these conditions are satisfied by the proposed algorithm. Experiments on a set of image restoration and reconstruction benchmark problems show that the proposed algorithm is a strong contender for the state-of-the-art.", "PublicationYear": "2009", "Authors": ["Manya V. Afonso", "Jos{\\'e} M. Bioucas-Dias", "M{\\'a}rio A. T. Figueiredo"], "RelatedTopics": ["Engineering", "Computer Science"], "References": ["7f9a95fab0688267bb5ca1061c8b38ffdf405015", "94f52a73625eeb62b98405201b748f87781913a8", "34fe87515826dce400f0b3090c4cdd638bc3277b", "64e9a50ebaa20fb34414c3fd0668bfef93e2366c", "1dc10432c79d3b08eabca20f7945f27292c2bf37", "5acfb2abca580a40f2f6890371c2387527dfefc0", "22297dffa7d0b613422eddd87f4ff25017086fe3", "783073258aa90a3ad100d1e6efb4207fe4005824", "0acd253741fede941cf323e577d4f9dfabb4636b", "56974187b4d9a8757f4d8a6fd6facc8b4ad08240"], "ReferenceCount": 62, "CitationCount": 1038}, {"URL": "https://www.semanticscholar.org/paper/Stable-recovery-of-sparse-overcomplete-in-the-of-Donoho-Elad/7236864d8c2f62defea559465462c43a4b4b6b47", "ID": "7236864d8c2f62defea559465462c43a4b4b6b47", "Title": "Stable recovery of sparse overcomplete representations in the presence of noise", "Abstract": "This paper establishes the possibility of stable recovery under a combination of sufficient sparsity and favorable structure of the overcomplete system and shows that similar stability is also available using the basis and the matching pursuit algorithms. Overcomplete representations are attracting interest in signal processing theory, particularly due to their potential to generate sparse representations of signals. However, in general, the problem of finding sparse representations must be unstable in the presence of noise. This paper establishes the possibility of stable recovery under a combination of sufficient sparsity and favorable structure of the overcomplete system. Considering an ideal underlying signal that has a sufficiently sparse representation, it is assumed that only a noisy version of it can be observed. Assuming further that the overcomplete system is incoherent, it is shown that the optimally sparse approximation to the noisy data differs from the optimally sparse decomposition of the ideal noiseless signal by at most a constant multiple of the noise level. As this optimal-sparsity method requires heavy (combinatorial) computational effort, approximation algorithms are considered. It is shown that similar stability is also available using the basis and the matching pursuit algorithms. Furthermore, it is shown that these methods result in sparse approximation of the noisy data that contains only terms also appearing in the unique sparsest representation of the ideal noiseless sparse signal.", "PublicationYear": "2006", "Authors": ["David L. Donoho", "Michael Elad", "Vladimir N. Temlyakov"], "RelatedTopics": ["Computer Science", "Engineering", "Mathematics"], "References": ["2942c20f111d6fd38ef6dd53bb6eeb3b880e3d5f", "46ee0292a71fa86a9e2f9d691da5f0f1cf281f83", "17e7cca7e795d8ba1fa9d2c88bf2675c2d6ddfe8", "6c1d6208ebfcbcbf01eb328b1414a14cbfb576b4", "6cf9b027aa09d042dd13fd9ae848d902240b3d34", "023417a8348a7c3353d73981e9787f30cf430735", "bd37f3015428d69d9b12667e4882811d2da38dfa", "006b782513a9c2871530d17eb68671b52572f3ae", "822f290fc58b19a8431f1a6d6a3b85b8b47125f2", "20394faa89898ec65b20d2e1008ff8a63cbabfcc"], "ReferenceCount": 48, "CitationCount": 2260}, {"URL": "https://www.semanticscholar.org/paper/From-Sparse-Solutions-of-Systems-of-Equations-to-of-Bruckstein-Donoho/63c53e35b25e09a3432e4f4dd786f5d539304f30", "ID": "63c53e35b25e09a3432e4f4dd786f5d539304f30", "Title": "From Sparse Solutions of Systems of Equations to Sparse Modeling of Signals and Images", "Abstract": "The aim of this paper is to introduce a few key notions and applications connected to sparsity, targeting newcomers interested in either the mathematical aspects of this area or its applications. A full-rank matrix ${\\\\bf A}\\\\in \\\\mathbb{R}^{n\\\\times m}$ with $n&lt;m$ generates an underdetermined system of linear equations ${\\\\bf Ax} = {\\\\bf b}$ having infinitely many solutions. Suppose we seek the sparsest solution, i.e., the one with the fewest nonzero entries. Can it ever be unique? If so, when? As optimization of sparsity is combinatorial in nature, are there efficient methods for finding the sparsest solution? These questions have been answered positively and constructively in recent years, exposing a wide variety of surprising phenomena, in particular the existence of easily verifiable conditions under which optimally sparse solutions can be found by concrete, effective computational methods.\\r\\n\\r\\nSuch theoretical results inspire a bold perspective on some important practical problems in signal and image processing. Several well-known signal and image processing problems can be cast as demanding solutions of undetermined systems of equations. Such problems have previously seemed, to many, intractable, but there is considerable evidence that these problems often have sparse solutions. Hence, advances in finding sparse solutions to underdetermined systems have energized research on such signal and image processing problems\u2014to striking effect.\\r\\n\\r\\nIn this paper we review the theoretical results on sparse solutions of linear systems, empirical results on sparse modeling of signals and images, and recent applications in inverse problems and compression in image processing. This work lies at the intersection of signal processing and applied mathematics, and arose initially from the wavelets and harmonic analysis research communities. The aim of this paper is to introduce a few key notions and applications connected to sparsity, targeting newcomers interested in either the mathematical aspects of this area or its applications.", "PublicationYear": "2009", "Authors": ["Alfred Marcel Bruckstein", "David L. Donoho", "Michael Elad"], "RelatedTopics": ["Mathematics", "Computer Science"], "References": ["fb2d7003623a31ffabba86841cf05b8b57030796", "3cb5a635215238ce7a8776a77a8e193bb385f382", "36ab8bd64210ac5c4f7d326ed2c0a5745e91320f", "59381588e492ecb2fa980b5f34a6a8c0e30a3420", "f6295fd69d76d606f66cc15f58767a8161d60335", "83b522f4bfa5db7f7d34f839475af7d078107634", "7236864d8c2f62defea559465462c43a4b4b6b47", "3424286d6d39de51080ddd683646565545d015e2", "e317022363c819fcf9667ff2eb685fad1f493b93", "c77338d031d41c3c5ae027e64a64242555b3ec2d"], "ReferenceCount": 177, "CitationCount": 2324}, {"URL": "https://www.semanticscholar.org/paper/On-the-Uniqueness-of-Nonnegative-Sparse-Solutions-Bruckstein-Elad/b2148e57be50122e569941e835208326e76ba79b", "ID": "b2148e57be50122e569941e835208326e76ba79b", "Title": "On the Uniqueness of Nonnegative Sparse Solutions to Underdetermined Systems of Equations", "Abstract": "It is shown that for matrices A with a row-span intersecting the positive orthant, if this problem admits a sufficiently sparse solution, it is necessarily unique, and the bound on the required sparsity depends on a coherence property of the matrix A. An underdetermined linear system of equations Ax = b with nonnegativity constraint x ges 0 is considered. It is shown that for matrices A with a row-span intersecting the positive orthant, if this problem admits a sufficiently sparse solution, it is necessarily unique. The bound on the required sparsity depends on a coherence property of the matrix A. This coherence measure can be improved by applying a conditioning stage on A, thereby strengthening the claimed result. The obtained uniqueness theorem relies on an extended theoretical analysis of the lscr0 - lscr1 equivalence developed here as well, considering a matrix A with arbitrary column norms, and an arbitrary monotone element-wise concave penalty replacing the lscr1-norm objective function. Finally, from a numerical point of view, a greedy algorithm-a variant of the matching pursuit-is presented, such that it is guaranteed to find this sparse solution. It is further shown how this algorithm can benefit from well-designed conditioning of A .", "PublicationYear": "2008", "Authors": ["Alfred Marcel Bruckstein", "Michael Elad", "Michael Zibulevsky"], "RelatedTopics": ["Mathematics"], "References": ["e16e77ab199a10603384fa2b1a820d4dac0d28c7", "8921fc0c7082524123b405acfcfcd8feae033268", "17e7cca7e795d8ba1fa9d2c88bf2675c2d6ddfe8", "7236864d8c2f62defea559465462c43a4b4b6b47", "dd03a177e5e51808f0cef46c602f9c6e2432cc95", "46ee0292a71fa86a9e2f9d691da5f0f1cf281f83", "a6f5c8d82f27bd68eb4cc40bc3d0b00fccc5d469", "f44e85948ef6bdc9645581173b1349d5dc569c9c", "c666f2811552d188b0a038f463b6333579d15cf6", "3d09f9b027cea21f443c331a9aad7bbb2b4ffa13"], "ReferenceCount": 42, "CitationCount": 298}, {"URL": "https://www.semanticscholar.org/paper/A-note-on-the-group-lasso-and-a-sparse-group-lasso-Friedman-Hastie/c8430c5d13834e46631960469d86f7ed4577b0e2", "ID": "c8430c5d13834e46631960469d86f7ed4577b0e2", "Title": "A note on the group lasso and a sparse group lasso", "Abstract": "An ecien t algorithm is derived for the resulting convex problem based on coordinate descent that can be used to solve the general form of the group lasso, with non-orthonormal model matrices. We consider the group lasso penalty for the linear model. We note that the standard algorithm for solving the problem assumes that the model matrices in each group are orthonormal. Here we consider a more general penalty that blends the lasso (L1) with the group lasso (\\\\two-norm\\\"). This penalty yields solutions that are sparse at both the group and individual feature levels. We derive an ecien t algorithm for the resulting convex problem based on coordinate descent. This algorithm can also be used to solve the general form of the group lasso, with non-orthonormal model matrices.", "PublicationYear": "2010", "Authors": ["Jerome H. Friedman", "Trevor J. Hastie", "Robert Tibshirani"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["f99ab20ae5674ad394086b1901fac654faf28a52", "cca1f7bbc6ba4dcf7be3a57e7d356ebc87fbfbfd", "d98ef875e2cbde3e2cc8fad521e3cbfe1bddbd69", "23be7d2d5472797576f0d0840ac4c46b0996125f", "4d2c09b57132c8edd710dbf7d3b758574793b792"], "ReferenceCount": 5, "CitationCount": 805}, {"URL": "https://www.semanticscholar.org/paper/Stable-signal-recovery-from-incomplete-and-Cand%C3%A8s-Romberg/915df1a8dda45221204f3ecbf70b07d8b34d7ba8", "ID": "915df1a8dda45221204f3ecbf70b07d8b34d7ba8", "Title": "Stable signal recovery from incomplete and inaccurate measurements", "Abstract": "It is shown that it is possible to recover x0 accurately based on the data y from incomplete and contaminated observations. Suppose we wish to recover a vector x0 \u2208 \u211d\ud835\udcc2 (e.g., a digital signal or image) from incomplete and contaminated observations y = A x0 + e; A is an \ud835\udcc3 \u00d7 \ud835\udcc2 matrix with far fewer rows than columns (\ud835\udcc3 \u226a \ud835\udcc2) and e is an error term. Is it possible to recover x0 accurately based on the data y?", "PublicationYear": "2005", "Authors": ["Emmanuel J. Cand{\\`e}s", "Justin K. Romberg", "Terence Tao"], "RelatedTopics": ["Mathematics", "Engineering", "Computer Science"], "References": ["9fb8c76e6b17f3fdbd0c8f293ce8da4b79f4ffeb", "a898ad13c96e5c068a2e4fc88227278e646b712e", "7236864d8c2f62defea559465462c43a4b4b6b47", "17e7cca7e795d8ba1fa9d2c88bf2675c2d6ddfe8", "a6f5c8d82f27bd68eb4cc40bc3d0b00fccc5d469", "54205667c1f65a320f667d73c354ed8e86f1b9d9", "c1180048929ed490ab25e0e612f8f7c3d7196450", "3424286d6d39de51080ddd683646565545d015e2", "b5e853572b2f3134acafa76d5ae80b9f28c7dca8", "64a4094ccbbb7f00491b25ac9089b7b6a58be721"], "ReferenceCount": 25, "CitationCount": 7351}, {"URL": "https://www.semanticscholar.org/paper/Decoding-by-linear-programming-Cand%C3%A8s-Tao/b5e853572b2f3134acafa76d5ae80b9f28c7dca8", "ID": "b5e853572b2f3134acafa76d5ae80b9f28c7dca8", "Title": "Decoding by linear programming", "Abstract": "F can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program) and numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y? We prove that under suitable conditions on the coding matrix A, the input f is the unique solution to the /spl lscr//sub 1/-minimization problem (/spl par/x/spl par//sub /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl isin/R/sup n/) /spl par/y - Ag/spl par//sub /spl lscr/1/ provided that the support of the vector of errors is not too large, /spl par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl ne/ 0}|/spl les//spl rho//spl middot/m for some /spl rho/&gt;0. In short, f can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This work is related to the problem of finding sparse solutions to vastly underdetermined systems of linear equations. There are also significant connections with the problem of recovering signals from highly incomplete measurements. In fact, the results introduced in this paper improve on our earlier work. Finally, underlying the success of /spl lscr//sub 1/ is a crucial property we call the uniform uncertainty principle that we shall describe in detail.", "PublicationYear": "2005", "Authors": ["Emmanuel J. Cand{\\`e}s", "Terence Tao"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["c1180048929ed490ab25e0e612f8f7c3d7196450", "a898ad13c96e5c068a2e4fc88227278e646b712e", "d3f2ff0a5e52c5b24c3ed956b0e5d4e358377f45", "64a4094ccbbb7f00491b25ac9089b7b6a58be721", "c20b0e62f510a0abbe676cd248ed7362e171a3b2", "1e45a001f9d3c044efc680611a0394c1b89157fb", "10197d1e071a5dc054c075a9856e1808b7613a05", "c63d91ee6006efba6336a33d2c79ba2498cfdc9f", "b561fba9a109e1ba3dcb12034cabf4423a88bfd1", "17e7cca7e795d8ba1fa9d2c88bf2675c2d6ddfe8"], "ReferenceCount": 38, "CitationCount": 7222}, {"URL": "https://www.semanticscholar.org/paper/Recent-Developments-in-Endmember-Extraction-and-Plaza-Mart%C3%ADn/f76d44cba31df357c8fa184b488d34ce9fb1fe9c", "ID": "f76d44cba31df357c8fa184b488d34ce9fb1fe9c", "Title": "Recent Developments in Endmember Extraction and Spectral Unmixing", "Abstract": "This chapter provides an overview of existing techniques for spectral unmixing and endmember extraction, with particular attention paid to recent advances in the field such as the incorporation of spatial information into the endmember searching process, or the use of nonlinear mixture models for fractional abundance characterization. Spectral unmixing is an important task for remotely sensed hyperspectral data exploitation. The spectral signatures collected in natural environments are invariably a mixture of the pure signatures of the various materials found within the spatial extent of the ground instantaneous field view of the imaging instrument. Spectral unmixing aims at inferring such pure spectral signatures, called endmembers, and the material fractions, called fractional abundances, at each pixel of the scene. In this chapter, we provide an overview of existing techniques for spectral unmixing and endmember extraction, with particular attention paid to recent advances in the field such as the incorporation of spatial information into the endmember searching process, or the use of nonlinear mixture models for fractional abundance characterization. In order to substantiate the methods presented throughout the chapter, highly representative hyperspectral scenes obtained by different imaging spectrometers are used to provide a quantitative and comparative algorithm assessment. To address the computational requirements introduced by hyperspectral imaging algorithms, the chapter also includes a parallel processing example in which the performance of a spectral unmixing chain (made up of spatial\u2013spectral endmember extraction followed by linear spectral unmixing) is accelerated by taking advantage of a low-cost commodity graphics co-processor (GPU). Combined, these parts are intended to provide a snapshot of recent developments in endmember extraction and spectral unmixing, and also to offer a thoughtful perspective on future potentials and emerging challenges in designing and implementing efficient hyperspectral imaging algorithms.", "PublicationYear": "2011", "Authors": ["Antonio J. Plaza", "Gabriel Mart{\\'i}n", "Javier Plaza", "Maciel Zortea", "Sergio S{\\'a}nchez"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["ba86f939cc588f82478a4719942ced254ec33ebe", "23d92dc4598dd7dfa78560f187fa75524584c038", "273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "3dccbfe44bf138f5097ca8c8a80141e55bd682bb", "8d03d8914268164fef0829c6e07cbe100100f035", "e616132691824d6eec92b0eb4560b286d732582b", "e0c7af2520925f5c730009dc5e6fec962f80e3f0", "a70157e7089b12b5cc8f0c5603f6970bbb0dadad", "094a5970dd5d4fac36fa00b81ced669cb208a74b"], "ReferenceCount": 60, "CitationCount": 79}, {"URL": "https://www.semanticscholar.org/paper/Nonlinear-Spectral-Mixture-Analysis-for-Imagery-in-Raksuntorn-Du/78bd5b068dd4be59e40fc642abd3b190d8636a2f", "ID": "78bd5b068dd4be59e40fc642abd3b190d8636a2f", "Title": "Nonlinear Spectral Mixture Analysis for Hyperspectral Imagery in an Unknown Environment", "Abstract": "This work takes advantage of the developed endmember variable linear mixture model (EVLMM) to search the actual endmember set for each pixel, which yields more accurate abundance estimation in terms of smaller pixel reconstruction error, smaller residual counts, and more pixel abundances satisfying sum-to-one and nonnegativity constraints. Nonlinear spectral mixture analysis for hyperspectral imagery is investigated without prior information about the image scene. A simple but effective nonlinear mixture model is adopted, where the multiplication of each pair of endmembers results in a virtual endmember representing multiple scattering effect during pixel construction process. The analysis is followed by linear unmixing for abundance estimation. Due to a large number of nonlinear terms being added in an unknown environment, the following abundance estimation may contain some errors if most of the endmembers do not really participate in the mixture of a pixel. We take advantage of the developed endmember variable linear mixture model (EVLMM) to search the actual endmember set for each pixel, which yields more accurate abundance estimation in terms of smaller pixel reconstruction error, smaller residual counts, and more pixel abundances satisfying sum-to-one and nonnegativity constraints.", "PublicationYear": "2010", "Authors": ["Nareenart Raksuntorn", "Qian Du"], "RelatedTopics": ["Environmental Science"], "References": ["6f0407baefb2c591790979e1e2f4cef1eb682173", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "4f9e0e55f7e4bcb562d6ee5ffeabb5fddf2f375f", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b", "7cd400437a5f99c6cf7fdbb5ff00e6c722dda00e", "31f29c9293fa0a91f1f7232f3af7cd4ddc019df2", "e797b13600a39826c4c7c3325455b09b2f6900db", "7fc18220b12594f06b4dfc72539ff4342060b210", "81cb1b3b7cbbbcbf9470a67db3c09ec4b6ff8977", "80b86a441ca58a06b318166b7bb247264aa02dd7"], "ReferenceCount": 27, "CitationCount": 71}, {"URL": "https://www.semanticscholar.org/paper/An-approach-based-on-constrained-nonnegative-matrix-Liu-Xia/f02cfba39160a2a5f7fe6d701bab5fb621728246", "ID": "f02cfba39160a2a5f7fe6d701bab5fb621728246", "Title": "An approach based on constrained nonnegative matrix factorization to unmix hyperspectral data", "Abstract": "The proposed algorithm retains all the advantages of NMF and effectively overcomes the shortcoming of local minima at the same time and shows the superiority of the proposed algorithm with respect to other state-of-the-art approaches. Nonnegative matrix factorization (NMF) has been recently applied to solve the hyperspectral unmixing problem because it ensures nonnegativity and needs no assumption for the presence of pure pixels. However, the algorithm has a large amount of local minima due to the obvious nonconvexity of the objective function. In order to improve its performance, auxiliary constraints can be introduced into the algorithm. In this paper, we propose a new approach named abundance separation and smoothness constrained NMF by introducing two constraints, namely, abundance separation and smoothness, into the NMF algorithm. These constraints are based on two properties of hyperspectral imagery. First, usually, every ground object presents dominance in a specific region of the entire image scene and the correlation is weak between different endmembers. Second, moving through various regions, ground objects usually vary slowly and abrupt changes rarely appear. We also propose a learning algorithm to further improve the performance of our method, from which the auxiliary constraints are removed at an appropriate time. The proposed algorithm retains all the advantages of NMF and effectively overcomes the shortcoming of local minima at the same time. Experimental results based on synthetic and real hyperspectral data show the superiority of the proposed algorithm with respect to other state-of-the-art approaches.", "PublicationYear": "2011", "Authors": ["Xuesong Liu", "Wei Xia", "Bin Wang", "Liming Zhang"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["d9919fd10760699c7e482bc941298670d8d77837", "6ba3b3b9122ab0e663af6186267a8c81a1dd661e", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b", "25d2a3753fb482ef94a4c9bd711b926ee373ddb0", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "23d92dc4598dd7dfa78560f187fa75524584c038", "73fc67a0d7b8bfc3398853ad51a6b239b4637141", "273ebdbefd2b0d9653491fed7bb7fb9c645a7171"], "ReferenceCount": 49, "CitationCount": 156}, {"URL": "https://www.semanticscholar.org/paper/Hyperspectral-Unmixing-Based-on-Mixtures-of-Nascimento-Bioucas-Dias/6acdf90e0d1d32480292cab70fdd75214ff22ef4", "ID": "6acdf90e0d1d32480292cab70fdd75214ff22ef4", "Title": "Hyperspectral Unmixing Based on Mixtures of Dirichlet Components", "Abstract": "A cyclic minimization algorithm is developed where the number of Dirichlet modes is inferred based on the minimum description length principle, thus automatically enforcing the constraints on the abundance fractions imposed by the acquisition process. This paper introduces a new unsupervised hyperspectral unmixing method conceived to linear but highly mixed hyperspectral data sets, in which the simplex of minimum volume, usually estimated by the purely geometrically based algorithms, is far way from the true simplex associated with the endmembers. The proposed method, an extension of our previous studies, resorts to the statistical framework. The abundance fraction prior is a mixture of Dirichlet densities, thus automatically enforcing the constraints on the abundance fractions imposed by the acquisition process, namely, nonnegativity and sum-to-one. A cyclic minimization algorithm is developed where the following are observed: 1) The number of Dirichlet modes is inferred based on the minimum description length principle; 2) a generalized expectation maximization algorithm is derived to infer the model parameters; and 3) a sequence of augmented Lagrangian-based optimizations is used to compute the signatures of the endmembers. Experiments on simulated and real data are presented to show the effectiveness of the proposed algorithm in unmixing problems beyond the reach of the geometrically based state-of-the-art competitors.", "PublicationYear": "2012", "Authors": ["Jos{\\'e} M. P. Nascimento", "Jos{\\'e} M. Bioucas-Dias"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["ed44465f0165e3a7d39737ca7cdfc37c4355e014", "0337e7041779082330ac74cf74aebe79fddb38d2", "f86791a9959c3abb4f15f3d1340e7dd15ec44a0b", "6ba3b3b9122ab0e663af6186267a8c81a1dd661e", "94a178b6edc6dfd907c40f9abc5e29a1297babd3", "d9919fd10760699c7e482bc941298670d8d77837", "cd88b3665a0533b72833929c1b8635622c693ea2", "5220eafbc2fbb3e6d7faaff5a0a9e2a0bc85c5b1", "a16ddf440077328c3e147cc703e8a0fe96d17622", "40b26eb9153fe141f771cc071f3211fcafa717c0"], "ReferenceCount": 69, "CitationCount": 144}, {"URL": "https://www.semanticscholar.org/paper/Semi-supervised-Hyperspectral-Image-Classification-Bandos-Zhou/fe1fed99da2ddb76b07cb636fe30fb673869c469", "ID": "fe1fed99da2ddb76b07cb636fe30fb673869c469", "Title": "Semi-supervised Hyperspectral Image Classification with Graphs", "Abstract": "The proposed method produces smoother classifications with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points with good accuracy in high dimensional spaces and low number of labeled samples (ill-posed situations). This paper presents a semi-supervised graph-based method for the classification of hyperspectral images. The method is designed to exploit the spatial/contextual information in the im- ages through composite kernels. The proposed method produces smoother classifications with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. Good accuracy in high dimensional spaces and low number of labeled samples (ill-posed situations) are produced as compared to standard inductive support vector machines.", "PublicationYear": "2006", "Authors": ["Tatyana V. Bandos", "Dai Zhou", "Gustau Camps-Valls"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["14b64bb5af95367883abd2b95d95979f87bcd5f0", "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "bf61786b0af62554ab7c650a8d473dd8a3729e01", "83e3788925a7a78bcc89a4540c8808f8e2b7acb0", "46770a8e7e2af28f5253e5961f709be74e34c1f6", "230c6c4a855fca11e1259308617d7041ef7f174f", "d36efb9ad91e00faa334b549ce989bfae7e2907a", "4c75b748911ddcd888c5122f7672f69caa5d661f", "b6fff8b8ea77f157913986e7af53951d9fc1128e"], "ReferenceCount": 11, "CitationCount": 25}, {"URL": "https://www.semanticscholar.org/paper/Kernel-based-methods-for-hyperspectral-image-Camps-Valls-Bruzzone/9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "ID": "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "Title": "Kernel-based methods for hyperspectral image classification", "Abstract": "This paper assesses performance of regularized radial basis function neural networks (Reg-RBFNN), standard support vector machines (SVMs), kernel Fisher discriminant (KFD) analysis, and regularized AdaBoost (reg-AB) in the context of hyperspectral image classification. This paper presents the framework of kernel-based methods in the context of hyperspectral image classification, illustrating from a general viewpoint the main characteristics of different kernel-based approaches and analyzing their properties in the hyperspectral domain. In particular, we assess performance of regularized radial basis function neural networks (Reg-RBFNN), standard support vector machines (SVMs), kernel Fisher discriminant (KFD) analysis, and regularized AdaBoost (Reg-AB). The novelty of this work consists in: 1) introducing Reg-RBFNN and Reg-AB for hyperspectral image classification; 2) comparing kernel-based methods by taking into account the peculiarities of hyperspectral images; and 3) clarifying their theoretical relationships. To these purposes, we focus on the accuracy of methods when working in noisy environments, high input dimension, and limited training sets. In addition, some other important issues are discussed, such as the sparsity of the solutions, the computational burden, and the capability of the methods to provide outputs that can be directly interpreted as probabilities.", "PublicationYear": "2005", "Authors": ["Gustau Camps-Valls", "Lorenzo Bruzzone"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["2badd8953397d757693859918cf9318fe7ec5e3b", "c57a50f79bf2e8174b76aed1ccabc53e9e966256", "58a4e754d333b2feafce58b7ec13dc818635099f", "5b92c12e80e82e2302c6f2570f415bbc26f966b0", "beaf082a29bc5e9721de478457cfce30a2047d4a", "0cfcfd98106a63a0b35021a3a1910ec53c62fc3a", "72d9f02f78570d680b9242866f925114061bb8da", "f76bb99b4e9f247d49dc46266f6351267c8db69f", "5260df181b79a5c91622d4c2da6d2c618852d6ff", "7547fd7c5e4bc3b8b8bf714583684ff187e8a382"], "ReferenceCount": 50, "CitationCount": 1417}, {"URL": "https://www.semanticscholar.org/paper/Semi-supervised-cloud-screening-with-Laplacian-SVM-G%C3%B3mez-Chova-Camps-Valls/282cb3c00f517146a81029f4e05e93958024c0eb", "ID": "282cb3c00f517146a81029f4e05e93958024c0eb", "Title": "Semi-supervised cloud screening with Laplacian SVM", "Abstract": "The proposed Laplacian SVM is tested in the challenging problem of cloud screening where the objective is to identify clouds in multispectral images acquired by space-borne sensors working in the visible and near-infrared spectral range. This work evaluates a new semi-supervised classification framework based on kernel methods and graph theory. In particular, the support vector machine (SVM) is further regularized with the un-normalized graph Laplacian, thus leading to the proposed Laplacian SVM. The method is tested in the challenging problem of cloud screening where the objective is to identify clouds in multispectral images acquired by space-borne sensors working in the visible and near-infrared spectral range. Preliminary results obtained using MERIS/ENVISAT data show the potential of the proposed Laplacian SVM in several scenarios.", "PublicationYear": "2007", "Authors": ["Luis G{\\'o}mez-Chova", "Gustau Camps-Valls", "Jordi Mu{\\~n}oz-Mar{\\'i}", "Javier Calpe-Maravilla"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["7c997a648976fb9df320c6ca332c9dc155820454", "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "3e32b4775f3aeff0e1eaf37cc46771376a0c8d08", "58022d9fb8e6c0bb2f8e05def8ee0a020322245e", "82a77879e4d4ce296c2399ac3e82494ca6f74529", "ed3c324be93f30797e0f71d5f5fb5417cdd790bc", "19bb0dce99466077e9bc5a2ad4941607fc28b40c", "554aabebf17b11046ac734aac8ef5a71872e93e3", "d2d13bc44e15fd93480e16305d37c025bc0818c2", "fc8cda36a0972e7de1ac3a7bcb81dc32da79bee4"], "ReferenceCount": 15, "CitationCount": 15}, {"URL": "https://www.semanticscholar.org/paper/Transductive-SVMs-for-semisupervised-classification-Bruzzone-Chi/ad086d2e679f54a4a866183b0f4c27d9fc47861f", "ID": "ad086d2e679f54a4a866183b0f4c27d9fc47861f", "Title": "Transductive SVMs for semisupervised classification of hyperspectral data", "Abstract": "Experimental results obtained on a real hyperspectral image point out that when small-size training data are available, the proposed TSVMs outperform standard inductive support vector machines (ISVMs). This paper presents transductive support vector machines (TSVMs) for the semisupervised classification of hyperspectral remote sensing images. On the basis of the analysis of TSVMs recently introduced in the machine learning literature and of the properties of hyperspectral classification problems, a specific TSVM algorithm is proposed to alleviate the Hughes phenomenon in a nonparametric and kernel-based classification framework. The extension of the proposed technique to multiclass cases is also discussed. Experimental results obtained on a real hyperspectral image point out that when small-size training data are available, the proposed TSVMs outperform standard inductive support vector machines (ISVMs).", "PublicationYear": "2005", "Authors": ["Lorenzo Bruzzone", "Mingmin Chi", "Mattia Marconcini"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["2badd8953397d757693859918cf9318fe7ec5e3b", "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "6f0c5d2ea33f8a02d2e4d9510c543bd760745e52", "7a9b043bdc48f894028e99c24435f591c626871a", "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8", "334867ed99a0af07d8a53dae4f7fdeffffdecc09", "d1fa8485ad749d51e7470d801bc1931706597601", "6d95b96d71669f3f4edfcc95cacd428b62b3fcde", "53fcc056f79e04daf11eb798a7238e93699665aa", "8213dbed4db44e113af3ed17d6dad57471a0c048"], "ReferenceCount": 12, "CitationCount": 32}, {"URL": "https://www.semanticscholar.org/paper/Support-vector-machines-for-hyperspectral-image-Mercier-Lennon/7b22587b518d406e81e10c74719696e439fef2a4", "ID": "7b22587b518d406e81e10c74719696e439fef2a4", "Title": "Support vector machines for hyperspectral image classification with spectral-based kernels", "Abstract": "It appears that modified kernels are presented to take into consideration the spectral similarity between support vectors to outperform SVM-based classification of hyperspectral data cube and reduce false alarms that were induced by illumination effects with classical kernels. Support vector machines (SVM) has been recently used with success for the classification of hyperspectral images. This method appears to be a robust alternative for pattern recognition with hyperspectral data: since the method is based on a geometric point of view, no statistical estimation has to be achieved. Then, SVM outperforms classical supervised classification algorithms such as the maximum likelihood when the number of spectral bands increases or when the number of training samples remains limited. Nevertheless, those kernel-based methods do not take into consideration the spectral similarity between support vectors. Then, some modified kernels are presented to take into consideration the spectral similarity between support vectors to outperform SVM-based classification of hyperspectral data cube. Those kernels (that still suit Mercer's conditions) are based on the use of spectral angle to evaluate the distance between support vectors. Classifiers to compare have been applied to an image from the CASI sensor including 17 bands from 450 to 950nm representing an intensive agricultural region (Brittany, France). It appears that those kernels reduce false alarms that were induced by illumination effects with classical kernels.", "PublicationYear": "2003", "Authors": ["Gr{\\'e}goire Mercier", "Marc Lennon"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["5b92c12e80e82e2302c6f2570f415bbc26f966b0", "a240da170041b9aa798b512160ba9712bf82a56e", "fcc88c373ad1506683fe0620a897f7659bfdcc2f", "7547fd7c5e4bc3b8b8bf714583684ff187e8a382", "fe84db9e87a513b285ab32147cd901782e66616d", "1e8a6bcb64caa49068ccecdf91ef358fafed1ec7", "9e7fa5be24ddda41c9dc9283c94c52f1ae2add6b", "7ea2423a01fc100e50d0b5d8c09ee8ca6f86ee6d", "7550a05bf00f7b24aed9c1ac3ef000575388d21c", "4c75b748911ddcd888c5122f7672f69caa5d661f"], "ReferenceCount": 11, "CitationCount": 271}, {"URL": "https://www.semanticscholar.org/paper/A-Novel-Transductive-SVM-for-Semisupervised-of-Bruzzone-Chi/3e32b4775f3aeff0e1eaf37cc46771376a0c8d08", "ID": "3e32b4775f3aeff0e1eaf37cc46771376a0c8d08", "Title": "A Novel Transductive SVM for Semisupervised Classification of Remote-Sensing Images", "Abstract": "A novel modified TSVM classifier designed for addressing ill-posed remote-sensing problems is proposed that is able to mitigate the effects of suboptimal model selection and can address multiclass cases. This paper introduces a semisupervised classification method that exploits both labeled and unlabeled samples for addressing ill-posed problems with support vector machines (SVMs). The method is based on recent developments in statistical learning theory concerning transductive inference and in particular transductive SVMs (TSVMs). TSVMs exploit specific iterative algorithms which gradually search a reliable separating hyperplane (in the kernel space) with a transductive process that incorporates both labeled and unlabeled samples in the training phase. Based on an analysis of the properties of the TSVMs presented in the literature, a novel modified TSVM classifier designed for addressing ill-posed remote-sensing problems is proposed. In particular, the proposed technique: 1) is based on a novel transductive procedure that exploits a weighting strategy for unlabeled patterns, based on a time-dependent criterion; 2) is able to mitigate the effects of suboptimal model selection (which is unavoidable in the presence of small-size training sets); and 3) can address multiclass cases. Experimental results confirm the effectiveness of the proposed method on a set of ill-posed remote-sensing classification problems representing different operative conditions", "PublicationYear": "2006", "Authors": ["Lorenzo Bruzzone", "Mingmin Chi", "Mattia Marconcini"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["9caf456489bc2a7d54dfc28ea83907ca8ebffdd7", "cc4585a50c4c13fed7068127d12caf82121f5da3", "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "2badd8953397d757693859918cf9318fe7ec5e3b", "8198e70878c907e1bd05e7a3fa4280d8c338df60", "ac9ee5788ee7d431086b9c908e6456ddb8027a2f", "6f0c5d2ea33f8a02d2e4d9510c543bd760745e52", "7f755d620b57acf27a16ff95923c5677ff8198bb", "d2c5d2cafc35856832f2b478790f0af119baab92", "9279fe2192c92b85e7e64ad67300633fc2f1b804"], "ReferenceCount": 34, "CitationCount": 581}, {"URL": "https://www.semanticscholar.org/paper/Robust-support-vector-method-for-hyperspectral-data-Camps-Valls-G%C3%B3mez-Chova/c57a50f79bf2e8174b76aed1ccabc53e9e966256", "ID": "c57a50f79bf2e8174b76aed1ccabc53e9e966256", "Title": "Robust support vector method for hyperspectral data classification and knowledge discovery", "Abstract": "Support vector machines yield better outcomes than neural networks regarding accuracy, simplicity, and robustness, and training neural and neurofuzzy models is unfeasible when working with high-dimensional input spaces and great amounts of training data. We propose the use of support vector machines (SVMs) for automatic hyperspectral data classification and knowledge discovery. In the first stage of the study, we use SVMs for crop classification and analyze their performance in terms of efficiency and robustness, as compared to extensively used neural and fuzzy methods. Efficiency is assessed by evaluating accuracy and statistical differences in several scenes. Robustness is analyzed in terms of: (1) suitability to working conditions when a feature selection stage is not possible and (2) performance when different levels of Gaussian noise are introduced at their inputs. In the second stage of this work, we analyze the distribution of the support vectors (SVs) and perform sensitivity analysis on the best classifier in order to analyze the significance of the input spectral bands. For classification purposes, six hyperspectral images acquired with the 128-band HyMAP spectrometer during the DAISEX-1999 campaign are used. Six crop classes were labeled for each image. A reduced set of labeled samples is used to train the models, and the entire images are used to assess their performance. Several conclusions are drawn: (1) SVMs yield better outcomes than neural networks regarding accuracy, simplicity, and robustness; (2) training neural and neurofuzzy models is unfeasible when working with high-dimensional input spaces and great amounts of training data; (3) SVMs perform similarly for different training subsets with varying input dimension, which indicates that noisy bands are successfully detected; and (4) a valuable ranking of bands through sensitivity analysis is achieved.", "PublicationYear": "2004", "Authors": ["Gustau Camps-Valls", "Luis G{\\'o}mez-Chova", "Javier Calpe-Maravilla", "Jos{\\'e} David Mart{\\'i}n-Guerrero", "Emilio Soria-Olivas", "Luis Alonso", "Jos{\\'e} F. Moreno"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["a89471e9dc0b18284c55631d73df2e489a020b01", "a3e41a217464d08281f202bde7d9251902772c7b", "9f1c580c6d8584be5440114d63d323be5aedef24", "4c41519acfa60972ce8a1d8c22736a1821d3a56c", "a240da170041b9aa798b512160ba9712bf82a56e", "b9ddc16cd2449e93d44c1c5360dcf765b91de099", "5b92c12e80e82e2302c6f2570f415bbc26f966b0", "6570084d4678746f439bc9baa6ff1182e99ee114", "6fa08993cbbfb19bcb9124dce3d2520312689d2e", "b0a7e26ec7bcc844abf209222c17d0a5b6d53a0e"], "ReferenceCount": 68, "CitationCount": 290}, {"URL": "https://www.semanticscholar.org/paper/Composite-kernels-for-hyperspectral-image-Camps-Valls-G%C3%B3mez-Chova/14b64bb5af95367883abd2b95d95979f87bcd5f0", "ID": "14b64bb5af95367883abd2b95d95979f87bcd5f0", "Title": "Composite kernels for hyperspectral image classification", "Abstract": "This framework of composite kernels demonstrates enhanced classification accuracy as compared to traditional approaches that take into account the spectral information only, flexibility to balance between the spatial and spectral information in the classifier, and computational efficiency. This letter presents a framework of composite kernel machines for enhanced classification of hyperspectral images. This novel method exploits the properties of Mercer's kernels to construct a family of composite kernels that easily combine spatial and spectral information. This framework of composite kernels demonstrates: 1) enhanced classification accuracy as compared to traditional approaches that take into account the spectral information only: 2) flexibility to balance between the spatial and spectral information in the classifier; and 3) computational efficiency. In addition, the proposed family of kernel classifiers opens a wide field for future developments in which spatial and spectral information can be easily integrated.", "PublicationYear": "2006", "Authors": ["Gustau Camps-Valls", "Luis G{\\'o}mez-Chova", "Jordi Mu{\\~n}oz-Mar{\\'i}", "Joan Vila-Franc{\\'e}s", "Javier Calpe-Maravilla"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6", "afa1265171e46354fac4b521f5907927803220ac", "7b22587b518d406e81e10c74719696e439fef2a4", "2badd8953397d757693859918cf9318fe7ec5e3b", "c57a50f79bf2e8174b76aed1ccabc53e9e966256", "5053dc68eea95b4248abc94bbfa6894d4b203e14", "0cfcfd98106a63a0b35021a3a1910ec53c62fc3a", "2b7c2f2404d5b53554c97335e509a817245aa723", "7547fd7c5e4bc3b8b8bf714583684ff187e8a382", "326118e307ea881899b9c2a9ca2de9456fb7619b"], "ReferenceCount": 27, "CitationCount": 1037}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-segmentation-of-multitemporal-SAR-Dammert-Askne/2ee856d5b6acc20f1313943d77374b37826ff97f", "ID": "2ee856d5b6acc20f1313943d77374b37826ff97f", "Title": "Unsupervised segmentation of multitemporal interferometric SAR images", "Abstract": "This paper shows how to segment large data sets of multitemporal and interferometric SAR images using an unsupervised, fuzzy clustering method which may drastically reduce the number of images and improves the final results. This paper shows how to segment large data sets of multitemporal and interferometric SAR images using an unsupervised, fuzzy clustering method. An adaptive feature extraction (principal component transformation) is employed which may drastically reduce the number of images and improves the final results. This also speeds up the fuzzy clustering iteration part considerably. The method is applied to data over two areas in Sweden: one typical urban area with forest and farmland surroundings and a forested area. The best classification accuracy is obtained when classifying the data into two classes, agreeing with the predictions of the cluster validity parameters used in this study. The method always finds the dominating land-covers in the images first. These are then subdivided as more clusters (classes) are identified, indicating that the segmentation is moderately hierarchical. The final classification results, between 65% and 75%, are comparable to those obtained in other studies. Analyzing the final cluster signatures reveals that the current unsupervised method has several similarities with rule-based methods.", "PublicationYear": "1999", "Authors": ["Patrik B. G. Dammert", "Jan I. H. Askne", "Sharon K{\\\"u}hlmann"], "RelatedTopics": ["Engineering", "Environmental Science"], "References": ["e63ca6917e7371849c2099a41cd5bbcdbe7df156", "af8b405f1cae74bb2d257ff11b9039225e1d11b1", "685082f58dc6757b106eb284657032dd301a097d", "bfba9da9e769e9338802078648597886b32a7783", "31e4a83031a31c289a96eb3fd4f6e8ff628a0d73", "04922468ad98d029e16b9b03235abd46a226ea67", "56dfbc418bdd878d1614aa7788e554602ed10534", "59d27c058a2d54c4d088becbb0e68f475b1e375e", "ecd3be3e9c6b114429acefc0673be0f4a090c61f", "07d7a4a6e55a9ebf9e6aab0204b130a81eab6e7c"], "ReferenceCount": 37, "CitationCount": 29}, {"URL": "https://www.semanticscholar.org/paper/Classification-and-feature-extraction-for-remote-on-Benediktsson-Pesaresi/ed4f21d6fd4ea0cd2decba6f126cf05e9d7c1326", "ID": "ed4f21d6fd4ea0cd2decba6f126cf05e9d7c1326", "Title": "Classification and feature extraction for remote sensing images from urban areas based on morphological transformations", "Abstract": "It is seen that relatively few features are needed to achieve the same classification accuracies as in the original feature space when classification of panchromatic high-resolution data from urban areas using morphological and neural approaches. Classification of panchromatic high-resolution data from urban areas using morphological and neural approaches is investigated. The proposed approach is based on three steps. First, the composition of geodesic opening and closing operations of different sizes is used in order to build a differential morphological profile that records image structural information. Although, the original panchromatic image only has one data channel, the use of the composition operations will give many additional channels, which may contain redundancies. Therefore, feature extraction or feature selection is applied in the second step. Both discriminant analysis feature extraction and decision boundary feature extraction are investigated in the second step along with a simple feature selection based on picking the largest indexes of the differential morphological profiles. Third, a neural network is used to classify the features from the second step. The proposed approach is applied in experiments on high-resolution Indian Remote Sensing 1C (IRS-1C) and IKONOS remote sensing data from urban areas. In experiments, the proposed method performs well in terms of classification accuracies. It is seen that relatively few features are needed to achieve the same classification accuracies as in the original feature space.", "PublicationYear": "2003", "Authors": ["J{\\'o}n Atli Benediktsson", "Martino Pesaresi", "Kolbeinn Amason"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["426c411a8725c8a6ca5d441512abe830d06687f9", "a9add89c424065562b6cf8c7e9ded69af8429cd8", "2c5d1eeade42c67c2f9c8e4e0a279850a5a7b088", "b56634bc0cad05e7adffd48aa0609616c3c10b2e", "63100c07af445d5cdbb976b7f7604cd1d1d118d9", "de26cb4a4eddfcc30c8c05be865ff9ee6117ad00", "679424fde825da349d6e2149d9cd67342dc26e3d", "c22e733914de4477c6bd29f32234e01379df650b", "aa8ad0d55d0ae799cd4081fecc13d5f7ad9d982f", "442c48540b4cf9f36b7e69e38de5c1eb65f161d0"], "ReferenceCount": 15, "CitationCount": 794}, {"URL": "https://www.semanticscholar.org/paper/Morphological-transformations-and-feature-of-urban-Palmason-Benediktsson/ead23f99658e2370d3c20428635c4d90e71cfb69", "ID": "ead23f99658e2370d3c20428635c4d90e71cfb69", "Title": "Morphological transformations and feature extraction of urban data with high spectral and spatial resolution", "Abstract": "The morphological approach is applied in experiments on high resolution DAIS remote sensing data from an urban area and it is observed that classification on reduced features gives higher accuracies than in the original feature space. The classification of urban data with high spectral and spatial resolution is considered. For processing, a morphological profile is constructed. The morphological profile is based on the repeated use of opening and closings with a differently sized structuring element. Morphological profiles have been shown to contain redundancies. Therefore, feature extraction is applied on the profile. The morphological approach is applied in experiments on high resolution DAIS remote sensing data from an urban area. To apply the morphological approach on the DAIS data, the first principal component is used as a basis for the morphological transformations. In experiments, the use of the morphological method performs well in terms of classification accuracies. With feature extraction, it is observed that classification on reduced features gives higher accuracies than in the original feature space.", "PublicationYear": "2003", "Authors": ["Jon Aevar Palmason", "J{\\'o}n Atli Benediktsson", "Kolbeinn {\\'A}rnason"], "RelatedTopics": ["Environmental Science", "Engineering", "Computer Science"], "References": ["a9add89c424065562b6cf8c7e9ded69af8429cd8", "442c48540b4cf9f36b7e69e38de5c1eb65f161d0", "c22e733914de4477c6bd29f32234e01379df650b", "de26cb4a4eddfcc30c8c05be865ff9ee6117ad00"], "ReferenceCount": 5, "CitationCount": 33}, {"URL": "https://www.semanticscholar.org/paper/Evaluation-of-MIVIS-hyperspectral-data-for-mapping-Fiumi/554006f9a6fb65441208956464e54bfb470916d5", "ID": "554006f9a6fb65441208956464e54bfb470916d5", "Title": "Evaluation of MIVIS hyperspectral data for mapping covering materials", "Abstract": "LARA, namely Airborne Laboratory for Environmental Research, is a division of the Atmospheric Pollution Institute of the Italian National Research Council; it carries out research activities by using hyperspectral data. acquired by means of MIVIS (Multispectral Infrared Visible Imaging Spectrometer). Over the years methodologies applied to the hyperspectral MIVIS data collected over different Italian towns (Rome, Naples, Milan, Verona, etc.) have been developed to discriminate and quantify urban elements and materials, like surface coatings, not covered structures, urban buildings, open air depots, vegetation, rivers, mobile elements and materials, shaded and sunny areas. Classification methodologies developed through the analysis of spectral responses, besides recognizing building elements with the maximum accuracy, are also able to discriminate the slightest variations of covering surfaces and distinguish a wide range of sub-classes which stress the typological characteristics of covering materials (bricks, grits, copper, lead, etc.). In particular a study aimed at assessing the potentiality of MIVIS hyperspectral data to map land coverings and monitor a sub-urban area of Rome, with a special attention to asbestos-cement coatings, is presented here. Data have been processed by means of a method known as spectral angle mapping (SAM). The results of this research, although they could be further validated from a methodological point of view, are at present already encouraging as they demonstrate possible successful operative applications of MIVIS data for monitoring the urban environment.", "PublicationYear": "2001", "Authors": ["L. Fiumi"], "RelatedTopics": ["Environmental Science"], "References": ["286a2be63f39a17c1c7431f761ddd4d923bb8b02"], "ReferenceCount": 0, "CitationCount": 10}, {"URL": "https://www.semanticscholar.org/paper/Automated-differentiation-of-urban-surfaces-based-Roessner-Segl/3f4a398762ae9cf721361d8c6b5a020be9dc5ef1", "ID": "3f4a398762ae9cf721361d8c6b5a020be9dc5ef1", "Title": "Automated differentiation of urban surfaces based on airborne hyperspectral imagery", "Abstract": "The results and their comparison with standard spectral classification methods show that the new pixel- and contest-based approach enables reasonable material-oriented differentiation of urban surfaces. The urban environment is characterized by an intense use of the available space, where the preservation of open green spaces is of special ecological importance. Because of dynamic urban development and high mapping costs, municipal authorities are interested in effective methods for mapping urban surface cover types that can be used for evaluating ecological conditions in urban structures and supporting updates of biotope mapping. Against this background, airborne hyperspectral remote sensing data of the DAIS 7915 instrument have been analyzed for their potential in automated area-wide differentiation of ecologically meaningful urban surface cover types for a study area in the city of Dresden, Germany. The small urban structures and the high spectral information content of the hyperspectral image data require the development of special methods capable of dealing with the resulting large number of mixed pixels. In this paper, a new approach is presented that combines advantages of classification with linear spectral unmixing. Since standard unmixing techniques are not suitable for an area-wide analysis of urban surfaces representing a large number of spectrally similar endmembers (EMs), the mathematical model, were extended and a new method for pixel-oriented EM selection was developed. This method reduces the number of possible EM combination for each pixel by introducing spectrally pure seedlings and a list of possible EM combinations into a neighborhood-oriented iterative unmixing procedure. The results and their comparison with standard spectral classification methods show that the new pixel- and contest-based approach enables reasonable material-oriented differentiation of urban surfaces.", "PublicationYear": "2001", "Authors": ["Sigrid Roessner", "Karl Segl", "Uta Heiden", "Hermann Kaufmann"], "RelatedTopics": ["Environmental Science"], "References": ["7982e5ff10ca758d6066f077a4fed2ca3af30c24", "9cca8ecf96fe1c0dbb2711e12c29eeccff11fea2", "7e9bbe1e47f9655eaf48681156df49dd4f347872", "268cbcc7e31bf1ccdc8991f2a149d65dd80395de", "f7e672743ae290c4dd5ee01a03c5a5f59b9a66fa", "488ce2aee490784fa68e3c7a4c52f8a629856d09", "6c92cdb1ee042f38da295b4968fc1db27f7082ca", "c9e0fa2e61f942d06cf06febbb878da4ef009ee4", "d751e42c63e39c6ad8ca80084afaac53d323c46d", "f9d22746bca7353e242ec226eb781ce825da11e0"], "ReferenceCount": 35, "CitationCount": 179}, {"URL": "https://www.semanticscholar.org/paper/A-new-method-for-target-detection-in-hyperspectral-Plaza-Mart%C3%ADnez/f306d6e22c997cd2de22cd0ad00b9612a5701c87", "ID": "f306d6e22c997cd2de22cd0ad00b9612a5701c87", "Title": "A new method for target detection in hyperspectral imagery based on extended morphological profiles", "Abstract": "A new unsupervised algorithm for the detection of both full pixel and mixed pixel targets in hyperspectral imagery is described, which automatically resolves targets by using extended mathematical morphology operations. Hyperspectral remote sensing increases the detectability of pixel-and subpixel-sized targets by exploiting the finer detail in the spectral signatures. In this paper, we describe a new unsupervised algorithm for the detection of both full pixel and mixed pixel targets in hyperspectral imagery. The proposed method automatically resolves targets by using extended mathematical morphology operations. The performance of the resulting detector is experimentally evaluated using simulated and real hyperspectral data collected by the NASA/Jet Propulsion Laboratory Airborne Visible/Infrared Imaging Spectrometer and the DLR Reflective Optics System Imaging Spectrometer (ROSIS).", "PublicationYear": "2003", "Authors": ["Antonio J. Plaza", "Pablo Mart{\\'i}nez", "Rosa M. P{\\'e}rez", "Javier Plaza"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "a9add89c424065562b6cf8c7e9ded69af8429cd8", "081ab5a5e28e54a2a869493600154e47ac5affe2", "9aec7cb9d361b1b1ea6b89e67c80363dd370777f", "f08ee063d9834c09acbf8327ede898cfc402bd88"], "ReferenceCount": 6, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Analysis-of-spectral-signatures-of-urban-surfaces-Heiden-Roessner/5e85f4cefa96286387a9717e3260111d64d7e2ae", "ID": "5e85f4cefa96286387a9717e3260111d64d7e2ae", "Title": "Analysis of spectral signatures of urban surfaces for their identification using hyperspectral HyMap data", "Abstract": "In this study a spectral library was developed, which forms the database for an area-wide identification of urban surface materials using hyperspectral HyMap data. Spectra are measured with a field spectrometer in the wavelength range between 0.35-2.5 /spl mu/m in 2151 channels. For the systematic assessment of materials the urban surface is categorized in regard to its degree of surface sealing resulting in urban surface cover types. These resulting categories form the thematic frame for the assessment of urban surface materials. The presented surface materials of the sealed category belong to e.g. the ceramic/mineral group, metallic or synthetic group. They are analyzed in regard to variations in color or manufacturing types. Non-sealed surfaces, such as soil, or vegetation are investigated in regard to their urban characteristics. The obtained spectral library is used to explore the spectral information content of hyperspectral HyMap data of Dresden, Germany. For an area-wide identification of urban surface materials, a combined classification and unmixing approach was applied leading to a precise identification of surface materials. Thereby, this technique benefits from the extracted knowledge about the spectral characteristics of urban surface materials.", "PublicationYear": "2001", "Authors": ["Uta Heiden", "Sigrid Roessner", "Karl Segl", "H. Kaufmann"], "RelatedTopics": ["Environmental Science", "Engineering"], "References": ["12a06b7e6691b918a02174b7cdc8eb1ca1f0abd9", "3f4a398762ae9cf721361d8c6b5a020be9dc5ef1", "268cbcc7e31bf1ccdc8991f2a149d65dd80395de", "5c811e1e7acc21de935ef568f7620f2bcea33b88", "849784c9d1fe958928f043a9d65701089622836d", "28b004d775a55f8f8ca1c0c4c638ec3ca03fe673", "d92f5b364f25839d82dd3ad7e0ebe46c8933086e", "bb93030f7d18bf94f659bd1228e3701cbbe3be52", "a69be3147642c638621eebb45ed92894ce0e20d6", "d6d90ca316b10199236f28926df4f29b8e01aa74"], "ReferenceCount": 12, "CitationCount": 38}, {"URL": "https://www.semanticscholar.org/paper/Exploiting-spectral-and-spatial-information-for-in-Dell%E2%80%99acqua-Gamba/c69db8cf4a77466e8a8b52fcc2ef1ca0e503764c", "ID": "c69db8cf4a77466e8a8b52fcc2ef1ca0e503764c", "Title": "Exploiting spectral and spatial information for classifying hyperspectral data in urban areas", "Abstract": "Very high resolution hyperspectral data are used to provide detailed maps of urban land cover, exploiting different classification tools, using multiple classifications and spatial refinement step to improve the mapping accuracy. This paper is devoted to urban hyperspectral remote sensing. Very high resolution hyperspectral data are used to provide detailed maps of urban land cover, exploiting different classification tools. In particular, multiple classifications and spatial refinement step are used to improve the mapping accuracy. We show results on DAIS data over the town of Pavia, Northern Italy. The four flight lines over the area, kindly provided by DLR in the framework of the HySens project, are partially overlapping. This helps, besides the test of the classification procedure here presented, even to understand the advantages of combining different views of the same area.", "PublicationYear": "2003", "Authors": ["Fabio Dell\u2019acqua", "Paolo Gamba", "Alessio Ferrari"], "RelatedTopics": ["Environmental Science", "Engineering"], "References": ["3f4a398762ae9cf721361d8c6b5a020be9dc5ef1", "0c1993e6fa2f9bb35fddde5f42ec3f3013073d04", "af6ebe79d99b1bb620552108d732af223c03156c"], "ReferenceCount": 4, "CitationCount": 28}, {"URL": "https://www.semanticscholar.org/paper/A-model-based-mixture-supervised-classification-in-Dundar-Landgrebe/eb925519b2cea6f75158f26ba57e70eee7c139f9", "ID": "eb925519b2cea6f75158f26ba57e70eee7c139f9", "Title": "A model-based mixture-supervised classification approach in hyperspectral data analysis", "Abstract": "A model- based mixture classifier, which uses mixture models to characterize class densities and the structure of class covariances is addressed through a model-based covariance estimation technique introduced in this paper. It is well known that there is a strong relation between class definition precision and classification accuracy in pattern classification applications. In hyperspectral data analysis, usually classes of interest contain one or more components and may not be well represented by a single Gaussian density function. In this paper, a model-based mixture classifier, which uses mixture models to characterize class densities, is discussed. However, a key outstanding problem of this approach is how to choose the number of components and determine their parameters for such models in practice, and to do so in the face of limited training sets where estimation error becomes a significant factor. The proposed classifier estimates the number of subclasses and class statistics simultaneously by choosing the best model. The structure of class covariances is also addressed through a model-based covariance estimation technique introduced in this paper.", "PublicationYear": "2002", "Authors": ["Murat Dundar", "David A. Landgrebe"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["34c78111224edf131ef9125254653b59722001f5", "663295171635241f9ba05432861929cda40d569d", "f85d66b2797eb1ab1da0f271286765991f766abe", "0b33f113bf20174ad602ea5b60151e76c6c56121", "114e1354cee7a687ae694f7d8134c7afc87abb47", "53b1f543ea8bcff02005f1322625f55ec52750a9", "2b5db2ef319226e1a019c10bd17af0c283b56cf7", "7ee1c6a35f55e04516a7e9578f961167b48a925a", "eab6475fa1dd6241cfcd72680aebcd571e134760", "7d50991b693fc23edda316fb1487f114f6cc6706"], "ReferenceCount": 15, "CitationCount": 66}, {"URL": "https://www.semanticscholar.org/paper/Improved-statistics-estimation-and-feature-for-data-Kuo-Landgrebe/e52e9bfe2932765ac6d8b1ac9ada313f98b4d08f", "ID": "e52e9bfe2932765ac6d8b1ac9ada313f98b4d08f", "Title": "Improved statistics estimation and feature extraction for hyperspectral data classification", "Abstract": "Experimental results show that using NWFE features applied to a mixture classifier based on the Mixed-LOOC2 covariance estimator has the best performance and is a robust procedure for classifying hyperspectral data. For hyperspectral data classification, the avoidance of singularity of covariance estimates or excessive near singularity estimation error due to limited training data is a key problem. This study is intended to solve problem via regularized covariance estimators and feature extraction algorithms. A second purpose is to build a robust classification procedure with the advantages of the algorithms proposed in this study but robust in the sense of not requiring extensive analyst operator skill. \\nA pair of covariance estimators called Mixed-LOOCs is proposed for avoiding excessive covariance estimator error. Mixed-LOOC2 has advantages over LOOC and BLOOC and needs less computation than those two. Based on Mixed-LOOC2, new DAFE and mixture classifier algorithms are proposed. \\nCurrent feature extraction algorithms, while effective in some circumstances, have significant limitations. Discriminate analysis feature extraction (DAFE) is fast but does not perform well with classes whose mean values are similar, and it produces only N-1 reliable features where N is the number of classes. Decision Boundary Feature Extraction does not have these limitations but does not perform well when training sets are small. A new nonparametric feature extraction method (NWFE) is developed to solve the problems of DAFE and DBFE. NWFE takes advantage of the desirable characteristics of DAFE and DBFE, while avoiding their shortcomings. \\nFinally, experimental results show that using NWFE features applied to a mixture classifier based on the Mixed-LOOC2 covariance estimator has the best performance and is a robust procedure for classifying hyperspectral data.", "PublicationYear": "2001", "Authors": ["Bor-Chen Kuo", "David A. Landgrebe"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["70525e69b8ebb7ee6bf72203059acda60072f567", "34c78111224edf131ef9125254653b59722001f5", "41d3bca9e168759799ab36bfcb04153dd095dca7", "902dcaa186d1156801f2d5d279c2706608796bf6", "75580b789a21a5ce7aabeacfec290a38867a4019", "07ac49a76e9ad5fe0aed2ccf384dd53d99898855", "d0d2229931c83043adeb8ee2334d09c71b3dcd15", "53b1f543ea8bcff02005f1322625f55ec52750a9", "58986f894c11447423f72b90445995d9ea770163", "5e23c634a7beb02a127ecb11551fd0333491c602"], "ReferenceCount": 25, "CitationCount": 34}, {"URL": "https://www.semanticscholar.org/paper/A-new-approach-for-the-morphological-segmentation-Pesaresi-Benediktsson/a9add89c424065562b6cf8c7e9ded69af8429cd8", "ID": "a9add89c424065562b6cf8c7e9ded69af8429cd8", "Title": "A new approach for the morphological segmentation of high-resolution satellite imagery", "Abstract": "The proposed method performs well in the presence of both low radiometric contrast and relatively low spatial resolution, which may produce a textural effect, a border effect, and ambiguity in the object/background distinction. A new segmentation method based on the morphological characteristic of connected components in images is proposed. Theoretical definitions of morphological leveling and morphological spectrum are used in the formal definition of a morphological characteristic. In multiscale segmentation, this characteristic is formalized through the derivative of the morphological profile. Multiscale segmentation is particularly well suited for complex image scenes such as aerial or fine resolution satellite images, where very thin, enveloped and/or nested regions must be retained. The proposed method performs well in the presence of both low radiometric contrast and relatively low spatial resolution. Those factors may produce a textural effect, a border effect, and ambiguity in the object/background distinction. Segmentation examples for satellite images are given.", "PublicationYear": "2001", "Authors": ["Martino Pesaresi", "J{\\'o}n Atli Benediktsson"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["4cf2be80a7c7a41d552e730f1287dc0dc97eb7ac", "426c411a8725c8a6ca5d441512abe830d06687f9", "796625850931034e84c789872db2e29ec35c054d", "cbdac03baf33c620a7ba19bf3516b51cb106c66e", "8facac98780a9dfa0c92dec8849b9f9945af8e50", "679424fde825da349d6e2149d9cd67342dc26e3d", "aa8ad0d55d0ae799cd4081fecc13d5f7ad9d982f", "442c48540b4cf9f36b7e69e38de5c1eb65f161d0", "d067212358e18aa48f85876b4452fecd9660ac66", "0e9acfa93414bb4752bb08829c06a36133c14f63"], "ReferenceCount": 23, "CitationCount": 887}, {"URL": "https://www.semanticscholar.org/paper/A-quantitative-and-comparative-analysis-of-from-Plaza-Mart%C3%ADnez/23d92dc4598dd7dfa78560f187fa75524584c038", "ID": "23d92dc4598dd7dfa78560f187fa75524584c038", "Title": "A quantitative and comparative analysis of endmember extraction algorithms from hyperspectral data", "Abstract": "A comparative study of standard endmember extraction algorithms using a custom-designed quantitative and comparative framework that involves both the spectral and spatial information indicates that endmember selection and subsequent mixed-pixel interpretation by a linear mixture model are more successful when methods combining spatial and spectral information are applied. Linear spectral unmixing is a commonly accepted approach to mixed-pixel classification in hyperspectral imagery. This approach involves two steps. First, to find spectrally unique signatures of pure ground components, usually known as endmembers, and, second, to express mixed pixels as linear combinations of endmember materials. Over the past years, several algorithms have been developed for autonomous and supervised endmember extraction from hyperspectral data. Due to a lack of commonly accepted data and quantitative approaches to substantiate new algorithms, available methods have not been rigorously compared by using a unified scheme. In this paper, we present a comparative study of standard endmember extraction algorithms using a custom-designed quantitative and comparative framework that involves both the spectral and spatial information. The algorithms considered in this study represent substantially different design choices. A database formed by simulated and real hyperspectral data collected by the Airborne Visible and Infrared Imaging Spectrometer (AVIRIS) is used to investigate the impact of noise, mixture complexity, and use of radiance/reflectance data on algorithm performance. The results obtained indicate that endmember selection and subsequent mixed-pixel interpretation by a linear mixture model are more successful when methods combining spatial and spectral information are applied.", "PublicationYear": "2004", "Authors": ["Antonio J. Plaza", "Pablo Mart{\\'i}nez", "Rosa M. P{\\'e}rez", "Javier Plaza"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "11286397e82f182fefbe555f6143d4a5ea1381c9", "0b5268541794302492e125c1f9840206ed2c5158", "4fb902607d7ef949736a377babf5bdd325a3b546", "4d3e9019eedec5e69864dcc2c814a0dff8cea826", "954c621a5be1193166e9c610e8323eff942da0a7", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "44cb48ed3c114a0072ac8061319c58dae85054ff", "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3", "3025669d7e66823fd97262ce2f22571845355606"], "ReferenceCount": 29, "CitationCount": 638}, {"URL": "https://www.semanticscholar.org/paper/Mapping-target-signatures-via-partial-unmixing-of-Boardman-Kruse/a70157e7089b12b5cc8f0c5603f6970bbb0dadad", "ID": "a70157e7089b12b5cc8f0c5603f6970bbb0dadad", "Title": "Mapping target signatures via partial unmixing of AVIRIS data: in Summaries", "Abstract": "A complete spectral unmixing of a complicated AVIRIS scene may not always be possible or even desired. High quality data of spectrally complex areas are very high dimensional and are consequently difficult to fully unravel. Partial unmixing provides a method of solving only that fraction of the data inversion problem that directly relates to the specific goals of the investigation. Many applications of imaging spectrometry can be cast in the form of the following question: 'Are my target signatures present in the scene, and if so, how much of each target material is present in each pixel?' This is a partial unmixing problem. The number of unmixing endmembers is one greater than the number of spectrally defined target materials. The one additional endmember can be thought of as the composite of all the other scene materials, or 'everything else'. Several workers have proposed partial unmixing schemes for imaging spectrometry data, but each has significant limitations for operational application. The low probability detection methods described by Farrand and Harsanyi and the foreground-background method of Smith et al are both examples of such partial unmixing strategies. The new method presented here builds on these innovative analysis concepts, combining their different positive attributes while attempting to circumvent their limitations. This new method partially unmixes AVIRIS data, mapping apparent target abundances, in the presence of an arbitrary and unknown spectrally mixed background. It permits the target materials to be present in abundances that drive significant portions of the scene covariance. Furthermore it does not require a priori knowledge of the background material spectral signatures. The challenge is to find the proper projection of the data that hides the background variance while simultaneously maximizing the variance amongst the targets.", "PublicationYear": "1995", "Authors": ["Joseph W. Boardman", "Fred A. Kruse", "Robert O. Green"], "RelatedTopics": ["Physics", "Environmental Science", "Engineering"], "References": ["efd13aa38e7b2ade54336f9afe10fbf79ab442a2", "2026074a08f81f890b191afcd500ecb8847af92b", "6ae00ebd3a91c0667c79c39035b5163025bcfcad", "c78a1b5c930f81ea8d9380fb5f9e0f1c96471e35", "ac2c1084720b12d139156261fe2280f26ee1ffb7", "2b2235386f196686dd39ad53c6f861ee2727f8b1"], "ReferenceCount": 8, "CitationCount": 1317}, {"URL": "https://www.semanticscholar.org/paper/Minimum-Volume-Simplex-Analysis%3A-A-Fast-Algorithm-Li-Bioucas-Dias/6ba3b3b9122ab0e663af6186267a8c81a1dd661e", "ID": "6ba3b3b9122ab0e663af6186267a8c81a1dd661e", "Title": "Minimum Volume Simplex Analysis: A Fast Algorithm to Unmix Hyperspectral Data", "Abstract": "This paper presents a new method of minimum volume class for hyperspectral unmixing, termed minimum volume simplex analysis (MVSA), and illustrates the state-of-the-art performance of the MVSA algorithm in un Mixing simulated data sets. This paper presents a new method of minimum volume class for hyperspectral unmixing, termed minimum volume simplex analysis (MVSA). The underlying mixing model is linear; i.e., the mixed hyperspectral vectors are modeled by a linear mixture of the end-member signatures weighted by the correspondent abundance fractions. MVSA approaches hyperspectral unmixing by fitting a minimum volume simplex to the hyperspectral data, constraining the abundance fractions to belong to the probability simplex. The resulting optimization problem is solved by implementing a sequence of quadratically constrained subproblems. In a final step, the hard constraint on the abundance fractions is replaced with a hinge type loss function to account for outliers and noise. We illustrate the state-of-the-art performance of the MVSA algorithm in unmixing simulated data sets. We are mainly concerned with the realistic scenario in which the pure pixel assumption (i.e., there exists at least one pure pixel per end member) is not fulfilled. In these conditions, the MVSA yields much better performance than the pure pixel based algorithms.", "PublicationYear": "2008", "Authors": ["Jun Li", "Jos{\\'e} M. Bioucas-Dias"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["0337e7041779082330ac74cf74aebe79fddb38d2", "26eaa00bc27aeb0a5bac4b1233697257a1ef9167", "954c621a5be1193166e9c610e8323eff942da0a7", "23d92dc4598dd7dfa78560f187fa75524584c038", "cd88b3665a0533b72833929c1b8635622c693ea2", "6ad6afe56f793a3a4facaa9e2dd2ec3622f1940b", "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "273ebdbefd2b0d9653491fed7bb7fb9c645a7171", "7de96c39028bcda531a437d8345489213f2fdf0c", "10ad2ec4ebcbecd4b2ddd3e88f9b125caf50a2fc"], "ReferenceCount": 18, "CitationCount": 402}, {"URL": "https://www.semanticscholar.org/paper/Does-independent-component-analysis-play-a-role-in-Nascimento-Bioucas-Dias/1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "ID": "1d10936a91dd0d570c764b5dffc67b6421b9b5fe", "Title": "Does independent component analysis play a role in unmixing hyperspectral data?", "Abstract": "The accuracy of these methods tends to improve with the increase of the signature variability, of the number of endmembers, and of the signal-to-noise ratio, and it is concluded that there are always endmembers incorrectly unmixed. Independent component analysis (ICA) has recently been proposed as a tool to unmix hyperspectral data. ICA is founded on two assumptions: 1) the observed spectrum vector is a linear mixture of the constituent spectra (endmember spectra) weighted by the correspondent abundance fractions (sources); 2)sources are statistically independent. Independent factor analysis (IFA) extends ICA to linear mixtures of independent sources immersed in noise. Concerning hyperspectral data, the first assumption is valid whenever the multiple scattering among the distinct constituent substances (endmembers) is negligible, and the surface is partitioned according to the fractional abundances. The second assumption, however, is violated, since the sum of abundance fractions associated to each pixel is constant due to physical constraints in the data acquisition process. Thus, sources cannot be statistically independent, this compromising the performance of ICA/IFA algorithms in hyperspectral unmixing. This paper studies the impact of hyperspectral source statistical dependence on ICA and IFA performances. We conclude that the accuracy of these methods tends to improve with the increase of the signature variability, of the number of endmembers, and of the signal-to-noise ratio. In any case, there are always endmembers incorrectly unmixed. We arrive to this conclusion by minimizing the mutual information of simulated and real hyperspectral mixtures. The computation of mutual information is based on fitting mixtures of Gaussians to the observed data. A method to sort ICA and IFA estimates in terms of the likelihood of being correctly unmixed is proposed.", "PublicationYear": "2003", "Authors": ["Jos{\\'e} M. P. Nascimento", "Jos{\\'e} M. Bioucas-Dias"], "RelatedTopics": ["Environmental Science"], "References": ["f363e7f2ee361fd38de50057d53c828c396d5ba4", "b7137c928d5531fce2c8873c18a5aa0db2bd132c", "77f964d83ed93648b17585df764ae914c60890be", "70a898b7a620b89ebeaa81f9f6df7702836a2ed6", "804519f49feee4d2bfafdc0db6d0d10f7f3ebf0c", "678ddfa79d0db8528d2deb4b52dc3b9118165708", "2b7533390fdc1726c2c89ad095741c4e0ffbd1af", "cdac03f90b204ecafa49baaf9535810fbf64f61d", "16785a5bd8c159885b6e7ab974584a954360874f", "e6334789ec6d43664f8f164a462461a4408243ba"], "ReferenceCount": 79, "CitationCount": 388}, {"URL": "https://www.semanticscholar.org/paper/Support-vector-machines-for-classification-of-Melgani-Bruzzone/a240da170041b9aa798b512160ba9712bf82a56e", "ID": "a240da170041b9aa798b512160ba9712bf82a56e", "Title": "Support vector machines for classification of hyperspectral remote-sensing images", "Abstract": "This paper investigates the effectiveness of SVMs in terms of classification accuracy, computational time and stability to parameter setting, and suggests them as a promising tool to classify hyperspectral remote-sensing images. In this paper, we address the problem of classification of hyperspectral remote-sensing images (in the original hyperdimensional feature space) by Support Vector Machines (SVMs). In particular, we investigate the effectiveness of SVMs in terms of classification accuracy, computational time and stability to parameter setting. Experiments, carried out on a standard AVIRIS hyperspectral data set, include a comparison with two other widely used nonparametric approaches, i.e., the K-nn and the Radial Basis Function (RBF) neural networks classifiers. The obtained results point out interesting properties of SVMs in hyperdimensional feature spaces and suggest them as a promising tool to classify hyperspectral remote-sensing images.", "PublicationYear": "2002", "Authors": ["Farid Melgani", "Lorenzo Bruzzone"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["f83b85d8daa4ee370982842a809b5c8dba63b645", "b9ddc16cd2449e93d44c1c5360dcf765b91de099", "beaf082a29bc5e9721de478457cfce30a2047d4a", "0078881114307a8daa26c69afab34d582011f5f3", "4c75b748911ddcd888c5122f7672f69caa5d661f"], "ReferenceCount": 5, "CitationCount": 90}, {"URL": "https://www.semanticscholar.org/paper/Support-vector-machines-for-hyperspectral-remote-Gualtieria-CrompbaApplied/5b92c12e80e82e2302c6f2570f415bbc26f966b0", "ID": "5b92c12e80e82e2302c6f2570f415bbc26f966b0", "Title": "Support vector machines for hyperspectral remote sensing classification", "Abstract": "A key feature of this classifier is its ability to use high-dimensional data without the usual recourse to a feature selection step to reduce the dimensionality of the data. The Support Vector Machine provides a new way to design classification algorithms which learn from examples (supervised learning) and generalize when applied to new data. We demonstrate its success on a difficult classification problem from hyperspectral remote sensing, where we obtain performances of 96%, and 87% correct for a 4 class problem, and a 16 class problem respectively. These results are somewhat better than other recent result on the same data. A key feature of this classifier is its ability to use high-dimensional data without the usual recourse to a feature selection step to reduce the dimensionality of the data. For this application, this is important, as hyperspectral data consists of several hundred contiguous spectral channels for each exemplar. We provide an introduction to this new approach, and demonstrate its application to classification of an agriculture scene.", "PublicationYear": "1999", "Authors": ["Anthony Gualtieria", "R. F. CrompbaApplied", "Gsfc Greenbelt", "J. Anthony Gualtieri"], "RelatedTopics": ["Environmental Science", "Computer Science"], "References": ["41d3bca9e168759799ab36bfcb04153dd095dca7", "0b14178e7d79ac426d0a39700e1ac8b2c6f2e752", "666010dc3621e1a08fb6830f03a1f7857c7377cc", "ee8c4ef01ba75b0b7e8cc839adc9f6140c5401d5", "825d76c1dfba015d7e15d878361634e58a351018", "8985a9637540daa0b7b8295f8a5bbda3a3be1dea", "51c1519a57a65351a713a3d74f8d477105df0ec3", "bfd47009b0487b042b17c7105587e17fb6b9ae2e", "4aaa30769ca49875f45670970130c088136986d1", "1b84b383ad59f79e607ad0f08a8a10876631a0cd"], "ReferenceCount": 38, "CitationCount": 480}, {"URL": "https://www.semanticscholar.org/paper/A-derivative-aided-hyperspectral-image-analysis-for-Tsai-Philpot/b821c3afbb404766ff2c768fa363803b8d256434", "ID": "b821c3afbb404766ff2c768fa363803b8d256434", "Title": "A derivative-aided hyperspectral image analysis system for land-cover classification", "Abstract": "This paper examines one possible procedure for selecting spectral derivatives to improve supervised classification of hyperspectral images to identify derivative features that are more effective at separating target classes and then add them to a base subset of features for classification. The large number of spectral bands in hyperspectral data seriously complicates their use for classification. Selection of a useful subset of bands or derived features (spectral ratios, differences, derivatives) is always desirable, strongly affects the accuracy of the classification, and is often a practical necessity to keep the processing speed and memory requirements under control. This paper examines one possible procedure for selecting spectral derivatives to improve supervised classification of hyperspectral images. The procedure is designed to identify derivative features that are more effective at separating target classes and then add them to a base subset of features for classification. The goal is to create the smallest set of features that will result in the best classification result. A key issue in this process is the interplay of the number of features and the size of the training data sets since classification accuracy declines if the dimensionality of the feature space is too large relative to the number of training samples.", "PublicationYear": "2002", "Authors": ["Fuan Tsai", "William D. Philpot"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["9745f1f3ec226d5d45f95ff06713b6e990f7d62c", "0e5262cc57c8510db60909aa03ff66d78087b382", "e6334789ec6d43664f8f164a462461a4408243ba", "7e9bbe1e47f9655eaf48681156df49dd4f347872", "2eb709ae7afb273589d98fdb215b682a3761023e", "46e527f606ac56ec4316d5c1657b45d6ff1f7879", "f72190f57f1ee671c9d5180f53f36c2cf0330395", "0f5c70476127f367d55f05f1643a60dfff3fa67f", "ce0c4290f58d6643202c01098e391e4d4ff45a86", "c0efe9f8af5df7a30dee1076af2a824e820f7419"], "ReferenceCount": 42, "CitationCount": 111}, {"URL": "https://www.semanticscholar.org/paper/Support-vector-machines-for-classification-of-data-Gualtieri-Chettri/b9ddc16cd2449e93d44c1c5360dcf765b91de099", "ID": "b9ddc16cd2449e93d44c1c5360dcf765b91de099", "Title": "Support vector machines for classification of hyperspectral data", "Abstract": "The support vector machine, recently introduced by Boser, Guyon, and Vapnik is useful in solving supervised classification in high dimensions and its application to high dimensional hyperspectral data taken from NASA's AVIRIS sensor and from a commercially available sensor called AISA. The support vector machine (SVM), recently introduced by Boser, Guyon, and Vapnik is useful in solving supervised classification in high dimensions. The authors discuss the SVM and its application to high dimensional hyperspectral data taken from NASA's AVIRIS sensor (224 bands) and from a commercially available sensor called AISA (20-40 bands), built by SPECIM of Finland. Traditionally, classifiers model the density of the various classes and then find a separating surface. However density estimation in high dimensions suffers from the Hughes effect, necessitating a feature selection step to reduce the dimensionality of the data. The SVM approach does not suffer this limitation because it directly seeks a separating surface through an optimization procedure that finds the exemplars that form the boundaries of the classes. These exemplars are called the support vectors. This is significant because it is usually true that there are a small subset of all the training data that are involved in defining the separating surface, i.e., those examples thatare closest to the separating surface. In addition, the SVM approach uses the kernel method, discussed below, to map the data with a non-linear transformation to a higher dimensional space and in that space attempts to find a linear separating surface between the two classes. Why the curse of dimensionality is not a problem for the kernel method is discussed below.", "PublicationYear": "2000", "Authors": ["J. Anthony Gualtieri", "Samir Chettri"], "RelatedTopics": ["Environmental Science", "Computer Science", "Engineering"], "References": ["5b92c12e80e82e2302c6f2570f415bbc26f966b0", "83e3788925a7a78bcc89a4540c8808f8e2b7acb0", "4aaa30769ca49875f45670970130c088136986d1", "3e3ec72e932d7205a541e67e0f9a1fde5235eefd", "1e52db1f61a5f0083cbe87845c019ab351bfe6c9", "7ee1c6a35f55e04516a7e9578f961167b48a925a"], "ReferenceCount": 6, "CitationCount": 92}, {"URL": "https://www.semanticscholar.org/paper/Support-vector-machines-for-remote-sensing-image-Roli-Fumera/f83b85d8daa4ee370982842a809b5c8dba63b645", "ID": "f83b85d8daa4ee370982842a809b5c8dba63b645", "Title": "Support vector machines for remote sensing image classification", "Abstract": "The application to remote-sensing image classification of a new pattern recognition technique recently introduced within the framework of the Statistical Learning Theory developed by V. Vapnik and his co-workers, namely, the Support Vector Machines (SVMs). In the last decade, the application of statistical and neural network classifiers to remote-sensing images has been deeply investigated. Therefore, performances, characteristics, and pros and cons of such classifiers are quite well known, even from remote-sensing practitioners. In this paper, we present the application to remote-sensing image classification of a new pattern recognition technique recently introduced within the framework of the Statistical Learning Theory developed by V. Vapnik and his co-workers, namely, the Support Vector Machines (SVMs). In section 1, the main theoretical foundations of SVMs are presented. In section 2, experiments carried out on a data set of multisensor remote-sensing images are described, with particular emphasis on the design and training phase of a SVM. In section 3, the experimental results are reported, together with a comparison between the performances of SVMs, neural network, and k-NN classifiers.", "PublicationYear": "2001", "Authors": ["Fabio Roli", "Giorgio Fumera"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["72d9f02f78570d680b9242866f925114061bb8da", "e6241d5c0c2e6646f6aa8f1f5117f6779a9199fb", "4876af291865ad1d39dfff1279a6aeb1e2efbbc5", "85e5834d5b518c4a9a01c18ea2a99c2ac7f39f14", "fffbf7e69ead7d61dda55c6baa6d0f9269000ea6", "ba204eafc82dba2b829a4d619d6bb16c9e9e93e7", "19ab896ca26e9a5dddc17bb6fb6101ea119373b5", "9c4da62e9e89e65ac78ee271e424e8b498053e8c", "7550a05bf00f7b24aed9c1ac3ef000575388d21c", "4c75b748911ddcd888c5122f7672f69caa5d661f"], "ReferenceCount": 11, "CitationCount": 77}, {"URL": "https://www.semanticscholar.org/paper/Cluster-space-representation-for-hyperspectral-data-Jia-Richards/75a963eff4fd7809694d2225b62db7569f1e1b93", "ID": "75a963eff4fd7809694d2225b62db7569f1e1b93", "Title": "Cluster-space representation for hyperspectral data classification", "Abstract": "This paper presents a generalization of the hybrid supervised-unsupervised approach to image classification, and an automatic procedure for implementing it with hyperspectral data. This paper presents a generalization of the hybrid supervised-unsupervised approach to image classification, and an automatic procedure for implementing it with hyperspectral data. Cluster-space representation is introduced in which clustered training data is displayed in a one-dimensional (1-D) cluster-space showing its probability distribution. This representation leads to automatic association of spectral clusters with information classes and the development of a cluster-space classification (CSC). Pixel labeling is undertaken by a combined decision based on its membership of belonging to defined clusters and the clusters' membership of belonging to information classes. The method provides a means of class data separability inspection, visually and quantitatively, regardless of the number of spectral bands used. The class modeling requires only that first degree statistics be estimated; therefore, the number of training samples required can be many fewer than when using Gaussian maximum likelihood (GML) classification. Experiments are presented based on computer generated data and AVIRIS data. The advantages of the method are demonstrated showing improved capacity for data classification.", "PublicationYear": "2002", "Authors": ["Xiuping Jia", "John A. Richards"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["b96124e98d030f7fbdd57d084fd1371264216f94", "f85d66b2797eb1ab1da0f271286765991f766abe", "260d888e16750e99143b990c6138e2d763893248", "2cad7cbd96df91cad3d98d667c66cfe61555d5d8", "3e3ec72e932d7205a541e67e0f9a1fde5235eefd", "bf61786b0af62554ab7c650a8d473dd8a3729e01", "42f75b297aed474599c8e598dd211a1999804138"], "ReferenceCount": 10, "CitationCount": 81}, {"URL": "https://www.semanticscholar.org/paper/Best-bases-feature-extraction-algorithms-for-of-Kumar-Ghosh/5355e8c7359b8dadb970099dcd6fa951fa5ef3b7", "ID": "5355e8c7359b8dadb970099dcd6fa951fa5ef3b7", "Title": "Best-bases feature extraction algorithms for classification of hyperspectral data", "Abstract": "A set of best-bases feature extraction algorithms that are simple, fast, and highly effective for classification of hyperspectral data are proposed. Due to advances in sensor technology, it is now possible to acquire hyperspectral data simultaneously in hundreds of bands. Algorithms that both reduce the dimensionality of the data sets and handle highly correlated bands are required to exploit the information in these data sets effectively. the authors propose a set of best-bases feature extraction algorithms that are simple, fast, and highly effective for classification of hyperspectral data. These techniques intelligently combine subsets of adjacent bands into a smaller number of features. Both top-down and bottom-up algorithms are proposed. The top-down algorithm recursively partitions the bands into two (not necessarily equal) sets of bands and then replaces each final set of bands by its mean value. The bottom-up algorithm builds an agglomerative tree by merging highly correlated adjacent bands and projecting them onto their Fisher direction, yielding high discrimination among classes. Both these algorithms are used in a pairwise classifier framework where the original C-class problem is divided into a set of (/sub 2//sup C/) two-class problems. The new algorithms (1) find variable length bases localized in wavelength, (2) favor grouping highly correlated adjacent bands that, when merged either by taking their mean or Fisher linear projection, yield maximum discrimination, and (3) seek orthogonal bases for each of the (/sub 2//sup C/) two-class problems into which a C-class problem can be decomposed. Experiments on an AVIRIS data set for a 12-class problem show significant improvements in classification accuracies while using a much smaller number of features.", "PublicationYear": "2001", "Authors": ["Shailesh Kumar", "Joydeep Ghosh", "Melba M. Crawford"], "RelatedTopics": ["Environmental Science", "Computer Science", "Engineering"], "References": ["c6ea923408fe23824b3492a9ff3855f47eb6c6d4", "0e5262cc57c8510db60909aa03ff66d78087b382", "9745f1f3ec226d5d45f95ff06713b6e990f7d62c", "dc159a43a588e5879d767e07eea7e80cb689bd0b", "088a2f2ec3a6ac8729204c2dabb481eb4dbb0f2e", "9341aa27db07d397077cf21338c99b3d30ae4b00", "6fa122867910391af18260c4a13bb8313166fc5b", "5478a91c183c3a460bd4098acb8927bfc671367c", "de26cb4a4eddfcc30c8c05be865ff9ee6117ad00", "f642a692da944604a7df590e9f9fa06089b7991a"], "ReferenceCount": 17, "CitationCount": 277}, {"URL": "https://www.semanticscholar.org/paper/A-new-search-algorithm-for-feature-selection-in-Serpico-Bruzzone/c94dec3fc99c4a653afb935d00246f788689c341", "ID": "c94dec3fc99c4a653afb935d00246f788689c341", "Title": "A new search algorithm for feature selection in hyperspectral remote sensing images", "Abstract": "Two new suboptimal search strategy suitable for feature selection in very high-dimensional remote sensing images (e.g., those acquired by hyperspectral sensors) are proposed, which allow interesting tradeoffs between the qualities of selected feature subsets and computational cost. A new suboptimal search strategy suitable for feature selection in very high-dimensional remote sensing images (e.g., those acquired by hyperspectral sensors) is proposed. Each solution of the feature selection problem is represented as a binary string that indicates which features are selected and which are disregarded. In turn, each binary string corresponds to a point of a multidimensional binary space. Given a criterion function to evaluate the effectiveness of a selected solution, the proposed strategy is based on the search for constrained local extremes of such a function in the above-defined binary space. In particular, two different algorithms are presented that explore the space of solutions in different ways. These algorithms are compared with the classical sequential forward selection and sequential forward floating selection suboptimal techniques, using hyperspectral remote sensing images (acquired by the airborne visible/infrared imaging spectrometer [AVIRIS] sensor) as a data set. Experimental results point out the effectiveness of both algorithms, which can be regarded as valid alternatives to classical methods, as they allow interesting tradeoffs between the qualities of selected feature subsets and computational cost.", "PublicationYear": "2001", "Authors": ["Sebastiano Bruno Serpico", "Lorenzo Bruzzone"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["c1aba3849c919e5aff1cf9efee4076a281640861", "aa541f56e1bf81312983009f3ee2f9aa371d59c7", "2a5b31aaefd943b8eb3334fda53311b06f0bdbf5", "3eea8ef1fef2881e313038cf03393848016d8dd4", "c0efe9f8af5df7a30dee1076af2a824e820f7419", "9b07027d4fc8460dba67514bbf45109e6dc043b5", "8aee4e1022b18e7ecad7a963a5f6a3edb3832f2d", "5523bedd0b1b74fa34509d56cb62f0e7b386a180", "3e3ec72e932d7205a541e67e0f9a1fde5235eefd", "8e855304e880f816f7df248aa860a65115c1f96d"], "ReferenceCount": 22, "CitationCount": 343}, {"URL": "https://www.semanticscholar.org/paper/Adaptive-Feature-Spaces-For-Land-Cover-With-Limited-Morgan-Henneguelle/ea82a3b3f8940c7e8f949d78639792ac345d09fd", "ID": "ea82a3b3f8940c7e8f949d78639792ac345d09fd", "Title": "Adaptive Feature Spaces For Land Cover Classification With Limited Ground Truth Data", "Abstract": "A feature reduction scheme that adaptively adjusts to the amount of labeled data available and can be used in conjunction with ECOC and the BHC, as well as other approaches such as round-robin classification that decompose a multiclass problem into a number of two (meta)-class problems. Classification of land cover based on hyperspectral data is very challenging because typically tens of classes with uneven priors are involved, the inputs are high dimensional, and there is often scarcity of labeled data. Several researchers have observed that it is often preferable to decompose a multiclass problem into multiple two-class problems, solve each such subproblem using a suitable binary classifier, and then combine the outputs of this collection of classifiers in a suitable manner to obtain the answer to the original multiclass problem. This approach is taken by the popular error correcting output codes (ECOC) technique, as well by the binary hierarchical classifier (BHC). Classical techniques for dealing with small sample sizes include regularization of covariance matrices and feature reduction. In this paper we address the twin problems of small sample sizes and multiclass settings by proposing a feature reduction scheme that adaptively adjusts to the amount of labeled data available. This scheme can be used in conjunction with ECOC and the BHC, as well as other approaches such as round-robin classification that decompose a multiclass problem into a number of two (meta)-class problems. In particular, we develop the best-basis binary hierarchical classifier (BB-BHC) and best basis ECOC (BB-ECOC) families of models that are adapted to \\\"small sample size\\\" situations. Currently, there are few studies that compare the efficacy of different approaches to multiclass problems in general settings as well as in the specific context of small sample sizes. Our experiments on two sets of remote sensing data show that both BB-BHC and BB-ECOC methods are superior to their nonadaptive versions when faced with limited data, with the BB-BHC showing a slight edge in terms of classification accuracy as well as interpretability.", "PublicationYear": "2004", "Authors": ["Joseph T. Morgan", "Alex Henneguelle", "Melba M. Crawford", "Joydeep Ghosh", "Amy L. Neuenschwander"], "RelatedTopics": ["Computer Science", "Engineering", "Environmental Science"], "References": ["3a058cbdda978b3c03f67adbef5dde7548b73522", "088a2f2ec3a6ac8729204c2dabb481eb4dbb0f2e", "4f6c4f1558dbebd371566816e66b1fb74eee272e", "afb210879d1d05fdb0417ff09a37c4ca7f48f247", "5355e8c7359b8dadb970099dcd6fa951fa5ef3b7", "0e5262cc57c8510db60909aa03ff66d78087b382", "3c0847899b15771cd835493995cadbb958abfc71", "b5a5683b0eff0d4755c7381ef570a36cafb00215", "9279fe2192c92b85e7e64ad67300633fc2f1b804", "41d3bca9e168759799ab36bfcb04153dd095dca7"], "ReferenceCount": 64, "CitationCount": 36}, {"URL": "https://www.semanticscholar.org/paper/Classification-of-multisource-and-hyperspectral-on-Benediktsson-Kanellopoulos/7dd9820b13754f05ae3f7f771fc8b2d7f4691c06", "ID": "7dd9820b13754f05ae3f7f771fc8b2d7f4691c06", "Title": "Classification of multisource and hyperspectral data based on decision fusion", "Abstract": "The proposed methods are applied in the classification of multisource and hyperdimensional data sets, and the results compared to accuracies obtained with conventional classification schemes. Multisource classification methods based on neural networks and statistical modeling are considered. For these methods, the individual data sources are at first treated separately and modeled by statistical methods. Then several decision fusion schemes are applied to combine the information from the individual data sources. These schemes include weighted consensus theory where the weights of the individual data sources reflect the reliability of the sources. The weights are optimized in order to improve the combined classification accuracies. Other considered decision fusion schemes are based on two-stage approaches which use voting in the first stage and reject samples if either the majority or all of the classifiers for the data sources do not agree on a classification of a sample. For the second stage, a neural network is used to classify the rejected samples. The proposed methods are applied in the classification of multisource and hyperdimensional data sets, and the results compared to accuracies obtained with conventional classification schemes.", "PublicationYear": "1999", "Authors": ["J{\\'o}n Atli Benediktsson", "Ioannis Kanellopoulos"], "RelatedTopics": ["Computer Science", "Environmental Science"], "References": ["69322a2d78efdce547ba7d2f429ff84a20cff31c", "e128711291a1c2c5b5238e34f62d1d63fa0abcc2", "79af782f61d04523c268bb892dafc26825c6b348", "13db5aa61348dbcf58fd454ce5204e19080b5465", "c45ed395992b043d5130dc66a2a3975fdebc00fe", "4876af291865ad1d39dfff1279a6aeb1e2efbbc5", "44aedd81e94bcda17a8081b98183a7763fc18f2d", "4db6e1de9f2a8e55385e4b8880c23c28e5be30e2", "93d89643a31e0249c87ab179d83a2ac506a35770", "ba8b278468c4e38a307fc328ec101951067ec345"], "ReferenceCount": 37, "CitationCount": 286}, {"URL": "https://www.semanticscholar.org/paper/Toward-Supervised-Anomaly-Detection-G%C3%B6rnitz-Kloft/f5a951b9596be0df5ad7ede180b405c9e97a65c9", "ID": "f5a951b9596be0df5ad7ede180b405c9e97a65c9", "Title": "Toward Supervised Anomaly Detection", "Abstract": "It is argued that semi-supervised anomaly detection needs to ground on the unsupervised learning paradigm and devise a novel algorithm that meets this requirement and it is shown that the optimization problem has a convex equivalent under relatively mild assumptions. Anomaly detection is being regarded as an unsupervised learning task as anomalies stem from adversarial or unlikely events with unknown distributions. However, the predictive performance of purely unsupervised anomaly detection often fails to match the required detection rates in many tasks and there exists a need for labeled data to guide the model generation. Our first contribution shows that classical semi-supervised approaches, originating from a supervised classifier, are inappropriate and hardly detect new and unknown anomalies. We argue that semi-supervised anomaly detection needs to ground on the unsupervised learning paradigm and devise a novel algorithm that meets this requirement. Although being intrinsically non-convex, we further show that the optimization problem has a convex equivalent under relatively mild assumptions. Additionally, we propose an active learning strategy to automatically filter candidates for labeling. In an empirical study on network intrusion detection data, we observe that the proposed learning methodology requires much less labeled data than the state-of-the-art, while achieving higher detection accuracies.", "PublicationYear": "2014", "Authors": ["Nico G{\\\"o}rnitz", "M. Kloft", "Konrad Rieck", "Ulf Brefeld"], "RelatedTopics": ["Computer Science"], "References": ["e98236e37049b46453c7d78f77c8cfaeefc0bfe9", "d612d7c21d4130a457968273d79c2c2f6946953d", "5f9b6151708f85dddd4a1ab03b82c85850fb73da", "6087667d775e160913277d356554698e63d23be9", "803d421305e07f471f0d0fd278d6043d26763767", "9e23e2881be1fadbfd270e4356ff35c1d060b53e", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "1e8984b6c962011be62b227bc931a067e543337c", "633305d1f4043fcd61df5a688ba496558230a946", "a4c52c6c4c852341304305afe909ab466551d0dc"], "ReferenceCount": 66, "CitationCount": 331}, {"URL": "https://www.semanticscholar.org/paper/Deep-Anomaly-Detection-with-Deviation-Networks-Pang-Shen/f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed", "ID": "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed", "Title": "Deep Anomaly Detection with Deviation Networks", "Abstract": "A novel anomaly detection framework and its instantiation that can be trained substantially more data-efficiently and achieves significantly better anomaly scoring than state-of-the-art competing methods is introduced. Although deep learning has been applied to successfully address many data mining problems, relatively limited work has been done on deep learning for anomaly detection. Existing deep anomaly detection methods, which focus on learning new feature representations to enable downstream anomaly detection methods, perform indirect optimization of anomaly scores, leading to data-inefficient learning and suboptimal anomaly scoring. Also, they are typically designed as unsupervised learning due to the lack of large-scale labeled anomaly data. As a result, they are difficult to leverage prior knowledge (e.g., a few labeled anomalies) when such information is available as in many real-world anomaly detection applications. This paper introduces a novel anomaly detection framework and its instantiation to address these problems. Instead of representation learning, our method fulfills an end-to-end learning of anomaly scores by a neural deviation learning, in which we leverage a few (e.g., multiple to dozens) labeled anomalies and a prior probability to enforce statistically significant deviations of the anomaly scores of anomalies from that of normal data objects in the upper tail. Extensive results show that our method can be trained substantially more data-efficiently and achieves significantly better anomaly scoring than state-of-the-art competing methods.", "PublicationYear": "2019", "Authors": ["Guansong Pang", "Chunhua Shen", "Anton van den Hengel"], "RelatedTopics": ["Computer Science"], "References": ["5f61089d3d548a515f01b473f0119137d1f340d4", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "6af440915b8a0718c93be1cf61905e41e620484a", "83fcb78e3b58c230a051914daac3bfb00482b34c", "267502d21b44884570fcd95a855821cc3e86e6eb", "93790640c42cfd72929af51e9ca13219e4803fca", "dcd9f5d61bc9a70c40be84a8d78fbee822ffcd9e", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "b5781eaafe1aff25a084d83dc38831ea09db42f3", "882e06d18c0fc0645ae559633eb178a7a41cfe79"], "ReferenceCount": 31, "CitationCount": 233}, {"URL": "https://www.semanticscholar.org/paper/Deep-Anomaly-Detection-with-Outlier-Exposure-Hendrycks-Mazeika/2d8c97db4bae00ff243d122b957091a236a697a7", "ID": "2d8c97db4bae00ff243d122b957091a236a697a7", "Title": "Deep Anomaly Detection with Outlier Exposure", "Abstract": "In extensive experiments on natural language processing and small- and large-scale vision tasks, it is found that Outlier Exposure significantly improves detection performance and that cutting-edge generative models trained on CIFar-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; OE is used to mitigate this issue. It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.", "PublicationYear": "2018", "Authors": ["Dan Hendrycks", "Mantas Mazeika", "Thomas G. Dietterich"], "RelatedTopics": ["Computer Science"], "References": ["4dcdae25a5e33682953f0853ee4cf7ca93be58a9", "54d2b5c64a67f65c5dd812b89e07973f97699552", "431ba9fae8fccad1665979d455c6307786e47318", "36653f8705b56e39642bcd123494eb680cd1636b", "d65ce2b8300541414bfe51d03906fca72e93523c", "1c4e9156ca07705531e45960b7a919dc473abb51", "123df44051ac8170a5cd60abd17c0e404e23955f", "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b", "b022f2a277a4bf5f42382e86e4380b96340b9e86", "8388f1be26329fa45e5807e968a641ce170ea078"], "ReferenceCount": 53, "CitationCount": 1116}, {"URL": "https://www.semanticscholar.org/paper/A-Hybrid-Semi-Supervised-Anomaly-Detection-Model-Song-Jiang/ca4edb65a0664804e4819c5c809d0dfba9bdb2df", "ID": "ca4edb65a0664804e4819c5c809d0dfba9bdb2df", "Title": "A Hybrid Semi-Supervised Anomaly Detection Model for High-Dimensional Data", "Abstract": "A hybrid semi-supervised anomaly detection model for high-dimensional data that consists of a deep autoencoder (DAE) and an ensemble k-nearest neighbor graphs- (K-NNG-) based anomaly detector is proposed. Anomaly detection, which aims to identify observations that deviate from a nominal sample, is a challenging task for high-dimensional data. Traditional distance-based anomaly detection methods compute the neighborhood distance between each observation and suffer from the curse of dimensionality in high-dimensional space; for example, the distances between any pair of samples are similar and each sample may perform like an outlier. In this paper, we propose a hybrid semi-supervised anomaly detection model for high-dimensional data that consists of two parts: a deep autoencoder (DAE) and an ensemble k-nearest neighbor graphs- (K-NNG-) based anomaly detector. Benefiting from the ability of nonlinear mapping, the DAE is first trained to learn the intrinsic features of a high-dimensional dataset to represent the high-dimensional data in a more compact subspace. Several nonparametric KNN-based anomaly detectors are then built from different subsets that are randomly sampled from the whole dataset. The final prediction is made by all the anomaly detectors. The performance of the proposed method is evaluated on several real-life datasets, and the results confirm that the proposed hybrid model improves the detection accuracy and reduces the computational complexity.", "PublicationYear": "2017", "Authors": ["Hongchao Song", "Zhuqing Jiang", "Aidong Men", "Bo Yang"], "RelatedTopics": ["Computer Science"], "References": ["f076e4355c0facf111716dcab2837803367dd2d8", "a8ad5657a52f549523fb5608c7a78801e8b7a950", "45cdc0c64f3c690c734c7022f22f2973986c356a", "43eced5f4cd0fc76975b97d7ce9664c8488174e2", "dcb207ce848b358aeb2e4698c9ea1ad273ce98db", "71df4b737c35fb3d05f44036419e78b5330b580f", "dcafe812c7f0ec094b25f32fe71010cad7323797", "b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b", "e3116ebb52c152deae918a04c34441ac0d956b8a", "8f923ad5bb95f67cd51f1de0a16c2c794cee2b29"], "ReferenceCount": 43, "CitationCount": 100}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-for-Anomaly-Detection%3A-A-Survey-Chalapathy-Chawla/a2e667e4382aaa8e02a17d0522c1a910790ab65b", "ID": "a2e667e4382aaa8e02a17d0522c1a910790ab65b", "Title": "Deep Learning for Anomaly Detection: A Survey", "Abstract": "A structured and comprehensive overview of research methods in deep learning-based anomaly detection, grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.", "PublicationYear": "2019", "Authors": ["Raghavendra Chalapathy", "Sanjay Chawla"], "RelatedTopics": ["Computer Science"], "References": ["a9d7904a78d6c4df31e003c9df55c78a9ca485de", "10a498003e9204f5fc1328e706510a37e514d8c7", "f3bf9356fefb63c9d04fd2f74e947a34f691969e", "f16b23e8e0788e3298e533e71bafef7135300a5e", "f6904e4f58aedbd26a257491b0bfedd74e331417", "1d4ec24a6da3be62dc5d7efbae2a101c63f187e8", "030dff9a7cba9b85be1fec18a895c86673264680", "69e460953d9b13aded4d906b974c0d80c1ceaef7", "d100f625580dd6df123c69abff1d094e2d745613", "355692eb86b06a0a23af45c106cfb02c95bf380e"], "ReferenceCount": 477, "CitationCount": 1197}, {"URL": "https://www.semanticscholar.org/paper/High-dimensional-and-large-scale-anomaly-detection-Erfani-Rajasegarar/f076e4355c0facf111716dcab2837803367dd2d8", "ID": "f076e4355c0facf111716dcab2837803367dd2d8", "Title": "High-dimensional and large-scale anomaly detection using a linear one-class SVM with deep learning", "Abstract": "Semantic Scholar extracted view of \\\"High-dimensional and large-scale anomaly detection using a linear one-class SVM with deep learning\\\" by S. Erfani et al.", "PublicationYear": "2016", "Authors": ["Sarah Monazam Erfani", "Sutharshan Rajasegarar", "Shanika Karunasekera", "Christopher Leckie"], "RelatedTopics": ["Computer Science"], "References": ["869a75dc4a7c54b940dcb07ada1a845c027e7350", "45e9cd822e6c285232a2a097ae485f384bfe6e34", "1430b115443d524b1a09c09172eb6152100b4e80", "0a230009eb4196214bfb5a3e678a419e3f8896fe", "5578f3d9e6931c3762b2275f5265113e8f94369a", "96c9f11fd9901f2edeaab8cf6bbff2590cea93c4", "cf03fdf52dd6e4249cbbdbd0bffbbbe5ca389feb", "e65bfaf266289c3932996799999633dd9e7539d4", "b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b", "aea23355420b2a679d2d6f0e6cc01f4a153710cb"], "ReferenceCount": 64, "CitationCount": 884}, {"URL": "https://www.semanticscholar.org/paper/Deep-One-Class-Classification-Ruff-G%C3%B6rnitz/6af440915b8a0718c93be1cf61905e41e620484a", "ID": "6af440915b8a0718c93be1cf61905e41e620484a", "Title": "Deep One-Class Classification", "Abstract": "This paper introduces a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective and shows the effectiveness of the method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GT-SRB stop signs. Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objec-tive. In this paper we introduce a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GT-SRB stop signs.", "PublicationYear": "2018", "Authors": ["Lukas Ruff", "Nico G{\\\"o}rnitz", "Lucas Deecke", "Shoaib Ahmed Siddiqui", "Robert A. Vandermeulen", "Alexander Binder", "Emmanuel M{\\\"u}ller", "M. Kloft"], "RelatedTopics": ["Computer Science"], "References": ["8388f1be26329fa45e5807e968a641ce170ea078", "bee044c8e8903fb67523c1f8c105ab4718600cdb", "f076e4355c0facf111716dcab2837803367dd2d8", "6259b02912cebc224f3a2b1324e811a152a0177d", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "843959ffdccf31c6694d135fad07425924f785b1", "1b225474e7a5794f98cdfbde8b12ccbc56799409", "60fef33549f57f5cbb6712a510c3a444ab682429"], "ReferenceCount": 58, "CitationCount": 1411}, {"URL": "https://www.semanticscholar.org/paper/Anomaly-Detection-using-One-Class-Neural-Networks-Chalapathy-Menon/67b9c2b376a01d8757dc6d704be450d1c46c4ced", "ID": "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "Title": "Anomaly Detection using One-Class Neural Networks", "Abstract": "A comprehensive set of experiments demonstrate that on complex data sets (like CIFAR and PFAM), OC-NN significantly outperforms existing state-of-the-art anomaly detection methods. We propose a one-class neural network (OC-NN) model to detect anomalies in complex data sets. OC-NN combines the ability of deep networks to extract a progressively rich representation of data with the one-class objective of creating a tight envelope around normal data. The OC-NN approach breaks new ground for the following crucial reason: data representation in the hidden layer is driven by the OC-NN objective and is thus customized for anomaly detection. This is a departure from other approaches which use a hybrid approach of learning deep features using an autoencoder and then feeding the features into a separate anomaly detection method like one-class SVM (OC-SVM). The hybrid OC-SVM approach is sub-optimal because it is unable to influence representational learning in the hidden layers. A comprehensive set of experiments demonstrate that on complex data sets (like CIFAR and GTSRB), OC-NN performs on par with state-of-the-art methods and outperformed conventional shallow methods in some scenarios.", "PublicationYear": "2018", "Authors": ["Raghavendra Chalapathy", "Aditya Krishna Menon", "Sanjay Chawla"], "RelatedTopics": ["Computer Science"], "References": ["f076e4355c0facf111716dcab2837803367dd2d8", "6af440915b8a0718c93be1cf61905e41e620484a", "1d4ec24a6da3be62dc5d7efbae2a101c63f187e8", "2b75ba7f75170b73d913c515cc0deefef6c88f5f", "88f761749f5ac789f84b19ed0cff75c131dd8a29", "c53352a4239568cc915ad968aff51c49924a3072", "00a1077d298f2917d764eb729ab1bc86af3bd241", "081651b38ff7533550a3adfc1c00da333a8fe86c", "995c5f5e62614fcb4d2796ad2faab969da51713e", "527cc8cd2af06a9ac2e5cded806bab5c3faad9cf"], "ReferenceCount": 46, "CitationCount": 352}, {"URL": "https://www.semanticscholar.org/paper/Image-Anomaly-Detection-with-Generative-Adversarial-Deecke-Vandermeulen/3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "ID": "3447d8b47a8cf7ce9f04ede314f0ded8172fa470", "Title": "Image Anomaly Detection with Generative Adversarial Networks", "Abstract": "This work proposes a novel approach to anomaly detection using generative adversarial networks, based on searching for a good representation of that sample in the latent space of the generator; if such a representation is not found, the sample is deemed anomalous. Many anomaly detection methods exist that perform well on low-dimensional problems however there is a notable lack of effective methods for high-dimensional spaces, such as images. Inspired by recent successes in deep learning we propose a novel approach to anomaly detection using generative adversarial networks. Given a sample under consideration, our method is based on searching for a good representation of that sample in the latent space of the generator; if such a representation is not found, the sample is deemed anomalous. We achieve state-of-the-art performance on standard image benchmark datasets and visual inspection of the most anomalous samples reveals that our method does indeed return anomalies.", "PublicationYear": "2018", "Authors": ["Lucas Deecke", "Robert A. Vandermeulen", "Lukas Ruff", "Stephan Mandt", "M. Kloft"], "RelatedTopics": ["Computer Science"], "References": ["6af440915b8a0718c93be1cf61905e41e620484a", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "8388f1be26329fa45e5807e968a641ce170ea078", "74ff6d48f9c62e937023106629d27ef2d2ddf8bc", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "e2ef0f1a528cd0f415be8265a04466a6d3f74e6c", "9a700c7a7e7468e436f00c34551fbe3e0f70e42f", "86ee1835a56722b76564119437070782fc90eb19"], "ReferenceCount": 52, "CitationCount": 182}, {"URL": "https://www.semanticscholar.org/paper/Enhancing-The-Reliability-of-Out-of-distribution-in-Liang-Li/547c854985629cfa9404a5ba8ca29367b5f8c25f", "ID": "547c854985629cfa9404a5ba8ca29367b5f8c25f", "Title": "Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks", "Abstract": "The proposed ODIN method, based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in- and out-of-distribution images, allowing for more effective detection, consistently outperforms the baseline approach by a large margin. We consider the problem of detecting out-of-distribution images in neural networks. We propose ODIN, a simple and effective method that does not require any change to a pre-trained neural network. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in- and out-of-distribution images, allowing for more effective detection. We show in a series of experiments that ODIN is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach by a large margin, establishing a new state-of-the-art performance on this task. For example, ODIN reduces the false positive rate from the baseline 34.7% to 4.3% on the DenseNet (applied to CIFAR-10) when the true positive rate is 95%.", "PublicationYear": "2017", "Authors": ["Shiyu Liang", "Yixuan Li", "Rayadurgam Srikant"], "RelatedTopics": ["Computer Science"], "References": ["eb42cf88027de515750f230b23b1a057dc782108", "6259b02912cebc224f3a2b1324e811a152a0177d", "6ff2a434578ff2746b9283e45abf296887f48a2d", "4dcdae25a5e33682953f0853ee4cf7ca93be58a9", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "4543670c4b2d88a9b67525e0084044adef94ae76", "d65ce2b8300541414bfe51d03906fca72e93523c", "5d90f06bb70a0a3dced62413346235c02b1aa086", "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad"], "ReferenceCount": 54, "CitationCount": 1518}, {"URL": "https://www.semanticscholar.org/paper/Model-selection-for-anomaly-detection-Burnaev-Erofeev/c72e91b2e5c103f529510fa15a156d61c5633da1", "ID": "c72e91b2e5c103f529510fa15a156d61c5633da1", "Title": "Model selection for anomaly detection", "Abstract": "This paper generalizes several kernel selection methods from binary-class case to the case of one-class classification and performs extensive comparison of these approaches using both synthetic and real-world data. Anomaly detection based on one-class classification algorithms is broadly used in many applied domains like image processing (e.g. detection of whether a patient is \u201ccancerous\u201d or \u201chealthy\u201d from mammography image), network intrusion detection, etc. Performance of an anomaly detection algorithm crucially depends on a kernel, used to measure similarity in a feature space. The standard approaches (e.g. cross-validation) for kernel selection, used in two-class classification problems, can not be used directly due to the specific nature of a data (absence of a second, abnormal, class data). In this paper we generalize several kernel selection methods from binary-class case to the case of one-class classification and perform extensive comparison of these approaches using both synthetic and real-world data.", "PublicationYear": "2015", "Authors": ["Evgeny Burnaev", "Pavel Erofeev", "Dmitry Smolyakov"], "RelatedTopics": ["Computer Science"], "References": ["153a99ad39e85eb09f6ae56b1eb72795265cb8a0", "4c65c5f32a8c47505f763b00c4e65a859856a3b3", "0407271bfd724bf397a44b5d146a400a2a39d9c3", "633f7d2b4014e3213c6eabfd6b157d14803dad2e", "44e4ae2fa3e71934e66f6c7996bd585b67ae103c", "7e2fd9c6205613c4858b36ebb4e1b655d915c099", "9fb8a2911f3d93c9f7ae4468990df944463e80ed", "8cb44f06586f609a29d9b496cc752ec01475dffe", "b94d0d78b705aafff7bc77174059f1921e6c5a77", "9cd3539312f5ddc59d9af2eab18f2834d44d76f5"], "ReferenceCount": 13, "CitationCount": 32}, {"URL": "https://www.semanticscholar.org/paper/Deep-Structured-Energy-Based-Models-for-Anomaly-Zhai-Cheng/10a498003e9204f5fc1328e706510a37e514d8c7", "ID": "10a498003e9204f5fc1328e706510a37e514d8c7", "Title": "Deep Structured Energy Based Models for Anomaly Detection", "Abstract": "This paper proposes deep structured energy based models (DSEBMs), where the energy function is the output of a deterministic deep neural network with structure, and develops novel model architectures to integrate EBMs with different types of data such as static data, sequential data, and spatial data. In this paper, we attack the anomaly detection problem by directly modeling the data distribution with deep architectures. We propose deep structured energy based models (DSEBMs), where the energy function is the output of a deterministic deep neural network with structure. We develop novel model architectures to integrate EBMs with different types of data such as static data, sequential data, and spatial data, and apply appropriate model architectures to adapt to the data structure. Our training algorithm is built upon the recent development of score matching \\\\cite{sm}, which connects an EBM with a regularized autoencoder, eliminating the need for complicated sampling method. Statistically sound decision criterion can be derived for anomaly detection purpose from the perspective of the energy landscape of the data distribution. We investigate two decision criteria for performing anomaly detection: the energy score and the reconstruction error. Extensive empirical studies on benchmark tasks demonstrate that our proposed model consistently matches or outperforms all the competing methods.", "PublicationYear": "2016", "Authors": ["Shuangfei Zhai", "Yu Cheng", "Weining Lu", "Zhongfei Zhang"], "RelatedTopics": ["Computer Science"], "References": ["72d9aa4abe4f8fd812377ee3595f13c314e0baa0", "2d851f681f82c71a934aebd16e8112adf1239f85", "4549ebd94667461cdcccadd4147c6f5fe54d6879", "7fc604e1a3e45cd2d2742f96d62741930a363efa", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "b68c34c55925a75804f97491b745de66b1ffc4be", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "390132e92cd34b912c56fd53dc086d53abb8780e", "abd1c342495432171beb7ca8fd9551ef13cbd0ff"], "ReferenceCount": 28, "CitationCount": 385}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Anomaly-Detection-with-Generative-to-Schlegl-Seeb%C3%B6ck/e163a2e89c136cb4442e34c72f7173a0ff46dc79", "ID": "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "Title": "Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery", "Abstract": "AnoGAN, a deep convolutional generative adversarial network is proposed to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.", "PublicationYear": "2017", "Authors": ["Thomas Schlegl", "Philipp Seeb{\\\"o}ck", "Sebastian M. Waldstein", "Ursula Margarethe Schmidt-Erfurth", "Georg Langs"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["45f490710b4dd6697dba4c9b385a49554501711a", "84f7f9e121c1285e15cefbfc44bcb3322f73b6aa", "75a838cbc1541858b9c484001cade327640dc280", "05dc42d9262c0ba8dd2d3a3798a2ce1e233cd3cc", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "8388f1be26329fa45e5807e968a641ce170ea078", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "571b0750085ae3d939525e62af510ee2cee9d5ea", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "f076e4355c0facf111716dcab2837803367dd2d8"], "ReferenceCount": 20, "CitationCount": 1798}, {"URL": "https://www.semanticscholar.org/paper/Variational-Autoencoder-based-Anomaly-Detection-An-Cho/061146b1d7938d7a8dae70e3531a00fceb3c78e8", "ID": "061146b1d7938d7a8dae70e3531a00fceb3c78e8", "Title": "Variational Autoencoder based Anomaly Detection using Reconstruction Probability", "Abstract": "The reconstruction probability has a theoretical background making it a more principled and objective anomaly score than the reconstruction error, which is used by autoencoder and principal components based anomaly detection methods. We propose an anomaly detection method using the reconstruction probability from the variational autoencoder. The reconstruction probability is a probabilistic measure that takes into account the variability of the distribution of variables. The reconstruction probability has a theoretical background making it a more principled and objective anomaly score than the reconstruction error, which is used by autoencoder and principal components based anomaly detection methods. Experimental results show that the proposed method outperforms autoencoder based and principal components based methods. Utilizing the generative characteristics of the variational autoencoder enables deriving the reconstruction of the data to analyze the underlying cause of the anomaly.", "PublicationYear": "2015", "Authors": ["Jinwon An", "Sungzoon Cho"], "RelatedTopics": ["Computer Science"], "References": ["43ad00536ded47beec2d3c63ca4370840752f10b", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "6bacf99c87991523a97165610b492f28c8cacbb2", "484ad17c926292fbe0d5211540832a8c8a8e958b", "2964d30862d0402b0d0ad4a427067f69e4a52130", "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "66ad2fbc8b73242a889699868611fcf239e3435d", "195d0a8233a7a46329c742eaff56c276f847fadc", "375d7b8a70277d5d7b5e0cc999b03ba395c42901", "9ceb1dea15ac3df3d610fd0b3cc52b9a4e9141a3"], "ReferenceCount": 16, "CitationCount": 1121}, {"URL": "https://www.semanticscholar.org/paper/Anomaly-detection%3A-A-survey-Chandola-Banerjee/71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "ID": "71d1ac92ad36b62a04f32ed75a10ad3259a7218d", "Title": "Anomaly detection: A survey", "Abstract": "This survey tries to provide a structured and comprehensive overview of the research on anomaly detection by grouping existing techniques into different categories based on the underlying approach adopted by each technique. Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.", "PublicationYear": "2009", "Authors": ["Varun Chandola", "Arindam Banerjee", "Vipin Kumar"], "RelatedTopics": ["Computer Science"], "References": ["fe04438184800230074ca343785da8985682d6c9", "a1345a6a94b10273c2a0246d972f3b961685b702", "153a99ad39e85eb09f6ae56b1eb72795265cb8a0", "863efef58318bdc21986470200f6d4f2d206e039", "62fdd44b8048848c5bd25cab55ff4913215da731", "a8c065c45e557ef1c5b831b43915fd8497ce3c32", "0195d819d26355e714007d8a4bce04d0700312ed", "441c26ac495a92e4020d04f5b70113045da9f862", "63b23d8fac97dd64a878471b5d2b08514f511569", "0da52a5651004a7fe0411b036cf898914b672e79"], "ReferenceCount": 399, "CitationCount": 9874}, {"URL": "https://www.semanticscholar.org/paper/Semi-Supervised-Novelty-Detection-Blanchard-Lee/d612d7c21d4130a457968273d79c2c2f6946953d", "ID": "d612d7c21d4130a457968273d79c2c2f6946953d", "Title": "Semi-Supervised Novelty Detection", "Abstract": "It is argued that novelty detection in this semi-supervised setting is naturally solved by a general reduction to a binary classification problem and provides a general solution to the general two-sample problem, that is, the problem of determining whether two random samples arise from the same distribution. A common setting for novelty detection assumes that labeled examples from the nominal class are available, but that labeled examples of novelties are unavailable. The standard (inductive) approach is to declare novelties where the nominal density is low, which reduces the problem to density level set estimation. In this paper, we consider the setting where an unlabeled and possibly contaminated sample is also available at learning time. We argue that novelty detection in this semi-supervised setting is naturally solved by a general reduction to a binary classification problem. In particular, a detector with a desired false positive rate can be achieved through a reduction to Neyman-Pearson classification. Unlike the inductive approach, semi-supervised novelty detection (SSND) yields detectors that are optimal (e.g., statistically consistent) regardless of the distribution on novelties. Therefore, in novelty detection, unlabeled data have a substantial impact on the theoretical properties of the decision rule. We validate the practical utility of SSND with an extensive experimental study. We also show that SSND provides distribution-free, learning-theoretic solutions to two well known problems in hypothesis testing. First, our results provide a general solution to the general two-sample problem, that is, the problem of determining whether two random samples arise from the same distribution. Second, a specialization of SSND coincides with the standard p-value approach to multiple testing under the so-called random effects model. Unlike standard rejection regions based on thresholded p-values, the general SSND framework allows for adaptation to arbitrary alternative distributions in multiple dimensions.", "PublicationYear": "2010", "Authors": ["Gilles Blanchard", "Gyemin Lee", "Clayton D. Scott"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["c8c8c29c231a7658c03613a5c7dcd8b136d4c79a", "1d844bb8b556a795115144e0264b44d7f68b841a", "13bacb18ed105ee7adb4355c7a40bedddb8f563a", "153a99ad39e85eb09f6ae56b1eb72795265cb8a0", "2a69315ff7e0eb8b815810922f2ef0374f99acd0", "5b7addfb161b6e43937c9b8db3c85f10de671d0c", "41d9b4104b6d8cb8c135560b5f775bc8cd7a720d", "8d714eb3d004a8a5f8981e246d5098fabdcf9a3a", "536845bbf379fd380ea2485aa883163205b0210d", "5a002b24c0a8a63527a8c0e0681d4747e227aa6f"], "ReferenceCount": 40, "CitationCount": 264}, {"URL": "https://www.semanticscholar.org/paper/Training-Adversarial-Discriminators-for-Abnormal-in-Ravanbakhsh-Sangineto/e399a626ba21fafb19b3661603ec9724058e951b", "ID": "e399a626ba21fafb19b3661603ec9724058e951b", "Title": "Training Adversarial Discriminators for Cross-Channel Abnormal Event Detection in Crowds", "Abstract": "Generative Adversarial Nets (GANs), which are trained to generate only the normal distribution of the data, are proposed, which outperforms previous state-of-the-art methods in both the frame-level and the pixel-level evaluation. Abnormal crowd behaviour detection attracts a large interest due to its importance in video surveillance scenarios. However, the ambiguity and the lack of sufficient abnormal ground truth data makes end-to-end training of large deep networks hard in this domain. In this paper we propose to use Generative Adversarial Nets (GANs), which are trained to generate only the normal distribution of the data. During the adversarial GAN training, a discriminator (D) is used as a supervisor for the generator network (G) and vice versa. At testing time we use D to solve our discriminative task (abnormality detection), where D has been trained without the need of manually-annotated abnormal data. Moreover, in order to prevent G learn a trivial identity function, we use a cross-channel approach, forcing G to transform raw-pixel data in motion information and vice versa. The quantitative results on standard benchmarks show that our method outperforms previous state-of-the-art methods in both the frame-level and the pixel-level evaluation.", "PublicationYear": "2017", "Authors": ["Mahdyar Ravanbakhsh", "E. Sangineto", "Moin Nabi", "N. Sebe"], "RelatedTopics": ["Computer Science"], "References": ["9d5290fadb7625862a966e0330bd0f9e111fc99d", "7d8755284169f6f721e046798df1eeb1170ebdd0", "571b0750085ae3d939525e62af510ee2cee9d5ea", "89b4fb65abb4a81bc492c3b686f5dfc5f175546d", "6259b02912cebc224f3a2b1324e811a152a0177d", "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "97e7c94a78ae17cfb90848c1cfca8c431082a7b2", "6f68ce1e03c56c186256dac689a21f6405ae8d96", "e5366a704ffa3b41aacd385f3c087ec3fd566934", "655b1f83ef218ee6a030b5541d2865bc6599e6d9"], "ReferenceCount": 37, "CitationCount": 174}, {"URL": "https://www.semanticscholar.org/paper/Inverting-the-Generator-of-a-Generative-Adversarial-Creswell-Bharath/559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "ID": "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "Title": "Inverting the Generator of a Generative Adversarial Network", "Abstract": "This paper introduces a technique, inversion, to project data samples, specifically images, to the latent space using a pretrained GAN, and demonstrates how the proposed inversion technique may be used to quantitatively compare the performance of various GAN models trained on three image data sets. Generative adversarial networks (GANs) learn a deep generative model that is able to synthesize novel, high-dimensional data samples. New data samples are synthesized by passing latent samples, drawn from a chosen prior distribution, through the generative model. Once trained, the latent space exhibits interesting properties that may be useful for downstream tasks such as classification or retrieval. Unfortunately, GANs do not offer an \u201cinverse model,\u201d a mapping from data space back to latent space, making it difficult to infer a latent representation for a given data sample. In this paper, we introduce a technique, inversion, to project data samples, specifically images, to the latent space using a pretrained GAN. Using our proposed inversion technique, we are able to identify which attributes of a data set a trained GAN is able to model and quantify GAN performance, based on a reconstruction loss. We demonstrate how our proposed inversion technique may be used to quantitatively compare the performance of various GAN models trained on three image data sets. We provide codes for all of our experiments in the website (https://github.com/ToniCreswell/InvertingGAN).", "PublicationYear": "2016", "Authors": ["Antonia Creswell", "Anil Anthony Bharath"], "RelatedTopics": ["Computer Science"], "References": ["39b8f34e71553622bb16b547211d0d769563c61d", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "571b0750085ae3d939525e62af510ee2cee9d5ea", "81d5740cac256489978c2751e867128e97620eae", "6de1299a192fdb852846e3cfa4a428b8fe81523f", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "edf73ab12595c6709f646f542a0d2b33eb20a3f4", "eb7ee0bc355652654990bcf9f92f124688fde493", "744fe47157477235032f7bb3777800f9f2f45e52", "32c09d2933a4638b034343f9be20544dacf6031f"], "ReferenceCount": 28, "CitationCount": 293}, {"URL": "https://www.semanticscholar.org/paper/Inverting-The-Generator-Of-A-Generative-Adversarial-Creswell-Bharath/39b8f34e71553622bb16b547211d0d769563c61d", "ID": "39b8f34e71553622bb16b547211d0d769563c61d", "Title": "Inverting The Generator Of A Generative Adversarial Network (II)", "Abstract": "This paper introduces a technique, inversion, to project data samples, specifically images, to the latent space using a pre-trained GAN, and demonstrates how the proposed inversion technique may be used to quantitatively compare performance of various GAN models trained on three image datasets. Generative adversarial networks (GANs) learn a deep generative model that is able to synthesise novel, high-dimensional data samples. New data samples are synthesised by passing latent samples, drawn from a chosen prior distribution, through the generative model. Once trained, the latent space exhibits interesting properties, that may be useful for down stream tasks such as classification or retrieval. Unfortunately, GANs do not offer an \\\"inverse model\\", "PublicationYear": "2018", "Authors": ["Antonia Creswell", "Anil Anthony Bharath"], "RelatedTopics": ["Computer Science"], "References": ["1db6e3078597386ac4222ba6c3f4f61b61f53539", "571b0750085ae3d939525e62af510ee2cee9d5ea", "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "6de1299a192fdb852846e3cfa4a428b8fe81523f", "13bc4e683075bdd6a3f0155241c276a772d4aa06", "eb7ee0bc355652654990bcf9f92f124688fde493", "458039cf3eafd40ce27f6d6cae557753f50e51b1", "8388f1be26329fa45e5807e968a641ce170ea078", "9a700c7a7e7468e436f00c34551fbe3e0f70e42f", "fc7822f56dd255a872326b9536a0821bbf0277dd"], "ReferenceCount": 16, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Adversarial-Autoencoders-Makhzani-Shlens/c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "ID": "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "Title": "Adversarial Autoencoders", "Abstract": "It is shown how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. In this paper, we propose the\\\"adversarial autoencoder\\\"(AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.", "PublicationYear": "2015", "Authors": ["Alireza Makhzani", "Jonathon Shlens", "Navdeep Jaitly", "Ian J. Goodfellow"], "RelatedTopics": ["Computer Science"], "References": ["2904a9932f4cd0f0886121dc1f2d4aaac0455176", "543f21d81bbea89f901dfcc01f4e332a9af6682d", "3e47c4c2dd98c49b7771c7228812d5fd9eee56a3", "d450b0f12ae0437048e4047a630c31d902002d0c", "5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d", "729b18d8d91035f4bb84bf2e61b0517824e5d31b", "6bacf99c87991523a97165610b492f28c8cacbb2", "39e0c341351f8f4a39ac890b96217c7f4bde5369", "995c5f5e62614fcb4d2796ad2faab969da51713e", "f6f5ca064e91b7836f728e313d0c92666756914d"], "ReferenceCount": 26, "CitationCount": 1925}, {"URL": "https://www.semanticscholar.org/paper/Improved-Techniques-for-Training-GANs-Salimans-Goodfellow/571b0750085ae3d939525e62af510ee2cee9d5ea", "ID": "571b0750085ae3d939525e62af510ee2cee9d5ea", "Title": "Improved Techniques for Training GANs", "Abstract": "This work focuses on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic, and presents ImageNet samples with unprecedented resolution and shows that the methods enable the model to learn recognizable features of ImageNet classes. We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.", "PublicationYear": "2016", "Authors": ["Tim Salimans", "Ian J. Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "RelatedTopics": ["Computer Science"], "References": ["2904a9932f4cd0f0886121dc1f2d4aaac0455176", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "4e2f6b4bc889eed1afe5833d5190f6f02e501061", "a9d83b30c3e615286d3e24b6a2e2228872b39bc8", "32c09d2933a4638b034343f9be20544dacf6031f", "d450b0f12ae0437048e4047a630c31d902002d0c", "543f21d81bbea89f901dfcc01f4e332a9af6682d", "b321e8eca4dbf424a9e30dd938fb423786c90b76", "4cd168514e9638e0212d130c382d78044e2b262a", "23ffaa0fe06eae05817f527a47ac3291077f9e58"], "ReferenceCount": 28, "CitationCount": 7505}, {"URL": "https://www.semanticscholar.org/paper/Adversarially-Learned-Inference-Dumoulin-Belghazi/fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "ID": "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "Title": "Adversarially Learned Inference", "Abstract": "The adversarially learned inference (ALI) model is introduced, which jointly learns a generation network and an inference network using an adversarial process and the usefulness of the learned representations is confirmed by obtaining a performance competitive with state-of-the-art on the semi-supervised SVHN and CIFAR10 tasks. We introduce the adversarially learned inference (ALI) model, which jointly learns a generation network and an inference network using an adversarial process. The generation network maps samples from stochastic latent variables to the data space while the inference network maps training examples in data space to the space of latent variables. An adversarial game is cast between these two networks and a discriminative network is trained to distinguish between joint latent/data-space samples from the generative network and joint samples from the inference network. We illustrate the ability of the model to learn mutually coherent inference and generation networks through the inspections of model samples and reconstructions and confirm the usefulness of the learned representations by obtaining a performance competitive with state-of-the-art on the semi-supervised SVHN and CIFAR10 tasks.", "PublicationYear": "2016", "Authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Mart{\\'i}n Arjovsky", "Olivier Mastropietro", "Aaron C. Courville"], "RelatedTopics": ["Computer Science"], "References": ["1db6e3078597386ac4222ba6c3f4f61b61f53539", "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "eb7ee0bc355652654990bcf9f92f124688fde493", "543f21d81bbea89f901dfcc01f4e332a9af6682d", "8388f1be26329fa45e5807e968a641ce170ea078", "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "571b0750085ae3d939525e62af510ee2cee9d5ea", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "729b18d8d91035f4bb84bf2e61b0517824e5d31b", "5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d"], "ReferenceCount": 44, "CitationCount": 1240}, {"URL": "https://www.semanticscholar.org/paper/Adversarial-Feature-Learning-Donahue-Kr%C3%A4henb%C3%BChl/1db6e3078597386ac4222ba6c3f4f61b61f53539", "ID": "1db6e3078597386ac4222ba6c3f4f61b61f53539", "Title": "Adversarial Feature Learning", "Abstract": "Bidirectional Generative Adversarial Networks are proposed as a means of learning the inverse mapping of GANs, and it is demonstrated that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning. The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.", "PublicationYear": "2016", "Authors": ["Jeff Donahue", "Philipp Kr{\\\"a}henb{\\\"u}hl", "Trevor Darrell"], "RelatedTopics": ["Computer Science"], "References": ["fcf43325529c8b1cc26aeb52fd5d7e532abb0a40", "8388f1be26329fa45e5807e968a641ce170ea078", "47900aca2f0b50da3010ad59b394c870f0e6c02e", "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "b8de958fead0d8a9619b55c7299df3257c624a96", "fc1b1c9364c58ec406f494dd944b609a6a038ba6", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "c3af47db3186691270192d5399bb5259e05c87a7", "2ec8f7e0257a07d3914322b36072d1bbcd58a1e0"], "ReferenceCount": 36, "CitationCount": 1678}, {"URL": "https://www.semanticscholar.org/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/86ee1835a56722b76564119437070782fc90eb19", "ID": "86ee1835a56722b76564119437070782fc90eb19", "Title": "Generative Adversarial Nets", "Abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.", "PublicationYear": "2014", "Authors": ["Ian J. Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron C. Courville", "Yoshua Bengio"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d", "23b80dc704e25cf52b5a14935002fc083ce9c317", "6bf0414dae4f10c7e54fb9e5e8af5d0d0cab290b", "d9704f8119d6ba748230b4f2ad59f0e8c64fdfb0", "695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864", "5d90f06bb70a0a3dced62413346235c02b1aa086", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "6bacf99c87991523a97165610b492f28c8cacbb2", "484ad17c926292fbe0d5211540832a8c8a8e958b"], "ReferenceCount": 35, "CitationCount": 769}, {"URL": "https://www.semanticscholar.org/paper/Context-Encoders%3A-Feature-Learning-by-Inpainting-Pathak-Kr%C3%A4henb%C3%BChl/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "ID": "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "Title": "Context Encoders: Feature Learning by Inpainting", "Abstract": "It is found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures, and can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods. We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders - a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.", "PublicationYear": "2016", "Authors": ["Deepak Pathak", "Philipp Kr{\\\"a}henb{\\\"u}hl", "Jeff Donahue", "Trevor Darrell", "Alexei A. Efros"], "RelatedTopics": ["Computer Science"], "References": ["fc1b1c9364c58ec406f494dd944b609a6a038ba6", "6d4ff172c2d1820f33c0c72286d52b846ab5a216", "b8de958fead0d8a9619b55c7299df3257c624a96", "c3af47db3186691270192d5399bb5259e05c87a7", "8388f1be26329fa45e5807e968a641ce170ea078", "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "843959ffdccf31c6694d135fad07425924f785b1", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "d0a8b5cf98b6721b743571ee13e6032ff5598aea", "c426ba865e9158a0f7962a86a50575aa943051b1"], "ReferenceCount": 42, "CitationCount": 4665}, {"URL": "https://www.semanticscholar.org/paper/Deep-Autoencoding-Models-for-Unsupervised-Anomaly-Baur-Wiestler/eb60fe884c53b420edbce57059b242cfcbae0f7c", "ID": "eb60fe884c53b420edbce57059b242cfcbae0f7c", "Title": "Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain MR Images", "Abstract": "This work shows that deep spatial autoencoding models can be efficiently used to capture normal anatomical variability of entire 2D brain MR images and shows that constraints on the latent space and adversarial training can further improve the segmentation performance over standard deep representation learning. Reliably modeling normality and differentiating abnormal appearances from normal cases is a very appealing approach for detecting pathologies in medical images. A plethora of such unsupervised anomaly detection approaches has been made in the medical domain, based on statistical methods, content-based retrieval, clustering and recently also deep learning. Previous approaches towards deep unsupervised anomaly detection model patches of normal anatomy with variants of Autoencoders or GANs, and detect anomalies either as outliers in the learned feature space or from large reconstruction errors. In contrast to these patch-based approaches, we show that deep spatial autoencoding models can be efficiently used to capture normal anatomical variability of entire 2D brain MR images. A variety of experiments on real MR data containing MS lesions corroborates our hypothesis that we can detect and even delineate anomalies in brain MR images by simply comparing input images to their reconstruction. Results show that constraints on the latent space and adversarial training can further improve the segmentation performance over standard deep representation learning.", "PublicationYear": "2018", "Authors": ["Christoph Baur", "Benedikt Wiestler", "Shadi Albarqouni", "Nassir Navab"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["e163a2e89c136cb4442e34c72f7173a0ff46dc79", "c62bf15759f48bab3bcfb6412dcd2858034f9fbe", "45f490710b4dd6697dba4c9b385a49554501711a", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "4714f863564b32be86dab6f2cd7ef8fbecc9bafb", "e8b8a7778ace2a02f8db6fe321a54520c6b283ca", "1db6e3078597386ac4222ba6c3f4f61b61f53539", "39d08fa8b028217384daeb3e622848451809a422", "199f0f56bc6cc5ff13cda5274797d46c3022e7c5", "527cc8cd2af06a9ac2e5cded806bab5c3faad9cf"], "ReferenceCount": 21, "CitationCount": 380}, {"URL": "https://www.semanticscholar.org/paper/Learning-Deep-Features-for-One-Class-Classification-Perera-Patel/732c21998e251d64cd58b6a86886ee5907efeaa5", "ID": "732c21998e251d64cd58b6a86886ee5907efeaa5", "Title": "Learning Deep Features for One-Class Classification", "Abstract": "A novel deep-learning-based approach for one-class transfer learning in which labeled data from an unrelated task is used for feature learning in one- class classification and achieves significant improvements over the state-of-the-art. We present a novel deep-learning-based approach for one-class transfer learning in which labeled data from an unrelated task is used for feature learning in one-class classification. The proposed method operates on top of a convolutional neural network (CNN) of choice and produces descriptive features while maintaining a low intra-class variance in the feature space for the given class. For this purpose two loss functions, compactness loss and descriptiveness loss, are proposed along with a parallel CNN architecture. A template matching-based framework is introduced to facilitate the testing process. Extensive experiments on publicly available anomaly detection, novelty detection, and mobile active authentication datasets show that the proposed deep one-class (DOC) classification method achieves significant improvements over the state-of-the-art.", "PublicationYear": "2018", "Authors": ["Pramuditha Perera", "Vishal M. Patel"], "RelatedTopics": ["Computer Science"], "References": ["00695a31a80221c7125e49885a4767896ec2c4f7", "2910bec6d4de87e22be5119cef3c488d2ae50e2a", "6af440915b8a0718c93be1cf61905e41e620484a", "67b9c2b376a01d8757dc6d704be450d1c46c4ced", "b8de958fead0d8a9619b55c7299df3257c624a96", "eb42cf88027de515750f230b23b1a057dc782108", "0b822de3ed689344862eecb5ad86c36eb2ff9de5", "f5a3598028cd375071a38f90f1b2122308e3a100", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "2f4df08d9072fc2ac181b7fced6a245315ce05c8"], "ReferenceCount": 58, "CitationCount": 323}, {"URL": "https://www.semanticscholar.org/paper/Improving-Unsupervised-Defect-Segmentation-by-to-Bergmann-L%C3%B6we/9c24454b071bc8e96ea46c5064a7bddf07cca464", "ID": "9c24454b071bc8e96ea46c5064a7bddf07cca464", "Title": "Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders", "Abstract": "This work proposes to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a pixel-wise reconstruction error based on an $\\\\ell^p$ distance. This procedure, however, leads to large residuals whenever the reconstruction encompasses slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that it cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over the state of the art approaches for unsupervised defect segmentation that use pixel-wise reconstruction error metrics.", "PublicationYear": "2018", "Authors": ["Paul Bergmann", "Sindy L{\\\"o}we", "Michael Fauser", "David Sattlegger", "Carsten Steger"], "RelatedTopics": ["Computer Science"], "References": ["90e4f12fa8fb126d0f416c8b61bfb5f73f8b7b74", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "8d7aa1e9c135c6998e9abe098c9478874a73f357", "9179e740dad4ca4c183f7677b854e5b15f9a122f", "eae2e0fa72e898c289365c0af16daf57a7a6cf40", "63eb7986f726c7a8cf14b720fa6eba3ab168c4a4", "6180c1217c2c37d0b2f3e41930032d5f64b28af2", "75a838cbc1541858b9c484001cade327640dc280", "85384a8871030bbd1681adee9e9956dce4d751ba", "e163a2e89c136cb4442e34c72f7173a0ff46dc79"], "ReferenceCount": 27, "CitationCount": 440}, {"URL": "https://www.semanticscholar.org/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d", "ID": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "Title": "Deep Residual Learning for Image Recognition", "Abstract": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.", "PublicationYear": "2015", "Authors": ["Kaiming He", "X. Zhang", "Shaoqing Ren", "Jian Sun"], "RelatedTopics": ["Computer Science"], "References": ["eb42cf88027de515750f230b23b1a057dc782108", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd", "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "d6f2f611da110b5b5061731be3fc4c7f45d8ee23", "995c5f5e62614fcb4d2796ad2faab969da51713e", "5e83ab70d0cbc003471e87ec306d27d9c80ecb16", "5d90f06bb70a0a3dced62413346235c02b1aa086", "b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14", "8ad35df17ae4064dd174690efb04d347428f1117"], "ReferenceCount": 55, "CitationCount": 151969}, {"URL": "https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/abd1c342495432171beb7ca8fd9551ef13cbd0ff", "ID": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "Title": "ImageNet classification with deep convolutional neural networks", "Abstract": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \\\"dropout\\\" that proved to be very effective. We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \\\"dropout\\\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.", "PublicationYear": "2012", "Authors": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "RelatedTopics": ["Computer Science"], "References": ["9952d4d5717afd4a27157ed8b98b0ee3dcb70d6c", "bea5780d621e669e8069f05d0f2fc0db9df4b50f", "82b9099ddf092463f497bd48bb112c46ca52c4d1", "398c296d0cc7f9d180f84969f8937e6d3a413796", "5d90f06bb70a0a3dced62413346235c02b1aa086", "5bdfd78fb2285b9306e93bd3a4b534d19bf55f06", "c43025c429b1fbf6f1379f61801a1b40834d62e7", "3a4a53fe47036ac89dad070ab87a9d8795b139b1", "5562a56da3a96dae82add7de705e2bd841eb00fc", "f354310098e09c1e1dc88758fca36767fd9d084d"], "ReferenceCount": 44, "CitationCount": 105585}, {"URL": "https://www.semanticscholar.org/paper/Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky/5d90f06bb70a0a3dced62413346235c02b1aa086", "ID": "5d90f06bb70a0a3dced62413346235c02b1aa086", "Title": "Learning Multiple Layers of Features from Tiny Images", "Abstract": "It is shown how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex, using a novel parallelization algorithm to distribute the work among multiple machines connected on a network. Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images.", "PublicationYear": "2009", "Authors": ["Alex Krizhevsky"], "RelatedTopics": ["Computer Science"], "References": ["54d2b5c64a67f65c5dd812b89e07973f97699552", "73e93d0346e8eee6c2ab45e46c26eaafb66e12a8", "71e3d9fc53ba14c2feeb7390f0dc99076553b05a", "ca1d23be869380ac9e900578c601c2d1febcc0c9", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "939d584316be99e2db3fec3fbf7d71f22a477f67", "08d0ea90b53aba0008d25811268fe46562cfb38c", "9360e5ce9c98166bb179ad479a9d2919ff13d022", "4f7476037408ac3d993f5088544aab427bc319c1", "73d6a26f407db77506959fdf3f7b853e44f3844a"], "ReferenceCount": 15, "CitationCount": 27154}, {"URL": "https://www.semanticscholar.org/paper/Deep-Transfer-Learning-for-Multiple-Class-Novelty-Perera-Patel/2910bec6d4de87e22be5119cef3c488d2ae50e2a", "ID": "2910bec6d4de87e22be5119cef3c488d2ae50e2a", "Title": "Deep Transfer Learning for Multiple Class Novelty Detection", "Abstract": "It is shown that thresholding the maximal activation of the proposed network can be used to identify novel objects effectively, and that the proposed method achieves significant improvements over the state-of-the-art methods. We propose a transfer learning-based solution for the problem of multiple class novelty detection. In particular, we propose an end-to-end deep-learning based approach in which we investigate how the knowledge contained in an external, out-of-distributional dataset can be used to improve the performance of a deep network for visual novelty detection. Our solution differs from the standard deep classification networks on two accounts. First, we use a novel loss function, membership loss, in addition to the classical cross-entropy loss for training networks. Secondly, we use the knowledge from the external dataset more effectively to learn globally negative filters, filters that respond to generic objects outside the known class set. We show that thresholding the maximal activation of the proposed network can be used to identify novel objects effectively. Extensive experiments on four publicly available novelty detection datasets show that the proposed method achieves significant improvements over the state-of-the-art methods.", "PublicationYear": "2019", "Authors": ["Pramuditha Perera", "Vishal M. Patel"], "RelatedTopics": ["Computer Science"], "References": ["732c21998e251d64cd58b6a86886ee5907efeaa5", "890e560015e39bbf4a6d34ff335430d22fa04877", "87e5b4d95f95a0975e855cf5ad402db7a3c64ff5", "599fd051c9438011ec5b581983c89e8922b4a5e6", "00695a31a80221c7125e49885a4767896ec2c4f7", "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "1972c73d96353e57599962fd6059572801382212", "eb42cf88027de515750f230b23b1a057dc782108", "d094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c", "e31fa9510047c0df23fb4dd37ee7c70783a3fa60"], "ReferenceCount": 30, "CitationCount": 85}, {"URL": "https://www.semanticscholar.org/paper/q-Space-Novelty-Detection-with-Variational-Vasilev-Golkov/68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6", "ID": "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6", "Title": "q-Space Novelty Detection with Variational Autoencoders", "Abstract": "This work proposes novelty detection methods based on training variational autoencoders (VAEs) on normal data to magnetic resonance imaging, namely to the detection of diffusion-space (q-space) abnormalities in diffusion MRI scans of multiple sclerosis patients, and shows that many of them are able to outperform the state of the art. In machine learning, novelty detection is the task of identifying novel unseen data. During training, only samples from the normal class are available. Test samples are classified as normal or abnormal by assignment of a novelty score. Here we propose novelty detection methods based on training variational autoencoders (VAEs) on normal data. Since abnormal samples are not used during training, we define novelty metrics based on the (partially complementary) assumptions that the VAE is less capable of reconstructing abnormal samples well; that abnormal samples more strongly violate the VAE regularizer; and that abnormal samples differ from normal samples not only in input-feature space, but also in the VAE latent space and VAE output. These approaches, combined with various possibilities of using (e.g. sampling) the probabilistic VAE to obtain scalar novelty scores, yield a large family of methods. We apply these methods to magnetic resonance imaging, namely to the detection of diffusion-space (q-space) abnormalities in diffusion MRI scans of multiple sclerosis patients, i.e. to detect multiple sclerosis lesions without using any lesion labels for training. Many of our methods outperform previously proposed q-space novelty detection methods. We also evaluate the proposed methods on the MNIST handwritten digits dataset and show that many of them are able to outperform the state of the art.", "PublicationYear": "2018", "Authors": ["Aleksei Vasilev", "Vladimir Golkov", "Ilona Lipp", "Eleonora Sgarlata", "Valentina Tomassini", "Derek K. Jones", "Daniel Cremers"], "RelatedTopics": ["Computer Science"], "References": ["98af3dc5af084967adcfeda40b58b0012f98e1e9", "705df884b2944e1a6f86e72ff1946318b4ad3bdd", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "6b1160f6ff6c4a8e1418f4edba9c6b9c2c6f385a", "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1", "817d88916e962b3bcf71de8bf49207916cfebb50", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "9acc51b06f54b07836fad4cc24633187dc21317f", "061146b1d7938d7a8dae70e3531a00fceb3c78e8"], "ReferenceCount": 21, "CitationCount": 51}, {"URL": "https://www.semanticscholar.org/paper/Latent-Space-Autoregression-for-Novelty-Detection-Abati-Porrello/5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "ID": "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d", "Title": "Latent Space Autoregression for Novelty Detection", "Abstract": "This proposal designs a general unsupervised framework where a deep autoencoder is equipped with a parametric density estimator that learns the probability distribution underlying the latent representations with an autoregressive procedure and shows that a maximum likelihood objective effectively acts as a regularizer for the task at hand. Novelty detection is commonly referred as the discrimination of observations that do not conform to a learned model of regularity. Despite its importance in different application settings, designing a novelty detector is utterly complex due to the unpredictable nature of novelties and its inaccessibility during the training procedure, factors which expose the unsupervised nature of the problem. In our proposal, we design a general unsupervised framework where we equip a deep autoencoder with a parametric density estimator that learns the probability distribution underlying the latent representations with an autoregressive procedure. We show that a maximum likelihood objective, optimized in conjunction with the reconstruction of normal samples, effectively acts as a regularizer for the task at hand, by minimizing the differential entropy of the distribution spanned by latent vectors. In addition to providing a very general formulation, extensive experiments of our model on publicly available datasets deliver on-par or superior performances if compared to state-of-the-art methods in one-class and in video anomaly detection settings. Differently from our competitors, we remark that our proposal does not make any assumption about the nature of the novelties, making our work easily applicable to disparate contexts.", "PublicationYear": "2018", "Authors": ["Davide Abati", "Angelo Porrello", "Simone Calderara", "Rita Cucchiara"], "RelatedTopics": ["Computer Science"], "References": ["8381157eae4fbf8908d0312a9642f8e69e944449", "dbc7401e3e75c40d3c720e7db3c906d48bd742d7", "90f72fbbe5f0a29e627db28999e01a30a9655bc6", "97e7c94a78ae17cfb90848c1cfca8c431082a7b2", "792250ae660b7c25f85eeea7dcae623e4301d97c", "99dff291f260b3cc3ff190106b0c2e3e685223a4", "705fd4febe2fff810d2f72f48dcda20826eca77a", "3262e77099cefe24cff1308f204e673cac832451", "39e0c341351f8f4a39ac890b96217c7f4bde5369", "4eb82d0ae0b60311779f2b1e1fa2d8789fb38cb2"], "ReferenceCount": 49, "CitationCount": 357}, {"URL": "https://www.semanticscholar.org/paper/f%E2%80%90AnoGAN%3A-Fast-unsupervised-anomaly-detection-with-Schlegl-Seeb%C3%B6ck/f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "ID": "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c", "Title": "f\u2010AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks", "Abstract": "Semantic Scholar extracted view of \\\"f\u2010AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks\\\" by T. Schlegl et al.", "PublicationYear": "2019", "Authors": ["Thomas Schlegl", "Philipp Seeb{\\\"o}ck", "Sebastian M. Waldstein", "Georg Langs", "Ursula Margarethe Schmidt-Erfurth"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["e163a2e89c136cb4442e34c72f7173a0ff46dc79", "c1cc356ae6303b254ce88919ade3907221a5b58d", "71c076b4c606174a6e83d7d64d2064827d6b6d11", "559a52d27ff8e3ae0cdf1e7948c137ff566285c8", "571b0750085ae3d939525e62af510ee2cee9d5ea", "2bf3a05467939fcb00de606cc1bcc9353ad288cb", "9d5290fadb7625862a966e0330bd0f9e111fc99d", "2a863a1ab6df3ca9a55573befcb89e1ed7b7df74", "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "05dc42d9262c0ba8dd2d3a3798a2ce1e233cd3cc"], "ReferenceCount": 45, "CitationCount": 777}, {"URL": "https://www.semanticscholar.org/paper/Metric-Learning-for-Novelty-and-Anomaly-Detection-Masana-Ruiz/317c172f314f8cb634f7569ed5bf3ae7dd25c313", "ID": "317c172f314f8cb634f7569ed5bf3ae7dd25c313", "Title": "Metric Learning for Novelty and Anomaly Detection", "Abstract": "This work proposes to use metric learning which does not have the drawback of the softmax layer (inherent to cross-entropy methods), which forces the network to divide its prediction power over the learned classes. When neural networks process images which do not resemble the distribution seen during training, so called out-of-distribution images, they often make wrong predictions, and do so too confidently. The capability to detect out-of-distribution images is therefore crucial for many real-world applications. We divide out-of-distribution detection between novelty detection ---images of classes which are not in the training set but are related to those---, and anomaly detection ---images with classes which are unrelated to the training set. By related we mean they contain the same type of objects, like digits in MNIST and SVHN. Most existing work has focused on anomaly detection, and has addressed this problem considering networks trained with the cross-entropy loss. Differently from them, we propose to use metric learning which does not have the drawback of the softmax layer (inherent to cross-entropy methods), which forces the network to divide its prediction power over the learned classes. We perform extensive experiments and evaluate both novelty and anomaly detection, even in a relevant application such as traffic sign recognition, obtaining comparable or better results than previous works.", "PublicationYear": "2018", "Authors": ["Marc Masana", "Idoia Ruiz", "Joan Serrat", "Joost van de Weijer", "Antonio M. L{\\'o}pez"], "RelatedTopics": ["Computer Science"], "References": ["547c854985629cfa9404a5ba8ca29367b5f8c25f", "36653f8705b56e39642bcd123494eb680cd1636b", "890e560015e39bbf4a6d34ff335430d22fa04877", "cdd8bad29b5e90a1f92080eaca51ba123f34ada5", "5d90f06bb70a0a3dced62413346235c02b1aa086", "1972c73d96353e57599962fd6059572801382212", "2ed7cc027367295b1a7d7cd49406acfa5c580138", "6ff2a434578ff2746b9283e45abf296887f48a2d", "9acc51b06f54b07836fad4cc24633187dc21317f", "4dcdae25a5e33682953f0853ee4cf7ca93be58a9"], "ReferenceCount": 36, "CitationCount": 69}, {"URL": "https://www.semanticscholar.org/paper/A-Gaussian-Mixture-Model-layer-jointly-optimized-a-Variani-McDermott/60d4ec78a673119420bee41268672a8f8669bb31", "ID": "60d4ec78a673119420bee41268672a8f8669bb31", "Title": "A Gaussian Mixture Model layer jointly optimized with discriminative features within a Deep Neural Network architecture", "Abstract": "The proposed Gaussian Mixture Model represented as the last layer of a Deep Neural Network architecture and jointly optimized with all previous layers using Asynchronous Stochastic Gradient Descent (ASGD) were found to yield Word Error Rates competitive with state-of-the-art DNN systems. This article proposes and evaluates a Gaussian Mixture Model (GMM) represented as the last layer of a Deep Neural Network (DNN) architecture and jointly optimized with all previous layers using Asynchronous Stochastic Gradient Descent (ASGD). The resulting \u201cDeep GMM\u201d architecture was investigated with special attention to the following issues: (1) The extent to which joint optimization improves over separate optimization of the DNN-based feature extraction layers and the GMM layer; (2) The extent to which depth (measured in number of layers, for a matched total number of parameters) helps a deep generative model based on the GMM layer, compared to a vanilla DNN model; (3) Head-to-head performance of Deep GMM architectures vs. equivalent DNN architectures of comparable depth, using the same optimization criterion (frame-level Cross Entropy (CE)) and optimization method (ASGD); (4) Expanded possibilities for modeling offered by the Deep GMM generative model. The proposed Deep GMMs were found to yield Word Error Rates (WERs) competitive with state-of-the-art DNN systems, at the cost of pre-training using standard DNNs to initialize the Deep GMM feature extraction layers. An extension to Deep Subspace GMMs is described, resulting in additional gains.", "PublicationYear": "2015", "Authors": ["Ehsan Variani", "Erik McDermott", "Georg Heigold"], "RelatedTopics": ["Computer Science"], "References": ["837ccad58318a1f18d1409bed60ee1e3fa90de94", "0523e14247d74c4505cd5e32e1f0495f291ec432", "375d7b8a70277d5d7b5e0cc999b03ba395c42901", "6dfce7144275e7ca3ada3a2075b82c0f97491243", "008e9e2d3908c964d5b1c408c478215709dbea10", "4326617172d0fc3901d3695091e040f17e226840", "06c152df89ca6a1f1b8f8e139ddda82cd4539415", "e33cbb25a8c7390aec6a398e36381f4f7770c283", "2443dc59cf3d6cc1deba6d3220d61664b1a7eada", "f084596fdc853f33e8bfdb86c114985202ead24b"], "ReferenceCount": 25, "CitationCount": 60}, {"URL": "https://www.semanticscholar.org/paper/Integrating-Gaussian-mixtures-into-deep-neural-with-T%C3%BCske-Tahir/aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "ID": "aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "Title": "Integrating Gaussian mixtures into deep neural networks: Softmax layer with hidden variables", "Abstract": "This paper shows that GMM can be easily integrated into the deep neural network framework by exploiting its equivalence with the log-linear mixture model (LMM), which can be transformed to a large softmax layer followed by a summation pooling layer. In the hybrid approach, neural network output directly serves as hidden Markov model (HMM) state posterior probability estimates. In contrast to this, in the tandem approach neural network output is used as input features to improve classic Gaussian mixture model (GMM) based emission probability estimates. This paper shows that GMM can be easily integrated into the deep neural network framework. By exploiting its equivalence with the log-linear mixture model (LMM), GMM can be transformed to a large softmax layer followed by a summation pooling layer. Theoretical and experimental results indicate that the jointly trained and optimally chosen GMM and bottleneck tandem features cannot perform worse than a hybrid model. Thus, the question \u201chybrid vs. tandem\u201d simplifies to optimizing the output layer of a neural network. Speech recognition experiments are carried out on a broadcast news and conversations task using up to 12 feed-forward hidden layers with sigmoid and rectified linear unit activation functions. The evaluation of the LMM layer shows recognition gains over the classic softmax output.", "PublicationYear": "2015", "Authors": ["Zolt{\\'a}n T{\\\"u}ske", "Muhammad Ali Tahir", "Ralf Schl{\\\"u}ter", "Hermann Ney"], "RelatedTopics": ["Computer Science"], "References": ["837ccad58318a1f18d1409bed60ee1e3fa90de94", "71f922985c2ca4553c0fbfc4fd30c240c798b6e3", "5e9082caea65c76bfd23b8763872804473ee7872", "3d82e058a5c40954b8f5db170a298a889a254c37", "4326617172d0fc3901d3695091e040f17e226840", "d82354fab1c800f3a50632d1371f083348af0971", "c510600e68740890f7d36c2c8545ddcff275fa99", "28a23135790ea496cf6564cf43b9f3caab6cd632", "5cea23330c76994cb626df20bed31cc2588033df", "b9e0a7eb79ab7ab02c30e43a3e5c75b48ea46b31"], "ReferenceCount": 27, "CitationCount": 40}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Dimensionality-Reduction-for-Gaussian-Yang-Huang/33a832399927971f144dee7fee50c0bcc5e1e659", "ID": "33a832399927971f144dee7fee50c0bcc5e1e659", "Title": "Unsupervised Dimensionality Reduction for Gaussian Mixture Model", "Abstract": "Experimental results show that the joint learning significantly outperforms the comparison method in terms of three criteria for supervised learning. Dimensionality reduction is a fundamental yet active research topic in pattern recognition and machine learning. On the other hand, Gaussian Mixture Model (GMM), a famous model, has been widely used in various applications, e.g., clustering and classification. For high-dimensional data, previous research usually performs dimensionality reduction first, and then inputs the reduced features to other available models, e.g., GMM. In particular, there are very few investigations or discussions on how dimensionality reduction could be interactively and systematically conducted together with the important GMM. In this paper, we study the problem how unsupervised dimensionality reduction could be performed together with GMM and if such joint learning could lead to improvement in comparison with the traditional unsupervised method. Specifically, we engage the Mixture of Factor Analyzers with the assumption that a common factor loading exist for all the components. Such setting exactly optimizes a dimensionality reduction together with the parameters of GMM. We compare the joint learning approach and the separate dimensionality reduction plus GMM method on both synthetic data and real data sets. Experimental results show that the joint learning significantly outperforms the comparison method in terms of three criteria for supervised learning.", "PublicationYear": "2014", "Authors": ["Xi Yang", "Kaizhu Huang", "Rui Zhang"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["b095d70aa087c3e3c90fbbffe7c0cc5bbfb326ee", "a67d2d9a318736560977a374c9a23d4dcf395f2b", "0f71e564c1558dff2c1bc7027848d18439be16b6", "0352f5a9ec509e78c0ee584f1e145725f12dfbb2", "4825aa7cc50db6c99b3678c4b77515875c1bad1b", "5e52081e0f9e534e609d3b47c96558afec2df276"], "ReferenceCount": 6, "CitationCount": 8}, {"URL": "https://www.semanticscholar.org/paper/Joint-Learning-of-Unsupervised-Dimensionality-and-Yang-Huang/3eeb8b5d5ee2db86fa359ec479b730a793d5971e", "ID": "3eeb8b5d5ee2db86fa359ec479b730a793d5971e", "Title": "Joint Learning of Unsupervised Dimensionality Reduction and Gaussian Mixture Model", "Abstract": "This paper compares the proposed joint learning approach with two competitive algorithms on one synthetic and six real data sets and shows that the joint learning significantly outperforms the comparison methods in terms of three criteria. Dimensionality reduction (DR) has been one central research topic in information theory, pattern recognition, and machine learning. Apparently, the performance of many learning models significantly rely on dimensionality reduction: successful DR can largely improve various approaches in clustering and classification, while inappropriate DR may deteriorate the systems. When applied on high-dimensional data, some existing research approaches often try to reduce the dimensionality first, and then input the reduced features to other available models, e.g., Gaussian mixture model (GMM). Such independent learning could however significantly limit the performance, since the optimal subspace given by a particular DR approach may not be appropriate for the following model. In this paper, we focus on investigating how unsupervised dimensionality reduction could be performed together with GMM and if such joint learning could lead to improvement in comparison with the traditional unsupervised method. In particular, we engage the mixture of factor analyzers with the assumption that a common factor loading exists for all the components. Based on that, we then present EM-algorithm that converges to a local optimal solution. Such setting exactly optimizes a dimensionality reduction together with the parameters of GMM. We describe the framework, detail the algorithm, and conduct a series of experiments to validate the effectiveness of our proposed approach. Specifically, we compare the proposed joint learning approach with two competitive algorithms on one synthetic and six real data sets. Experimental results show that the joint learning significantly outperforms the comparison methods in terms of three criteria.", "PublicationYear": "2017", "Authors": ["Xi Yang", "Kaizhu Huang", "John Yannis Goulermas", "Rui Zhang"], "RelatedTopics": ["Computer Science"], "References": ["33a832399927971f144dee7fee50c0bcc5e1e659", "b095d70aa087c3e3c90fbbffe7c0cc5bbfb326ee", "291c1274ee45bf78662ed60831ef1bdaf89bed94", "a67d2d9a318736560977a374c9a23d4dcf395f2b", "9b819c146dba12efdc7996d975fb3d4fac2faa9d", "b08e2ea6f1ed75e14c74c8e303bf11c0abfedad4", "5cc77c2e2cb74b192e183aa62b3fe86be778ff48", "0352f5a9ec509e78c0ee584f1e145725f12dfbb2", "802f2afd13b209d4c6d6d3622efc48a7256d7207", "801ecc5cb8b81da722fc7cfb1e41d2b1d7bfe94a"], "ReferenceCount": 22, "CitationCount": 20}, {"URL": "https://www.semanticscholar.org/paper/Towards-K-means-friendly-Spaces%3A-Simultaneous-Deep-Yang-Fu/ca9f84c3922004ec6133aa9c2048ceeb17702fee", "ID": "ca9f84c3922004ec6133aa9c2048ceeb17702fee", "Title": "Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering", "Abstract": "A joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN) while exploiting theDeep neural network's ability to approximate any nonlinear function is proposed. Most learning approaches treat dimensionality reduction (DR) and clustering separately (i.e., sequentially), but recent research has shown that optimizing the two tasks jointly can substantially improve the performance of both. The premise behind the latter genre is that the data samples are obtained via linear transformation of latent representations that are easy to cluster; but in practice, the transformation from the latent space to the data can be more complicated. In this work, we assume that this transformation is an unknown and possibly nonlinear function. To recover the 'clustering-friendly' latent representations and to better cluster the data, we propose a joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN). The motivation is to keep the advantages of jointly optimizing the two tasks, while exploiting the deep neural network's ability to approximate any nonlinear function. This way, the proposed approach can work well for a broad class of generative models. Towards this end, we carefully design the DNN structure and the associated joint optimization criterion, and propose an effective and scalable algorithm to handle the formulated optimization problem. Experiments using different real datasets are employed to showcase the effectiveness of the proposed approach.", "PublicationYear": "2016", "Authors": ["Bo Yang", "Xiao Fu", "N. Sidiropoulos", "Mingyi Hong"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["2eecf2a2788117b808b72321802731efc86526b2", "ac120ca0a53715d3674410bf7d3384116a81338a", "3332dc72fbe3907e45e8a500c6a1202ad5092c0f", "8db95dbd08e4ee64fb258e5380e78cfa507ed94d", "f44ff4fc0ed0142cb18472a5ba421bb538aa837e", "995c5f5e62614fcb4d2796ad2faab969da51713e", "e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "5aa26299435bdf7db874ef1640a6c3b5a4a2c394", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd"], "ReferenceCount": 47, "CitationCount": 718}, {"URL": "https://www.semanticscholar.org/paper/Stacked-Denoising-Autoencoders%3A-Learning-Useful-in-Vincent-Larochelle/e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "ID": "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "Title": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion", "Abstract": "This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations. We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.", "PublicationYear": "2010", "Authors": ["Pascal Vincent", "H. Larochelle", "Isabelle Lajoie", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "RelatedTopics": ["Computer Science"], "References": ["843959ffdccf31c6694d135fad07425924f785b1", "b2af2a2f2d1be22ebf473f7e0f501f1f5c02f222", "0d2336389dff3031910bd21dd1c44d1b4cd51725", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "739edc6ae61cb246493a7d2ab6e320d10ace4412", "05fd1da7b2e34f86ec7f010bef068717ae964332", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "202cbbf671743aefd380d2f23987bd46b9caaf97", "932c2a02d462abd75af018125413b1ceaa1ee3f4"], "ReferenceCount": 60, "CitationCount": 6680}, {"URL": "https://www.semanticscholar.org/paper/Neural-Variational-Inference-and-Learning-in-Belief-Mnih-Gregor/331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "ID": "331f0fb3b6176c6e463e0401025b04f6ace9ccd3", "Title": "Neural Variational Inference and Learning in Belief Networks", "Abstract": "This work proposes a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior and shows that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset. Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference network gradient is too high-variance to be useful, we make it practical by applying several straightforward model-independent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.", "PublicationYear": "2014", "Authors": ["Andriy Mnih", "Karol Gregor"], "RelatedTopics": ["Computer Science"], "References": ["6bacf99c87991523a97165610b492f28c8cacbb2", "f87247fb37f6b48da0757d7a1acf38da44510cdb", "08d0ea90b53aba0008d25811268fe46562cfb38c", "484ad17c926292fbe0d5211540832a8c8a8e958b", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "6a667700100e228cb30a5d884258a0db921603fe", "00cd1dab559a9671b692f39f14c1573ab2d1416b", "695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864", "512ea8d0c5b5de896129e76d4276f7b996fe88d8", "9ceb1dea15ac3df3d610fd0b3cc52b9a4e9141a3"], "ReferenceCount": 34, "CitationCount": 692}, {"URL": "https://www.semanticscholar.org/paper/Speaker-adaptive-joint-training-of-Gaussian-mixture-T%C3%BCske-Golik/8080c7954944e4e293028768e7dcbaead190c85e", "ID": "8080c7954944e4e293028768e7dcbaead190c85e", "Title": "Speaker adaptive joint training of Gaussian mixture models and bottleneck features", "Abstract": "Experiments show that the deeper backpropagation through the speaker dependent layer is necessary for improved recognition performance, and the speaker adaptively and jointly trained BN-GMM results in 5% relative improvement over very strong speaker-independent hybrid baseline on the Quaero English broadcast news and conversations task, and on the 300-hour Switchboard task. In the tandem approach, the output of a neural network (NN) serves as input features to a Gaussian mixture model (GMM) aiming to improve the emission probability estimates. As has been shown in our previous work, GMM with pooled covariance matrix can be integrated into a neural network framework as a softmax layer with hidden variables, which allows for joint estimation of both neural network and Gaussian mixture parameters. Here, this approach is extended to include speaker adaptive training (SAT) by introducing a speaker dependent neural network layer. Error backpropagation beyond this speaker dependent layer realizes the adaptive training of the Gaussian parameters as well as the optimization of the bottleneck (BN) tandem features of the underlying acoustic model, simultaneously. In this study, after the initialization by constrained maximum likelihood linear regression (CMLLR) the speaker dependent layer itself is kept constant during the joint training. Experiments show that the deeper backpropagation through the speaker dependent layer is necessary for improved recognition performance. The speaker adaptively and jointly trained BN-GMM results in 5% relative improvement over very strong speaker-independent hybrid baseline on the Quaero English broadcast news and conversations task, and on the 300-hour Switchboard task.", "PublicationYear": "2015", "Authors": ["Zolt{\\'a}n T{\\\"u}ske", "Pavel Golik", "Ralf Schl{\\\"u}ter", "Hermann Ney"], "RelatedTopics": ["Computer Science"], "References": ["aedbddf72cb82c77d715a12dc43a98a0b1f1982f", "247425484c95e37554989be2ac3444f244bd8b07", "d1a60aa2362783b479cfe37963e14ab28d3d9181", "8e46a2e57ce37b846bef48d776aeafa16c411681", "778015de7b81dfde54367dd57fb76c86faa72be4", "05de249c56353b8916d3eb2fec76ddf7fbd47f33", "ae4614f758dfa344a04b33377c96abc10d5eeda7", "398dc5a65123364bd327bfbb17d2a2533b08c301", "3afede5fa4234141788a7667169b5dfe02f8266e", "7600cf5da33b19d37266da4d2edcbd32bc0ecb5e"], "ReferenceCount": 51, "CitationCount": 27}, {"URL": "https://www.semanticscholar.org/paper/Robust-feature-learning-by-stacked-autoencoder-with-Qi-Wang/357733cc76e31a499a27ba2da8612174aafb3213", "ID": "357733cc76e31a499a27ba2da8612174aafb3213", "Title": "Robust feature learning by stacked autoencoder with maximum correntropy criterion", "Abstract": "A robust stacked autoencoder based on maximum correntropy criterion (MCC) to deal with the data containing non-Gaussian noises and outliers is proposed and Experimental results show that R-SAE is capable of learning robust features on noisy data. Unsupervised feature learning with deep networks has been widely studied in the recent years. Despite the progress, most existing models would be fragile to non-Gaussian noises and outliers due to the criterion of mean square error (MSE). In this paper, we propose a robust stacked autoencoder (R-SAE) based on maximum correntropy criterion (MCC) to deal with the data containing non-Gaussian noises and outliers. By replacing MSE with MCC, the anti-noise ability of stacked autoencoder is improved. The proposed method is evaluated using the MNIST benchmark dataset. Experimental results show that, compared with the ordinary stacked autoencoder, the R-SAE improves classification accuracy by 14% and reduces the reconstruction error by 39%, which demonstrates that R-SAE is capable of learning robust features on noisy data.", "PublicationYear": "2014", "Authors": ["Yu Qi", "Yueming Wang", "Xiaoxiang Zheng", "Zhaohui Wu"], "RelatedTopics": ["Computer Science"], "References": ["843959ffdccf31c6694d135fad07425924f785b1", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "0ff94e25a8ff3bd5c98899684d0885423fbe4f91", "a2017ec2c60d542af5e9993176ba68f89529dbce", "8a09668efc95eafd6c3056ff1f0fbc43bb5774db", "fbaecde38bf43214778193d3728f8f33471b0a91", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "298ecc682355a202e520ae0640191cdfbec85b1a", "268b8f10a45e71f63daab6403bb453da31ae28a7", "c22ca1c712bc18915dc9737e9d61b69574455021"], "ReferenceCount": 15, "CitationCount": 79}, {"URL": "https://www.semanticscholar.org/paper/Robust-feature-learning-by-improved-auto-encoder-Zhao-Guo/00af02c2cb48920af477115e870a42ac4f8a3834", "ID": "00af02c2cb48920af477115e870a42ac4f8a3834", "Title": "Robust feature learning by improved auto-encoder from non-Gaussian noised images", "Abstract": "Experimental results show that, compared with the traditional auto-encoders, the proposed method learns robust features, improves classification accuracy and reduces the reconstruction error, which demonstrates thatThe proposed method is capable of learning robust features on noisy data. Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Net-works(DBN) and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and languages datasets. These learning algorithms aim to find good representations for data, which can be used for classification, reconstruction, visualization and so on. Despite the progress, most existing algorithms would be fragile to non-Gaussian noises and outliers due to the criterion of mean square error(MSE) and cross entropy(CE). In this paper, we propose a robust auto-encoder called correntropy-based contractive auto-encoder(C-CAE) to learn robust features from data with non-Gaussian noises and outliers. The maximum correntropy criterion(MCC) is adopted as reconstruction cost function and a well chosen penalty term is added to the reconstruction cost function. By replacing cross entropy with MCC, the proposed method can learn robust features from the data containing non-Gaussian noises and outliers. The penalty term corresponds to the Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input. By adding the penalty term, the antinoise ability of the proposed method is improved. The proposed method is evaluated using the MNIST benchmark dataset. Experimental results show that, compared with the traditional auto-encoders, the proposed method learns robust features, improves classification accuracy and reduces the reconstruction error, which demonstrates that the proposed method is capable of learning robust features on noisy data.", "PublicationYear": "2015", "Authors": ["Dan Zhao", "Bao-long Guo", "Jinfu Wu", "Weikang Ning", "Yunyi Yan"], "RelatedTopics": ["Computer Science"], "References": ["357733cc76e31a499a27ba2da8612174aafb3213", "195d0a8233a7a46329c742eaff56c276f847fadc", "a2017ec2c60d542af5e9993176ba68f89529dbce", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "843959ffdccf31c6694d135fad07425924f785b1", "2964d30862d0402b0d0ad4a427067f69e4a52130", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "2617b3108d6cd2c4c92e48b71520317d1b1bd2a3"], "ReferenceCount": 29, "CitationCount": 8}, {"URL": "https://www.semanticscholar.org/paper/Research-on-denoising-sparse-autoencoder-Meng-Ding/fbb38946334941292800a82c99c0dc4feb0cb882", "ID": "fbb38946334941292800a82c99c0dc4feb0cb882", "Title": "Research on denoising sparse autoencoder", "Abstract": "The results suggest that different autoencoders mentioned in this paper have some close relation and the model the authors researched can extract interesting features which can reconstruct original data well, and all results show a promising approach to utilizing the proposed autoencoder to build deep models. Autoencoder can learn the structure of data adaptively and represent data efficiently. These properties make autoencoder not only suit huge volume and variety of data well but also overcome expensive designing cost and poor generalization. Moreover, using autoencoder in deep learning to implement feature extraction could draw better classification accuracy. However, there exist poor robustness and overfitting problems when utilizing autoencoder. In order to extract useful features, meanwhile improve robustness and overcome overfitting, we studied denoising sparse autoencoder through adding corrupting operation and sparsity constraint to traditional autoencoder. The results suggest that different autoencoders mentioned in this paper have some close relation and the model we researched can extract interesting features which can reconstruct original data well. In addition, all results show a promising approach to utilizing the proposed autoencoder to build deep models.", "PublicationYear": "2017", "Authors": ["Lingheng Meng", "Shifei Ding", "Yu Xue"], "RelatedTopics": ["Computer Science"], "References": ["f3ad764e559d3589063d31efcdf2baac64e6ebfc", "b94043a133e3d07ed0b1cfc036829e619ea0ba22", "843959ffdccf31c6694d135fad07425924f785b1", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "23c833a82e757b05dda2d1e8b647d3a5af2cc46f", "a5bdc9026d96b0a3317c93110fc2e56f59db2f9a", "2a4774a811ec32f005a043653dd15eb184d96dfa", "bb1d6215f0cfd84b5efc7173247b016ade4c976e", "53959db687bb17f6f1438c0f8c70eb389dd1ece1", "9dd460477be1b1c4e1d65b2cbfa3d1653df6df87"], "ReferenceCount": 32, "CitationCount": 49}, {"URL": "https://www.semanticscholar.org/paper/Extracting-and-composing-robust-features-with-Vincent-Larochelle/843959ffdccf31c6694d135fad07425924f785b1", "ID": "843959ffdccf31c6694d135fad07425924f785b1", "Title": "Extracting and composing robust features with denoising autoencoders", "Abstract": "This work introduces and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.", "PublicationYear": "2008", "Authors": ["Pascal Vincent", "H. Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["41fef1a197fab9684a4608b725d3ae72e1ab4b39", "e07416eabd4ba6c69fa473756bb04ae7161177be", "932c2a02d462abd75af018125413b1ceaa1ee3f4", "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3", "b8012351bc5ebce4a4b3039bbbba3ce393bc3315", "2077d0f30507d51a0d3bbec4957d55e817d66a59", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "d90df19826e5ccf940f8259c7d7ca054e1506b00", "43c8a545f7166659e9e21c88fe234e0323855216"], "ReferenceCount": 30, "CitationCount": 6718}, {"URL": "https://www.semanticscholar.org/paper/Parallel-auto-encoder-for-efficient-outlier-Ma-Zhang/ec7e0ceea8f79735742ea671b3c37148cae9f22c", "ID": "ec7e0ceea8f79735742ea671b3c37148cae9f22c", "Title": "Parallel auto-encoder for efficient outlier detection", "Abstract": "This paper builds a replicator model of the input data to obtain the representation of sample data, and uses this model to measure the replicability of test data, where records having higher reconstruction errors are classified as outliers. Detecting outliers from big data plays an important role in network security. Previous outlier detection algorithms are generally incapable of handling big data. In this paper we present an parallel outlier detection method for big data, based on a new parallel auto-encoder method. Specifically, we build a replicator model of the input data to obtain the representation of sample data. Then, the replicator model is used to measure the replicability of test data, where records having higher reconstruction errors are classified as outliers. Experimental results show the performance of the proposed parallel algorithm.", "PublicationYear": "2013", "Authors": ["Yunlong Ma", "Peng Zhang", "Yanan Cao", "Li Guo"], "RelatedTopics": ["Computer Science"], "References": ["353b5ed7874b7134ee95021bce60b7ac0ee7e1ed", "83e9565cede81b2b88a9fa241833135da142f4d3", "a3f8a3948e5999def4a0819d0dbaef2ae05e1599", "d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "8eb453d79c172c4bca3dd184679a7796ade1ff01", "b8434eecf8cdcedc9ae5f33af382f175b3d5d815"], "ReferenceCount": 6, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Image-Denoising-and-Inpainting-with-Deep-Neural-Xie-Xu/a2017ec2c60d542af5e9993176ba68f89529dbce", "ID": "a2017ec2c60d542af5e9993176ba68f89529dbce", "Title": "Image Denoising and Inpainting with Deep Neural Networks", "Abstract": "A novel approach to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder (DA) is presented and can automatically remove complex patterns like superimposed text from an image, rather than simple patterns like pixels missing at random. We present a novel approach to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder (DA). We propose an alternative training scheme that successfully adapts DA, originally designed for unsupervised feature learning, to the tasks of image denoising and blind inpainting. Our method's performance in the image denoising task is comparable to that of KSVD which is a widely used sparse coding technique. More importantly, in blind image inpainting task, the proposed method provides solutions to some complex problems that have not been tackled before. Specifically, we can automatically remove complex patterns like superimposed text from an image, rather than simple patterns like pixels missing at random. Moreover, the proposed method does not need the information regarding the region that requires inpainting to be given a priori. Experimental results demonstrate the effectiveness of the proposed method in the tasks of image denoising and blind inpainting. We also show that our new training scheme for DA is more effective and can improve the performance of unsupervised feature learning.", "PublicationYear": "2012", "Authors": ["Junyuan Xie", "Linli Xu", "Enhong Chen"], "RelatedTopics": ["Computer Science"], "References": ["b2af2a2f2d1be22ebf473f7e0f501f1f5c02f222", "51a7a32dd55f46d60509044da79cd963e150e89c", "92281d5002178003bd7060fc66677a3471cdaa4b", "bff8a31320941e41123a94c8818bef9f1c898c7d", "0f6395aa7c09bf81c7753a04c789a1dac0c0eb5c", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "e07416eabd4ba6c69fa473756bb04ae7161177be", "4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c", "e763e059cead07d1c03646bfb8cb4a0a75ffc3ef", "a4b01a1eb80f004fc67d4180c24cb4c203324e21"], "ReferenceCount": 23, "CitationCount": 1369}, {"URL": "https://www.semanticscholar.org/paper/Contractive-Auto-Encoders%3A-Explicit-Invariance-Rifai-Vincent/195d0a8233a7a46329c742eaff56c276f847fadc", "ID": "195d0a8233a7a46329c742eaff56c276f847fadc", "Title": "Contractive Auto-Encoders: Explicit Invariance During Feature Extraction", "Abstract": "It is found empirically that this penalty helps to carve a representation that better captures the local directions of variation dictated by the data, corresponding to a lower-dimensional non-linear manifold, while being more invariant to the vast majority of directions orthogonal to the manifold. We present in this paper a novel approach for training deterministic auto-encoders. We show that by adding a well chosen penalty term to the classical reconstruction cost function, we can achieve results that equal or surpass those attained by other regularized auto-encoders as well as denoising auto-encoders on a range of datasets. This penalty term corresponds to the Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input. We show that this penalty term results in a localized space contraction which in turn yields robust features on the activation layer. Furthermore, we show how this penalty term is related to both regularized auto-encoders and denoising auto-encoders and how it can be seen as a link between deterministic and non-deterministic auto-encoders. We find empirically that this penalty helps to carve a representation that better captures the local directions of variation dictated by the data, corresponding to a lower-dimensional non-linear manifold, while being more invariant to the vast majority of directions orthogonal to the manifold. Finally, we show that by using the learned features to initialize a MLP, we achieve state of the art classification error on a range of datasets, surpassing other methods of pretraining.", "PublicationYear": "2011", "Authors": ["Salah Rifai", "Pascal Vincent", "Xavier Muller", "Xavier Glorot", "Yoshua Bengio"], "RelatedTopics": ["Computer Science"], "References": ["e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3", "ff32cebbdb8a436ccd8ae797647428615ae32d74", "2805537bec87a6177037b18f9a3a9d3f1038867b", "9552ac39a57daacf3d75865a268935b5a0df9bbb", "5d90f06bb70a0a3dced62413346235c02b1aa086", "8978cf7574ceb35f4c3096be768c7547b28a35d0", "54a9c2553138932426faebcaa67a63a84a56b55d", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "1e80f755bcbf10479afd2338cec05211fdbd325c"], "ReferenceCount": 19, "CitationCount": 1423}, {"URL": "https://www.semanticscholar.org/paper/Extracting-deep-bottleneck-features-using-stacked-Gehring-Miao/2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35", "ID": "2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35", "Title": "Extracting deep bottleneck features using stacked auto-encoders", "Abstract": "It is found that increasing the number of auto-encoders in the network produces more useful features, but requires pre-training, especially when little training data is available. In this work, a novel training scheme for generating bottleneck features from deep neural networks is proposed. A stack of denoising auto-encoders is first trained in a layer-wise, unsupervised manner. Afterwards, the bottleneck layer and an additional layer are added and the whole network is fine-tuned to predict target phoneme states. We perform experiments on a Cantonese conversational telephone speech corpus and find that increasing the number of auto-encoders in the network produces more useful features, but requires pre-training, especially when little training data is available. Using more unlabeled data for pre-training only yields additional gains. Evaluations on larger datasets and on different system setups demonstrate the general applicability of our approach. In terms of word error rate, relative improvements of 9.2% (Cantonese, ML training), 9.3% (Tagalog, BMMI-SAT training), 12% (Tagalog, confusion network combinations with MFCCs), and 8.7% (Switchboard) are achieved.", "PublicationYear": "2013", "Authors": ["Jonas Gehring", "Yajie Miao", "Florian Metze", "Alexander H. Waibel"], "RelatedTopics": ["Computer Science"], "References": ["008e9e2d3908c964d5b1c408c478215709dbea10", "375d7b8a70277d5d7b5e0cc999b03ba395c42901", "6658bbf68995731b2083195054ff45b4eca38b3a", "137b572ca406ba8fc86e985c185233b8cd6517d2", "31868290adf1c000c611dfc966b514d5a34e8d23", "843959ffdccf31c6694d135fad07425924f785b1", "1528918ae0c9f70ba6da030cb8dbc72f71bc198b", "e33cbb25a8c7390aec6a398e36381f4f7770c283", "cd62c9976534a6a2096a38244f6cbb03635a127e", "06c152df89ca6a1f1b8f8e139ddda82cd4539415"], "ReferenceCount": 24, "CitationCount": 295}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-LeCun-Bengio/a4cec122a08216fe8a3bc19b22e78fbaea096256", "ID": "a4cec122a08216fe8a3bc19b22e78fbaea096256", "Title": "Deep Learning", "Abstract": "Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years, and will have many more successes in the near future because it requires very little engineering by hand and can easily take advantage of increases in the amount of available computation and data. Machine-learning technology powers many aspects of modern society: from web searches to content filtering on social networks to recommendations on e-commerce websites, and it is increasingly present in consumer products such as cameras and smartphones. Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users\u2019 interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition or machine-learning system required careful engineering and considerable domain expertise to design a feature extractor that transformed the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input. Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification. Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned. For classification tasks, higher layers of representation amplify aspects of the input that are important for discrimination and suppress irrelevant variations. An image, for example, comes in the form of an array of pixel values, and the learned features in the first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image. The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions. The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects, and subsequent layers would detect objects as combinations of these parts. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. In addition to beating records in image recognition and speech recognition, it has beaten other machine-learning techniques at predicting the activity of potential drug molecules, analysing particle accelerator data, reconstructing brain circuits, and predicting the effects of mutations in non-coding DNA on gene expression and disease. Perhaps more surprisingly, deep learning has produced extremely promising results for various tasks in natural language understanding, particularly topic classification, sentiment analysis, question answering and language translation. We think that deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data. New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.", "PublicationYear": "2015", "Authors": ["Yann LeCun", "Yoshua Bengio", "Geoffrey E. Hinton"], "RelatedTopics": ["Computer Science"], "References": ["5d90f06bb70a0a3dced62413346235c02b1aa086", "be9a17321537d9289875fe475b71f4821457b435", "25badc676197a70aaf9911865eb03469e402ba57", "3137bc367c61c0e507a5e3c1f8caeb26f292d79f", "41fef1a197fab9684a4608b725d3ae72e1ab4b39", "162d958ff885f1462aeda91cd72582323fd6a1f4", "755e9f43ce398ae8737366720c5f82685b0c253e", "72e93aa6767ee683de7f001fa72f1314e40a8f35", "1128c5607a19af6022be723d10dbf8fad3ca26ab", "081651b38ff7533550a3adfc1c00da333a8fe86c"], "ReferenceCount": 831, "CitationCount": 58364}, {"URL": "https://www.semanticscholar.org/paper/Incremental-Kernel-Null-Space-Discriminant-Analysis-Liu-Lian/5d666e2761bbac7d8e0ac724280d20fd24d71a6b", "ID": "5d666e2761bbac7d8e0ac724280d20fd24d71a6b", "Title": "Incremental Kernel Null Space Discriminant Analysis for Novelty Detection", "Abstract": "Experiments demonstrate that the proposed Incremental Kernel Null Space based Discriminant Analysis (IKNDA) algorithm yields comparable performance as the batch KNDA yet significantly reduces the computational complexity, and markedly outperform approaches using deep neural network (DNN) classifiers. Novelty detection, which aims to determine whether a given data belongs to any category of training data or not, is considered to be an important and challenging problem in areas of Pattern Recognition, Machine Learning, etc. Recently, kernel null space method (KNDA) was reported to have state-of-the-art performance in novelty detection. However, KNDA is hard to scale up because of its high computational cost. With the ever-increasing size of data, accelerating the implementing speed of KNDA is desired and critical. Moreover, it becomes incapable when there exist successively injected data. To address these issues, we propose the Incremental Kernel Null Space based Discriminant Analysis (IKNDA) algorithm. The key idea is to extract new information brought by newly-added samples and integrate it with the existing model by an efficient updating scheme. Experiments conducted on two publicly-available datasets demonstrate that the proposed IKNDA yields comparable performance as the batch KNDA yet significantly reduces the computational complexity, and our IKNDA based novelty detection methods markedly outperform approaches using deep neural network (DNN) classifiers. This validates the superiority of our IKNDA against the state of the art in novelty detection for large-scale data.", "PublicationYear": "2017", "Authors": ["Juncheng Liu", "Zhouhui Lian", "Yi Wang", "Jianguo Xiao"], "RelatedTopics": ["Computer Science"], "References": ["1972c73d96353e57599962fd6059572801382212", "ecade8c741e29b89143450f6b098cd618bc5237d", "0145c5d5b916d844088a136b114f5597ead2244c", "20830f958fa822fe8f0fb8aecd2a2655e595438a", "78874a205a307f4412f46c5284b97649b6b2dc3e", "20ff2e46a193dfe9add95f780f7f81536f4bb279", "4e326167b7bb989215ac4d35e0c5d1f4102451a0", "9acc51b06f54b07836fad4cc24633187dc21317f", "724d0b9b7f6a62adbc7395f7c2bfa8436622d423", "3cc33df94447c7e1959c876d9d0bc14edebc0c96"], "ReferenceCount": 27, "CitationCount": 52}, {"URL": "https://www.semanticscholar.org/paper/Image-Denoising-via-CNNs%3A-An-Adversarial-Approach-Divakar-Babu/a7fae7dba0db74cc21a7c7b70157fe601784b681", "ID": "a7fae7dba0db74cc21a7c7b70157fe601784b681", "Title": "Image Denoising via CNNs: An Adversarial Approach", "Abstract": "A new CNN architecture for blind image denoising which synergically combines three architecture components, a multi-scale feature extraction layer which helps in reducing the effect of noise on feature maps, an \u2113p regularizer which helps on selecting only the appropriate feature maps for the task of reconstruction, and a three step training approach which leverages adversarial training to give the final performance boost to the model. Is it possible to recover an image from its noisy version using convolutional neural networks? This is an interesting problem as convolutional layers are generally used as feature detectors for tasks like classification, segmentation and object detection. We present a new CNN architecture for blind image denoising which synergically combines three architecture components, a multi-scale feature extraction layer which helps in reducing the effect of noise on feature maps, an \u2113p regularizer which helps in selecting only the appropriate feature maps for the task of reconstruction, and finally a three step training approach which leverages adversarial training to give the final performance boost to the model. The proposed model shows competitive denoising performance when compared to the state-of-the-art approaches.", "PublicationYear": "2017", "Authors": ["Nithish Divakar", "R. Venkatesh Babu"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["47900aca2f0b50da3010ad59b394c870f0e6c02e", "b2af2a2f2d1be22ebf473f7e0f501f1f5c02f222", "8388f1be26329fa45e5807e968a641ce170ea078", "1d70937202d843664c5591fde4fb0d48627d1cf6", "df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3", "eb42cf88027de515750f230b23b1a057dc782108", "17fa1c2a24ba8f731c8b21f1244463bc4b465681", "571b0750085ae3d939525e62af510ee2cee9d5ea", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "e15cf50aa89fee8535703b9f9512fca5bfc43327"], "ReferenceCount": 27, "CitationCount": 69}, {"URL": "https://www.semanticscholar.org/paper/Deep-Cascade%3A-Cascading-3D-Deep-Neural-Networks-for-Sabokrou-Fayyaz/6f68ce1e03c56c186256dac689a21f6405ae8d96", "ID": "6f68ce1e03c56c186256dac689a21f6405ae8d96", "Title": "Deep-Cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes", "Abstract": "It is shown that the proposed novel technique, characterised by a cascade of two cascaded classifiers, performs comparable to current top-performing detection and localization methods on standard benchmarks, but outperforms those in general with respect to required computation time. This paper proposes a fast and reliable method for anomaly detection and localization in video data showing crowded scenes. Time-efficient anomaly localization is an ongoing challenge and subject of this paper. We propose a cubic-patch-based method, characterised by a cascade of classifiers, which makes use of an advanced feature-learning approach. Our cascade of classifiers has two main stages. First, a light but deep 3D auto-encoder is used for early identification of \u201cmany\u201d normal cubic patches. This deep network operates on small cubic patches as being the first stage, before carefully resizing the remaining candidates of interest, and evaluating those at the second stage using a more complex and deeper 3D convolutional neural network (CNN). We divide the deep auto-encoder and the CNN into multiple sub-stages, which operate as cascaded classifiers. Shallow layers of the cascaded deep networks (designed as Gaussian classifiers, acting as weak single-class classifiers) detect \u201csimple\u201d normal patches, such as background patches and more complex normal patches, are detected at deeper layers. It is shown that the proposed novel technique (a cascade of two cascaded classifiers) performs comparable to current top-performing detection and localization methods on standard benchmarks, but outperforms those in general with respect to required computation time.", "PublicationYear": "2017", "Authors": ["M. Sabokrou", "Mohsen Fayyaz", "Mahmood Fathy", "Reinhard Klette"], "RelatedTopics": ["Computer Science"], "References": ["2e61eb4a5c6fe6c0fdb36cfb84d460ee1524099f", "60fef33549f57f5cbb6712a510c3a444ab682429", "ae8d8f417ca05bba10dac49400dc9a09e71ac2b2", "5727ec1431551cee254201c5465fa384198bc4ca", "11655f8630262e5830352b68962bb721ed261f7d", "851ff5f13fbff7023717c3913f2df4a7551a374a", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "d7c3c875f2f0c8ff1e8361802eca52c7b1d481c5", "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "109eef0f2319c6173b7cc22120254f01746ef77a"], "ReferenceCount": 53, "CitationCount": 305}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078", "ID": "8388f1be26329fa45e5807e968a641ce170ea078", "Title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks", "Abstract": "This work introduces a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrates that they are a strong candidate for unsupervised learning. In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.", "PublicationYear": "2015", "Authors": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "RelatedTopics": ["Computer Science"], "References": ["47900aca2f0b50da3010ad59b394c870f0e6c02e", "1e80f755bcbf10479afd2338cec05211fdbd325c", "c08f5fa876181fc040d76c75fe2433eee3c9b001", "0f84a81f431b18a78bd97f59ed4b9d8eda390970", "bcaf73e6389261da6f2fdf88b20b17f4fc2add90", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "571b0750085ae3d939525e62af510ee2cee9d5ea", "4dcdae25a5e33682953f0853ee4cf7ca93be58a9", "182015c5edff1956cbafbcb3e7bbe294aa54f9fc", "86ee1835a56722b76564119437070782fc90eb19"], "ReferenceCount": 46, "CitationCount": 12532}, {"URL": "https://www.semanticscholar.org/paper/One-class-classification%3A-taxonomy-of-study-and-of-Khan-Madden/9eb1b16fbd4786eaac91f308d75609b9321868ce", "ID": "9eb1b16fbd4786eaac91f308d75609b9321868ce", "Title": "One-class classification: taxonomy of study and review of techniques", "Abstract": "A unified view of the general problem of OCC is presented by presenting a taxonomy of study for OCC problems, which is based on the availability of training data, algorithms used and the application domains applied. Abstract One-class classification (OCC) algorithms aim to build classification models when the negative class is either absent, poorly sampled or not well defined. This unique situation constrains the learning of efficient classifiers by defining class boundary just with the knowledge of positive class. The OCC problem has been considered and applied under many research themes, such as outlier/novelty detection and concept learning. In this paper, we present a unified view of the general problem of OCC by presenting a taxonomy of study for OCC problems, which is based on the availability of training data, algorithms used and the application domains applied. We further delve into each of the categories of the proposed taxonomy and present a comprehensive literature review of the OCC algorithms, techniques and methodologies with a focus on their significance, limitations and applications. We conclude our paper by discussing some open research problems in the field of OCC and present our vision for future research.", "PublicationYear": "2013", "Authors": ["Shehroz S. Khan", "Michael G. Madden"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["c0c07935977e70e71d296535729fc718636d76c4", "27a9048fdb07a7c49dd9941c59fbad5d6b9e443d", "b72f1ff0f1a29888546b21a925484f267ef15c30", "0bb0c6dfeb8f838470f27cefd0ba42192ecaf90a", "5ff9cb1a917026e313f6f7e3ae59cb21825d9a49", "0bacda847c2eaaa4690ec341a819994ebddbbd3d", "82ee4bb629b61096c154e3e05e4782f533006630", "a61509ec3c93e5fb00661606289cc12accd283d2", "c72bb6c83db08e17e2736bc1d2cf439fe1f71905", "9a336d940160cc8ef20b3fcef15b8774a3a8c41a"], "ReferenceCount": 195, "CitationCount": 491}, {"URL": "https://www.semanticscholar.org/paper/Abnormal-event-detection-in-videos-using-generative-Ravanbakhsh-Nabi/9d5290fadb7625862a966e0330bd0f9e111fc99d", "ID": "9d5290fadb7625862a966e0330bd0f9e111fc99d", "Title": "Abnormal event detection in videos using generative adversarial nets", "Abstract": "Experimental results on challenging abnormality detection datasets show the superiority of the proposed method compared to the state of the art in both frame-level and pixel-level abnormality Detection tasks. In this paper we address the abnormality detection problem in crowded scenes. We propose to use Generative Adversarial Nets (GANs), which are trained using normal frames and corresponding optical-flow images in order to learn an internal representation of the scene normality. Since our GANs are trained with only normal data, they are not able to generate abnormal events. At testing time the real data are compared with both the appearance and the motion representations reconstructed by our GANs and abnormal areas are detected by computing local differences. Experimental results on challenging abnormality detection datasets show the superiority of the proposed method compared to the state of the art in both frame-level and pixel-level abnormality detection tasks.", "PublicationYear": "2017", "Authors": ["Mahdyar Ravanbakhsh", "Moin Nabi", "E. Sangineto", "Lucio Marcenaro", "Carlo S. Regazzoni", "N. Sebe"], "RelatedTopics": ["Computer Science"], "References": ["7d8755284169f6f721e046798df1eeb1170ebdd0", "e5366a704ffa3b41aacd385f3c087ec3fd566934", "655b1f83ef218ee6a030b5541d2865bc6599e6d9", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6", "fd52349a019d928cd9b09c2f6a8a689f174bbbf2", "869b17632ed4f19f93b3b58dcaa9f0b8e92108f3", "67dccc9a856b60bdc4d058d83657a089b8ad4486", "571b0750085ae3d939525e62af510ee2cee9d5ea", "8388f1be26329fa45e5807e968a641ce170ea078"], "ReferenceCount": 31, "CitationCount": 379}, {"URL": "https://www.semanticscholar.org/paper/Fully-Convolutional-Neural-Network-for-Fast-Anomaly-Sabokrou-Fayyaz/6259b02912cebc224f3a2b1324e811a152a0177d", "ID": "6259b02912cebc224f3a2b1324e811a152a0177d", "Title": "Fully Convolutional Neural Network for Fast Anomaly Detection in Crowded Scenes", "Abstract": "An FCN-based architecture for anomaly detection and localization in crowded scenes videos is proposed, which includes two main components, one for feature representation, and one for cascaded out-layer detection. We present an efficient method for detecting and localizing anomalies in videos showing crowded scenes. Research on {\\\\it fully convolutional neural networks} (FCNs) has shown the potentials of this technology for object detection and localization, especially in images. We investigate how to involve temporal data, and how to transform a supervised FCN into an unsupervised one such that the resulting FCN ensures anomaly detection. Altogether, we propose an FCN-based architecture for anomaly detection and localization in crowded scenes videos. For reducing computations and, consequently, improving performance both with respect to speed and accuracy, we investigate the use of cascaded out-layer detection. Our architecture includes two main components, one for feature representation, and one for cascaded out-layer detection. Experimental results on Subway and UCSD benchmarks confirm that the detection and localization accuracy of our method is comparable to state-of-the-art methods, but at a significantly increased speed of 370 fps.", "PublicationYear": "2016", "Authors": ["M. Sabokrou", "Mohsen Fayyaz", "Mahmood Fathy", "Reinhard Klette"], "RelatedTopics": ["Computer Science", "Engineering"], "References": [], "ReferenceCount": 0, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Learning-Deep-Representations-of-Appearance-and-for-Xu-Ricci/60fef33549f57f5cbb6712a510c3a444ab682429", "ID": "60fef33549f57f5cbb6712a510c3a444ab682429", "Title": "Learning Deep Representations of Appearance and Motion for Anomalous Event Detection", "Abstract": "This work proposes Appearance and Motion DeepNet (AMDN) which utilizes deep neural networks to automatically learn feature representations, and introduces a novel double fusion framework, combining both the benefits of traditional early fusion and late fusion strategies. We present a novel unsupervised deep learning framework for anomalous event detection in complex video scenes. While most existing works merely use hand-crafted appearance and motion features, we propose Appearance and Motion DeepNet (AMDN) which utilizes deep neural networks to automatically learn feature representations. To exploit the complementary information of both appearance and motion patterns, we introduce a novel double fusion framework, combining both the benefits of traditional early fusion and late fusion strategies. Specifically, stacked denoising autoencoders are proposed to separately learn both appearance and motion features as well as a joint representation (early fusion). Based on the learned representations, multiple one-class SVM models are used to predict the anomaly scores of each input, which are then integrated with a late fusion strategy for final anomaly detection. We evaluate the proposed method on two publicly available video surveillance datasets, showing competitive performance with respect to state of the art approaches.", "PublicationYear": "2015", "Authors": ["Dan Xu", "Elisa Ricci", "Yan Yan", "Jingkuan Song", "N. Sebe"], "RelatedTopics": ["Computer Science"], "References": ["e5366a704ffa3b41aacd385f3c087ec3fd566934", "146adb105ebcece295a24e8cf3643c9fd0f89bcb", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "67dccc9a856b60bdc4d058d83657a089b8ad4486", "2dccec3c1a8a17883cece784e8f0fc0af413eb83", "b2180fc4f5cb46b5b5394487842399c501381d67", "a605a375d0803794adee9eac225011d294dfbada", "ae37774ff871575b7799411bf87f42eb52634390", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "ce9edb785f28c81bd7c2864940ed001429178e1e"], "ReferenceCount": 40, "CitationCount": 480}, {"URL": "https://www.semanticscholar.org/paper/Unsupervised-Anomaly-Localization-using-Variational-Zimmerer-Isensee/06fad023ef0274e7d6727ecbd1ef46887a6806df", "ID": "06fad023ef0274e7d6727ecbd1ef46887a6806df", "Title": "Unsupervised Anomaly Localization using Variational Auto-Encoders", "Abstract": "Results show that the proposed formalism outperforms the state of the art VAE-based localization of anomalies across many hyperparameter settings and also shows a competitive max performance. An assumption-free automatic check of medical images for potentially overseen anomalies would be a valuable assistance for a radiologist. Deep learning and especially Variational Auto-Encoders (VAEs) have shown great potential in the unsupervised learning of data distributions. In principle, this allows for such a check and even the localization of parts in the image that are most suspicious. Currently, however, the reconstruction-based localization by design requires adjusting the model architecture to the specific problem looked at during evaluation. This contradicts the principle of building assumption-free models. We propose complementing the localization part with a term derived from the Kullback-Leibler (KL)-divergence. For validation, we perform a series of experiments on FashionMNIST as well as on a medical task including &gt;1000 healthy and &gt;250 brain tumor patients. Results show that the proposed formalism outperforms the state of the art VAE-based localization of anomalies across many hyperparameter settings and also shows a competitive max performance.", "PublicationYear": "2019", "Authors": ["David Zimmerer", "Fabian Isensee", "Jens Petersen", "Simon A. A. Kohl", "Klaus Maier-Hein"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["a14b354fe3e1f1f3fec821fbcde02064fcbe297a", "eb60fe884c53b420edbce57059b242cfcbae0f7c", "83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476", "a3fce9324329581d484dfc8c3f018bc31751ca82", "e163a2e89c136cb4442e34c72f7173a0ff46dc79", "5ad2476610312f380dd4e6475ee706199560b21a", "31a2053ebda7f6f77afe8c3fc53269b73567e446", "f6a201eed70e8b48e2f60d97c98cfc8fe3b7b175", "5bd34f60889c33aba677c7c123e6d4dbb86b8350", "8388f1be26329fa45e5807e968a641ce170ea078"], "ReferenceCount": 23, "CitationCount": 90}, {"URL": "https://www.semanticscholar.org/paper/A-Case-for-the-Score%3A-Identifying-Image-Anomalies-Zimmerer-Petersen/fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d", "ID": "fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d", "Title": "A Case for the Score: Identifying Image Anomalies using Variational Autoencoder Gradients", "Abstract": "It is argued that pixel-wise anomaly ratings derived from a Variational Autoencoder based score approximation yield a theoretically better grounded and more faithful estimate on unsupervisedpixel-wise tumor detection on the BraTS-2017 dataset. Through training on unlabeled data, anomaly detection has the potential to impact computer-aided diagnosis by outlining suspicious regions. Previous work on deep-learning-based anomaly detection has primarily focused on the reconstruction error. We argue instead, that pixel-wise anomaly ratings derived from a Variational Autoencoder based score approximation yield a theoretically better grounded and more faithful estimate. In our experiments, Variational Autoencoder gradient-based rating outperforms other approaches on unsupervised pixel-wise tumor detection on the BraTS-2017 dataset with a ROC-AUC of 0.94.", "PublicationYear": "2019", "Authors": ["David Zimmerer", "Jens Petersen", "Simon A. A. Kohl", "Klaus Maier-Hein"], "RelatedTopics": ["Computer Science"], "References": ["eb60fe884c53b420edbce57059b242cfcbae0f7c", "f538dca4def5167a32fbc12107b69a05f0c9d832", "7198f45e979d4e7bb2ad2f8a5f098ab196c532b6", "a3fce9324329581d484dfc8c3f018bc31751ca82", "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476", "21b786b3f870fc7fa247c143aa41de88b1fc6141", "1cb5dea2a8f6abf0ef61ce229ee866594b6c5228", "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b", "6bacf99c87991523a97165610b492f28c8cacbb2"], "ReferenceCount": 20, "CitationCount": 21}, {"URL": "https://www.semanticscholar.org/paper/Classification-Accuracy-Score-for-Conditional-Ravuri-Vinyals/ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa", "ID": "ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa", "Title": "Classification Accuracy Score for Conditional Generative Models", "Abstract": "This work uses class-conditional generative models from a number of model classes---variational autoencoders, autoregressive models, and generative adversarial networks (GANs)---to infer the class labels of real data and reveals some surprising results not identified by traditional metrics. Deep generative models (DGMs) of images are now sufficiently mature that they produce nearly photorealistic samples and obtain scores similar to the data distribution on heuristics such as Frechet Inception Distance (FID). These results, especially on large-scale datasets such as ImageNet, suggest that DGMs are learning the data distribution in a perceptually meaningful space and can be used in downstream tasks. To test this latter hypothesis, we use class-conditional generative models from a number of model classes---variational autoencoders, autoregressive models, and generative adversarial networks (GANs)---to infer the class labels of real data. We perform this inference by training an image classifier using only synthetic data and using the classifier to predict labels on real data. The performance on this task, which we call Classification Accuracy Score (CAS), reveals some surprising results not identified by traditional metrics and constitute our contributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1 and Top-5 accuracy decrease by 27.9\\\\% and 41.6\\\\%, respectively, compared to the original data; and conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on this benchmark. Second, CAS automatically surfaces particular classes for which generative models failed to capture the data distribution, and were previously unknown in the literature. Third, we find traditional GAN metrics such as Inception Score (IS) and FID neither predictive of CAS nor useful when evaluating non-GAN models. Furthermore, in order to facilitate better diagnoses of generative models, we open-source the proposed metric.", "PublicationYear": "2019", "Authors": ["Suman V. Ravuri", "Oriol Vinyals"], "RelatedTopics": ["Computer Science"], "References": ["571b0750085ae3d939525e62af510ee2cee9d5ea", "1ea9f643171115e4a89e77c9a770c593f0794712", "9e94feb128625ea51b0ef04e74ea6fe84f237c8f", "fcdcde3f796fc2c7d6bdeeb4f6b2281ec18be614", "6be216d93421bf19c1659e7721241ae73d483baf", "097ccdfc47f1974591e2c1c6d17532b9b96a17a1", "8b1a1949789d12997b0a5ade953309308a81e115", "22aab110058ebbd198edb1f1e7b4f69fb13c0613", "d383dd8ced85d7898d8b1546c514a34fb626ea16", "60b2e0b0f91432aa7e6500d6d0f92d391c96e717"], "ReferenceCount": 48, "CitationCount": 168}, {"URL": "https://www.semanticscholar.org/paper/Towards-Visually-Explaining-Variational-Liu-Li/0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b", "ID": "0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b", "Title": "Towards Visually Explaining Variational Autoencoders", "Abstract": "This work proposes the first technique to visually explain VAEs by means of gradient-based attention, and presents methods to generate visual attention from the learned latent space, and shows how such attention explanations serve more than just explaining VAE predictions. Recent advances in Convolutional Neural Network (CNN) model interpretability have led to impressive progress in visualizing and understanding model predictions. In particular, gradient-based visual attention methods have driven much recent effort in using visual attention maps as a means for visual explanations. A key problem, however, is these methods are designed for classification and categorization tasks, and their extension to explaining generative models, e.g., variational autoencoders (VAE) is not trivial. In this work, we take a step towards bridging this crucial gap, proposing the first technique to visually explain VAEs by means of gradient-based attention. We present methods to generate visual attention from the learned latent space, and also demonstrate such attention explanations serve more than just explaining VAE predictions. We show how these attention maps can be used to localize anomalies in images, demonstrating state-of-the-art performance on the MVTec-AD dataset. We also show how they can be infused into model training, helping bootstrap the VAE into learning improved latent space disentanglement, demonstrated on the Dsprites dataset.", "PublicationYear": "2019", "Authors": ["Wenqian Liu", "Runze Li", "Meng Zheng", "Srikrishna Karanam", "Ziyan Wu", "Bir Bhanu", "Richard J. Radke", "Octavia I. Camps"], "RelatedTopics": ["Computer Science"], "References": ["6bacf99c87991523a97165610b492f28c8cacbb2", "04541599accc47d8174f63345ce9c987ef21685b", "a90226c41b79f8b06007609f39f82757073641e2", "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "13bc4e683075bdd6a3f0155241c276a772d4aa06", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "0d0a810f622a0d753ef41f32cf963254ba9926b8", "e3b5c2fecec38ab3a7139fcc45814073f1369248", "3aa681914a7da79f7d7293f51a058eefe61c8bb7"], "ReferenceCount": 48, "CitationCount": 152}, {"URL": "https://www.semanticscholar.org/paper/Pathology-Aware-Deep-Network-Visualization-and-Its-Wang-Xu/39972fb3a9cbac1e25b2c096e3e28bba2eee7aa4", "ID": "39972fb3a9cbac1e25b2c096e3e28bba2eee7aa4", "Title": "Pathology-Aware Deep Network Visualization and Its Application in Glaucoma Image Synthesis", "Abstract": "This paper proposes a novel pathology-aware visualization approach for DNN-based glaucoma classification, which is used to locate the pathological evidence from fundus images for glAUcoma, and applies the visualization framework to the glauca images synthesis task, through which specific pathological areas of synthesized images can be enhanced. The past few years have witnessed the great success of applying deep neural networks (DNNs) in computer-aided diagnosis. However, little attention has been paid to provide pathological evidence in the existing DNNs for medical diagnosis. In fact, feature visualization in DNNs is able to help understanding how the computer make decisions, and thus it shows promise on finding pathological evidence from computer-aided diagnosis. In this paper, we propose a novel pathology-aware visualization approach for DNN-based glaucoma classification, which is used to locate the pathological evidence from fundus images for glaucoma. Besides, we apply the visualization framework to the glaucoma images synthesis task, through which specific pathological areas of synthesized images can be enhanced. Finally, experimental results show that the visualization heat maps can pinpoint different glaucoma pathologies with high accuracy, and that the generated glaucoma images are more pathophysiologically clear in rim loss (RL) and retinal neural fiber layer damage (RNFLD), which is verified by the ophthalmologist.", "PublicationYear": "2019", "Authors": ["Xiaofei Wang", "Mai Xu", "Liu Li", "Zulin Wang", "Zhenyu Guan"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["90e86fa36b56c8860719ef11ecfa2ebf3333ad1e", "d95abb4a05e21e4e2929c3cfccf58abce7d18796", "872de2cc2613f18a3a08c75883b834747708a583", "6380f7d6f61646a4dc07a6b489ddf445a0da5df4", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "e1ec11a1cb3d9745fb18d3bf74247f95a6663d08", "35d0998f2c5b53591073d36c9e2b0ddc89a496b1", "159f4c05bc29e86bcbf8c1bcd9eae1f33ce2f3da", "1a2a770d23b4a171fa81de62a78a3deb0588f238", "9b86f1ceafed523f97ac574f105c50757e144884"], "ReferenceCount": 13, "CitationCount": 9}, {"URL": "https://www.semanticscholar.org/paper/Future-Frame-Prediction-for-Anomaly-Detection-A-New-Liu-Luo/8a6acba7fb2aad1299fcf35701417e063d410ed4", "ID": "8a6acba7fb2aad1299fcf35701417e063d410ed4", "Title": "Future Frame Prediction for Anomaly Detection - A New Baseline", "Abstract": "This paper proposes to tackle the anomaly detection problem within a video prediction framework by introducing a motion (temporal) constraint in video prediction by enforcing the optical flow between predicted frames and ground truth frames to be consistent, and is the first work that introduces a temporal constraint into the video prediction task. Anomaly detection in videos refers to the identification of events that do not conform to expected behavior. However, almost all existing methods tackle the problem by minimizing the reconstruction errors of training data, which cannot guarantee a larger reconstruction error for an abnormal event. In this paper, we propose to tackle the anomaly detection problem within a video prediction framework. To the best of our knowledge, this is the first work that leverages the difference between a predicted future frame and its ground truth to detect an abnormal event. To predict a future frame with higher quality for normal events, other than the commonly used appearance (spatial) constraints on intensity and gradient, we also introduce a motion (temporal) constraint in video prediction by enforcing the optical flow between predicted frames and ground truth frames to be consistent, and this is the first work that introduces a temporal constraint into the video prediction task. Such spatial and motion constraints facilitate the future frame prediction for normal events, and consequently facilitate to identify those abnormal events that do not conform the expectation. Extensive experiments on both a toy dataset and some publicly available datasets validate the effectiveness of our method in terms of robustness to the uncertainty in normal events and the sensitivity to abnormal events. All codes are released in https://github.com/StevenLiuWen/ano_pred_cvpr2018.", "PublicationYear": "2017", "Authors": ["Wen Liu", "Weixin Luo", "Dongze Lian", "Shenghua Gao"], "RelatedTopics": ["Computer Science"], "References": ["84f7f9e121c1285e15cefbfc44bcb3322f73b6aa", "7a89447be0a176368926f1ef108512f4df5e27be", "792250ae660b7c25f85eeea7dcae623e4301d97c", "731a2844c5af6b072d3b404ecabbb488cdad9d46", "60fef33549f57f5cbb6712a510c3a444ab682429", "9d3f0d47449c7db37d1bae3b70db2928610a8db7", "094ac7510d1723cb9c2da01db47291322aa29025", "f36f8d32252679f4221c3d2afc2407a9f56b29a7", "ae37774ff871575b7799411bf87f42eb52634390", "17fa1c2a24ba8f731c8b21f1244463bc4b465681"], "ReferenceCount": 46, "CitationCount": 795}, {"URL": "https://www.semanticscholar.org/paper/Learning-Deep-Features-for-Discriminative-Zhou-Khosla/31f9eb39d840821979e5df9f34a6e92dd9c879f2", "ID": "31f9eb39d840821979e5df9f34a6e92dd9c879f2", "Title": "Learning Deep Features for Discriminative Localization", "Abstract": "This work revisits the global average pooling layer proposed in [13], and sheds light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.", "PublicationYear": "2015", "Authors": ["Bolei Zhou", "Aditya Khosla", "{\\`A}gata Lapedriza", "Aude Oliva", "Antonio Torralba"], "RelatedTopics": ["Computer Science"], "References": ["bd2f443fc18947d2c9ecb81192b3f0a9cd2cf3f1", "1109b663453e78a59e4f66446d71720ac58cec25", "eb42cf88027de515750f230b23b1a057dc782108", "ec679c45e88fa25fec32c30bc7c1b7d7fd0facec", "b8de958fead0d8a9619b55c7299df3257c624a96", "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "c08f5fa876181fc040d76c75fe2433eee3c9b001", "401192b00b650adfa5ac49de59b720e1c81f1410", "e15cf50aa89fee8535703b9f9512fca5bfc43327", "125f7b539e89cd0940ff89c231902b1d4023b3ba"], "ReferenceCount": 37, "CitationCount": 7709}, {"URL": "https://www.semanticscholar.org/paper/Attention-Based-Glaucoma-Detection%3A-A-Large-Scale-Li-Xu/97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f", "ID": "97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f", "Title": "Attention Based Glaucoma Detection: A Large-Scale Database and CNN Model", "Abstract": "The proposed AG-CNN approach significantly advances state-of-the-art glaucoma detection, including an attention prediction subnet, a pathological area localization subnet and a glauca classification subnet. Recently, the attention mechanism has been successfully applied in convolutional neural networks (CNNs), significantly boosting the performance of many computer vision tasks. Unfortunately, few medical image recognition approaches incorporate the attention mechanism in the CNNs. In particular, there exists high redundancy in fundus images for glaucoma detection, such that the attention mechanism has potential in improving the performance of CNN-based glaucoma detection. This paper proposes an attention-based CNN for glaucoma detection (AG-CNN). Specifically, we first establish a large-scale attention based glaucoma (LAG) database, which includes 5,824 fundus images labeled with either positive glaucoma (2,392) or negative glaucoma (3,432). The attention maps of the ophthalmologists are also collected in LAG database through a simulated eye-tracking experiment. Then, a new structure of AG-CNN is designed, including an attention prediction subnet, a pathological area localization subnet and a glaucoma classification subnet. Different from other attention-based CNN methods, the features are also visualized as the localized pathological area, which can advance the performance of glaucoma detection. Finally, the experiment results show that the proposed AG-CNN approach significantly advances state-of-the-art glaucoma detection.", "PublicationYear": "2019", "Authors": ["Liu Li", "Mai Xu", "Xiaofei Wang", "Lai Jiang", "Hanruo Liu"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["d95abb4a05e21e4e2929c3cfccf58abce7d18796", "d3dad3c88acfa4080747767d01eabe92b4f7b3c3", "115e499872480ae3e54277a4861e7fd9295a25d7", "90e86fa36b56c8860719ef11ecfa2ebf3333ad1e", "f550c444c91174592a73df4476f9bc921af3c393", "9ec2f647349aaf43615bb50742176741d5accd2e", "26b632d486741a346e4658d5f9b0d5431cb6e7dc", "b954efe5e46b8952f5a8daf42e7e535119b5408b", "c8eec916ea6e6d2a57a0d9ca29c9b95525b53314", "5c45a5d05ac564adb67811eeb9d41d6460c70135"], "ReferenceCount": 47, "CitationCount": 153}, {"URL": "https://www.semanticscholar.org/paper/A-Hybrid-Deep-Learning-Architecture-for-Mobile-Osia-Shamsabadi/6f0685d61328f0f90972fe822258d574b74e9c7a", "ID": "6f0685d61328f0f90972fe822258d574b74e9c7a", "Title": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics", "Abstract": "This article presents a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics, and shows that by using Siamese fine-tuning and at a small processing cost, this approach can greatly reduce the level of unnecessary, potentially sensitive information in the personal data. Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user\u2019s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.", "PublicationYear": "2017", "Authors": ["Seyed Ali Osia", "Ali Shahin Shamsabadi", "Sina Sajadmanesh", "Ali Taheri", "Kleomenis Katevas", "Hamid R. Rabiee", "Nicholas D. Lane", "Hamed Haddadi"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["65c8a794830f9a11aa0b9ab682f3b6256be67185", "6c20cd584e7258056840eb88437d69731000bb0f", "60951974d24dd83e288117b0cd217af6a5d34178", "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "8a5d0579590465494c9aba58a857af43b190b6a6", "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "187a78ebfe654e9c1d3e8d070c8845a49c1d1a42", "5a7a7dfea3674d4e0474f7fdd596951da44babe4", "7fcb90f68529cbfab49f471b54719ded7528d0ef", "405006da005398279bdf7c3423d47aa0951c5391"], "ReferenceCount": 70, "CitationCount": 203}, {"URL": "https://www.semanticscholar.org/paper/mSieve%3A-differential-behavioral-privacy-in-time-of-Saleheen-Chakraborty/36051962fdcfa536c3cc1cd27b17649d84a8cf09", "ID": "36051962fdcfa536c3cc1cd27b17649d84a8cf09", "Title": "mSieve: differential behavioral privacy in time series of mobile sensor data", "Abstract": "This work defines a new behavioral privacy metric based on differential privacy and proposes a novel data substitution mechanism to protect behavioral privacy and demonstrates that it is possible to retain meaningful utility, in terms of inference accuracy, while simultaneously preserving the privacy of sensitive behaviors. Differential privacy concepts have been successfully used to protect anonymity of individuals in population-scale analysis. Sharing of mobile sensor data, especially physiological data, raise different privacy challenges, that of protecting private behaviors that can be revealed from time series of sensor data. Existing privacy mechanisms rely on noise addition and data perturbation. But the accuracy requirement on inferences drawn from physiological data, together with well-established limits within which these data values occur, render traditional privacy mechanisms inapplicable. In this work, we define a new behavioral privacy metric based on differential privacy and propose a novel data substitution mechanism to protect behavioral privacy. We evaluate the efficacy of our scheme using 660 hours of ECG, respiration, and activity data collected from 43 participants and demonstrate that it is possible to retain meaningful utility, in terms of inference accuracy (90%), while simultaneously preserving the privacy of sensitive behaviors.", "PublicationYear": "2016", "Authors": ["Nazir Saleheen", "Supriyo Chakraborty", "Nasir Ali", "Md. Mahbubur Rahman", "Syed Monowar Hossain", "Rummana Bari", "Eugene H. Buder", "Mani B. Srivastava", "Santosh Kumar"], "RelatedTopics": ["Computer Science"], "References": ["0faf2183975567ea3791f6dfd4ec50d7453bc507", "7dee8c690e23585f0beffa3c81933f8691b06a73", "f0de4c800d0367f489b2a9f26df9f1255641fa93", "20780ad665e496aa128f82713bb78d13fd87cd0a", "017d615afa48eea38ae741d0071c4781dc0d1024", "8b0f280e7e39bff806cbada63e242d0441429896", "33eebf77fc733dd0f8053c449d52bb17319539ee", "d6e72a44ee3d7661434a052d7034f18e7f12ff2e", "70fda5147aedd42c64143a464117b5ffde18a2e4", "e9603ae83f5572f61c54f0e963840c865376997d"], "ReferenceCount": 44, "CitationCount": 44}, {"URL": "https://www.semanticscholar.org/paper/A-Collaborative-Privacy-Preserving-Deep-Learning-in-Liu-Jiang/818e1e81b9bf13f4803934b15f4f6b3cb9251658", "ID": "818e1e81b9bf13f4803934b15f4f6b3cb9251658", "Title": "A Collaborative Privacy-Preserving Deep Learning System in Distributed Mobile Environment", "Abstract": "This work proposed a collaborative privacy-preserving learning system based on deep neural network, which does not share local raw data, and reconstructed rate is proposed to evaluate the performance of distributed system compared with centralized training. In the last couple years, deep learning gained great popularity in health and medical science. For analyzing personal health data, privacy of patients and their data is one of the biggest concerns. Traditional methods have the possibility of leaking data because of transferring raw data and storing all data in centralized houseware. Therefore, we proposed a collaborative privacy-preserving learning system based on deep neural network, which does not share local raw data. The system is implemented on an XMPP server and several mobile devices. In the experiments, reconstructed rate is proposed to evaluate the performance of distributed system compared with centralized training. The rate is over 90% in different scenarios. Furthermore, the network traffic while collaborative learning is also measured.", "PublicationYear": "2016", "Authors": ["Menghan Liu", "Haotian Jiang", "Jia Chen", "Alaa Badokhon", "Xuetao Wei", "Ming-chun Huang"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["6065090377b440bbf5dc02ede58aeaa7d7811f5c", "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "a5e42129623f41c9f1657217e2b2c90da6c0eb4d", "f4ad11f180a2125dc38f666ac792209c1ba152bc", "c9b7fb86cc8f1a2e01dd2ce3a7420bd891bae206", "cf8e5a8d993529a7da098c188faf40fb6507e5c3", "dc702d7721b244f3b81d29e41a45716b005d916e", "8c911997c9ed034fbd0e7f19ce474a2dc29e4e5c", "0624b46f9d1addbff15cadc3529480642e4e9216", "4f605b3bb3ce574f4053f19264434baa522305b7"], "ReferenceCount": 16, "CitationCount": 31}, {"URL": "https://www.semanticscholar.org/paper/A-framework-for-context-aware-privacy-of-sensor-on-Chakraborty-Raghavan/7dee8c690e23585f0beffa3c81933f8691b06a73", "ID": "7dee8c690e23585f0beffa3c81933f8691b06a73", "Title": "A framework for context-aware privacy of sensor data on mobile systems", "Abstract": "We study the competing goals of utility and privacy as they arise when a user shares personal sensor data with apps on a smartphone. On the one hand, there can be value to the user for sharing data in the form of various personalized services and recommendations; on the other hand, there is the risk of revealing behaviors to the app producers that the user would like to keep private. The current approaches to privacy, usually defined in multi-user settings, rely on anonymization to prevent such sensitive behaviors from being traced back to the user---a strategy which does not apply if user identity is already known, as is the case here.\\n Instead of protecting identity, we focus on the more general problem of choosing what data to share, in such a way that certain kinds of inferences---i.e., those indicating the user's sensitive behavior---cannot be drawn. The use of inference functions allows us to establish a terminology to unify prior notions of privacy as special cases of this more general problem. We identify several information disclosure regimes, each corresponding to a specific privacy-utility tradeoff, as well as privacy mechanisms designed to realize these tradeoff points. Finally, we propose ipShield as a privacy-aware framework which uses current user context together with a model of user behavior to quantify an adversary's knowledge regarding a sensitive inference, and obfuscate data accordingly before sharing. We conclude by describing initial work towards realizing this framework.", "PublicationYear": "2013", "Authors": ["Supriyo Chakraborty", "Kasturi Rangan Raghavan", "Matthew P. Johnson", "Mani B. Srivastava"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["e14eddf4900c3dd29c53d4d1f0dbfbdcda405173", "017d615afa48eea38ae741d0071c4781dc0d1024", "e65bbc87249d2a0c239f923afff7d4207cb56bd4", "d79ed41122871e18760166a91771b8e33651ef0c", "62ce35108ef0a816ba1929223f511c976079a300", "f33eea8ff4591a7e16e705a16c94e13c66bb80c0", "dcea5988be255774405d1ba24fe85c0df9c746ee", "046c6c8e15d9b9ecd73b5d2ce125db20bbcdec4b", "5c508c62b29fee8133f663e6be680348f4f0bbfc", "6b04fba371a8e50a9c9b158a1645f4d6425d5cff"], "ReferenceCount": 24, "CitationCount": 66}, {"URL": "https://www.semanticscholar.org/paper/MaskIt%3A-privately-releasing-user-context-streams-G%C3%B6tz-Nath/017d615afa48eea38ae741d0071c4781dc0d1024", "ID": "017d615afa48eea38ae741d0071c4781dc0d1024", "Title": "MaskIt: privately releasing user context streams for personalized mobile applications", "Abstract": "This paper presents MASKIT, a technique to filter a user context stream that provably preserves privacy and presents two novel privacy checks and explains how to choose the one with the higher utility for a user. The rise of smartphones equipped with various sensors has enabled personalization of various applications based on user contexts extracted from sensor readings. At the same time it has raised serious concerns about the privacy of user contexts. In this paper, we present MASKIT, a technique to filter a user context stream that provably preserves privacy. The filtered context stream can be released to applications or be used to answer their queries. Privacy is defined with respect to a set of sensitive contexts specified by the user. MASKIT limits what adversaries can learn from the filtered stream about the user being in a sensitive context - even if the adversaries are powerful and have knowledge about the filtering system and temporal correlations in the context stream. At the heart of MASKIT is a privacy check deciding whether to release or suppress the current user context. We present two novel privacy checks and explain how to choose the one with the higher utility for a user. Our experiments on real smartphone context traces of 91 users demonstrate the high utility of MASKIT.", "PublicationYear": "2012", "Authors": ["Michael G{\\\"o}tz", "Suman Nath", "Johannes Gehrke"], "RelatedTopics": ["Computer Science"], "References": ["c1339458836db3645c9fe29362e180ae84a9e206", "33f0bf88560db6967d10356a26c0dab269be2b9a", "f4e0eced09ae83207645a89ae760e40998bca2f9", "1e0b693c1c9c69aae413729b58c552ad3cc838ca", "e8f9c3728d10968ab05979f1e87158cfd0a42e8e", "5705dd3568168f6c4ebd3fda5e938243a748d633", "65192559b209e1b76b7292e9fed93ebfbce73276", "f4c0e4b5c289a68b46099fb37f8c6552ebf458a0", "d0b185094e7d2f165cc21d92756a54a696157136", "45be07dcadbded384b944f7abaa5c1c0cdd77661"], "ReferenceCount": 39, "CitationCount": 117}, {"URL": "https://www.semanticscholar.org/paper/Differential-Privacy-Preservation-for-Deep-an-of-Phan-Wang/6065090377b440bbf5dc02ede58aeaa7d7811f5c", "ID": "6065090377b440bbf5dc02ede58aeaa7d7811f5c", "Title": "Differential Privacy Preservation for Deep Auto-Encoders: an Application of Human Behavior Prediction", "Abstract": "The main idea is to enforce \u03b5-differential privacy by perturbing the objective functions of the traditional deep auto-encoder, rather than its results. \\n \\n In recent years, deep learning has spread beyond both academia and industry with many exciting real-world applications. The development of deep learning has presented obvious privacy issues. However, there has been lack of scientific study about privacy preservation in deep learning. In this paper, we concentrate on the auto-encoder, a fundamental component in deep learning, and propose the deep private auto-encoder (dPA). Our main idea is to enforce \u03b5-differential privacy by perturbing the objective functions of the traditional deep auto-encoder, rather than its results. We apply the dPA to human behavior prediction in a health social network. Theoretical analysis and thorough experimental evaluations show that the dPA is highly effective and efficient, and it significantly outperforms existing solutions.\\n \\n", "PublicationYear": "2016", "Authors": ["Nhathai Phan", "Yue Wang", "Xintao Wu", "Dejing Dou"], "RelatedTopics": ["Computer Science"], "References": ["f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef", "cd078c0cf75a952eb34ac560bb71a0a6d3c0c983", "b57c54350769ffa59ff57f79ee5aad918844d298", "5c3fe6e86068f46f4b9ea3a51977d044a89e2826", "a188d2ac0d10bdd4d4a04c92cdc76523e11c155c", "facf10888bfea439dcb6e7c400d42233becbfe0f", "56c56187cdaa03372298fb6ad1dc51dba7b3499b", "c90dd7731b01b3b486b5a28e1ce9bec547c9cfab", "355d44f53428b1ac4fb2ab468d593c720640e5bd", "fff114cbba4f3ba900f33da574283e3de7f26c83"], "ReferenceCount": 27, "CitationCount": 212}, {"URL": "https://www.semanticscholar.org/paper/Privacy-Utility-Trade-Off-for-Time-Series-with-to-Erdogdu-Fawaz/ffc77622fca7aa46de7ef7ded3031e31c3bacce4", "ID": "ffc77622fca7aa46de7ef7ded3031e31c3bacce4", "Title": "Privacy-Utility Trade-Off for Time-Series with Application to Smart-Meter Data", "Abstract": "Smart-meter data can be randomized for privacy purposes to prevent disaggregation of per-device energy consumption, while preserving the utility and the performance of the framework is evaluated over synthetic and real-world time-series data. We consider the online setting where a user would like to continuously release a time-series of data that is correlated with his private data, to a service provider in the hope of deriving some utility. Due to correlations, the continual observation of the released time-series puts the user at risk of inference of his private data by an adversary. To protect the user from inference attacks on his private data, the time-series is randomized prior to its release according to a probabilistic privacy mapping. The privacy mapping should be designed in a way that balances privacy and utility requirements over time. Our contributions are threefold. First, we formalize the framework for the design of utility-aware privacy mappings for time-series data, under both online and batch models. We provide a sequential scheme that allows to design online privacy mappings at scale, that account for privacy risk from the history of released data and future releases to come. Second, we prove the equivalence of the optimal mappings under the batch and the online models, in the case where the time-series samples are independent across time. We further show that there exists a gap between optimal batch and online privacy mappings when certain conditions are not satisfied. Finally, we evaluate the performance of the framework over synthetic and real-world time-series data. In particular, we show that smart-meter data can be randomized for privacy purposes to prevent disaggregation of per-device energy consumption, while preserving the utility.", "PublicationYear": "2015", "Authors": ["Murat A. Erdogdu", "Nadia Fawaz", "Andrea Montanari"], "RelatedTopics": ["Computer Science", "Engineering"], "References": ["3751ece306198102d15c70c7559447bbc129187b", "cdf8a5b6256823bca38a1d2347ab36f8e4a2ca94", "014a0a9d5d7f6cf88b401f2601069b59262cae1b", "2b7892e85fe08f0ad97f41512378011a3d21f659", "7cc53ef35f8398181bd09755ecc2fa8f52d0da1d", "592b28828c0a528396e41110dcafb974194beb83", "e4ce10063cd25447dcde75c2d9ce327446ced952", "528d3b56227b2a91c55116db36d00598ca8a6511", "106c6bfed325c0391f6cefee215236302ae5e80d", "2882cbe709b231bf56a18aa16150f6a4d2b6be35"], "ReferenceCount": 24, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Chiaroscuro%3A-Transparency-and-Privacy-for-Massive-Allard-H%C3%A9brail/b3de61ce1665d7f8b5ddc344289b7a4e18f015f6", "ID": "b3de61ce1665d7f8b5ddc344289b7a4e18f015f6", "Title": "Chiaroscuro: Transparency and Privacy for Massive Personal Time-Series Clustering", "Abstract": "This paper proposes Chiaroscuro, a complete solution for clustering personal data with strong privacy guarantees, and builds on the novel data structure, called Diptych, which allows the participating devices to collaborate privately by combining encryption with differential privacy. The advent of on-body/at-home sensors connected to personal devices leads to the generation of fine grain highly sensitive personal data at an unprecendent rate. However, despite the promises of large scale analytics there are obvious privacy concerns that prevent individuals to share their personnal data. In this paper, we propose Chiaroscuro, a complete solution for clustering personal data with strong privacy guarantees. The execution sequence produced by Chiaroscuro is massively distributed on personal devices, coping with arbitrary connections and disconnections. Chiaroscuro builds on our novel data structure, called Diptych, which allows the participating devices to collaborate privately by combining encryption with differential privacy. Our solution yields a high clustering quality while minimizing the impact of the differentially private perturbation. Chiaroscuro is both correct and secure. Finally, we provide an experimental validation of our approach on both real and synthetic sets of time-series.", "PublicationYear": "2015", "Authors": ["T. Allard", "Georges H{\\'e}brail", "Florent Masseglia", "Esther Pacitti"], "RelatedTopics": ["Computer Science"], "References": ["3751ece306198102d15c70c7559447bbc129187b", "7cc53ef35f8398181bd09755ecc2fa8f52d0da1d", "e9c0820a48dde2d13bf73a2543e8cd9e1a41eb93", "eda07dc46d0ad7df2641c281d02d3868416bf4c4", "29e24506e8301b8ea158692ae5b0a2fffcbaa43c", "0a0fa32bb0d6d8f4283f08501189425b53ec97e0", "8ca8ae4a784ca3a788ab844efde8b1b8acfd14e8", "98b78b6702e28075466488c840be49f5b0956fe5", "78f6f52a2e5f836fb4c24902be11ca3b81982847", "c9a2206285fe23fb09ac7c396dc4119556629150"], "ReferenceCount": 45, "CitationCount": 26}]