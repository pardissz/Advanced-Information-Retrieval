[{"URL": "https://www.semanticscholar.org/paper/Transformer-based-deep-neural-network-language-for-Roshanzamir-Aghajan/6d8052588c62e5bf2a073ae414867a78784ff663", "ID": "6d8052588c62e5bf2a073ae414867a78784ff663", "Title": "Transformer-based deep neural network language models for Alzheimer\u2019s disease risk assessment from targeted speech", "Abstract": "Using pre-trained language models can improve AD prediction not only solves the problem of lack of sufficiently large datasets, but also reduces the need for expert-defined features. Background We developed transformer-based deep learning models based on natural language processing for early risk assessment of Alzheimer\u2019s disease from the picture description test. Methods The lack of large datasets poses the most important limitation for using complex models that do not require feature engineering. Transformer-based pre-trained deep language models have recently made a large leap in NLP research and application. These models are pre-trained on available large datasets to understand natural language texts appropriately, and are shown to subsequently perform well on classification tasks with small training sets. The overall classification model is a simple classifier on top of the pre-trained deep language model. Results The models are evaluated on picture description test transcripts of the Pitt corpus, which contains data of 170 AD patients with 257 interviews and 99 healthy controls with 243 interviews. The large bidirectional encoder representations from transformers (BERT Large ) embedding with logistic regression classifier achieves classification accuracy of 88.08%, which improves the state-of-the-art by 2.48%. Conclusions Using pre-trained language models can improve AD prediction. This not only solves the problem of lack of sufficiently large datasets, but also reduces the need for expert-defined features.", "PublicationYear": "2021", "Authors": ["Ali Roshanzamir", "Hamid K. Aghajan", "Mahdieh Soleymani Baghshah"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["a7425f74a9e7bdd3ae6763c515c9534fb18a3560", "73ee478f44296ee9a9e810fa106462ca52ece708", "9e7b0384bc48c3ae6dc1c66d6ee674902380a2c8", "9620bda083e3a3b7d55a5fdc5198c5f62052d323", "4d4117e4e5214dcc887317e302db724df545729e", "bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "8cd1d603498e65ae19baa59bdb31617f441d4296", "360806c34ea0dcb5faab9824dababc094bb05c07", "bbeae238e2d1373b75ce20ce96b4a5b87383a622", "6ca330477a1509b0a5b3d1848564b954bb5e29a4"], "ReferenceCount": 55, "CitationCount": 50}, {"URL": "https://www.semanticscholar.org/paper/MG-BERT%3A-Multi-Graph-Augmented-BERT-for-Masked-BehnamGhader-Zakerinia/b9464b492f6638035d25b42f32ff3d51cb6d1e30", "ID": "b9464b492f6638035d25b42f32ff3d51cb6d1e30", "Title": "MG-BERT: Multi-Graph Augmented BERT for Masked Language Modeling", "Abstract": "Multi-Graph augmented BERT (MG-BERT) model that is based on BERT embeds tokens while taking advantage of a static multi-graph containing global word co-occurrences in the text corpus beside global real-world facts about words in knowledge graphs is proposed. Pre-trained models like Bidirectional Encoder Representations from Transformers (BERT), have recently made a big leap forward in Natural Language Processing (NLP) tasks. However, there are still some shortcomings in the Masked Language Modeling (MLM) task performed by these models. In this paper, we first introduce a multi-graph including different types of relations between words. Then, we propose Multi-Graph augmented BERT (MG-BERT) model that is based on BERT. MG-BERT embeds tokens while taking advantage of a static multi-graph containing global word co-occurrences in the text corpus beside global real-world facts about words in knowledge graphs. The proposed model also employs a dynamic sentence graph to capture local context effectively. Experimental results demonstrate that our model can considerably enhance the performance in the MLM task.", "PublicationYear": "2021", "Authors": ["Parishad BehnamGhader", "Hossein Zakerinia", "Mahdieh Soleymani Baghshah"], "RelatedTopics": ["Computer Science"], "References": ["5f994dc8cae24ca9d1ed629e517fcc652660ddde", "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "31184789ef4c3084af930b1e0dede3215b4a9240", "96901acc92d68350443774596fa2b38bc522a0ce", "b36b2914f16c78b1bf88ee720342d893d8a9fc46", "56cafbac34f2bb3f6a9828cd228ff281b810d6bb", "cd8a9914d50b0ac63315872530274d158d6aff09", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "2cab7f5d64a427cb59fb21112fe8dc28fb753b56", "c80fecc35eb0f26bd1e8af02e53234ac830b63ff"], "ReferenceCount": 29, "CitationCount": 2}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-Based-Proarrhythmia-Analysis-Using-Golgooni-Mirsadeghi/b9e98f630e8eaf77ddcd0f80d1360b611ae61e70", "ID": "b9e98f630e8eaf77ddcd0f80d1360b611ae61e70", "Title": "Deep Learning-Based Proarrhythmia Analysis Using Field Potentials Recorded From Human Pluripotent Stem Cells Derived Cardiomyocytes", "Abstract": "A novel method for automated analysis of \u201cirregularity\u201d in an in vitro model of cardiotoxicity experiments is introduced, which may overcome the drawbacks of using predesigned features that restricts the classification performance to the comprehensiveness and the quality of the designed features. An early characterization of drug-induced cardiotoxicity may be possible by combining comprehensive in vitro proarrhythmia assay and deep learning techniques. We aimed to develop a method to automatically detect irregular beating rhythm of field potentials recorded from human pluripotent stem cells (hPSC) derived cardiomyocytes (hPSC-CM) by multi-electrode array (MEA) system. We included field potentials from 380 experiments, which were labeled as normal or arrhythmic by electrophysiology experts. Convolutional and recurrent neural networks (CNN and RNN) were employed for automatic classification of field potential recordings. A preparation phase was initially applied to split 60-s long recordings into a series of 5-s windows. Subsequently, the classification phase comprising of two main steps was designed and applied. The first step included the classification of 5-s windows by using a designated CNN. While, the results of 5-s window assessments were used as the input sequence to an RNN that aggregates these results in the second step. The output was then compared to electrophysiologist-level arrhythmia detection, resulting in 0.83 accuracy, 0.93 sensitivity, 0.70 specificity, and 0.80 precision. In summary, this paper introduces a novel method for automated analysis of \u201cirregularity\u201d in an in vitro model of cardiotoxicity experiments. Thus, our method may overcome the drawbacks of using predesigned features that restricts the classification performance to the comprehensiveness and the quality of the designed features. Furthermore, automated analysis may facilitate the quality control experiments through the procedure of drug development with respect to cardiotoxicity and avoid late drug attrition from market.", "PublicationYear": "2019", "Authors": ["Zeinab Golgooni", "Sara Mirsadeghi", "Mahdieh Soleymani Baghshah", "Pedram Ataee", "Hossein Baharvand", "Sara Pahlavan", "Hamid R. Rabiee"], "RelatedTopics": ["Medicine", "Engineering"], "References": ["50afa4fa74b0475ca0264461c79f7bd42fcc494c", "307ff8f512098497e2c69b79c00fbb7b3cc9650e", "7a373d7dbd44ad99e5287f78b0e168e33498b44d", "04232aeef8343cfdf85fe9b5d0164ea186029ed1", "e6f337f871168ec891b3f0fc1b060005e8e4de01", "4ef11d0b2d5bd02eab3f8113601370fc7183cc30", "b2e9ab6f182579d75fa0a61d266252b258e61746", "04aecf353a9d854d4ce2b602a6d5920af7f07b2b", "89a125d1a89bcd0c18df6810786f92d27ee4e17f", "c3abc2d4b3cb86d6e3606f225c671fff3b334c9b"], "ReferenceCount": 46, "CitationCount": 7}, {"URL": "https://www.semanticscholar.org/paper/A-Deep-Learning-Framework-for-Viable-Tumor-Burden-Jahromi-Khani/1eae26fe1ca566f17468080c3aecab1c3f9efb66", "ID": "1eae26fe1ca566f17468080c3aecab1c3f9efb66", "Title": "A Deep Learning Framework for Viable Tumor Burden Estimation", "Abstract": "This paper proposes a deep learning framework for the segmentation of whole and viable tumor areas of liver cancer from whole-slide images (WSIs) using Fast Segmentation Convolutional Neural Network (Fast-SCNN) as the network. Liver masses have become a common clinical challenge since they require to be defined and accurately categorized as neoplastic or nonneoplastic lesions. Hepatocellular carcinoma (HCC), the most common histologic type of primary liver malignancy, is a global health concern being the fifth most common cancer and the second cause of cancer mortality worldwide. Accurate diagnosis, which in some circumstances requires histopathology results, is necessary for appropriate management. Also, some tumor characteristics help in predicting tumor behavior and patient response to therapy. In this paper, we propose a deep learning framework for the segmentation of whole and viable tumor areas of liver cancer from whole-slide images (WSIs). To this end, we use Fast Segmentation Convolutional Neural Network (Fast-SCNN) as our network. We use the dataset from PAIP 2019 challenge. After data-augmentation on the training subset, we train the network with a multi-term loss function and SWA technique. Our model achieves 0.80 for the median of the Jaccard Index for the task of Viable Tumor Segmentation and 0.77 for the median of Weighted Absolute Accuracy for the task of Viable Tumor Burden Estimation on the whole-slide images of the test subset.", "PublicationYear": "2020", "Authors": ["Seyed Alireza Fatemi Jahromi", "Ali Asghar Khani", "Hatef Otroshi Shahreza", "Mahdieh Soleymani Baghshah", "Hamid Behroozi"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["d779b87172306c37c2c711512e84bc8112adf21e", "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7", "769149c0dc0ed308eca8bc916f4326b2e2f57a1f", "21ba757bf394720e0b66b86e7638ae28742d6570", "f9638ee3738d30c23a5f8f84988aed7120a08fac", "6048de9749a1f31ac70e5c30030ceb1dc5d3f2b0", "ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba", "188f8f6f70947215a9dfeebb0b577155e0d3d339", "ae1c89817a3a239e5344293138bdd80293983460", "57a892b9576baeba70277179712d5b09e19224b9"], "ReferenceCount": 62, "CitationCount": 3}, {"URL": "https://www.semanticscholar.org/paper/An-attribute-learning-method-for-zero-shot-Yazdanian-Shojaee/5a5f7d39433d68059e513b947a9fde62b5d4d3fe", "ID": "5a5f7d39433d68059e513b947a9fde62b5d4d3fe", "Title": "An attribute learning method for zero-shot recognition", "Abstract": "Experimental results show that the learned attributes by the proposed attribute learning method can improve the accuracy of the state-of-the-art zero-shot learning methods. Recently, the problem of integrating side information about classes has emerged in the learning settings like zero-shot learning. Although using multiple sources of information about the input space has been investigated in the last decade and many multi-view and multi-modal learning methods have already been introduced, the attribute learning for classes (output space) is a new problem that has been attended in the last few years. In this paper, we propose an attribute learning method that can use different sources of descriptions for classes to find new attributes that are more proper to be used as class signatures. Experimental results show that the learned attributes by the proposed method can improve the accuracy of the state-of-the-art zero-shot learning methods.", "PublicationYear": "2017", "Authors": ["Ramtin Yazdanian", "Seyed Mohsen Shojaee", "Mahdieh Soleymani Baghshah"], "RelatedTopics": ["Computer Science"], "References": ["5fd80e47d53c64512a0b85a4c7a0beb24bc35766", "a6b8cd5f34b438f487679b1166ea03e56eb14c9e", "b29227f8dde62a5cd21678b4bc429206615485a2", "846946cd21413211a4701f309c3927d67363cd30", "ac98259064e86f643f2cd11e5417b43bf28daa91", "caa632d101a41a7860562e4399a5eaa9a4088b55", "755e9f43ce398ae8737366720c5f82685b0c253e", "244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa", "018e730f8947173e1140210d4d1760d05c9d3854", "cb461276fad5710d8a7e2868867a9b01df040119"], "ReferenceCount": 29, "CitationCount": 0}, {"URL": "https://www.semanticscholar.org/paper/Automatic-Diagnosis-of-Alzheimer%E2%80%99s-Disease-Using-Fritsch-Wankerl/a7425f74a9e7bdd3ae6763c515c9534fb18a3560", "ID": "a7425f74a9e7bdd3ae6763c515c9534fb18a3560", "Title": "Automatic Diagnosis of Alzheimer\u2019s Disease Using Neural Network Language Models", "Abstract": "A way to significantly improve the method introduced by Wankerl et al. by evaluating the perplexity of transliterations of descriptions of the Cookie Theft picture from DementiaBank\u2019s Pitt Corpus. In today\u2019s aging society, the number of neurodegenerative diseases such as Alzheimer\u2019s disease (AD) increases. Reliable tools for automatic early screening as well as monitoring of AD patients are necessary. For that, semantic deficits have been shown to be useful indicators. We present a way to significantly improve the method introduced by Wankerl et al. [1]. The purely statistical approach of n-gram language models (LMs) is enhanced by using the rwthlm toolkit to create neural network language models (NNLMs) with Long Short Term-Memory (LSTM) cells. The prediction is solely based on evaluating the perplexity of transliterations of descriptions of the Cookie Theft picture from DementiaBank\u2019s Pitt Corpus. Each transliteration is evaluated on LMs of both control and Alzheimer speakers in a leave-one-speaker-out cross-validation scheme. The resulting perplexity values reveal enough discrepancy to classify patients on just those two values with an accuracy of 85.6% at equal-error-rate.", "PublicationYear": "2019", "Authors": ["Julian Fritsch", "Sebastian Wankerl", "Elmar N{\\\"o}th"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["c940a209c47594443c5f352890b37a8d3fa9525f", "3c0edbe173aa15ffa3eb203cfa463e7f0abb8240", "bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "3ce917438bba77b3c73ee865512e6d66930b7090", "137743ee8d930661ede1f297d9dc5b593b0d580c", "084a54c5b76e10648e1d15985641baa5433ff893", "0b485413633fecfb2073f6ec4bf4d4777b3cb4c0", "0a4426ee1a2374baa7ef4b9c3c05516e6b1e66cc", "f9a1b3850dfd837793743565a8af95973d395a4e", "a17745f1d7045636577bcd5d513620df5860e9e5"], "ReferenceCount": 18, "CitationCount": 48}, {"URL": "https://www.semanticscholar.org/paper/Deep-Deep-Neural-Network-Language-Models-for-Mild-Orimaye-Wong/73ee478f44296ee9a9e810fa106462ca52ece708", "ID": "73ee478f44296ee9a9e810fa106462ca52ece708", "Title": "Deep-Deep Neural Network Language Models for Predicting Mild Cognitive Impairment", "Abstract": "Results on the DementiaBank language transcript clinical dataset show that D2NNLM sufficiently learned several linguistic biomarkers to distinguish the MCI group from the healthy group with reasonable accuracy, which could help clinical diagnosis even in the absence of sufficient training data. Early diagnosis of Mild Cognitive Impairment (MCI) is currently a challenge. Currently, MCI is diagnosed using specific clinical diagnostic criteria and neuropsychological examinations. As such we propose an automated diagnostic technique using a variant of deep neural networks language models (DNNLM) on the verbal utterances of MCI patients. Motivated by the success of DNNLM on natural language tasks, we propose a combination of deep neural network and deep language models (D2NNLM) to predict MCI. Results on the DementiaBank language transcript clinical dataset show that D2NNLM sufficiently learned several linguistic biomarkers in the form of higher order n-grams and skip-grams to distinguish the MCI group from the healthy group with reasonable accuracy, which could help clinical diagnosis even in the absence of sufficient training data.", "PublicationYear": "2016", "Authors": ["Sylvester Olubolu Orimaye", "Jojo Sze-Meng Wong", "Judyanne Sharmini Gilbert Fernandez"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["e6ee69f334b71dc0edc72eecc3f29d0ef846560b", "7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "bca9453da6fbfd06ff9db5bbcb25fabaf9370e22", "4dc3d29f66e887c780343226c8a4278df758a17e", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "a17745f1d7045636577bcd5d513620df5860e9e5", "04473f90a3aed35ac938b1ed960146bc27c76af8", "9f79b994b6bbb2da8002582200f6f0b8ba6daf91", "0b485413633fecfb2073f6ec4bf4d4777b3cb4c0", "3e5c06e477cf11a0b5823338b4ad31c103dbee5b"], "ReferenceCount": 34, "CitationCount": 12}, {"URL": "https://www.semanticscholar.org/paper/Multilingual-prediction-of-Alzheimer%E2%80%99s-disease-and-Fraser-Linz/9e7b0384bc48c3ae6dc1c66d6ee674902380a2c8", "ID": "9e7b0384bc48c3ae6dc1c66d6ee674902380a2c8", "Title": "Multilingual prediction of Alzheimer\u2019s disease through domain adaptation and concept-based language modelling", "Abstract": "A new set of features are introduced to model the order in which information units are produced by dementia patients and controls, and these concept-based language model features improve classification performance in both English and French separately. There is growing evidence that changes in speech and language may be early markers of dementia, but much of the previous NLP work in this area has been limited by the size of the available datasets. Here, we compare several methods of domain adaptation to augment a small French dataset of picture descriptions (n = 57) with a much larger English dataset (n = 550), for the task of automatically distinguishing participants with dementia from controls. The first challenge is to identify a set of features that transfer across languages; in addition to previously used features based on information units, we introduce a new set of features to model the order in which information units are produced by dementia patients and controls. These concept-based language model features improve classification performance in both English and French separately, and the best result (AUC = 0.89) is achieved using the multilingual training set with a combination of information and language model features.", "PublicationYear": "2019", "Authors": ["Kathleen C. Fraser", "Nicklas Linz", "Bai Li", "Kristina Lundholm Fors", "Frank Rudzicz", "Alexandra K{\\\"o}nig", "Jan Alexandersson", "Philippe H. Robert", "Dimitrios Kokkinakis"], "RelatedTopics": ["Medicine", "Computer Science", "Linguistics"], "References": ["d035391d54e9a8b2f0f3393886ae82349d4fffae", "c756b90d1d87707895aa0870730b07743957e7f0", "dbcc61f2bfb5fd4edd48aa70e375a3d4b81a8d2a", "bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "8cd1d603498e65ae19baa59bdb31617f441d4296", "1c5547142eaad896209d23af525c5d162d87d286", "bbeae238e2d1373b75ce20ce96b4a5b87383a622", "4dfd60a301f792311c7967f08b22d606091f9d12", "0b82ba2817418837d0e88259051de568c5ffc85e", "3838e92e4a20e230c697c107638d5fea542181f8"], "ReferenceCount": 55, "CitationCount": 13}, {"URL": "https://www.semanticscholar.org/paper/Detecting-Linguistic-Characteristics-of-Alzheimer%E2%80%99s-Karlekar-Niu/9620bda083e3a3b7d55a5fdc5198c5f62052d323", "ID": "9620bda083e3a3b7d55a5fdc5198c5f62052d323", "Title": "Detecting Linguistic Characteristics of Alzheimer\u2019s Dementia by Interpreting Neural Models", "Abstract": "This work uses NLP techniques to classify and analyze the linguistic characteristics ofAD patients using the DementiaBank dataset, and shows that first derivative saliency can not only rediscover previous language patterns of AD patients, but also shed light on the limitations of neural models. Alzheimer\u2019s disease (AD) is an irreversible and progressive brain disease that can be stopped or slowed down with medical treatment. Language changes serve as a sign that a patient\u2019s cognitive functions have been impacted, potentially leading to early diagnosis. In this work, we use NLP techniques to classify and analyze the linguistic characteristics of AD patients using the DementiaBank dataset. We apply three neural models based on CNNs, LSTM-RNNs, and their combination, to distinguish between language samples from AD and control patients. We achieve a new independent benchmark accuracy for the AD classification task. More importantly, we next interpret what these neural models have learned about the linguistic characteristics of AD patients, via analysis based on activation clustering and first-derivative saliency techniques. We then perform novel automatic pattern discovery inside activation clusters, and consolidate AD patients\u2019 distinctive grammar patterns. Additionally, we show that first derivative saliency can not only rediscover previous language patterns of AD patients, but also shed light on the limitations of neural models. Lastly, we also include analysis of gender-separated AD data.", "PublicationYear": "2018", "Authors": ["Sweta Karlekar", "Tong Niu", "Mohit Bansal"], "RelatedTopics": ["Computer Science", "Linguistics", "Medicine"], "References": ["bb83cccd9309861aeff98bfcba3653d4dde1dc87", "73ee478f44296ee9a9e810fa106462ca52ece708", "e6ee69f334b71dc0edc72eecc3f29d0ef846560b", "25176248277bd8ad6aaf7a472be9ad21bcbddd9c", "c918ad033313ace6cb412063fc9f730ed348229c", "074a31b5599a3deebb869a0ded54ddccf86c5655", "1bb94d5f567071985b17cc117e6f59ad857aec55", "87812cc86532a63b0640ec909081ce081196f206", "347c431613fd835ca25a2de277a71de84f4a46c4", "543292e3965e681b322c86204a545e3ac915fef2"], "ReferenceCount": 47, "CitationCount": 95}, {"URL": "https://www.semanticscholar.org/paper/Learning-Predictive-Linguistic-Features-for-Disease-Orimaye-Wong/4d4117e4e5214dcc887317e302db724df545729e", "ID": "4d4117e4e5214dcc887317e302db724df545729e", "Title": "Learning Predictive Linguistic Features for Alzheimer\u2019s Disease and related Dementias using Verbal Utterances", "Abstract": "This paper uses several Machine Learning (ML) algorithms to build diagnostic models using syntactic and lexical features resulting from verbal utterances of AD and related Dementia patients, and shows that syntacticandLexical features could be good indicative features for helping to diagnose AD andrelated Dementias. Early diagnosis of neurodegenerative disorders (ND) such as Alzheimer\u2019s disease (AD) and related Dementias is currently a challenge. Currently, AD can only be diagnosed by examining the patient\u2019s brain after death and Dementia is diagnosed typically through consensus using specific diagnostic criteria and extensive neuropsychological examinations with tools such as the Mini-Mental State Examination (MMSE) or the Montreal Cognitive Assessment (MoCA). In this paper, we use several Machine Learning (ML) algorithms to build diagnostic models using syntactic and lexical features resulting from verbal utterances of AD and related Dementia patients. We emphasize that the best diagnostic model distinguished the AD and related Dementias group from the healthy elderly group with 74% FMeasure using Support Vector Machines (SVM). Additionally, we perform several statistical tests to indicate the significance of the selected linguistic features. Our results show that syntactic and lexical features could be good indicative features for helping to diagnose AD and related Dementias.", "PublicationYear": "2014", "Authors": ["Sylvester Olubolu Orimaye", "Jojo Sze-Meng Wong", "Karen J. Golden"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["6eef856f1276c7f77c1d1c3aeb7e0bafcce512f1", "cc435c9efd3a6454c150ab781dadc7f4fc5c8e9d", "0959830b666ec7871b547a486076a706571c3e5a", "6fcbf100eb09852c645ca20e04aafa37b1fe4536", "e729730d5f69c9af97c4e3748297e37e057fd55f", "8e361ca7c689d70c8ea16d42be37e333f051e25a", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "4def26f02218aff759e752870ee9d5f76d00e17c", "94ff6ac108cc105c578f838df2f814c1dfac976c", "97f1d23c912ba12aa117e9de4e5f1b02749b5aa8"], "ReferenceCount": 26, "CitationCount": 103}, {"URL": "https://www.semanticscholar.org/paper/Linguistic-Features-Identify-Alzheimer's-Disease-in-Fraser-Meltzer/bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "ID": "bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "Title": "Linguistic Features Identify Alzheimer's Disease in Narrative Speech.", "Abstract": "BACKGROUND\\nAlthough memory impairment is the main symptom of Alzheimer's disease (AD), language impairment can be an important marker. Relatively few studies of language in AD quantify the impairments in connected speech using computational techniques.\\n\\n\\nOBJECTIVE\\nWe aim to demonstrate state-of-the-art accuracy in automatically identifying Alzheimer's disease from short narrative samples elicited with a picture description task, and to uncover the salient linguistic factors with a statistical factor analysis.\\n\\n\\nMETHODS\\nData are derived from the DementiaBank corpus, from which 167 patients diagnosed with \\\"possible\\\" or \\\"probable\\\" AD provide 240 narrative samples, and 97 controls provide an additional 233. We compute a number of linguistic variables from the transcripts, and acoustic variables from the associated audio files, and use these variables to train a machine learning classifier to distinguish between participants with AD and healthy controls. To examine the degree of heterogeneity of linguistic impairments in AD, we follow an exploratory factor analysis on these measures of speech and language with an oblique promax rotation, and provide interpretation for the resulting factors.\\n\\n\\nRESULTS\\nWe obtain state-of-the-art classification accuracies of over 81% in distinguishing individuals with AD from those without based on short samples of their language on a picture description task. Four clear factors emerge: semantic impairment, acoustic abnormality, syntactic impairment, and information impairment.\\n\\n\\nCONCLUSION\\nModern machine learning and linguistic analysis will be increasingly useful in assessment and clustering of suspected AD.", "PublicationYear": "2015", "Authors": ["Kathleen C. Fraser", "Jed A. Meltzer", "Frank Rudzicz"], "RelatedTopics": ["Medicine", "Linguistics"], "References": ["ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "2a75030045c68f142e834e099e6e1c591d55c56b", "3720bc93ed64a447b25a2be1efafa3b6b0f8fcd5", "7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "4d4117e4e5214dcc887317e302db724df545729e", "8cd1d603498e65ae19baa59bdb31617f441d4296", "c1c33280fe9e00d8047ced66815e7232403e4ca2", "3d0bffdf62b34efbd2535a9c6b72289306d12511", "647c4649b11a92d4797950d50a8294b1beaba22b", "6ca330477a1509b0a5b3d1848564b954bb5e29a4"], "ReferenceCount": 133, "CitationCount": 545}, {"URL": "https://www.semanticscholar.org/paper/Features-and-machine-learning-classification-of-and-Rentoumi-Raoufian/8cd1d603498e65ae19baa59bdb31617f441d4296", "ID": "8cd1d603498e65ae19baa59bdb31617f441d4296", "Title": "Features and machine learning classification of connected speech samples from patients with autopsy proven Alzheimer's disease with and without additional vascular pathology.", "Abstract": "Language samples obtained during the course of a longitudinal clinical study from patients in whom one or other pathology was verified at post mortem were analyzed to confirm the presence of differences in language produced by members of the two groups using quantitative methods of evaluation and ascertain the most informative sources of variation between the groups. Mixed vascular and Alzheimer-type dementia and pure Alzheimer's disease are both associated with changes in spoken language. These changes have, however, seldom been subjected to systematic comparison. In the present study, we analyzed language samples obtained during the course of a longitudinal clinical study from patients in whom one or other pathology was verified at post mortem. The aims of the study were twofold: first, to confirm the presence of differences in language produced by members of the two groups using quantitative methods of evaluation; and secondly to ascertain the most informative sources of variation between the groups. We adopted a computational approach to evaluate digitized transcripts of connected speech along a range of language-related dimensions. We then used machine learning text classification to assign the samples to one of the two pathological groups on the basis of these features. The classifiers' accuracies were tested using simple lexical features, syntactic features, and more complex statistical and information theory characteristics. Maximum accuracy was achieved when word occurrences and frequencies alone were used. Features based on syntactic and lexical complexity yielded lower discrimination scores, but all combinations of features showed significantly better performance than a baseline condition in which every transcript was assigned randomly to one of the two classes. The classification results illustrate the word content specific differences in the spoken language of the two groups. In addition, those with mixed pathology were found to exhibit a marked reduction in lexical variation and complexity compared to their pure AD counterparts.", "PublicationYear": "2014", "Authors": ["Vassiliki Rentoumi", "Ladan Raoufian", "Samrah Ahmed", "Celeste A. de Jager", "Peter Garrard"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "c1c33280fe9e00d8047ced66815e7232403e4ca2", "cc435c9efd3a6454c150ab781dadc7f4fc5c8e9d", "bdd7750c5be25be75e39c7ff0c383ff50065acbf", "f402db195032286e8a715e531aca1357ac6f4b3a", "addce4c2a2b9a8fa7fe2851824b860aae919cc26", "c11125f8ee935fdd2494c20e84ea80acece44c29", "0959830b666ec7871b547a486076a706571c3e5a", "216e373390e16cd474442dfcb9f1eecb3a4cdc99", "b50cdb9d179fb9905f3bd8efade58a8d0da2e8de"], "ReferenceCount": 34, "CitationCount": 55}, {"URL": "https://www.semanticscholar.org/paper/Vector-space-topic-models-for-detecting-Alzheimer%E2%80%99s-Yancheva-Rudzicz/360806c34ea0dcb5faab9824dababc094bb05c07", "ID": "360806c34ea0dcb5faab9824dababc094bb05c07", "Title": "Vector-space topic models for detecting Alzheimer\u2019s disease", "Abstract": "A generalizable method for automatic generation of information content units (ICUs) for a picture used in a standard clinical task, achieving high recall, 96.8%, of human-supplied ICUs. Semantic de\ufb01cit is a symptom of language impairment in Alzheimer\u2019s disease (AD). We present a generalizable method for automatic generation of information content units (ICUs) for a picture used in a standard clinical task, achieving high recall, 96.8%, of human-supplied ICUs. We use the automatically generated topic model to extract semantic features, and train a random forest classi\ufb01er to achieve an F-score of 0.74 in binary classi\ufb01cation of controls versus people with AD using a set of only 12 features. This is comparable to re-sults (0.72 F-score) with a set of 85 manual features. Adding semantic information to a set of standard lexicosyntactic and acoustic features improves F-score to 0.80. While control and dementia subjects discuss the same topics in the same contexts, controls are more informative per second of speech.", "PublicationYear": "2016", "Authors": ["Maria Yancheva", "Frank Rudzicz"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "2da167f503f3eea7f591b672068e3ff941af53d8", "bdd7750c5be25be75e39c7ff0c383ff50065acbf", "647c4649b11a92d4797950d50a8294b1beaba22b", "1e46a6d8d52c8d254706509a81748d766405dc85", "c705c9be9e8debdc40a30d637a4b533b7e4fc390", "f37e1b62a767a307c046404ca96bc140b3e68cb5", "c1c33280fe9e00d8047ced66815e7232403e4ca2", "f47e58797316ca268fa08b601bca33c0eefdc791", "068a3d62f1d3eaaaba03df23912db89b5adeb41c"], "ReferenceCount": 22, "CitationCount": 53}, {"URL": "https://www.semanticscholar.org/paper/Idea-density-for-predicting-Alzheimer%E2%80%99s-disease-Sirts-Piguet/bbeae238e2d1373b75ce20ce96b4a5b87383a622", "ID": "bbeae238e2d1373b75ce20ce96b4a5b87383a622", "Title": "Idea density for predicting Alzheimer\u2019s disease from transcribed speech", "Abstract": "DDEPID is developed, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas\u2014a feature characteristic to AD speech. Idea Density (ID) measures the rate at which ideas or elementary predications are expressed in an utterance or in a text. Lower ID is found to be associated with an increased risk of developing Alzheimer\u2019s disease (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas\u2014a feature characteristic to AD speech. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an F-score of 84.8.", "PublicationYear": "2017", "Authors": ["Kairit Sirts", "Olivier Piguet", "Mark Johnson"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["360806c34ea0dcb5faab9824dababc094bb05c07", "be9de6c52b9567d1306d1cc703d9cac698c15b7e", "bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "bdd7750c5be25be75e39c7ff0c383ff50065acbf", "4d4117e4e5214dcc887317e302db724df545729e", "6ca330477a1509b0a5b3d1848564b954bb5e29a4", "fd46e4c4ad23ea006523b305a401de92e11f1f49", "c35396244ee8028d3553ff1fd920248d534ae2ae", "7d50bfd726677efb91ee21a7fec90de18d273c5b", "8cd1d603498e65ae19baa59bdb31617f441d4296"], "ReferenceCount": 35, "CitationCount": 23}, {"URL": "https://www.semanticscholar.org/paper/Automatic-detection-and-rating-of-dementia-of-type-Thomas-Keselj/6ca330477a1509b0a5b3d1848564b954bb5e29a4", "ID": "6ca330477a1509b0a5b3d1848564b954bb5e29a4", "Title": "Automatic detection and rating of dementia of Alzheimer type through lexical analysis of spontaneous speech", "Abstract": "This work addresses the issue of language deficits in spontaneous speech by exploring novel automatic and objective methods for diagnosing patients through analysis of spontaneous speech, and shows that purely computational solutions offer a viable alternative to standard approaches to diagnosing the level of impairment in patients. Current methods of assessing dementia of Alzheimer type (DAT) in older adults involve structured interviews that attempt to capture the complex nature of deficits suffered. One of the most significant areas affected by the disease is the capacity for functional communication as linguistic skills break down. These methods often do note capture the true nature of language deficits in spontaneous speech. We address this issue by exploring novel automatic and objective methods for diagnosing patients through analysis of spontaneous speech. We detail several lexical approaches to the problem of detecting and rating DAT. The approaches explored rely on character n-gram-based techniques, shown recently to perform successfully in a different, but related task of automatic authorship attribution. We also explore the correlation of usage frequency of different parts of speech and DAT. We achieve a high 95% accuracy of detecting dementia when compared with a control group, and we achieve 70% accuracy in rating dementia in two classes, and 50% accuracy in rating dementia into four classes. Our results show that purely computational solutions offer a viable alternative to standard approaches to diagnosing the level of impairment in patients. These results are significant step forward toward automatic and objective means to identifying early symptoms of DAT in older adults.", "PublicationYear": "2005", "Authors": ["Calvin Thomas", "Vlado Keselj", "Nick Cercone", "Kenneth Rockwood", "Elissa Asp"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["3d0bffdf62b34efbd2535a9c6b72289306d12511", "ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "33192c6378b46f9e7c7f46eb365bf3a2679cf4aa", "9208fe3a308483ffc4a4859ef01464bc0244282d", "d686a6d2a91f4aa73627608d44f2ed63762227d0", "52cabd4b2127899b191ecaebf00d295f9cc9f90c", "1757d7d3f803c2c250121f070a9fd3f335c4b6fe", "59735a30545b145e7395cb889e1da586d2405270", "0a4426ee1a2374baa7ef4b9c3c05516e6b1e66cc", "bc9edab1799a43f97bbeda92ec13681c486d6c67"], "ReferenceCount": 28, "CitationCount": 111}, {"URL": "https://www.semanticscholar.org/paper/ERNIE%3A-Enhanced-Language-Representation-with-Zhang-Han/5f994dc8cae24ca9d1ed629e517fcc652660ddde", "ID": "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "Title": "ERNIE: Enhanced Language Representation with Informative Entities", "Abstract": "This paper utilizes both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE) which can take full advantage of lexical, syntactic, and knowledge information simultaneously, and is comparable with the state-of-the-art model BERT on other common NLP tasks. Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.", "PublicationYear": "2019", "Authors": ["Zhengyan Zhang", "Xu Han", "Zhiyuan Liu", "Xin Jiang", "Maosong Sun", "Qun Liu"], "RelatedTopics": ["Computer Science"], "References": ["3b1d8eb163ffff598c2faa0d9d7cf933857a359f", "083b9fd0f36528eb7ca35786ba5fb0149adc7727", "031e4e43aaffd7a479738dcea69a2d5be7957aa3", "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "5aadc803228b70c3cc6b31e332770d47d7fb1e6e", "400e746bc8027c4b5f915cae6123cd1775484b4d", "345ef9a7d9af0ac0816d76803ddcf9b6d19404d7", "df2b0e26d0599ce3e70df8a9da02e51594e0e992"], "ReferenceCount": 59, "CitationCount": 1083}, {"URL": "https://www.semanticscholar.org/paper/BERT%3A-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang/df2b0e26d0599ce3e70df8a9da02e51594e0e992", "ID": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "Title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "Abstract": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks. We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).", "PublicationYear": "2019", "Authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "RelatedTopics": ["Computer Science"], "References": ["204e3073870fae3d05bcbc2f6a8e263d9b72e776", "ac11062f1f368d97f4c826c317bf50dcc13fdb59", "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e", "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "b9de9599d7241459db9213b5cdd7059696f5ef8d", "8c1b00128e74f1cd92aede3959690615695d5101", "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "6e795c6e9916174ae12349f5dc3f516570c17ce8", "7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d", "421fc2556836a6b441de806d7b393a35b6eaea58"], "ReferenceCount": 63, "CitationCount": 67464}, {"URL": "https://www.semanticscholar.org/paper/KG-BERT%3A-BERT-for-Knowledge-Graph-Completion-Yao-Mao/31184789ef4c3084af930b1e0dede3215b4a9240", "ID": "31184789ef4c3084af930b1e0dede3215b4a9240", "Title": "KG-BERT: BERT for Knowledge Graph Completion", "Abstract": "This work treats triples in knowledge graphs as textual sequences and proposes a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.", "PublicationYear": "2019", "Authors": ["Liang Yao", "Chengsheng Mao", "Yuan Luo"], "RelatedTopics": ["Computer Science"], "References": ["cd8a9914d50b0ac63315872530274d158d6aff09", "96acb1c882ad655c6b8459c2cd331803801446ca", "cab46caf83a9e0390c6ca4d8603187969c9a53ad", "bd345877856dc83c2c10c125dbf0f41e2bde38b1", "e379f7c85441df5d8ddc1565cabf4b4290c22f1f", "17a1e5d78bffb17979ac55aa792698727fe25a21", "3ce14b7a3c1b89c717eba10229d9d80d80bd0e04", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "67cab3bafc8fa9e1ae3ff89791ad43c81441d271", "5f994dc8cae24ca9d1ed629e517fcc652660ddde"], "ReferenceCount": 44, "CitationCount": 358}, {"URL": "https://www.semanticscholar.org/paper/Barack%E2%80%99s-Wife-Hillary%3A-Using-Knowledge-Graphs-for-RobertL.Logan-Liu/96901acc92d68350443774596fa2b38bc522a0ce", "ID": "96901acc92d68350443774596fa2b38bc522a0ce", "Title": "Barack\u2019s Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling", "Abstract": "This work introduces the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context that enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model\u2019s ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.", "PublicationYear": "2019", "Authors": ["IV RobertL.Logan", "Nelson F. Liu", "Matthew E. Peters", "Matt Gardner", "Sameer Singh"], "RelatedTopics": ["Computer Science"], "References": ["58c6f890a1ae372958b7decf56132fe258152722", "9c81f16df774c772dbefc947fe0e467b72500844", "0fa5142f908afc94c923ca2adbe14a5673bc76eb", "dab7e605237ad4f4fe56dcba2861b8f0a57112be", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "9405cc0d6169988371b2755e573cc28650d14dfe", "13395213d47f78672ab4e81573f2b0fa0cfc8c6d", "efbd381493bb9636f489b965a2034d529cd56bcd", "604764133befe7a0aaa692919545846197e6e065", "dec8fe49a9336149e1268a332ce4ab9ecea7841b"], "ReferenceCount": 29, "CitationCount": 158}, {"URL": "https://www.semanticscholar.org/paper/Learning-beyond-Datasets%3A-Knowledge-Graph-Augmented-Annervaz-Chowdhury/b36b2914f16c78b1bf88ee720342d893d8a9fc46", "ID": "b36b2914f16c78b1bf88ee720342d893d8a9fc46", "Title": "Learning beyond Datasets: Knowledge Graph Augmented Neural Networks for Natural Language Processing", "Abstract": "This work proposes to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks by introducing a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. Machine Learning has been the quintessential solution for many AI problems, but learning models are heavily dependent on specific training data. Some learning models can be incorporated with prior knowledge using a Bayesian setup, but these learning models do not have the ability to access any organized world knowledge on demand. In this work, we propose to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks. Our aim is to develop a deep learning model that can extract relevant prior support facts from knowledge graphs depending on the task using attention mechanism. We introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. We show that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task. Using this method we show significant improvement in performance for text classification with 20Newsgroups (News20) & DBPedia datasets, and natural language inference with Stanford Natural Language Inference (SNLI) dataset. We also demonstrate that a deep learning model can be trained with substantially less amount of labeled training data, when it has access to organized world knowledge in the form of a knowledge base.", "PublicationYear": "2018", "Authors": ["K. M. Annervaz", "Somnath Basu Roy Chowdhury", "Ambedkar Dukkipati"], "RelatedTopics": ["Computer Science"], "References": ["96acb1c882ad655c6b8459c2cd331803801446ca", "e3274206b36a603abc4a335af91273ecba5e73cc", "6fba4968f1b39d490bf95fe4030e3d385f167074", "033f25ad905ef2ed32a8331cf38b83953ff15922", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "79baf8cf6be6510f69be8c515516136138678cf5", "d77de3a4ddfa62f8105c0591fd41e549edcfd95f", "18bd7cd489874ed9976b4f87a6a558f9533316e0", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "955fe2ee26d888ae22749b0853981b8b581b133d"], "ReferenceCount": 40, "CitationCount": 61}, {"URL": "https://www.semanticscholar.org/paper/KEPLER%3A-A-Unified-Model-for-Knowledge-Embedding-and-Wang-Gao/56cafbac34f2bb3f6a9828cd228ff281b810d6bb", "ID": "56cafbac34f2bb3f6a9828cd228ff281b810d6bb", "Title": "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation", "Abstract": "A unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs is proposed. Abstract Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.", "PublicationYear": "2019", "Authors": ["Xiaozhi Wang", "Tianyu Gao", "Zhaocheng Zhu", "Zhiyuan Liu", "Juan-Zi Li", "Jian Tang"], "RelatedTopics": ["Computer Science"], "References": ["5f994dc8cae24ca9d1ed629e517fcc652660ddde", "06a73ad09664435f8b3cd90293f4e05a047cf375", "bfeb827d06c1a3583b5cc6d25241203a81f6af09", "96acb1c882ad655c6b8459c2cd331803801446ca", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "70af3ee98c53441d9090119f7b76efb1b6d03edd", "6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8", "96901acc92d68350443774596fa2b38bc522a0ce", "994afdf0db0cb0456f4f76468380822c2f532726", "f7b0d94fd4a32c4c9be472b4e8d6c5bc308f0dfa"], "ReferenceCount": 75, "CitationCount": 418}, {"URL": "https://www.semanticscholar.org/paper/Modeling-Relational-Data-with-Graph-Convolutional-Schlichtkrull-Kipf/cd8a9914d50b0ac63315872530274d158d6aff09", "ID": "cd8a9914d50b0ac63315872530274d158d6aff09", "Title": "Modeling Relational Data with Graph Convolutional Networks", "Abstract": "It is shown that factorization models for link prediction such as DistMult can be significantly improved through the use of an R-GCN encoder model to accumulate evidence over multiple inference steps in the graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline. Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to handle the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved through the use of an R-GCN encoder model to accumulate evidence over multiple inference steps in the graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline.", "PublicationYear": "2017", "Authors": ["M. Schlichtkrull", "Thomas Kipf", "Peter Bloem", "Rianne van den Berg", "Ivan Titov", "Max Welling"], "RelatedTopics": ["Computer Science"], "References": ["9697d32ed0a16da167f2bdba05ef96d0da066eb5", "822f1ed9a76a57cc19d8fda7745365b97130b97a", "af2e6165b68e75c911dfdb8f81f9ab6627722ab7", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "86412306b777ee35aba71d4795b02915cb8a04c3", "1ef01e7bfab2041bc0c0a56a57906964df9fc985", "e745b0506f4133263633eb05e5006a8cff4129f0", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "6b7d6e6416343b2a122f8416e69059ce919026ef", "97f7ef7a5332218e0e9ce75ad5cf77048466ca83"], "ReferenceCount": 54, "CitationCount": 3564}, {"URL": "https://www.semanticscholar.org/paper/Translating-Embeddings-for-Modeling-Data-Bordes-Usunier/2582ab7c70c9e7fcb84545944eba8f3a7f253248", "ID": "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "Title": "Translating Embeddings for Modeling Multi-relational Data", "Abstract": "TransE is proposed, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities, which proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.", "PublicationYear": "2013", "Authors": ["Antoine Bordes", "Nicolas Usunier", "Alberto Garc{\\'i}a-Dur{\\'a}n", "Jason Weston", "Oksana Yakhnenko"], "RelatedTopics": ["Computer Science"], "References": ["04cc04457e09e17897f9256c86b45b92d70a401f", "f6764d853a14b0c34df1d2283e76277aead40fde", "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "834cb8e1e738b8d2c6d24e652ac966d6e7089a46", "8007fc25a1f5c03f7c8ac95ccf5cf8aa3d989092", "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "1f4a4769e4d2fb846e59c2f185e0377190739f18", "fec691d09b564986ad27162ce15344604c840ff9", "81bbe42e3ec09c28b8864956148e58f4cb5aa860", "4e07791ee0872401215f12aefde342bd843240cc"], "ReferenceCount": 18, "CitationCount": 6030}, {"URL": "https://www.semanticscholar.org/paper/Enriching-BERT-with-Knowledge-Graph-Embeddings-for-Ostendorff-Bourgonje/2cab7f5d64a427cb59fb21112fe8dc28fb753b56", "ID": "2cab7f5d64a427cb59fb21112fe8dc28fb753b56", "Title": "Enriching BERT with Knowledge Graph Embeddings for Document Classification", "Abstract": "Building upon BERT, a deep neural language model, it is demonstrated how to combine text representations with metadata and knowledge graph embeddings, which encode author information. In this paper, we focus on the classification of books using short descriptive texts (cover blurbs) and additional metadata. Building upon BERT, a deep neural language model, we demonstrate how to combine text representations with metadata and knowledge graph embeddings, which encode author information. Compared to the standard BERT approach we achieve considerably better results for the classification task. For a more coarse-grained classification using eight labels we achieve an F1- score of 87.20, while a detailed classification using 343 labels yields an F1-score of 64.70. We make the source code and trained models of our experiments publicly available", "PublicationYear": "2019", "Authors": ["Malte Ostendorff", "Peter Bourgonje", "Maria Berger", "Juli{\\'a}n Moreno Schneider", "Georg Rehm", "Bela Gipp"], "RelatedTopics": ["Computer Science"], "References": ["1a9954d86466a7e4de6f98ddee452ceb50e15d86", "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "58203813610b866483ffc2bd1181f616ae38107c", "64c5f7055b2e6982b6b95e069b22230d13a134bb", "fc1d23d2f9167d13ef1bce098ef55d1b40894dd4", "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "455afd748e8834ef521e4b67c7c056d3c33429e2", "160563abbd75265b19afc8b4169bab9e1eb33d97", "7ac58400e5063bed9b7c35f87e44ddb917ccf357", "031e4e43aaffd7a479738dcea69a2d5be7957aa3"], "ReferenceCount": 18, "CitationCount": 68}, {"URL": "https://www.semanticscholar.org/paper/Augmenting-Named-Entity-Recognition-with-Knowledge-Dekhili-Le/c80fecc35eb0f26bd1e8af02e53234ac830b63ff", "ID": "c80fecc35eb0f26bd1e8af02e53234ac830b63ff", "Title": "Augmenting Named Entity Recognition with Commonsense Knowledge", "Abstract": "This research takes advantage of the availability of the open multilingual knowledge graph ConceptNet by using it as an additional external resource in Named Entity Recognition (NER) and proposes an architecture that involves BiLSTM layers combined with a CRF layer that was augmented with some features such as pre-trained word embedding layers and dropout layers. Commonsense can be vital in some applications like Natural Language Understanding (NLU), where it is often required to resolve ambiguity arising from implicit knowledge and underspecification. In spite of the remarkable success of neural network approaches on a variety of Natural Language Processing tasks, many of them struggle to react effectively in cases that require commonsense knowledge. In the present research, we take advantage of the availability of the open multilingual knowledge graph ConceptNet, by using it as an additional external resource in Named Entity Recognition (NER). Our proposed architecture involves BiLSTM layers combined with a CRF layer that was augmented with some features such as pre-trained word embedding layers and dropout layers. Moreover, apart from using word representations, we used also character-based representation to capture the morphological and the orthographic information. Our experiments and evaluations showed an improvement in the overall performance with +2.86 in the F1-measure. Commonsense reasonnig has been employed in other studies and NLP tasks but to the best of our knowledge, there is no study relating the integration of a commonsense knowledge base in NER.", "PublicationYear": "2019", "Authors": ["Ghaith Dekhili", "Ngoc Tan Le", "Fatiha Sadat"], "RelatedTopics": ["Computer Science"], "References": ["d7b6753a2d4a2b286c396854063bde3a91b75535", "f37e1b62a767a307c046404ca96bc140b3e68cb5", "6f5e816654d2b01e4b4f2c8ecee95b242a23d68f", "f6b51c8753a871dc94ff32152c00c01e94f90f09", "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb", "24158c9fc293c8a998ac552b1188404a877da292", "f4ba954b0412773d047dc41231c733de0c1f4926"], "ReferenceCount": 8, "CitationCount": 4}, {"URL": "https://www.semanticscholar.org/paper/In-vitro-electrophysiological-drug-testing-using-Caspi-Itzhaki/50afa4fa74b0475ca0264461c79f7bd42fcc494c", "ID": "50afa4fa74b0475ca0264461c79f7bd42fcc494c", "Title": "In vitro electrophysiological drug testing using human embryonic stem cell derived cardiomyocytes.", "Abstract": "It is hypothesized that human embryonic stem cell-derived cardiomyocytes assessed with a combination of single cell electrophysiology and microelectrode array (MEA) mapping can serve as a novel model for Electrophysiological drug screening. Pro-arrhythmia (development of cardiac arrhythmias as a pharmacological side effect) has become the single most common cause of the withdrawal or restrictions of previously marketed drugs. The development of new medications, free from these side effects, is hampered by the lack of an in vitro assay for human cardiac tissue. We hypothesized that human embryonic stem cell-derived cardiomyocytes (hESC-CMs) assessed with a combination of single cell electrophysiology and microelectrode array (MEA) mapping can serve as a novel model for electrophysiological drug screening. Current-clamp studies revealed that E-4031 and Sotalol (IKr blockers) significantly increased hESC-CM's action potential duration and also induced after-depolarizations (the in vitro correlates of increased arrhythmogenic potential). Multicellular aggregates of hESC-CMs were then analyzed with the MEA technique. Application of class I (Quinidine, Procaineamide) and class III (Sotalol) antiarrhythmic agents, E-4031, and Cisapride (a noncardiogenic agent known to lengthen QT) resulted in dose-dependent prolongation of the corrected field potential duration (cFPD). We next utilized the MEA technique to also assess pharmacological effects on conduction. Activation maps demonstrated significant conduction slowing following administration of Na channel blockers (Quinidine and Propafenone) and of the gap junction blocker (1-heptanol). While most attention has been focused on the prospects of using hESC-derived cardiomyocytes for regenerative medicine, this study highlights the possible utilization of these unique cells also for cardiac electrophysiological studies, drug screening, and target validation.", "PublicationYear": "2009", "Authors": ["Oren Caspi", "Ilanit Itzhaki", "Izhak Kehat", "Amira Gepstein", "Gil Arbel", "Irit Huber", "Jonathan Satin", "Lior Gepstein"], "RelatedTopics": ["Medicine"], "References": ["2269e63b969cb7b62d51c86f2c58ec645dad2303", "0e01651f92b8aa685df569856997f2ddff12c1e5", "65b5a7936849b6f1278cdf6b5b9eaf9e126799c4", "cf06c03542b1407e3da9d8fdb8ce7ace9a8ba07c", "00edea7e3c0f45492baea5ffa637b311857a6383", "997aeac7640fdf10adc7486a02173d144a767aee", "bc0e497fd8d8ed4ecf91075373af29cf0b049d4f", "84d07718fa5452e3899d6070d17b4bbdcb87bd61", "ad421e55153d9e844c2be6db43d2a450076c3b73", "5b11057670ddd12789ab9d0bf10b7e7bb76ce9f0"], "ReferenceCount": 53, "CitationCount": 237}, {"URL": "https://www.semanticscholar.org/paper/Estimating-the-risk-of-drug-induced-proarrhythmia-Guo-Abrams/307ff8f512098497e2c69b79c00fbb7b3cc9650e", "ID": "307ff8f512098497e2c69b79c00fbb7b3cc9650e", "Title": "Estimating the risk of drug-induced proarrhythmia using human induced pluripotent stem cell-derived cardiomyocytes.", "Abstract": "The first published report of a high-throughput functional assay employing a monolayer of beating human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) is described, detailing a model that accurately detects drug-induced cardiac abnormalities. Improved in vitro systems for predicting drug-induced toxicity are needed in the pharmaceutical and biotechnology industries to decrease late-stage drug attrition. One unmet need is an early screen for cardiotoxicity, which accounts for about one third of safety-based withdrawn pharmaceuticals. Herein, the first published report of a high-throughput functional assay employing a monolayer of beating human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) is described, detailing a model that accurately detects drug-induced cardiac abnormalities. Using 96-well plates with interdigitated electrode arrays that assess impedance, the rhythmic, synchronous contractions of the iPSC-CMs were detected. Treatment of the iPSC-CMs with 28 different compounds with known cardiac effects resulted in compound-specific changes in the beat rate and/or the amplitude of the impedance measurement. Changes in impedance for the compounds tested were comparable with the results from a related technology, electric field potential assessment obtained from microelectrode arrays. Using the results from the set of compounds, an index of drug-induced arrhythmias was calculated, enabling the determination of a drug's proarrhythmic potential. This system of interrogating human cardiac function in vitro opens new opportunities for predicting cardiac toxicity and studying cardiac biology.", "PublicationYear": "2011", "Authors": ["Liang Guo", "Rory M. C. Abrams", "Joshua Babiarz", "Jennifer D. Cohen", "Seiji Kameoka", "Martin J. Sanders", "Eric T Chiao", "Kyle L Kolaja"], "RelatedTopics": ["Medicine"], "References": ["0e01651f92b8aa685df569856997f2ddff12c1e5", "65b5a7936849b6f1278cdf6b5b9eaf9e126799c4", "c1cb043d6cc44f9c661a45c1daba623d41b36bf1", "2b552d462e7cc16f40d1e8ef2765c9e81f8c54db", "22a81a3583b6993c46a6e006a684529668239b89", "9ec3175129b38d7c239f9a640b8252e643728f57", "cf313169a9639e7b837404546589aeb24224e863", "cca805487ff41c849517930de4e53c00f2116213", "0d6cbdbb65410e3853272e74e8f7707897d8a8b2", "43ca6679e5e24a6d70634be4f23de81d09415c14"], "ReferenceCount": 42, "CitationCount": 263}, {"URL": "https://www.semanticscholar.org/paper/Interpretation-of-field-potentials-measured-on-a-in-Tertoolen-Braam/7a373d7dbd44ad99e5287f78b0e168e33498b44d", "ID": "7a373d7dbd44ad99e5287f78b0e168e33498b44d", "Title": "Interpretation of field potentials measured on a multi electrode array in pharmacological toxicity screening on primary and human pluripotent stem cell-derived cardiomyocytes", "Abstract": "Semantic Scholar extracted view of \\\"Interpretation of field potentials measured on a multi electrode array in pharmacological toxicity screening on primary and human pluripotent stem cell-derived cardiomyocytes\\\" by L. Tertoolen et al.", "PublicationYear": "2017", "Authors": ["Leon G. J. Tertoolen", "Stefan R. Braam", "B. J. van Meer", "Robert Passier", "Christine L. Mummery", "Christine L. Mummery"], "RelatedTopics": ["Engineering", "Medicine"], "References": ["0e01651f92b8aa685df569856997f2ddff12c1e5", "88499b49a830a39dd16381e224d8880e47d868ce", "bf613c2aa1d514e099cff15eeb751653321cbcb6", "04b17d30b1cee5eba210e40150e80a51b196dc7a", "98fb5773e149e1ef59e9612098209d2ac44cdd8a", "f8317fe10a44714ed9c1d6df54c50bd075896f01", "74062c98a4c16981407a0c181abadc85dd03eb97", "0ed904b68234575f6109403eb7a228da2f1b0faa", "9e4ba0fc9b6103fdd5509e8cdf370971648a6e2f", "de63e783210fe097f6164e66aa125ed014d44dff"], "ReferenceCount": 11, "CitationCount": 53}, {"URL": "https://www.semanticscholar.org/paper/Electrophysiological-Analysis-of-human-Pluripotent-Sala-Oostwaard/04232aeef8343cfdf85fe9b5d0164ea186029ed1", "ID": "04232aeef8343cfdf85fe9b5d0164ea186029ed1", "Title": "Electrophysiological Analysis of human Pluripotent Stem Cell-derived Cardiomyocytes (hPSC-CMs) Using Multi-electrode Arrays (MEAs)", "Abstract": "This protocol describes how to dissociate 2D cell cultures of hPSC-CMs to small aggregates and single cells and plate them on MEAs to record their spontaneous electrical activity as field potential and methods for analyzing the recorded data to extract specific parameters, such as the QT and the RR intervals. Cardiomyocytes can now be derived with high efficiency from both human embryonic and human induced-Pluripotent Stem Cells (hPSC). hPSC-derived cardiomyocytes (hPSC-CMs) are increasingly recognized as having great value for modeling cardiovascular diseases in humans, especially arrhythmia syndromes. They have also demonstrated relevance as in vitro systems for predicting drug responses, which makes them potentially useful for drug-screening and discovery, safety pharmacology and perhaps eventually for personalized medicine. This would be facilitated by deriving hPSC-CMs from patients or susceptible individuals as hiPSCs. For all applications, however, precise measurement and analysis of hPSC-CM electrical properties are essential for identifying changes due to cardiac ion channel mutations and/or drugs that target ion channels and can cause sudden cardiac death. Compared with manual patch-clamp, multi-electrode array (MEA) devices offer the advantage of allowing medium- to high-throughput recordings. This protocol describes how to dissociate 2D cell cultures of hPSC-CMs to small aggregates and single cells and plate them on MEAs to record their spontaneous electrical activity as field potential. Methods for analyzing the recorded data to extract specific parameters, such as the QT and the RR intervals, are also described here. Changes in these parameters would be expected in hPSC-CMs carrying mutations responsible for cardiac arrhythmias and following addition of specific drugs, allowing detection of those that carry a cardiotoxic risk.", "PublicationYear": "2017", "Authors": ["Luca Sala", "Dorien Ward-van Oostwaard", "Leon G. J. Tertoolen", "Christine L. Mummery", "Milena Bellin"], "RelatedTopics": ["Engineering", "Medicine"], "References": ["8fdcc7c7765f06a1836db3647aec32fddbed0b7f", "878ba1facdba4e27058a664860fdaee5b02a4ff0", "8b65176229dde32cd4c1cf2b9d04807f0dab29e8", "5d3185baf131f5f08e55667a475d15abb629efda", "184177e938c9176f5fee59eefa2ab959dffa5351", "7a373d7dbd44ad99e5287f78b0e168e33498b44d", "127615ea4a38e98be0bdcc8b76a326c338f30535", "e57d812c931e2f2d775f9b472c3b61c895bddbaf", "cbfac1f03e8a04ec04ac2d5368ece85676edf5e9", "95183f57aea770611a0847ad2f73c7c85a48269d"], "ReferenceCount": 62, "CitationCount": 36}, {"URL": "https://www.semanticscholar.org/paper/Screening-Drug-Induced-Arrhythmia-Using-Human-Stem-Navarrete-Liang/e6f337f871168ec891b3f0fc1b060005e8e4de01", "ID": "e6f337f871168ec891b3f0fc1b060005e8e4de01", "Title": "Screening Drug-Induced Arrhythmia Using Human Induced Pluripotent Stem Cell\u2013Derived Cardiomyocytes and Low-Impedance Microelectrode Arrays", "Abstract": "The data indicate that the MEA/hiPSC-CM assay is a sensitive, robust, and efficient platform for testing drug effectiveness and for arrhythmia screening and may provide significant advantages over current industry standard assays that use immortalized cell lines or animal models. Background\u2014 Drug-induced arrhythmia is one of the most common causes of drug development failure and withdrawal from market. This study tested whether human induced pluripotent stem cell\u2013derived cardiomyocytes (hiPSC-CMs) combined with a low-impedance microelectrode array (MEA) system could improve on industry-standard preclinical cardiotoxicity screening methods, identify the effects of well-characterized drugs, and elucidate underlying risk factors for drug-induced arrhythmia. hiPSC-CMs may be advantageous over immortalized cell lines because they possess similar functional characteristics as primary human cardiomyocytes and can be generated in unlimited quantities. Methods and Results\u2014 Pharmacological responses of beating embryoid bodies exposed to a comprehensive panel of drugs at 65 to 95 days postinduction were determined. Responses of hiPSC-CMs to drugs were qualitatively and quantitatively consistent with the reported drug effects in literature. Torsadogenic hERG blockers, such as sotalol and quinidine, produced statistically and physiologically significant effects, consistent with patch-clamp studies, on human embryonic stem cell\u2013derived cardiomyocytes hESC-CMs. False-negative and false-positive hERG blockers were identified accurately. Consistent with published studies using animal models, early afterdepolarizations and ectopic beats were observed in 33% and 40% of embryoid bodies treated with sotalol and quinidine, respectively, compared with negligible early afterdepolarizations and ectopic beats in untreated controls. Conclusions\u2014 We found that drug-induced arrhythmias can be recapitulated in hiPSC-CMs and documented with low impedance MEA. Our data indicate that the MEA/hiPSC-CM assay is a sensitive, robust, and efficient platform for testing drug effectiveness and for arrhythmia screening. This system may hold great potential for reducing drug development costs and may provide significant advantages over current industry standard assays that use immortalized cell lines or animal models.", "PublicationYear": "2013", "Authors": ["Enrique G. Navarrete", "Ping Liang", "Feng Lan", "Veronica Sanchez-Freire", "Chelsey S. Simmons", "Tingyu Gong", "Arun Sharma", "Paul W. Burridge", "Bhagat Patlolla", "Andrew Stephen Lee", "Haodi Wu", "Ramin E. Beygui", "Sean M. Wu", "Robert C. Robbins", "Donald M. Bers", "Joseph C. Wu"], "RelatedTopics": ["Medicine", "Engineering"], "References": ["50afa4fa74b0475ca0264461c79f7bd42fcc494c", "307ff8f512098497e2c69b79c00fbb7b3cc9650e", "a610242d1e177bb04a3d6e35b5d34afd8648bfb0", "878ba1facdba4e27058a664860fdaee5b02a4ff0", "0e01651f92b8aa685df569856997f2ddff12c1e5", "d1c166e8edf5e672ccc08dc65b1979aaeaafa775", "88499b49a830a39dd16381e224d8880e47d868ce", "c79706e7edb52f5b61155c1b626686a147576ffe", "c1cb043d6cc44f9c661a45c1daba623d41b36bf1", "65b5a7936849b6f1278cdf6b5b9eaf9e126799c4"], "ReferenceCount": 74, "CitationCount": 276}, {"URL": "https://www.semanticscholar.org/paper/Cardiomyocyte-MEA-Data-Analysis-(CardioMDA)-%E2%80%93-A-for-Pradhapan-Kuusela/4ef11d0b2d5bd02eab3f8113601370fc7183cc30", "ID": "4ef11d0b2d5bd02eab3f8113601370fc7183cc30", "Title": "Cardiomyocyte MEA Data Analysis (CardioMDA) \u2013 A Novel Field Potential Data Analysis Software for Pluripotent Stem Cell Derived Cardiomyocytes", "Abstract": "An offline, semi-automatic data analysis software equipped with correlation analysis and ensemble averaging techniques to improve the accuracy, reliability and throughput rate of analysing human pluripotent stem cell derived cardiomyocyte field potentials, and will facilitate the analysis of CM MEA signals in semi-automated way. Cardiac safety pharmacology requires in-vitro testing of all drug candidates before clinical trials in order to ensure they are screened for cardio-toxic effects which may result in severe arrhythmias. Micro-electrode arrays (MEA) serve as a complement to current in-vitro methods for drug safety testing. However, MEA recordings produce huge volumes of data and manual analysis forms a bottleneck for high-throughput screening. To overcome this issue, we have developed an offline, semi-automatic data analysis software, \u2018Cardiomyocyte MEA Data Analysis (CardioMDA)\u2019, equipped with correlation analysis and ensemble averaging techniques to improve the accuracy, reliability and throughput rate of analysing human pluripotent stem cell derived cardiomyocyte (CM) field potentials. With the program, true field potential and arrhythmogenic complexes can be distinguished from one another. The averaged field potential complexes, analysed using our software to determine the field potential duration, were compared with the analogous values obtained from manual analysis. The reliability of the correlation analysis algorithm, evaluated using various arrhythmogenic and morphology changing signals, revealed a mean sensitivity and specificity of 99.27% and 94.49% respectively, in determining true field potential complexes. The field potential duration of the averaged waveforms corresponded well to the manually analysed data, thus demonstrating the reliability of the software. The software has also the capability to create overlay plots for signals recorded under different drug concentrations in order to visualize and compare the magnitude of response on different ion channels as a result of drug treatment. Our novel field potential analysis platform will facilitate the analysis of CM MEA signals in semi-automated way and provide a reliable means of efficient and swift analysis for cardiomyocyte drug or disease model studies.", "PublicationYear": "2013", "Authors": ["Paruthi Pradhapan", "Jukka Kuusela", "Jari Viik", "Katriina Aalto-Set{\\\"a}l{\\\"a}", "Jari A.K. Hyttinen"], "RelatedTopics": ["Engineering", "Medicine"], "References": ["50afa4fa74b0475ca0264461c79f7bd42fcc494c", "42c550a012171047707cd12afb10ef6d2c3e661c", "0e01651f92b8aa685df569856997f2ddff12c1e5", "2269e63b969cb7b62d51c86f2c58ec645dad2303", "09c77cd329a36c22f62d6bc3204499e6a9794c26", "881744b7a097ab9804d0dd3d1456a0c9e0337759", "63f4067d18d872fa045d3b2b7ba1fa251bb01dcf", "b4427af5b7f8d0d230a1a3f3c519fca87e896d6b", "e0ba942b9ccdb5448da8738ae005fe7c3fd05951", "a80930d3b42106fd4bbe5715e3e95155a97b0fd8"], "ReferenceCount": 53, "CitationCount": 32}, {"URL": "https://www.semanticscholar.org/paper/Effects-of-cardioactive-drugs-on-human-induced-stem-Kuusela-Kujala/b2e9ab6f182579d75fa0a61d266252b258e61746", "ID": "b2e9ab6f182579d75fa0a61d266252b258e61746", "Title": "Effects of cardioactive drugs on human induced pluripotent stem cell derived long QT syndrome cardiomyocytes", "Abstract": "The drug effects on these patient-specific cardiomyocytes appear to recapitulate clinical observations and provide further evidence that these cells can be applied for in vitro drug testing to probe their vulnerability to arrhythmia. Human induced pluripotent stem cells (hiPSC) have enabled a major step forward in pathophysiologic studies of inherited diseases and may also prove to be valuable in in vitro drug testing. Long QT syndrome (LQTS), characterized by prolonged cardiac repolarization and risk of sudden death, may be inherited or result from adverse drug effects. Using a microelectrode array platform, we investigated the effects of six different drugs on the electrophysiological characteristics of human embryonic stem cell-derived cardiomyocytes as well as hiPSC-derived cardiomyocytes from control subjects and from patients with type 1 (LQT1) and type 2 (LQT2) of LQTS. At baseline the repolarization time was significantly longer in LQTS cells compared to controls. Isoprenaline increased the beating rate of all cell lines by 10\u201373\u00a0% but did not show any arrhythmic effects in any cell type. Different QT-interval prolonging drugs caused prolongation of cardiac repolarization by 3\u201313\u00a0% (cisapride), 10\u201320\u00a0% (erythromycin), 8\u201323\u00a0% (sotalol), 16\u201342\u00a0% (quinidine) and 12\u201327\u00a0% (E-4031), but we did not find any systematic differences in sensitivity between the control, LQT1 and LQT2 cell lines. Sotalol, quinidine and E-4031 also caused arrhythmic beats and beating arrests in some cases. In summary, the drug effects on these patient-specific cardiomyocytes appear to recapitulate clinical observations and provide further evidence that these cells can be applied for in vitro drug testing to probe their vulnerability to arrhythmia.", "PublicationYear": "2016", "Authors": ["Jukka Kuusela", "Ville J. Kujala", "Annamari Kiviaho", "Marisa Ojala", "Heikki Swan", "Kimmo K. Kontula", "Katriina Aalto-Set{\\\"a}l{\\\"a}"], "RelatedTopics": ["Medicine"], "References": ["d1c166e8edf5e672ccc08dc65b1979aaeaafa775", "50afa4fa74b0475ca0264461c79f7bd42fcc494c", "0e01651f92b8aa685df569856997f2ddff12c1e5", "8b5f6a39faf2b5586012d9fccb19c0f43120b642", "a80930d3b42106fd4bbe5715e3e95155a97b0fd8", "09f4b7dd63927fcfadd5fec2cc9de065ae83d911", "2fd46267aaab85b200d3a95fb32539a76b19255b", "4a4ead8cc2068d34c6a71597f5885137986ab67d", "e6f337f871168ec891b3f0fc1b060005e8e4de01", "362dd25ebea6d4e2fb6da58cadbf64b07de1dc85"], "ReferenceCount": 48, "CitationCount": 26}, {"URL": "https://www.semanticscholar.org/paper/High-throughput-multi-parameter-profiling-of-drug-Clements-Thomas/04aecf353a9d854d4ce2b602a6d5920af7f07b2b", "ID": "04aecf353a9d854d4ce2b602a6d5920af7f07b2b", "Title": "High-throughput multi-parameter profiling of electrophysiological drug effects in human embryonic stem cell derived cardiomyocytes using multi-electrode arrays.", "Abstract": "This study is the first to apply multi-parameter phenotypic profiling and clustering techniques commonly used for high-content imaging and microarray data to the analysis of electrophysiology data obtained by multi-electrode array (MEA) analysis of hESC-CM. Human stem cell derived cardiomyocytes (hESC-CM) provide a potential model for development of improved assays for pre-clinical predictive drug safety screening. We have used multi-electrode array (MEA) analysis of hESC-CM to generate multi-parameter data to profile drug impact on cardiomyocyte electrophysiology using a panel of 21 compounds active against key cardiac ion channels. Our study is the first to apply multi-parameter phenotypic profiling and clustering techniques commonly used for high-content imaging and microarray data to the analysis of electrophysiology data obtained by MEA analysis. Our data show good correlations with previous studies in stem cell derived cardiomyocytes and demonstrate improved specificity in compound risk assignment over convention single-parametric approaches. These analyses indicate great potential for multi-parameter MEA data acquired from hESC-CM to enable drug electrophysiological liabilities to be assessed in pre-clinical cardiotoxicity assays, facilitating informed decision making and liability management at the optimum point in drug development.", "PublicationYear": "2014", "Authors": ["Mike Clements", "Nick Thomas"], "RelatedTopics": ["Medicine", "Engineering"], "References": ["50afa4fa74b0475ca0264461c79f7bd42fcc494c", "307ff8f512098497e2c69b79c00fbb7b3cc9650e", "b704c18b49757a3f43ebc7f29c6bbe27702dcfaa", "e0ba942b9ccdb5448da8738ae005fe7c3fd05951", "0e01651f92b8aa685df569856997f2ddff12c1e5", "cf79baec2b4441d2d87d473d18697b17c452c0ec", "e5a18de385cb61dd3cd5f98fffe48a0f17a1cfb1", "3a5d9f656bbed7d7a9e9930626a78e02c0fa29f3", "89a125d1a89bcd0c18df6810786f92d27ee4e17f", "6ccf3818d0a2380430f85c514703705832a9752e"], "ReferenceCount": 33, "CitationCount": 135}, {"URL": "https://www.semanticscholar.org/paper/Refining-the-human-iPSC-cardiomyocyte-arrhythmic-Guo-Coyle/89a125d1a89bcd0c18df6810786f92d27ee4e17f", "ID": "89a125d1a89bcd0c18df6810786f92d27ee4e17f", "Title": "Refining the human iPSC-cardiomyocyte arrhythmic risk assessment model.", "Abstract": "This hCAR assay showed increased performance over existing preclinical tools in predicting clinical QT prolongation, arrhythmia, and TdP, and hiPS-CMs are a relevant cell system to improve evaluating cardiac safety liabilities of drug candidates. Human induced pluripotent stem cell-derived cardiomyocytes (hiPS-CMs) are capable of detecting drug-induced clinical arrhythmia, Torsade de Pointes (TdP), and QT prolongation. Efforts herein employ a broad set of structurally diverse drugs to optimize the predictive algorithm for applications in discovery toxicology and cardiac safety screening. The changes in the beat rhythm and rate of a confluent monolayer of hiPS-CMs by 88 marketed and 30 internal discovery compounds were detected with real-time cellular impedance measurement and quantified by measures of arrhythmic beating (IB20, lowest concentration inducing \u2265 20% arrhythmic [irregular, atypical] beats in 3 consecutive 20-s sweeps, and predicted proarrhythmic score [PPS]-IB20) or changes in beat rate (BR20, the lowest concentration inducing a reduction in beat rate of \u2265 20% at 3 consecutive sweeps compared with the time-matched vehicle control group, and PPS-BR20). Drug-induced arrhythmic beats and reductions in beat rates are predictive of clinical arrhythmia and QT prolongation, respectively. A threshold of \u2264 10 \u03bcM for class determination results in 82% in vitro-in vivo concordance for TdP prediction and 91% sensitivity for non-TdP arrhythmia detection, or 83% and 91% if clinically efficacious plasma (effective serum therapeutic concentration [C eff]) values are incorporated. This human cardiomyocyte arrhythmic risk (hCAR) model provides greater predictivity for torsadogenicity in humans compared with either human ether-a-go-go-related gene (hERG) inhibition (75%) or QT prolongation (81%). The concordance of beat rate reductions to predict clinical QT prolongation is 86%, or 87% when C eff is considered, which is greater than a hERG signal (80%). Further, arrhythmic beats resulting from cytotoxicity were identified by a distinct arrhythmic beating pattern, which occurred after the onset of cytolethality. This hCAR assay showed increased performance over existing preclinical tools in predicting clinical QT prolongation, arrhythmia, and TdP. Thus, hiPS-CMs are a relevant cell system to improve evaluating cardiac safety liabilities of drug candidates.", "PublicationYear": "2013", "Authors": ["Liang Guo", "Luke A. Coyle", "Rory M. C. Abrams", "Raymond A. Kemper", "Eric T Chiao", "Kyle L Kolaja"], "RelatedTopics": ["Chemistry", "Medicine"], "References": ["307ff8f512098497e2c69b79c00fbb7b3cc9650e", "d33fc88776aa3cafaee9e6cb40738c3d19bd9ac1", "dfce4451e73ab7108517c0b020a4fc2cc4e63e1b", "c79706e7edb52f5b61155c1b626686a147576ffe", "c1cb043d6cc44f9c661a45c1daba623d41b36bf1", "c53bbacfe5f720a9cb464ed0a94349a69de1d8d2", "1cbee9a44469d434efd9ed0d55347e4b2c80e2f8", "88499b49a830a39dd16381e224d8880e47d868ce", "f5ddb94efb7cd13f6fa7f1ba1f0d12a387837e55", "41e1e4d6154c0e9193e808b9ac815a9c6024b52e"], "ReferenceCount": 40, "CitationCount": 119}, {"URL": "https://www.semanticscholar.org/paper/In-vitro-Modeling-of-Ryanodine-Receptor-2-Using-Fatima-Xu/c3abc2d4b3cb86d6e3606f225c671fff3b334c9b", "ID": "c3abc2d4b3cb86d6e3606f225c671fff3b334c9b", "Title": "In vitro Modeling of Ryanodine Receptor 2 Dysfunction Using Human Induced Pluripotent Stem Cells", "Abstract": "This study demonstrates the suitability of iPS cells in modeling RYR2-related cardiac disorders in vitro and opens new opportunities for investigating the disease mechanism in vitro, developing new drugs, predicting their toxicity, and optimizing current treatment strategies. Background/Aims: Induced pluripotent stem (iPS) cells generated from accessible adult cells of patients with genetic diseases open unprecedented opportunities for exploring the pathophysiology of human diseases in vitro. Catecholaminergic polymorphic ventricular tachycardia type 1 (CPVT1) is an inherited cardiac disorder that is caused by mutations in the cardiac ryanodine receptor type 2 gene (RYR2) and is characterized by stress-induced ventricular arrhythmia that can lead to sudden cardiac death in young individuals. The aim of this study was to generate iPS cells from a patient with CPVT1 and determine whether iPS cell-derived cardiomyocytes carrying patient specific RYR2 mutation recapitulate the disease phenotype in vitro. Methods: iPS cells were derived from dermal fibroblasts of healthy donors and a patient with CPVT1 carrying the novel heterozygous autosomal dominant mutation p.F2483I in the RYR2. Functional properties of iPS cell derived-cardiomyocytes were analyzed by using whole-cell current and voltage clamp and calcium imaging techniques. Results: Patch-clamp recordings revealed arrhythmias and delayed afterdepolarizations (DADs) after catecholaminergic stimulation of CPVT1-iPS cell-derived cardiomyocytes. Calcium imaging studies showed that, compared to healthy cardiomyocytes, CPVT1-cardiomyocytes exhibit higher amplitudes and longer durations of spontaneous Ca2+ release events at basal state. In addition, in CPVT1-cardiomyocytes the Ca2+-induced Ca2+-release events continued after repolarization and were abolished by increasing the cytosolic cAMP levels with forskolin. Conclusion: This study demonstrates the suitability of iPS cells in modeling RYR2-related cardiac disorders in vitro and opens new opportunities for investigating the disease mechanism in vitro, developing new drugs, predicting their toxicity, and optimizing current treatment strategies.", "PublicationYear": "2011", "Authors": ["Azra Fatima", "Guoxing Xu", "Kaifeng Shao", "Symeon Papadopoulos", "Martin Lehmann", "Juan Jose Arnaiz-Cot", "Angelo Oscar Rosa", "Filomain Nguemo", "Matthias Matzkies", "Sven Dittmann", "Susannah L. Stone", "M Linke", "Ulrich Zechner", "Vera Beyer", "Hans Christian Hennies", "Stephan Rosenkranz", "Baerbel Klauke", "Abdul Shokor Parwani", "Wilhelm Haverkamp", "Gabriele Pfitzer", "Martin Farr", "Lars Nilausen Cleemann", "Martin Morad", "Hendrik Milting", "J{\\\"u}ergen Hescheler", "Tomo {\\vS}ari{\\'c}"], "RelatedTopics": ["Biology", "Medicine"], "References": ["d1c166e8edf5e672ccc08dc65b1979aaeaafa775", "42c550a012171047707cd12afb10ef6d2c3e661c", "eca1788d965fd45ebd011677c4f64a819f4cee34", "4a4ead8cc2068d34c6a71597f5885137986ab67d", "78518cbc7679530967d8ad894e244db8b27a0988", "9c3fe9272d32260f3b8308c21fb9ee5365e74412", "fb176b6504e797fcff1571abf9ea83d8ff66785f", "4724c49eb2ff897876c2464d9970fd21746526ad", "b23ccb4b1492d21a8794ceec3ae6ecf7cc718e49", "eb6bf9ccb643f065cd25b095d676dbd4fea2ccbb"], "ReferenceCount": 64, "CitationCount": 204}, {"URL": "https://www.semanticscholar.org/paper/Towards-Automatic-Prostate-Gleason-Grading-Via-Deep-Khani-Jahromi/d779b87172306c37c2c711512e84bc8112adf21e", "ID": "d779b87172306c37c2c711512e84bc8112adf21e", "Title": "Towards Automatic Prostate Gleason Grading Via Deep Convolutional Neural Networks", "Abstract": "This paper uses the DeepLabV3+ model with MobileNetV2 backbone and train it with the newly released dataset from Gleason 2019 challenge and achieves the mean Cohen's quadratic kappa score of 0.56 with the pathologists' annotations on the test subset which is higher than the inter-pathologists' score. Prostate Cancer has become one of the deadliest cancers among males in many nations. Pathologists use various approaches for the detection and the staging of prostate cancer. Microscopic inspection of biopsy tissues is the most accurate approach among them. The Gleason grading system is used to evaluate the stage of Prostate Cancer using prostate biopsy samples. The task of assigning a grade to each region in a tissue is a time-consuming task. Furthermore, this task often has several challenges since it has considerable inter-observer variability even among expert pathologists. In this paper, we propose an automatic method for this task using a deep learningbased approach. For this purpose, we use the DeepLabV3+ model with MobileNetV2 backbone and train it with the newly released dataset from Gleason 2019 challenge. Our model achieves the mean Cohen's quadratic kappa score of 0.56 with the pathologists' annotations on the test subset which is higher than the inter-pathologists' score (0.55).", "PublicationYear": "2019", "Authors": ["Ali Asghar Khani", "Seyed Alireza Fatemi Jahromi", "Hatef Otroshi Shahreza", "Hamid Behroozi", "Mahdieh Soleymani Baghshah"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["2c2f461af47644c0c05a62da0739c4bb48b99cdf", "8ce6b544554a79e077e5fc52f55ba8234ce606d4", "47262a72c9c7bf5070b97e70b55c6190d1079260", "d5b91f292c611dea61f6e95b007ae53c2766a5f9", "d20dff7103c3da6753ef108dc825d9fe44bd00d2", "50004c086ffd6a201a4b782281aaa930fbfe6ecf", "a6876ea89e677a7cc42dd43f27165ff6fd414de5", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "8f7bb9b751da9ede977395630b4482df634c38be", "84c1717345dd451e7a61fe89807b4c017754fc4e"], "ReferenceCount": 36, "CitationCount": 7}, {"URL": "https://www.semanticscholar.org/paper/Detecting-Cancer-Metastases-on-Gigapixel-Pathology-Liu-Gadepalli/915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7", "ID": "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7", "Title": "Detecting Cancer Metastases on Gigapixel Pathology Images", "Abstract": "This work presents a framework to automatically detect and localize tumors as small as 100 x 100 pixels in gigapixel microscopy images sized 100,000 x100,000 pixels and achieves image-level AUC scores above 97% on both the Camelyon16 test set and an independent set of 110 slides. Each year, the treatment decisions for more than 230,000 breast cancer patients in the U.S. hinge on whether the cancer has metastasized away from the breast. Metastasis detection is currently performed by pathologists reviewing large expanses of biological tissues. This process is labor intensive and error-prone. We present a framework to automatically detect and localize tumors as small as 100 x 100 pixels in gigapixel microscopy images sized 100,000 x 100,000 pixels. Our method leverages a convolutional neural network (CNN) architecture and obtains state-of-the-art results on the Camelyon16 dataset in the challenging lesion-level tumor detection task. At 8 false positives per image, we detect 92.4% of the tumors, relative to 82.7% by the previous best automated approach. For comparison, a human pathologist attempting exhaustive search achieved 73.2% sensitivity. We achieve image-level AUC scores above 97% on both the Camelyon16 test set and an independent set of 110 slides. In addition, we discover that two slides in the Camelyon16 training set were erroneously labeled normal. Our approach could considerably reduce false negative rates in metastasis detection.", "PublicationYear": "2017", "Authors": ["Yun Liu", "Krishna Gadepalli", "Mohammad Norouzi", "George E. Dahl", "Timo Kohlberger", "Aleksey Boyko", "Subhashini Venugopalan", "Aleksei Timofeev", "Phil Q. Nelson", "Greg S Corrado", "Jason D. Hipp", "Lily H. Peng", "Martin C. Stumpe"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["21ba757bf394720e0b66b86e7638ae28742d6570", "2f11f86fd805807076b22317738c819484a8e21b", "47262a72c9c7bf5070b97e70b55c6190d1079260", "80b0a281c520581e474d178e4020721c61ab5667", "94087ad5ed11555c260a42f2f9ca9da183c6f87e", "d847ee63fe234f9cc2a8be851ed511b7d1a8da36", "6196fa503ecd1b0798e5fd3a48ea519fc3ff5765", "4661b82606512f03a2f3fcc1d2587152b89f8e73", "2729d2918978d5ed602aa843fbdd027d83e0036f", "2f4df08d9072fc2ac181b7fced6a245315ce05c8"], "ReferenceCount": 25, "CitationCount": 587}, {"URL": "https://www.semanticscholar.org/paper/Classification-and-mutation-prediction-from-cell-Coudray-Ocampo/769149c0dc0ed308eca8bc916f4326b2e2f57a1f", "ID": "769149c0dc0ed308eca8bc916f4326b2e2f57a1f", "Title": "Classification and mutation prediction from non\u2013small cell lung cancer histopathology images using deep learning", "Abstract": "A deep convolutional neural network model is trained on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue and predicts the ten most commonly mutated genes in LUAD. Visual inspection of histopathology slides is one of the main methods used by pathologists to assess the stage, type and subtype of lung tumors. Adenocarcinoma (LUAD) and squamous cell carcinoma (LUSC) are the most prevalent subtypes of lung cancer, and their distinction requires visual inspection by an experienced pathologist. In this study, we trained a deep convolutional neural network (inception v3) on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue. The performance of our method is comparable to that of pathologists, with an average area under the curve (AUC) of 0.97. Our model was validated on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues and biopsies. Furthermore, we trained the network to predict the ten most commonly mutated genes in LUAD. We found that six of them\u2014STK11, EGFR, FAT1, SETBP1, KRAS and TP53\u2014can be predicted from pathology images, with AUCs from 0.733 to 0.856 as measured on a held-out population. These findings suggest that deep-learning models can assist pathologists in the detection of cancer subtype or gene mutations. Our approach can be applied to any cancer type, and the code is available at https://github.com/ncoudray/DeepPATH.A convolutional neural network model using feature extraction and machine-learning techniques provides a tool for classification of lung cancer histopathology images and predicting mutational status of driver oncogenes", "PublicationYear": "2018", "Authors": ["Nicolas Coudray", "Paolo Santiago Ocampo", "Theodore Sakellaropoulos", "Navneet Narula", "Matija Snuderl", "David Feny{\\\"o}", "Andre L. Moreira", "Narges Razavian", "Aristotelis Tsirigos"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["94087ad5ed11555c260a42f2f9ca9da183c6f87e", "bd6f783022ebd6704ff34f6bf824ef1cb1ad0cee", "add18010e1af63998bae7573f4cd5d2843eeb5bb", "abb569b5b79365f57e7d20150b31bf65da89f275", "d5b91f292c611dea61f6e95b007ae53c2766a5f9", "7256088eece603df2e5675025e8bed90c0f21171", "bcc9db4c560ea48d1b205acfc8ec77568d913503", "e1ec11a1cb3d9745fb18d3bf74247f95a6663d08", "e1e27b29318ff47de91619940019b10fd584c231", "30027db82f4eb242a2ee05973cabb06c8f02bd73"], "ReferenceCount": 69, "CitationCount": 1674}, {"URL": "https://www.semanticscholar.org/paper/Deep-Learning-for-Identifying-Metastatic-Breast-Wang-Khosla/21ba757bf394720e0b66b86e7638ae28742d6570", "ID": "21ba757bf394720e0b66b86e7638ae28742d6570", "Title": "Deep Learning for Identifying Metastatic Breast Cancer", "Abstract": "The power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses is demonstrated, by combining the deep learning system's predictions with the human pathologist's diagnoses. The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses.", "PublicationYear": "2016", "Authors": ["Dayong Wang", "Aditya Khosla", "Rishab Gargeya", "Humayun Irshad", "Andrew H. Beck"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["077592c2b76318a15562cf9f962f515988c011fb", "13de33ee941f1ebf3ed185c20fb4453a07302c30", "bd898f483476e3dcacf83cd85efc64e6319da0e1", "64aec645896bb6b444f6d81620fd5c9a1e3d6d6c", "44381cda660845d029a111bed20c0e8a8ed2d29b", "6196fa503ecd1b0798e5fd3a48ea519fc3ff5765", "ab9dce8b2af5e11985736be6bd73ec0968b2bb27", "a601a1ea75bde37f4dffd4f4c6025e91d2ae9a29", "ef6a1baa9441a4ebc4a5fb90f8c64ff67a61b288", "7651dc7f8e73be39aec686542bdc418de69a8b31"], "ReferenceCount": 26, "CitationCount": 835}, {"URL": "https://www.semanticscholar.org/paper/Multi-scale-fully-convolutional-neural-networks-for-Schmitz-Madesta/f9638ee3738d30c23a5f8f84988aed7120a08fac", "ID": "f9638ee3738d30c23a5f8f84988aed7120a08fac", "Title": "Multi-scale fully convolutional neural networks for histopathology image segmentation: from nuclear aberrations to the global tissue architecture", "Abstract": "Semantic Scholar extracted view of \\\"Multi-scale fully convolutional neural networks for histopathology image segmentation: from nuclear aberrations to the global tissue architecture\\\" by R\u00fcdiger Schmitz et al.", "PublicationYear": "2019", "Authors": ["R{\\\"u}diger Schmitz", "Frederic Madesta", "Maximilian Nielsen", "Ren{\\'e} Werner", "Thomas R{\\\"o}sch"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["784906ab63c3743a5d26dca846a49c2edbf4dc6a", "455e92c1f629cd8065bc0c8287d3da52b451b98c", "9987d9b7fc3a5b3c9d35f47be5cc5d9eede9bf4b", "cd7ac742125095aa68a7873e75421f8ef9bc26aa", "7e3f1e7e25c7ee9977f7dd78cd6c1d2cab6049bb", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "95db99286b274352e7e1906ebf63e10ae9fce30c", "80bfef962e21e78d3958cf60bd99b143820af1db", "a86d7289c76d832e83c99539859b7b186e4ea6c8", "7c2bcf6f32b05a04cd3444c030db743e5666af88"], "ReferenceCount": 54, "CitationCount": 53}, {"URL": "https://www.semanticscholar.org/paper/PFA-ScanNet%3A-Pyramidal-Feature-Aggregation-with-for-Zhao-Lin/6048de9749a1f31ac70e5c30030ceb1dc5d3f2b0", "ID": "6048de9749a1f31ac70e5c30030ceb1dc5d3f2b0", "Title": "PFA-ScanNet: Pyramidal Feature Aggregation with Synergistic Learning for Breast Cancer Metastasis Analysis", "Abstract": "A novel Pyramidal Feature Aggregation ScanNet (PFA-ScanNet) for robust and fast analysis of breast cancer metastasis, which mainly benefits from the aggregation of extracted local-to-global features with diverse receptive fields and a high-efficiency inference mechanism designed with dense pooling layers. Automatic detection of cancer metastasis from whole slide images (WSIs) is a crucial step for following patient staging and prognosis. Recent convolutional neural network based approaches are struggling with the trade-off between accuracy and computational efficiency due to the difficulty in processing large-scale gigapixel WSIs. To meet this challenge, we propose a novel Pyramidal Feature Aggregation ScanNet (PFA-ScanNet) for robust and fast analysis of breast cancer metastasis. Our method mainly benefits from the aggregation of extracted local-to-global features with diverse receptive fields, as well as the proposed synergistic learning for training the main detector and extra decoder with semantic guidance. Furthermore, a high-efficiency inference mechanism is designed with dense pooling layers, which allows dense and fast scanning for gigapixel WSI analysis. As a result, the proposed PFA-ScanNet achieved the state-of-the-art FROC of 90.2% on the Camelyon16 dataset, as well as competitive kappa score of 0.905 on the Camelyon17 leaderboard. In addition, our method shows leading speed advantage over other methods, about 7.2 min per WSI with a single GPU, making automatic analysis of breast cancer metastasis more applicable in the clinical usage.", "PublicationYear": "2019", "Authors": ["Zixu Zhao", "Huangjing Lin", "Hao Chen", "Pheng-Ann Heng"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["e0a711d111eb0373a06d46bbe26b710f7c924ccb", "c1555c566a2628f0485b16b2ae4371aff617d7f7", "7642c455f69a2fe21d8f03679d3f6df7fcf0e9a5", "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7", "4bfddce2f6356166be52eb7044864812df9c646b", "21ba757bf394720e0b66b86e7638ae28742d6570", "cfa3d45a6fcf704fe7ab6953424481d1698055a4", "5fd490e5ceed129a83d16dbda29ab61fe4aa1acb", "2a94c84383ee3de5e6211d43d16e7de387f68878", "3617ccfec4bed2d8ac15d0ad1a35b589d9b270cb"], "ReferenceCount": 14, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Diagnostic-Assessment-of-Deep-Learning-Algorithms-Bejnordi-Veta/ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba", "ID": "ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba", "Title": "Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer", "Abstract": "In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Importance Application of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency. Objective Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin\u2013stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists\u2019 diagnoses in a diagnostic setting. Design, Setting, and Participants Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n\u2009=\u2009110) and without (n\u2009=\u2009160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). Exposures Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. Main Outcomes and Measures The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. Results The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4% [95% CI, 64.3%-80.4%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884]; P\u2009&lt;\u2009.001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95% CI, 0.927-0.998] for the pathologist WOTC). Conclusions and Relevance In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.", "PublicationYear": "2017", "Authors": ["Babak Ehteshami Bejnordi", "Mitko Veta", "Paul Johannes van Diest", "Bram van Ginneken", "Nico Karssemeijer", "Geert J. S. Litjens", "Jeroen A. van der Laak", "Meyke Hermsen", "Quirine F. Manson", "Maschenka C. A. Balkenhol", "Oscar G. F. Geessink", "Nikolaos Stathonikos", "Marcory Crf van Dijk", "Peter Bult", "Francisco Beca", "Andrew H. Beck", "Dayong Wang", "Aditya Khosla", "Rishab Gargeya", "Humayun Irshad", "Aoxiao Zhong", "Qi Dou", "Quanzheng Li", "Hao Chen", "Huangjing Lin", "Pheng-Ann Heng", "Christian Hass", "Elia Bruni", "Quincy Kwan-Sut Wong", "Ugur Halici", "Mustafa {\\\"U}mit {\\\"O}ner", "Rengul Cetin-Atalay", "Matt Berseth", "Vitali Khvatkov", "A. Vylegzhanin", "Oren Z. Kraus", "Muhammad Shaban", "Nasir M. Rajpoot", "Ruqayya Awan", "Korsuk Sirinukunwattana", "Talha Qaiser", "Yee-Wah Tsang", "David Tellez", "Jonas Annuscheit", "Peter Hufnagl", "Mira Valkonen", "Kimmo Kartasalo", "Leena Latonen", "Pekka Ruusuvuori", "Kaisa Liimatainen", "Shadi Albarqouni", "Bharti Mungal", "Amitha Anna George", "Stefanie Demirci", "Nassir Navab", "Seiryo Watanabe", "Shigeto Seno", "Yoichi Takenaka", "Hideo Matsuda", "Hady Ahmady Phoulady", "Vassili A. Kovalev", "Alexander Kalinovsky", "Vitali Liauchuk", "Gloria Bueno", "Maria del Milagro Fern{\\'a}ndez-Carrobles", "Ismael Serrano", "Oscar Deniz", "Daniel Racoceanu", "Rui Ven{\\^a}ncio"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["47262a72c9c7bf5070b97e70b55c6190d1079260", "a8916917d2e8bf88a63e27c2ecbe6e3294882667", "64439e2ec6150424534378a689fa7484849756c5", "b23a7d485ee8f60f33119c27acf43607caee3cd3", "e1ec11a1cb3d9745fb18d3bf74247f95a6663d08", "2729d2918978d5ed602aa843fbdd027d83e0036f", "c767fbf94ae063f91fbf14b511bbb21664a394bf", "c912e250ba2703d06e4399c7103e84457ecc39d8", "f15a6caf0d6062fc6e100c3ed64e2634e5f9949f", "ea93a4bed1b4223799795d1a47d8b47de1b61fff"], "ReferenceCount": 71, "CitationCount": 2145}, {"URL": "https://www.semanticscholar.org/paper/1399-H%26E-stained-sentinel-lymph-node-sections-of-Litjens-B%C3%A1ndi/188f8f6f70947215a9dfeebb0b577155e0d3d339", "ID": "188f8f6f70947215a9dfeebb0b577155e0d3d339", "Title": "1399 H&E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset", "Abstract": "A unique dataset of annotated, whole-slide digital histopathology images has been provided with high potential for re-use, in 3 terabytes of data in the context of the CAMELYON16 and CAMELYon17 Grand Challenges. Abstract Background The presence of lymph node metastases is one of the most important factors in breast cancer prognosis. The most common way to assess regional lymph node status is the sentinel lymph node procedure. The sentinel lymph node is the most likely lymph node to contain metastasized cancer cells and is excised, histopathologically processed, and examined by a pathologist. This tedious examination process is time-consuming and can lead to small metastases being missed. However, recent advances in whole-slide imaging and machine learning have opened an avenue for analysis of digitized lymph node sections with computer algorithms. For example, convolutional neural networks, a type of machine-learning algorithm, can be used to automatically detect cancer metastases in lymph nodes with high accuracy. To train machine-learning models, large, well-curated datasets are needed. Results We released a dataset of 1,399 annotated whole-slide images (WSIs) of lymph nodes, both with and without metastases, in 3 terabytes of data in the context of the CAMELYON16 and CAMELYON17 Grand Challenges. Slides were collected from five medical centers to cover a broad range of image appearance and staining variations. Each WSI has a slide-level label indicating whether it contains no metastases, macro-metastases, micro-metastases, or isolated tumor cells. Furthermore, for 209 WSIs, detailed hand-drawn contours for all metastases are provided. Last, open-source software tools to visualize and interact with the data have been made available. Conclusions A unique dataset of annotated, whole-slide digital histopathology images has been provided with high potential for re-use.", "PublicationYear": "2018", "Authors": ["Geert J. S. Litjens", "P{\\'e}ter B{\\'a}ndi", "Babak Ehteshami\u00a0Bejnordi", "Oscar G. F. Geessink", "Maschenka C. A. Balkenhol", "Peter Bult", "Altuna Halilovic", "Meyke Hermsen", "Rob van\u00a0de\u00a0Loo", "Rob Vogels", "Quirine F. Manson", "Nikolas Stathonikos", "Alexi Baidoshvili", "Paul van\u00a0Diest", "Carla A.P. Wauters", "Marcory van\u00a0Dijk", "Jeroen van\u00a0der\u00a0Laak"], "RelatedTopics": ["Medicine"], "References": ["ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba", "2d422a474e5d346ac73a386c7e7fcbab2805db5d", "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7", "b23a7d485ee8f60f33119c27acf43607caee3cd3", "47262a72c9c7bf5070b97e70b55c6190d1079260", "3bc56f7c5807e2dafcf39eb704051e2ce25eceeb", "fe132ff1a013c626f21122165af2065428491825", "67f2a9f2de5090d137a2e0b7984ecc32c4f094f3", "d6f5b61f6a24009d1ed741f49a024b7eb5c5357e", "d0ad4142e4e7fb052935b349dc67bac288c83ff3"], "ReferenceCount": 30, "CitationCount": 278}, {"URL": "https://www.semanticscholar.org/paper/Attention-U-Net%3A-Learning-Where-to-Look-for-the-Oktay-Schlemper/ae1c89817a3a239e5344293138bdd80293983460", "ID": "ae1c89817a3a239e5344293138bdd80293983460", "Title": "Attention U-Net: Learning Where to Look for the Pancreas", "Abstract": "A novel attention gate (AG) model for medical imaging that automatically learns to focus on target structures of varying shapes and sizes is proposed to eliminate the necessity of using explicit external tissue/organ localisation modules of cascaded convolutional neural networks (CNNs). We propose a novel attention gate (AG) model for medical imaging that automatically learns to focus on target structures of varying shapes and sizes. Models trained with AGs implicitly learn to suppress irrelevant regions in an input image while highlighting salient features useful for a specific task. This enables us to eliminate the necessity of using explicit external tissue/organ localisation modules of cascaded convolutional neural networks (CNNs). AGs can be easily integrated into standard CNN architectures such as the U-Net model with minimal computational overhead while increasing the model sensitivity and prediction accuracy. The proposed Attention U-Net architecture is evaluated on two large CT abdominal datasets for multi-class image segmentation. Experimental results show that AGs consistently improve the prediction performance of U-Net across different datasets and training sizes while preserving computational efficiency. The code for the proposed architecture is publicly available.", "PublicationYear": "2018", "Authors": ["Ozan Oktay", "Jo Schlemper", "Lo{\\\"i}c Le Folgoc", "M. J. Lee", "Mattias P. Heinrich", "Kazunari Misawa", "Kensaku Mori", "Steven G. McDonagh", "Nils Y. Hammerla", "Bernhard Kainz", "Ben Glocker", "Daniel Rueckert"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["aac368016f2540683ad2f611eb0cd889d350ff72", "50004c086ffd6a201a4b782281aaa930fbfe6ecf", "6364fdaa0a0eccd823a779fcdd489173f938e91a", "3d44a1a97b6c768ae3080adf717326167457b0ad", "65147d0652741e886243549123dab142699e07eb", "c70218603f0af1be5d063056cbe629e042141a86", "1acdfdf6e24dc6c89f61aa7600648b38870bbc9b", "01556b9fbade335e0b58812fa75023a6dd409ce1", "b1135c3ba94839082c91c5b2600181d251b2634b", "569977bdb3f31d4b7c78ab3834fd34b370330e4e"], "ReferenceCount": 41, "CitationCount": 3182}, {"URL": "https://www.semanticscholar.org/paper/Automated-Gleason-grading-of-prostate-cancer-tissue-Arvaniti-Fricker/57a892b9576baeba70277179712d5b09e19224b9", "ID": "57a892b9576baeba70277179712d5b09e19224b9", "Title": "Automated Gleason grading of prostate cancer tissue microarrays via deep learning", "Abstract": "A deep learning approach for automated Gleason grading of prostate cancer tissue microarrays with Hematoxylin and Eosin (H&E) staining achieves pathology expert-level stratification of patients into prognostically distinct groups, on the basis of disease-specific survival data available for the test cohort. The Gleason grading system remains the most powerful prognostic predictor for patients with prostate cancer since the 1960s. Its application requires highly-trained pathologists, is tedious and yet suffers from limited inter-pathologist reproducibility, especially for the intermediate Gleason score 7. Automated annotation procedures constitute a viable solution to remedy these limitations. In this study, we present a deep learning approach for automated Gleason grading of prostate cancer tissue microarrays with Hematoxylin and Eosin (H&E) staining. Our system was trained using detailed Gleason annotations on a discovery cohort of 641 patients and was then evaluated on an independent test cohort of 245 patients annotated by two pathologists. On the test cohort, the inter-annotator agreements between the model and each pathologist, quantified via Cohen\u2019s quadratic kappa statistic, were 0.75 and 0.71 respectively, comparable with the inter-pathologist agreement (kappa\u2009=\u20090.71). Furthermore, the model\u2019s Gleason score assignments achieved pathology expert-level stratification of patients into prognostically distinct groups, on the basis of disease-specific survival data available for the test cohort. Overall, our study shows promising results regarding the applicability of deep learning-based solutions towards more objective and reproducible prostate cancer grading, especially for cases with heterogeneous Gleason patterns.", "PublicationYear": "2018", "Authors": ["Eirini Arvaniti", "Kim S. Fricker", "Michael Moret", "Niels J. Rupp", "Thomas Hermanns", "Christian Daniel Fankhauser", "Norbert Wey", "Peter J. Wild", "Jan Hendrik R{\\\"u}schoff", "Manfred Claassen"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["e37ab4e114de7b8ab60ca74e6a89e4fbbed3a625", "47262a72c9c7bf5070b97e70b55c6190d1079260", "5faf07decd896237a82b89e4e4fd42739a3eea1b", "561a83fb8e86461e6d2432e382ffc0b32575cb54", "d20dff7103c3da6753ef108dc825d9fe44bd00d2", "8cb8c1b719f27b7a22c4e9bf5211f7403d22c749", "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7", "abb569b5b79365f57e7d20150b31bf65da89f275", "b2b6dc48ba97c26d92c8a772213284a0eb546bdd", "077592c2b76318a15562cf9f962f515988c011fb"], "ReferenceCount": 42, "CitationCount": 299}, {"URL": "https://www.semanticscholar.org/paper/Semi-supervised-Zero-Shot-Learning-by-a-Approach-Shojaee-Baghshah/5fd80e47d53c64512a0b85a4c7a0beb24bc35766", "ID": "5fd80e47d53c64512a0b85a4c7a0beb24bc35766", "Title": "Semi-supervised Zero-Shot Learning by a Clustering-based Approach", "Abstract": "A novel semi-supervised zero-shot learning method that works on an embedding space corresponding to abstract deep visual features, such that the mapped signatures of the seen classes are close to labeled samples of the corresponding classes and unlabeled data are also close to the mapped signature of one of the unseen classes. In some of object recognition problems, labeled data may not be available for all categories. Zero-shot learning utilizes auxiliary information (also called signatures) describing each category in order to find a classifier that can recognize samples from categories with no labeled instance. In this paper, we propose a novel semi-supervised zero-shot learning method that works on an embedding space corresponding to abstract deep visual features. We seek a linear transformation on signatures to map them onto the visual features, such that the mapped signatures of the seen classes are close to labeled samples of the corresponding classes and unlabeled data are also close to the mapped signatures of one of the unseen classes. \\nWe use the idea that the rich deep visual features provide a representation space in which samples of each class are usually condensed in a cluster. The effectiveness of the proposed method is demonstrated through extensive experiments on four public benchmarks improving the state-of-the-art prediction accuracy on three of them.", "PublicationYear": "2016", "Authors": ["Seyed Mohsen Shojaee", "Mahdieh Soleymani Baghshah"], "RelatedTopics": ["Computer Science"], "References": ["a6b8cd5f34b438f487679b1166ea03e56eb14c9e", "846946cd21413211a4701f309c3927d67363cd30", "b29227f8dde62a5cd21678b4bc429206615485a2", "4cc2273cf8640ddd497e86d949dfd79057e5caea", "ac98259064e86f643f2cd11e5417b43bf28daa91", "244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa", "ccbc09d498cad330c37f94e15b77bf220b10ccb4", "b2a5c3744eea40c76d0359e517026e8ed6c922ff", "cb461276fad5710d8a7e2868867a9b01df040119", "caa632d101a41a7860562e4399a5eaa9a4088b55"], "ReferenceCount": 44, "CitationCount": 35}, {"URL": "https://www.semanticscholar.org/paper/Semi-Supervised-Zero-Shot-Classification-with-Label-Li-Guo/a6b8cd5f34b438f487679b1166ea03e56eb14c9e", "ID": "a6b8cd5f34b438f487679b1166ea03e56eb14c9e", "Title": "Semi-Supervised Zero-Shot Classification with Label Representation Learning", "Abstract": "A novel zero-shot classification approach that automatically learns label embeddings from the input data in a semi-supervised large-margin learning framework that tackles the target prediction problem directly without introducing intermediate prediction problems. Given the challenge of gathering labeled training data, zero-shot classification, which transfers information from observed classes to recognize unseen classes, has become increasingly popular in the computer vision community. Most existing zero-shot learning methods require a user to first provide a set of semantic visual attributes for each class as side information before applying a two-step prediction procedure that introduces an intermediate attribute prediction problem. In this paper, we propose a novel zero-shot classification approach that automatically learns label embeddings from the input data in a semi-supervised large-margin learning framework. The proposed framework jointly considers multi-class classification over all classes (observed and unseen) and tackles the target prediction problem directly without introducing intermediate prediction problems. It also has the capacity to incorporate semantic label information from different sources when available. To evaluate the proposed approach, we conduct experiments on standard zero-shot data sets. The empirical results show the proposed approach outperforms existing state-of-the-art zero-shot learning methods.", "PublicationYear": "2015", "Authors": ["X. Li", "Yuhong Guo", "Dale Schuurmans"], "RelatedTopics": ["Computer Science"], "References": ["b29227f8dde62a5cd21678b4bc429206615485a2", "ab50e0fba1e7964d2686e90f9bed66a06ed6ff42", "ccbc09d498cad330c37f94e15b77bf220b10ccb4", "755e9f43ce398ae8737366720c5f82685b0c253e", "d6714ee0a3c3c5ead3d681d4bec8e60f042928ef", "caa632d101a41a7860562e4399a5eaa9a4088b55", "018e730f8947173e1140210d4d1760d05c9d3854", "c30b9fb837e912ccf3919fdb64e9543fca57799e", "f038e8c3656f5c7a4846a7eca731eb567255adcb", "88e090ffc1f75eed720b5afb167523eb2e316f7f"], "ReferenceCount": 34, "CitationCount": 115}, {"URL": "https://www.semanticscholar.org/paper/Max-Margin-Zero-Shot-Learning-for-Multi-class-Li-Guo/b29227f8dde62a5cd21678b4bc429206615485a2", "ID": "b29227f8dde62a5cd21678b4bc429206615485a2", "Title": "Max-Margin Zero-Shot Learning for Multi-class Classification", "Abstract": "A semi-supervised max-margin learning framework that integrates the semisupervised classification problem over observed classes and the unsupervised clustering problem over unseen classes together to tackle zero-shot multi-class classification is proposed. Due to the dramatic expanse of data categories and the lack of labeled instances, zero-shot learning, which transfers knowledge from observed classes to recognize unseen classes, has started drawing a lot of attention from the research community. In this paper, we propose a semi-supervised max-margin learning framework that integrates the semisupervised classification problem over observed classes and the unsupervised clustering problem over unseen classes together to tackle zero-shot multi-class classification. By further integrating label embedding into this framework, we produce a dual formulation that permits convenient incorporation of auxiliary label semantic knowledge to improve zero-shot learning. We conduct extensive experiments on three standard image data sets to evaluate the proposed approach by comparing to two state-of-the-art methods. Our results demonstrate the efficacy of the proposed framework.", "PublicationYear": "2015", "Authors": ["X. Li", "Yuhong Guo"], "RelatedTopics": ["Computer Science"], "References": ["d6714ee0a3c3c5ead3d681d4bec8e60f042928ef", "ab50e0fba1e7964d2686e90f9bed66a06ed6ff42", "caa632d101a41a7860562e4399a5eaa9a4088b55", "c30b9fb837e912ccf3919fdb64e9543fca57799e", "be2f5d8a7e6b415f1e22cee7dfd9be56b1afd8be", "516b1eda00a955043fbcf037f128b117c9d9b10c", "2750dbc60d5ccc8fbe5e4babae6cfab543940f1a", "0566bf06a0368b518b8b474166f7b1dfef3f9283", "88e090ffc1f75eed720b5afb167523eb2e316f7f", "3fd90098551bf88c7509521adf1c0ba9b5dfeb57"], "ReferenceCount": 28, "CitationCount": 40}, {"URL": "https://www.semanticscholar.org/paper/Synthesized-Classifiers-for-Zero-Shot-Learning-Changpinyo-Chao/846946cd21413211a4701f309c3927d67363cd30", "ID": "846946cd21413211a4701f309c3927d67363cd30", "Title": "Synthesized Classifiers for Zero-Shot Learning", "Abstract": "This work introduces a set of \\\"phantom\\\" object classes whose coordinates live in both the semantic space and the model space and demonstrates superior accuracy of this approach over the state of the art on four benchmark datasets for zero-shot learning. Given semantic descriptions of object classes, zero-shot learning aims to accurately recognize objects of the unseen classes, from which no examples are available at the training stage, by associating them to the seen classes, from which labeled examples are provided. We propose to tackle this problem from the perspective of manifold learning. Our main idea is to align the semantic space that is derived from external information to the model space that concerns itself with recognizing visual features. To this end, we introduce a set of \\\"phantom\\\" object classes whose coordinates live in both the semantic space and the model space. Serving as bases in a dictionary, they can be optimized from labeled data such that the synthesized real object classifiers achieve optimal discriminative performance. We demonstrate superior accuracy of our approach over the state of the art on four benchmark datasets for zero-shot learning, including the full ImageNet Fall 2011 dataset with more than 20,000 unseen classes.", "PublicationYear": "2016", "Authors": ["Soravit Changpinyo", "Wei-Lun Chao", "Boqing Gong", "Fei Sha"], "RelatedTopics": ["Computer Science"], "References": ["755e9f43ce398ae8737366720c5f82685b0c253e", "a6b8cd5f34b438f487679b1166ea03e56eb14c9e", "ac98259064e86f643f2cd11e5417b43bf28daa91", "b2a5c3744eea40c76d0359e517026e8ed6c922ff", "b58e0a726d5923f27b83d5cedd0b33fbe2142e45", "7c0773c7578433a2277e919ac824f142d5de351c", "ccbc09d498cad330c37f94e15b77bf220b10ccb4", "b0d08e25e46c28423b60668836d382fdf245e7d9", "018e730f8947173e1140210d4d1760d05c9d3854", "1b63449f310542b5f65a9c437ccd9e63fbef2f84"], "ReferenceCount": 55, "CitationCount": 710}, {"URL": "https://www.semanticscholar.org/paper/Zero-Shot-Learning-via-Semantic-Similarity-Zhang-Saligrama/ac98259064e86f643f2cd11e5417b43bf28daa91", "ID": "ac98259064e86f643f2cd11e5417b43bf28daa91", "Title": "Zero-Shot Learning via Semantic Similarity Embedding", "Abstract": "A version of the zero-shot learning problem where seen class source and target domain data are provided and the goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information for unseen classes. In this paper we consider a version of the zero-shot learning problem where seen class source and target domain data are provided. The goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information (e.g. attributes) for unseen classes. Our method is based on viewing each source or target data as a mixture of seen class proportions and we postulate that the mixture patterns have to be similar if the two instances belong to the same unseen class. This perspective leads us to learning source/target embedding functions that map an arbitrary source/target domain data into a same semantic space where similarity can be readily measured. We develop a max-margin framework to learn these similarity functions and jointly optimize parameters by means of cross validation. Our test results are compelling, leading to significant improvement in terms of accuracy on most benchmark datasets for zero-shot recognition.", "PublicationYear": "2015", "Authors": ["Ziming Zhang", "Venkatesh Saligrama"], "RelatedTopics": ["Computer Science"], "References": ["ccbc09d498cad330c37f94e15b77bf220b10ccb4", "755e9f43ce398ae8737366720c5f82685b0c253e", "caa632d101a41a7860562e4399a5eaa9a4088b55", "be2f5d8a7e6b415f1e22cee7dfd9be56b1afd8be", "d6714ee0a3c3c5ead3d681d4bec8e60f042928ef", "ab50e0fba1e7964d2686e90f9bed66a06ed6ff42", "4aa4069693bee00d1b0759ca3df35e59284e9845", "018e730f8947173e1140210d4d1760d05c9d3854", "c30b9fb837e912ccf3919fdb64e9543fca57799e", "caccc069e658ea397c9faf673e74c959c734ff53"], "ReferenceCount": 49, "CitationCount": 581}, {"URL": "https://www.semanticscholar.org/paper/Label-Embedding-for-Attribute-Based-Classification-Akata-Perronnin/caa632d101a41a7860562e4399a5eaa9a4088b55", "ID": "caa632d101a41a7860562e4399a5eaa9a4088b55", "Title": "Label-Embedding for Attribute-Based Classification", "Abstract": "This work proposes to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors, and introduces a function which measures the compatibility between an image and a label embedding. Attributes are an intermediate representation, which enables parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function which measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. The label embedding framework offers other advantages such as the ability to leverage alternative sources of information in addition to attributes (e.g. class hierarchies) or to transition smoothly from zero-shot learning to learning with large quantities of data.", "PublicationYear": "2013", "Authors": ["Zeynep Akata", "Florent Perronnin", "Za{\\\"i}d Harchaoui", "Cordelia Schmid"], "RelatedTopics": ["Computer Science"], "References": ["54aacc196ffe49b3450059fccdf7cd3bb6f6f3c3", "88e090ffc1f75eed720b5afb167523eb2e316f7f", "a3ea706f6604a1e6e87c33d7a3b4b97b1bb338ef", "16a3c2c3e2bfbac65cc89a031b340a5951526183", "0566bf06a0368b518b8b474166f7b1dfef3f9283", "3a4a53fe47036ac89dad070ab87a9d8795b139b1", "9d69a7ab54c717df44f152c617a8cc76218437ff", "3089e6745b7dd50e41a3a50c6ff831415fe22739", "fc23a386c2189f221b25dbd0bb34fcd26ccf60fa", "c30b9fb837e912ccf3919fdb64e9543fca57799e"], "ReferenceCount": 46, "CitationCount": 615}, {"URL": "https://www.semanticscholar.org/paper/Zero-Shot-Learning-Through-Cross-Modal-Transfer-Socher-Ganjoo/755e9f43ce398ae8737366720c5f82685b0c253e", "ID": "755e9f43ce398ae8737366720c5f82685b0c253e", "Title": "Zero-Shot Learning Through Cross-Modal Transfer", "Abstract": "This work introduces a model that can recognize objects in images even if no training data is available for the object class, and uses novelty detection methods to differentiate unseen classes from seen classes. This work introduces a model that can recognize objects in images even if no training data is available for the object class. The only necessary knowledge about unseen visual categories comes from unsupervised text corpora. Unlike previous zero-shot learning models, which can only differentiate between unseen classes, our model can operate on a mixture of seen and unseen classes, simultaneously obtaining state of the art performance on classes with thousands of training images and reasonable performance on unseen classes. This is achieved by seeing the distributions of words in texts as a semantic space for understanding what objects look like. Our deep learning model does not require any manually defined semantic or visual features for either words or images. Images are mapped to be close to semantic word vectors corresponding to their classes, and the resulting image embeddings can be used to distinguish whether an image is of a seen or unseen class. We then use novelty detection methods to differentiate unseen classes from seen classes. We demonstrate two novelty detection strategies; the first gives high accuracy on unseen classes, while the second is conservative in its prediction of novelty and keeps the seen classes' accuracy high.", "PublicationYear": "2013", "Authors": ["Richard Socher", "Milind Ganjoo", "Christopher D. Manning", "A. Ng"], "RelatedTopics": ["Computer Science"], "References": ["0566bf06a0368b518b8b474166f7b1dfef3f9283", "5d90f06bb70a0a3dced62413346235c02b1aa086", "812355cec91fa30bb50e9e992a3549af39e4f6eb", "5726c7b40fcc454b77d989656c085520bf6c15fa", "6eb3a15108dfdec25b46522ed94b866aeb156de9", "100a038fdf29b4b20801887f0ec40e3f10d9a4f9", "a78273144520d57e150744cf75206e881e11cc5b", "0f6911bc1e6abee8bbf9dd3f8d54d40466429da7", "0d8ec0d3ac8c8e0f6dcda6e0b1845d29e985e58b", "67fdc1e0d878675e9ac765830f85b461777e49ec"], "ReferenceCount": 36, "CitationCount": 1375}, {"URL": "https://www.semanticscholar.org/paper/Multi-cue-Zero-Shot-Learning-with-Strong-Akata-Malinowski/244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa", "ID": "244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa", "Title": "Multi-cue Zero-Shot Learning with Strong Supervision", "Abstract": "This work introduces a joint embedding framework that maps multiple text parts as well as multiple semantic parts into a common space that consistently and significantly improves on the state-of-the-art in zero-short recognition and retrieval. Scaling up visual category recognition to large numbers of classes remains challenging. A promising research direction is zero-shot learning, which does not require any training data to recognize new classes, but rather relies on some form of auxiliary information describing the new classes. Ultimately, this may allow to use textbook knowledge that humans employ to learn about new classes by transferring knowledge from classes they know well. The most successful zero-shot learning approaches currently require a particular type of auxiliary information - namely attribute annotations performed by humans - that is not readily available for most classes. Our goal is to circumvent this bottleneck by substituting such annotations by extracting multiple pieces of information from multiple unstructured text sources readily available on the web. To compensate for the weaker form of auxiliary information, we incorporate stronger supervision in the form of semantic part annotations on the classes from which we transfer knowledge. We achieve our goal by a joint embedding framework that maps multiple text parts as well as multiple semantic parts into a common space. Our results consistently and significantly improve on the state-of-the-art in zero-short recognition and retrieval.", "PublicationYear": "2016", "Authors": ["Zeynep Akata", "Mateusz Malinowski", "Mario Fritz", "Bernt Schiele"], "RelatedTopics": ["Computer Science"], "References": ["ccbc09d498cad330c37f94e15b77bf220b10ccb4", "c30b9fb837e912ccf3919fdb64e9543fca57799e", "4aa4069693bee00d1b0759ca3df35e59284e9845", "6540cb7971d1a9d72562d465172e010fbb729bc3", "be2f5d8a7e6b415f1e22cee7dfd9be56b1afd8be", "caccc069e658ea397c9faf673e74c959c734ff53", "cb461276fad5710d8a7e2868867a9b01df040119", "aea0f946e8dcddb65cc2e907456c42453f246a50", "88e090ffc1f75eed720b5afb167523eb2e316f7f", "98bb60748eb8ef7a671cdd22faa87e377fd13060"], "ReferenceCount": 55, "CitationCount": 138}, {"URL": "https://www.semanticscholar.org/paper/Zero-shot-recognition-with-unreliable-attributes-Jayaraman-Grauman/018e730f8947173e1140210d4d1760d05c9d3854", "ID": "018e730f8947173e1140210d4d1760d05c9d3854", "Title": "Zero-shot recognition with unreliable attributes", "Abstract": "This work proposes a novel random forest approach to train zero-shot models that explicitly accounts for the unreliability of attribute predictions, and obtains more robust discriminative models for the unseen classes by leveraging statistics about each attribute's error tendencies. In principle, zero-shot learning makes it possible to train a recognition model simply by specifying the category's attributes. For example, with classifiers for generic attributes like striped and four-legged, one can construct a classifier for the zebra category by enumerating which properties it possesses\u2014even without providing zebra training images. In practice, however, the standard zero-shot paradigm suffers because attribute predictions in novel images are hard to get right. We propose a novel random forest approach to train zero-shot models that explicitly accounts for the unreliability of attribute predictions. By leveraging statistics about each attribute's error tendencies, our method obtains more robust discriminative models for the unseen classes. We further devise extensions to handle the few-shot scenario and unreliable attribute descriptions. On three datasets, we demonstrate the benefit for visual category learning with zero or few training examples, a critical domain for rare categories or categories defined on the fly.", "PublicationYear": "2014", "Authors": ["Dinesh Jayaraman", "Kristen Grauman"], "RelatedTopics": ["Computer Science"], "References": ["88e090ffc1f75eed720b5afb167523eb2e316f7f", "23e568fcf0192e4ff5e6bed7507ee5b9e6c43598", "d6714ee0a3c3c5ead3d681d4bec8e60f042928ef", "2198f4130c4850ffebe52d5eeaefc61e15b60426", "5e470f5320ae9920b597422dfae5d5e1eadbf55e", "caa632d101a41a7860562e4399a5eaa9a4088b55", "3fd90098551bf88c7509521adf1c0ba9b5dfeb57", "4aa4069693bee00d1b0759ca3df35e59284e9845", "0566bf06a0368b518b8b474166f7b1dfef3f9283", "54aacc196ffe49b3450059fccdf7cd3bb6f6f3c3"], "ReferenceCount": 32, "CitationCount": 284}, {"URL": "https://www.semanticscholar.org/paper/Label-Embedding-for-Image-Classification-Akata-Perronnin/cb461276fad5710d8a7e2868867a9b01df040119", "ID": "cb461276fad5710d8a7e2868867a9b01df040119", "Title": "Label-Embedding for Image Classification", "Abstract": "This work proposes to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors, and introduces a function that measures the compatibility between an image and a label embedding. Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as, e.g., class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.", "PublicationYear": "2015", "Authors": ["Zeynep Akata", "Florent Perronnin", "Za{\\\"i}d Harchaoui", "Cordelia Schmid"], "RelatedTopics": ["Computer Science"], "References": ["caa632d101a41a7860562e4399a5eaa9a4088b55", "caccc069e658ea397c9faf673e74c959c734ff53", "54aacc196ffe49b3450059fccdf7cd3bb6f6f3c3", "88e090ffc1f75eed720b5afb167523eb2e316f7f", "755e9f43ce398ae8737366720c5f82685b0c253e", "4aa4069693bee00d1b0759ca3df35e59284e9845", "0566bf06a0368b518b8b474166f7b1dfef3f9283", "a3ea706f6604a1e6e87c33d7a3b4b97b1bb338ef", "3a4a53fe47036ac89dad070ab87a9d8795b139b1", "2198f4130c4850ffebe52d5eeaefc61e15b60426"], "ReferenceCount": 77, "CitationCount": 670}, {"URL": "https://www.semanticscholar.org/paper/An-N-Gram-Based-Approach-to-the-Automatic-Diagnosis-Wankerl-N%C3%B6th/c940a209c47594443c5f352890b37a8d3fa9525f", "ID": "c940a209c47594443c5f352890b37a8d3fa9525f", "Title": "An N-Gram Based Approach to the Automatic Diagnosis of Alzheimer's Disease from Spoken Language", "Abstract": "A purely statistical approach towards the automatic diagnosis of AD which is solely based on n-gram models with subsequent evaluation of the perplexity and does not incorporate any further linguistic features, which reveals some of the cognitive limitations of AD patients and can help to better diagnose the disease based on speech. Alzheimer\u2019s disease (AD) is the most common cause of dementia and affects wide parts of the elderly population. Since there exists no cure for this illness, it is of particular interest to develop reliable and easy-to-use diagnostic methods to alleviate its effects. Speech can be a useful indicator to reach this goal. We propose a purely statistical approach towards the automatic diagnosis of AD which is solely based on n-gram models with subsequent evaluation of the perplexity and does not incorporate any further linguistic features. Hence, it works independently of a concrete language. We evaluate our approach on the DementiaBank which contains spontaneous speech of test subjects describing a picture. Using the Equal-Error-Rate as clas-si\ufb01cation threshold, we achieve an accuracy of 77.1%. In addition to that, we studied the correlation between the calculated perplexities and the Mini\u2013Mental State Examination (MMSE) scores of the test subjects. While there is little correlation for the healthy control group, a higher correlation could be found when considering the demented speakers. This makes it reasonable to conclude that our approach reveals some of the cognitive limitations of AD patients and can help to better diagnose the disease based on speech.", "PublicationYear": "2017", "Authors": ["Sebastian Wankerl", "Elmar N{\\\"o}th", "Stefan Evert"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "4a5314fa5f521e78b0ef360369e6c62d37d6dbb2", "2e35a38916906e59d86cca79093a5b1ade02a3f1", "360c643dd1b622983cda13904849e1db3472b924", "c10c1ab95e2ceb01fa84897b521d99f1a1f399d1", "137743ee8d930661ede1f297d9dc5b593b0d580c", "c1ce0f32db5d096b583a8d5e0af6949cf44c928a", "069674cfe6c8830cc101b9f5e21c9e169f81f5a7", "e0bb444a95bbcd49c484c46527be5cfe26205da7", "0a4426ee1a2374baa7ef4b9c3c05516e6b1e66cc"], "ReferenceCount": 22, "CitationCount": 45}, {"URL": "https://www.semanticscholar.org/paper/ANN-based-Alzheimer's-disease-classification-from-Klumpp-Fritsch/3c0edbe173aa15ffa3eb203cfa463e7f0abb8240", "ID": "3c0edbe173aa15ffa3eb203cfa463e7f0abb8240", "Title": "ANN-based Alzheimer's disease classification from bag of words", "Abstract": "This work proposes the approach of counting word occurrences in transcriptions, storing them in a bag of words (BoW) vector, and using this vector as an input into an artificial neural network which classifies between AD and healthy state. Alzheimer\u2019s disease (AD) is the most frequent cause of dementia and the patient numbers are increasing within an aging society. Prior research has shown that AD significantly affects the speech signal, and many approaches were published on how to detect AD from only speech or spoken text information. In an earlier work, we have proven the reliability of language models to statistically evaluate transcriptions from AD and healthy control participants. Based on these results, we propose the approach of counting word occurrences in transcriptions, storing them in a bag of words (BoW) vector, and using this vector as an input into an artificial neural network which classifies between AD and healthy state. It could be shown that the new method reached very similar results compared to the language model classifiers, although information about the word order was omitted.", "PublicationYear": "2018", "Authors": ["Philipp Klumpp", "Julian Fritsch", "Elmar N{\\\"o}th"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["c940a209c47594443c5f352890b37a8d3fa9525f", "a7425f74a9e7bdd3ae6763c515c9534fb18a3560", "3d13d6f847e8f4c76c5a8d6f99fa49dbabe473c0", "6ca330477a1509b0a5b3d1848564b954bb5e29a4", "8bf7ecd164a6c07dd4c45eede1bf9fae8542db89", "726be3231996cbe4fb35b3c9975a002aa0d1b2f1", "ea9c98e1ddb14618d2b34c84186381f04fbabf72", "e2828773d39f86550b9fffd1dc566409a313eeb5", "1bb94d5f567071985b17cc117e6f59ad857aec55", "3d0bffdf62b34efbd2535a9c6b72289306d12511"], "ReferenceCount": 22, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Manual-and-Automatic-Transcriptions-in-Dementia-Weiner-Engelbart/3ce917438bba77b3c73ee865512e6d66930b7090", "ID": "3ce917438bba77b3c73ee865512e6d66930b7090", "Title": "Manual and Automatic Transcriptions in Dementia Detection from Speech", "Abstract": "This work presents two pipelines of feature extraction for dementia detection: the manual pipeline uses manual transcriptions while the fully automatic pipeline uses transcriptions created by automatic speech recognition (ASR), and shows that the ASR system\u2019s transcription quality is a good single feature and that the features extracted from automatic transcriptions perform similar or slightly better than the features extracting from the manual transcription. As the population in developed countries is aging, larger numbers of people are at risk of developing dementia. In the near future there will be a need for time- and cost-efficient screening methods. Speech can be recorded and analyzed in this manner, and as speech and language are affected early on in the course of dementia, automatic speech processing can provide valuable support for such screening methods. We present two pipelines of feature extraction for dementia detection: the manual pipeline uses manual transcriptions while the fully automatic pipeline uses transcriptions created by automatic speech recognition (ASR). The acoustic and linguistic features that we extract need no language specific tools other than the ASR system. Using these two different feature extraction pipelines we automatically detect dementia. Our results show that the ASR system\u2019s transcription quality is a good single feature and that the features extracted from automatic transcriptions perform similar or slightly better than the features extracted from the manual transcriptions.", "PublicationYear": "2017", "Authors": ["Jochen Weiner", "Mathis Engelbart", "Tanja Schultz"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["be74c71f46bf42bb948d662fcd1ef137dc6dde45", "651fd60a871cd7f06511da049427cd7702965884", "6ca330477a1509b0a5b3d1848564b954bb5e29a4", "8aed7cdbc093dd14c20181ce35d4162dde914ccb", "a214611baf46be5a21276218f892753177eed1f8", "9eb018471ead7824f3e093673669a9c088044dce", "90272b8038d334c8587c9a7751097c5882ce3f0c", "170ab7312d5f8f109bf124fb3dfaad6139f536f9", "3d0bffdf62b34efbd2535a9c6b72289306d12511", "638dc3e4d52802fcb1cb97e032ba1353d7637bcd"], "ReferenceCount": 30, "CitationCount": 42}, {"URL": "https://www.semanticscholar.org/paper/The-natural-history-of-Alzheimer's-disease.-of-and-Becker-Boiler/137743ee8d930661ede1f297d9dc5b593b0d580c", "ID": "137743ee8d930661ede1f297d9dc5b593b0d580c", "Title": "The natural history of Alzheimer's disease. Description of study cohort and accuracy of diagnosis.", "Abstract": "It is indicated that longitudinal follow-up of demented cases increases accuracy of diagnosis, and that detailed cognitive testing aids in early classification, in a natural history study of Alzheimer's disease. OBJECTIVE\\nWe describe the sampling, initial evaluation, and final diagnostic classification of subjects enrolled in a natural history study of Alzheimer's disease (AD).\\n\\n\\nDESIGN\\nVolunteer cohort study.\\n\\n\\nSETTING\\nMultidisciplinary behavioral neurology research clinic.\\n\\n\\nPATIENTS OR OTHER PARTICIPANTS\\nThree-hundred nineteen individuals were enrolled in the Alzheimer Research Program between March 1983 and March 1988. Of these, 204 were originally classified with AD, 102 were normal elderly control subjects, and 13 were considered special cases.\\n\\n\\nMAIN OUTCOME MEASURES\\nFinal consensus clinical diagnosis, final neuropathologic diagnosis, and death.\\n\\n\\nRESULTS\\nOf the 204 patients enrolled in the study, re-review after as many as 5 years of follow-up resulted in a final clinical classification of 188 with probable AD. Seven patients were believed to have a significant vascular component to the dementia, three were found to have developed depression, and six were excluded on other clinical grounds. Neuropathologic examination of 50 brains indicated definite AD in 43. After removing these seven misdiagnosed patients, the final group of probable/definite AD totaled 181 individuals. Accuracy of the baseline clinical diagnosis relative to neuropathology was 86%, and when follow-up clinical data were considered, 91.4%. Detailed neuropsychological testing yielded high sensitivity (0.988) and specificity (0.983) to dementia. Analyses of survival time from study entry until death revealed that older patients were significantly more likely to die during follow-up, but neither sex, years of education, nor pattern of cognitive impairment were related to survival.\\n\\n\\nCONCLUSIONS\\nThese data provide the descriptive basis for future studies of this cohort. They indicate that longitudinal follow-up of demented cases increases accuracy of diagnosis, and that detailed cognitive testing aids in early classification.", "PublicationYear": "1994", "Authors": ["James T. Becker", "Franc\u0327ois Boiler", "Oscar L. Lopez", "Judith A. Saxton", "Karen L. McGonigle"], "RelatedTopics": ["Medicine"], "References": ["49261025f3be57b6a272ad20740cb806934f24e0", "c08eb5afd0e93aa226ed7b258f3a04fc12f27aa0", "0861a26cac82cc8e276585c1274e32a5d586dbc5", "ed9218301cc00b33eae2e3f5c5af511ffffcb2fd", "6aba613577ec7d467cf0f93d409f504e56673bf3", "1bb94d5f567071985b17cc117e6f59ad857aec55", "0d6d11a2660545910f429c9ef40d9a292f953f58", "cfbb712669cfba03eb597ae15beb39526f9b9223", "339236705f61678697519c23ae233d0afa3d23ad", "a17aa0e70d0bc5323f6b0566bc571794d3b64914"], "ReferenceCount": 60, "CitationCount": 431}, {"URL": "https://www.semanticscholar.org/paper/rwthlm-the-RWTH-aachen-university-neural-network-Sundermeyer-Schl%C3%BCter/084a54c5b76e10648e1d15985641baa5433ff893", "ID": "084a54c5b76e10648e1d15985641baa5433ff893", "Title": "rwthlm - the RWTH aachen university neural network language modeling toolkit", "Abstract": "A novel toolkit that implements the long short-term memory (LSTM) neural network concept for language modeling is presented, which allows fast training of standard recurrent and LSTM neural network language models. We present a novel toolkit that implements the long short-term memory (LSTM) neural network concept for language modeling. The main goal is to provide a software which is easy to use, and which allows fast training of standard recurrent and LSTM neural network language models. The toolkit obtains state-of-the-art performance on the standard Treebank corpus. To reduce the training time, BLAS and related libraries are supported, and it is possible to evaluate multiple word sequences in parallel. In addition, arbitrary word classes can be used to speed up the computation in case of large vocabulary sizes. Finally, the software allows easy integration with SRILM, and it supports direct decoding and rescoring of HTK lattices. The toolkit is available for download under an open source license.", "PublicationYear": "2014", "Authors": ["Martin Sundermeyer", "Ralf Schl{\\\"u}ter", "Hermann Ney"], "RelatedTopics": ["Computer Science"], "References": ["f9a1b3850dfd837793743565a8af95973d395a4e", "d1275b2a2ab53013310e759e5c6878b96df643d4", "d36b19b4c5977dd2a2796a5ad3508a3d8a087809", "167ad306d84cca2455bc50eb833454de9f2dcd02", "86d62362d50fd3d26f0c049fc72d4cf40bd218b6", "51f7ff895b854e421fbabf76a1039f1abb41d5d4", "c19fbefdeead6a4154a22a9c8551a18b1530033a", "a17745f1d7045636577bcd5d513620df5860e9e5", "fcfb39e64678fe9cb681f11b9a3314becec82bb2", "0fcc184b3b90405ec3ceafd6a4007c749df7c363"], "ReferenceCount": 32, "CitationCount": 41}, {"URL": "https://www.semanticscholar.org/paper/A-meta-analysis-of-the-accuracy-of-the-mini-mental-Mitchell/0b485413633fecfb2073f6ec4bf4d4777b3cb4c0", "ID": "0b485413633fecfb2073f6ec4bf4d4777b3cb4c0", "Title": "A meta-analysis of the accuracy of the mini-mental state examination in the detection of dementia and mild cognitive impairment.", "Abstract": "Semantic Scholar extracted view of \\\"A meta-analysis of the accuracy of the mini-mental state examination in the detection of dementia and mild cognitive impairment.\\\" by A. Mitchell", "PublicationYear": "2009", "Authors": ["Alex J Mitchell"], "RelatedTopics": ["Medicine"], "References": ["c8bcd7737042a052e4cf431df7c2860d0f1de346", "9171813d88373c90e2862d3441c6862d35a6d3af", "9e4d2357b1aa305f6ab223fab7d1001bea7fd2a5", "92a108f926ef45ec7310e66802d68c4c4c52b47e", "0fe6a1b6adfb13dd790007e5fa98fcfa7741e3c8", "12a971d19e68520899034040d5942e7d7157cc83", "84d70cea9bb5bf8b39327d3e2551cc58e180999e", "4e2cbb181a0c75850488978aa57d116812e9e3b4", "15228d45cf3f43a6db2c306a8320fd4187ba4965", "4c04526aaa7d560ec28ce6be2c39d271c24e3f80"], "ReferenceCount": 106, "CitationCount": 914}, {"URL": "https://www.semanticscholar.org/paper/%E2%80%9CMini-mental-state%E2%80%9D%3A-A-practical-method-for-grading-Folstein-Folstein/0a4426ee1a2374baa7ef4b9c3c05516e6b1e66cc", "ID": "0a4426ee1a2374baa7ef4b9c3c05516e6b1e66cc", "Title": "\u201cMini-mental state\u201d: A practical method for grading the cognitive state of patients for the clinician", "Abstract": "Semantic Scholar extracted view of \\\"\u201cMini-mental state\u201d: A practical method for grading the cognitive state of patients for the clinician\\\" by M. Folstein et al.", "PublicationYear": "1975", "Authors": ["Marshal F. Folstein", "Marshal F. Folstein", "Susan E B Folstein", "Susan E B Folstein", "Paul R. McHugh", "Paul R. McHugh"], "RelatedTopics": ["Psychology"], "References": ["bd2a21cbedcf13057bf5b919a719a87accc4f964", "a7c742b4a8a6a46fe3c410ec1f73818ab8f10031", "ece9ab2423579280d7da8a859a161a34af23ae8c", "c71591ba82461a4a49975af3544cc8ab7d312a89", "a99d947bc3509efc8e84eea82ded200c14f67cda"], "ReferenceCount": 5, "CitationCount": 83647}, {"URL": "https://www.semanticscholar.org/paper/LSTM-Neural-Networks-for-Language-Modeling-Sundermeyer-Schl%C3%BCter/f9a1b3850dfd837793743565a8af95973d395a4e", "ID": "f9a1b3850dfd837793743565a8af95973d395a4e", "Title": "LSTM Neural Networks for Language Modeling", "Abstract": "This work analyzes the Long Short-Term Memory neural network architecture on an English and a large French language modeling task and gains considerable improvements in WER on top of a state-of-the-art speech recognition system. Neural networks have become increasingly popular for the task of language modeling. Whereas feed-forward networks only exploit a fixed context length to predict the next word of a sequence, conceptually, standard recurrent neural networks can take into account all of the predecessor words. On the other hand, it is well known that recurrent networks are difficult to train and therefore are unlikely to show the full potential of recurrent models. These problems are addressed by a the Long Short-Term Memory neural network architecture. In this work, we analyze this type of network on an English and a large French language modeling task. Experiments show improvements of about 8 % relative in perplexity over standard recurrent neural network LMs. In addition, we gain considerable improvements in WER on top of a state-of-the-art speech recognition system.", "PublicationYear": "2012", "Authors": ["Martin Sundermeyer", "Ralf Schl{\\\"u}ter", "Hermann Ney"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["9819b600a828a57e1cde047bbe710d3446b30da5", "e4a94d6eef25cdebdde2c91fb3c45a737d5e3141", "c19fbefdeead6a4154a22a9c8551a18b1530033a", "07ca885cb5cc4328895bfaec9ab752d5801b14cd", "47e3d8a1f8e92923e739ca34bea17004a40514e9", "0fcc184b3b90405ec3ceafd6a4007c749df7c363", "5536d42ce80e129be8cae172ed1b7659c769d31d", "6c2b28f9354f667cd5bd07afc0471d8334430da7", "11540131eae85b2e11d53df7f1360eeb6476e7f4", "86d62362d50fd3d26f0c049fc72d4cf40bd218b6"], "ReferenceCount": 19, "CitationCount": 1810}, {"URL": "https://www.semanticscholar.org/paper/Deep-Neural-Network-Language-Models-Arisoy-Sainath/a17745f1d7045636577bcd5d513620df5860e9e5", "ID": "a17745f1d7045636577bcd5d513620df5860e9e5", "Title": "Deep Neural Network Language Models", "Abstract": "Results on a Wall Street Journal (WSJ) task demonstrate that DNN LMs offer improvements over a single hidden layer NNLM, and are competitive with a model M language model, considered to be one of the current state-of-the-art techniques for language modeling. In recent years, neural network language models (NNLMs) have shown success in both peplexity and word error rate (WER) compared to conventional n-gram language models. Most NNLMs are trained with one hidden layer. Deep neural networks (DNNs) with more hidden layers have been shown to capture higher-level discriminative information about input features, and thus produce better networks. Motivated by the success of DNNs in acoustic modeling, we explore deep neural network language models (DNN LMs) in this paper. Results on a Wall Street Journal (WSJ) task demonstrate that DNN LMs offer improvements over a single hidden layer NNLM. Furthermore, our preliminary results are competitive with a model M language model, considered to be one of the current state-of-the-art techniques for language modeling.", "PublicationYear": "2012", "Authors": ["Ebru Arisoy", "Tara N. Sainath", "Brian Kingsbury", "Bhuvana Ramabhadran"], "RelatedTopics": ["Computer Science"], "References": ["9819b600a828a57e1cde047bbe710d3446b30da5", "3aaa1e4974800767fcbd2c24c2f2af42bf412f97", "8b395470a57c48d174c4216ea21a7a58bc046917", "c19fbefdeead6a4154a22a9c8551a18b1530033a", "0fcc184b3b90405ec3ceafd6a4007c749df7c363", "f37cfdc4520c56c1eaf87cee5ec2a4028ceaa9c5", "d7174b0cf599408fb723e6702504e27dc9d6c203", "cb45e9217fe323fbc199d820e7735488fca2a9b3", "a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb", "07ca885cb5cc4328895bfaec9ab752d5801b14cd"], "ReferenceCount": 24, "CitationCount": 197}, {"URL": "https://www.semanticscholar.org/paper/Learning-Linguistic-Biomarkers-for-Predicting-Mild-Orimaye-Tai/e6ee69f334b71dc0edc72eecc3f29d0ef846560b", "ID": "e6ee69f334b71dc0edc72eecc3f29d0ef846560b", "Title": "Learning Linguistic Biomarkers for Predicting Mild Cognitive Impairment using Compound Skip-grams", "Abstract": "This model learned several linguistic biomarkers to distinguish between 19 patients with MCI and 19 healthy control individuals from the DementiaBank language transcript clinical dataset and showed that a model with compound of skip-grams has better AUC and could help ML prediction on small MCI data sample. Predicting Mild Cognitive Impairment (MCI) is currently a challenge as existing diagnostic criteria rely on neuropsychological examinations. Automated Machine Learning (ML) models that are trained on verbal utterances of MCI patients can aid diagnosis. Using a combination of skip-gram features, our model learned several linguistic biomarkers to distinguish between 19 patients with MCI and 19 healthy control individuals from the DementiaBank language transcript clinical dataset. Results show that a model with compound of skip-grams has better AUC and could help ML prediction on small MCI data sample.", "PublicationYear": "2015", "Authors": ["Sylvester Olubolu Orimaye", "Kah Yee Tai", "Jojo Sze-Meng Wong", "Chee Piau Wong"], "RelatedTopics": ["Computer Science", "Linguistics", "Medicine"], "References": ["7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "ff2511b2d54017d6dd8c250dca05ec85b8ba5e26", "00b2b55669d446fdfde8e6d4b307da5fa8b400cf", "0cfaf3793b3dbea856d1ffc3ced785449a0a2f2a", "f6ee0132df38556a69ba21da6eb215285f172249", "a0968b29aa9d4d5aae6456d7c1dbbe62fbfa9b0d", "dc50623f4f38345adf8497ea7835f4efd64cbe45", "a42ca00fc188beb5586ad4c7108b70aeb5317da0", "2e2b9a021a054459627771f6b13f9ee7e3e3e79e"], "ReferenceCount": 12, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Automated-classification-of-primary-progressive-Fraser-Meltzer/7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "ID": "7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "Title": "Automated classification of primary progressive aphasia subtypes from narrative speech transcripts", "Abstract": "Semantic Scholar extracted view of \\\"Automated classification of primary progressive aphasia subtypes from narrative speech transcripts\\\" by Kathleen C. Fraser et al.", "PublicationYear": "2014", "Authors": ["Kathleen C. Fraser", "Jed A. Meltzer", "Naida Graham", "Carol Leonard", "Elizabeth Rochon"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["c5597a370f5db6067a261e0764671b47bfe0545c", "e16f8b75483e836dbbe0374373c656abea82c650", "2a75030045c68f142e834e099e6e1c591d55c56b", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "b1507b2e1d5e4202d71419f60947952ba2a55c8f", "3a78d460643ff8e1f6677533b6837c188cefac0a", "bf99b6193a232c2e70ab45fce53415369d0e658a", "6bba9a8182ec660ec23383a304e08d91a20dc7c1", "3c24d224879361a1dacb277c5318e2c18af6962d", "3971135f684ed9ce58d85336b8e81ab825de08c8"], "ReferenceCount": 73, "CitationCount": 191}, {"URL": "https://www.semanticscholar.org/paper/Detection-of-early-Alzheimer's-disease-in-MCI-by-of-Pozueta-Rodr%C3%ADguez-Rodr%C3%ADguez/bca9453da6fbfd06ff9db5bbcb25fabaf9370e22", "ID": "bca9453da6fbfd06ff9db5bbcb25fabaf9370e22", "Title": "Detection of early Alzheimer's disease in MCI patients by the combination of MMSE and an episodic memory test", "Abstract": "Pr-AD might be distinguished from S-MCI at baseline using the combination of MMSE and CVLT-LDTR, which are relatively brief and may be readily completed in non-specialist clinical settings. BackgroundMild cognitive impairment (MCI) is a heterogeneous clinical entity that comprises the prodromal phase of Alzheimer's disease (Pr-AD). New biomarkers are useful in detecting Pr-AD, but they are not universally available. We aimed to investigate baseline clinical and neuropsychological variables that might predict progression from MCI to AD dementia.MethodsAll patients underwent a complete clinical and neuropsychological evaluation at baseline and every 6 months during a two-year follow-up period, with 54 out of 109 MCI patients progressing to dementia (50 of them progressed to AD dementia), and 55 remaining as stable MCI (S-MCI).ResultsA combination of MMSE and California Verbal Learning Test Long Delayed Total Recall (CVLT-LDTR) constituted the best predictive model: subjects scoring above 26/30 on MMSE and 4/16 on CVLT-LDTR had a negative predictive value of 93.93% at 2 years, whereas those subjects scoring below both of these cut-off scores had a positive predictive value of 80.95%.ConclusionsPr-AD might be distinguished from S-MCI at baseline using the combination of MMSE and CVLT-LDTR. These two neuropsychological predictors are relatively brief and may be readily completed in non-specialist clinical settings.", "PublicationYear": "2011", "Authors": ["Ana Pozueta", "Eloy Rodr{\\'i}guez-Rodr{\\'i}guez", "Jos{\\'e} Luis V{\\'a}zquez-Higuera", "Ignacio Mateo", "Pascual S{\\'a}nchez-Juan", "Soraya Gonz{\\'a}lez-Perez", "Jos{\\'e} Berciano", "Onofre Combarros"], "RelatedTopics": ["Medicine"], "References": ["81772f1d67d06d1d1795473f4bbfd2e66b1a9096", "1b5634f36ebda7bdd5105570e67bfcfb66f8459b", "7a9b34867c3e27c293a78b1b7d7994c4a59271a1", "8e46ef284cf30166f444f5daa6a65fe6d7455928", "731f7c69ab0dcee4cf2a9a3965d9e40ed5df332c", "aa0c5feaa50de86e8107edb2da26fd6fd721b60b", "b6b5e13a5e03147fa970daf67e1c8e010c5ae80c", "8096579c5885c3f0b97d58afc6a47d1852ac173a", "ae1436bf7642095d98f0dbfdebeced1b6ad6d52c", "38a72b26cee37dd4e0581ff45f32baf700807449"], "ReferenceCount": 21, "CitationCount": 52}, {"URL": "https://www.semanticscholar.org/paper/Graph-Based-Word-Alignment-for-Clinical-Language-Prud'hommeaux-Roark/4dc3d29f66e887c780343226c8a4278df758a17e", "ID": "4dc3d29f66e887c780343226c8a4278df758a17e", "Title": "Graph-Based Word Alignment for Clinical Language Evaluation", "Abstract": "A method for extracting narrative recall scores automatically and highly accurately from a word-level alignment between a retelling and the source narrative is presented and improvements to existing machine translation\u2013based systems for word alignment are proposed, including a novel method of word alignment relying on random walks on a graph that achieves alignment accuracy superior to that of standard expectation maximization\u2013based techniques. Among the more recent applications for natural language processing algorithms has been the analysis of spoken language data for diagnostic and remedial purposes, fueled by the demand for simple, objective, and unobtrusive screening tools for neurological disorders such as dementia. The automated analysis of narrative retellings in particular shows potential as a component of such a screening tool since the ability to produce accurate and meaningful narratives is noticeably impaired in individuals with dementia and its frequent precursor, mild cognitive impairment, as well as other neurodegenerative and neurodevelopmental disorders. In this article, we present a method for extracting narrative recall scores automatically and highly accurately from a word-level alignment between a retelling and the source narrative. We propose improvements to existing machine translation\u2013based systems for word alignment, including a novel method of word alignment relying on random walks on a graph that achieves alignment accuracy superior to that of standard expectation maximization\u2013based techniques for word alignment in a fraction of the time required for expectation maximization. In addition, the narrative recall score features extracted from these high-quality word alignments yield diagnostic classification accuracy comparable to that achieved using manually assigned scores and significantly higher than that achieved with summary-level text similarity metrics used in other areas of NLP. These methods can be trivially adapted to spontaneous language samples elicited with non-linguistic stimuli, thereby demonstrating the flexibility and generalizability of these methods.", "PublicationYear": "2015", "Authors": ["Emily Tucker Prud'hommeaux", "Brian Roark"], "RelatedTopics": ["Computer Science", "Medicine", "Linguistics"], "References": ["d613f1c8618c564aefc90c8a08fa5ff9d9fa3a48", "6ee346c4cd9ce26f76c3e1758c492dc430140645", "4a19612cc1e5a56796749b8beaad7be4d66d3af9", "7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "44fca068eecce2203d111213e3691647914a3945", "a8cd4009c4a2d92b49625179e0a35677ccb75606", "1b8f0ba79f50700449836b54fc5920b87e141b9f", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "e465564f1de4181dffd4fc8235ca8d2efe56cfa6", "216e373390e16cd474442dfcb9f1eecb3a4cdc99"], "ReferenceCount": 83, "CitationCount": 25}, {"URL": "https://www.semanticscholar.org/paper/Spoken-Language-Derived-Measures-for-Detecting-Mild-Roark-Mitchell/343a5ab97e47368da0aa7b50256736297cbb9ce6", "ID": "343a5ab97e47368da0aa7b50256736297cbb9ce6", "Title": "Spoken Language Derived Measures for Detecting Mild Cognitive Impairment", "Abstract": "The results indicate that using multiple, complementary measures can aid in automatic detection of MCI, and demonstrate a statistically significant improvement in the area under the ROC curve (AUC) when using automatic spoken language derived features in addition to the neuropsychological test scores. Spoken responses produced by subjects during neuropsychological exams can provide diagnostic markers beyond exam performance. In particular, characteristics of the spoken language itself can discriminate between subject groups. We present results on the utility of such markers in discriminating between healthy elderly subjects and subjects with mild cognitive impairment (MCI). Given the audio and transcript of a spoken narrative recall task, a range of markers are automatically derived. These markers include speech features such as pause frequency and duration, and many linguistic complexity measures. We examine measures calculated from manually annotated time alignments (of the transcript with the audio) and syntactic parse trees, as well as the same measures calculated from automatic (forced) time alignments and automatic parses. We show statistically significant differences between clinical subject groups for a number of measures. These differences are largely preserved with automation. We then present classification results, and demonstrate a statistically significant improvement in the area under the ROC curve (AUC) when using automatic spoken language derived features in addition to the neuropsychological test scores. Our results indicate that using multiple, complementary measures can aid in automatic detection of MCI.", "PublicationYear": "2011", "Authors": ["Brian Roark", "Margaret Mitchell", "John-Paul Hosom", "Kristy Hollingshead", "Jeffrey A. Kaye"], "RelatedTopics": ["Medicine", "Computer Science", "Psychology"], "References": ["7670373c12530269f790ac851c0e1d1716b2b84b", "7e75adf26035f8f3f77759ea5736d18c4d84b4b8", "d634adcb9d65f8636b0f37f90797cc354b2a5e91", "988b823416cbd73bdb33063ad1c3df2a73992fba", "0a4426ee1a2374baa7ef4b9c3c05516e6b1e66cc", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "52fd805daaeadafd58b1b8751123832e3145b510", "15b8576bf70d4987844e1dc4b0d1cfb7772c0148", "4937be611fb1f272b7545a0caa88237d9830ad5a", "468f3a9796ce6b97df20b5edf93cbe46a9b2b6cb"], "ReferenceCount": 52, "CitationCount": 297}, {"URL": "https://www.semanticscholar.org/paper/Journal-of-Psychiatric-Research-Tanner/04473f90a3aed35ac938b1ed960146bc27c76af8", "ID": "04473f90a3aed35ac938b1ed960146bc27c76af8", "Title": "Journal of Psychiatric Research", "Abstract": "Six candidate genes involved in the typical asymmetric brain dominance could be deregulated in autism were chosen because they have an involvement in brain function as indicated by previous functional studies, animal modeling or brain-specific expression, or because they are related to a neuropathology. Autism is a neurodevelopmental disorder which etiology is still unknown in the majority of cases. Common brain abnormalities have been described in autistic individuals: increased brain volume, neuroanatomic alterations in the prefrontal cortex and abnormal hemispheric lateralization (Lainhart, 2006). Several studies found an atypical cerebral asymmetry (ACA) in autistic individuals, i.e. the atypical profile of the right hemisphere dominance for language (Flagg et al., 2005; Kleinhans et al., 2008). Noteworthy, children with autism display some degree of language impairment and approximately one third of them never develop speech. Brain asymmetry has been related to transcriptional asymmetry in the two hemispheres at early embryonic stages (Sun et al., 2005). In this regard, 27 genes were found to be differentially expressed between the right and left human embryonic cortex, and were postulated to be involved in normal brain lateralization. Based on the hypothesis that genes involved in the typical asymmetric brain dominance could be deregulated in autism, we selected six candidate genes from the study of Sun et al. (BAIAP2, DAPPER1, LMO4, NEUROD6, ATP2B3 and ID2) to perform a case\u2013 control association study in 330 autistic patients and 490 controls. These genes showed 1.9to 8-fold differential expression between hemispheres and were chosen because they have an involvement in brain function as indicated by previous functional studies, animal modeling or brain-specific expression, or because they are related to a neuropathology. The patients\u2019 cohort met DSM-IV-TR criteria for autism and Asperger disorder based on ADI-R (Autism-Diagnostic Interview-Revised) and ADOS-G (Autism Diagnostic Observation Schedule-Generic) diagnostic instruments. Cytogenetic abnormalities and positive Fragile X test were considered as exclusion criteria. The control sample consisted of 490 healthy blood donors, sex-matched with the case sample and Spanish and Caucasian like the patients. Population stratification was excluded in our sample by genotyping 46 unlinked non-genic SNPs (data no shown; for methodological details, see Ribas\u00e9s et al., 2009). We selected single nucleotide polymorphisms (SNPs) to cover all exons, introns and 3\u20135-Kb sequences upstream and downstream of each candidate gene. We minimized marker redundancy by evaluating linkage disequilibrium patterns and the distribution of haplotype blocks in the CEU population from the HapMap database project (release 20, www.hapmap.org). A SNPlex assay (Applied Biosystems) could be designed to genotype 30 tagSNPs and one non-synonymous variant (rs17832998). Three of those SNPs were excluded for one of the following reasons: r2 &gt; 0.85 from another studied SNP, genotyping call rate &lt;85% or deviation from Hardy\u2013Weinberg equilibrium (p-value threshold set at 0.01 in the control population).", "PublicationYear": "1962", "Authors": ["J. M. Tanner"], "RelatedTopics": ["Psychology"], "References": [], "ReferenceCount": 0, "CitationCount": 116}, {"URL": "https://www.semanticscholar.org/paper/The-diagnosis-of-mild-cognitive-impairment-due-to-Albert-DeKosky/9f79b994b6bbb2da8002582200f6f0b8ba6daf91", "ID": "9f79b994b6bbb2da8002582200f6f0b8ba6daf91", "Title": "The diagnosis of mild cognitive impairment due to Alzheimer\u2019s disease: Recommendations from the National Institute on Aging-Alzheimer\u2019s Association workgroups on diagnostic guidelines for Alzheimer's disease", "Abstract": "Semantic Scholar extracted view of \\\"The diagnosis of mild cognitive impairment due to Alzheimer\u2019s disease: Recommendations from the National Institute on Aging-Alzheimer\u2019s Association workgroups on diagnostic guidelines for Alzheimer's disease\\\" by M. Albert et al.", "PublicationYear": "2011", "Authors": ["Marilyn S. Albert", "Steven T. DeKosky", "Dennis W. Dickson", "Bruno Dubois", "Howard H. Feldman", "Nick C Fox", "Anthony Collins Gamst", "David M. Holtzman", "William J. Jagust", "Ronald C. Petersen", "Peter J. Snyder", "Maria C. Carrillo", "Bill Thies", "Creighton H. Phelps"], "RelatedTopics": ["Medicine"], "References": ["37d2d04f8c09da1f0cf8434a38a51841b5b703bf", "deb71aca84609c4e659b804e4ff62ba839b8e5c2", "1182c26cae997bfadd5746317222a5c673441159", "f2b79d55d40f12ad81ed4f349de6476ac8c8ecc9", "18ed28c5a7d8becd04ac9cb27b94279b036bffbe", "8497a1668076cb0b91669f0fdd8d089011c9e880", "793b6ef444cf7046e70b3fd524ad7dc0f14122a5", "0a3a207fde1aecf73134e3382c94d1f268edd93a", "2f2e7f3aa0be8203d212f105c861ca167dc7b73e", "da827ffb6cde4ba18fb5b76029fbf39b6234b957"], "ReferenceCount": 20, "CitationCount": 7015}, {"URL": "https://www.semanticscholar.org/paper/Utility-and-limits-of-the-mini-mental-state-in-in-Kim-Caine/3e5c06e477cf11a0b5823338b4ad31c103dbee5b", "ID": "3e5c06e477cf11a0b5823338b4ad31c103dbee5b", "Title": "Utility and limits of the mini mental state examination in evaluating consent capacity in Alzheimer's disease.", "Abstract": "In this study of 37 patients with mild to moderate Alzheimer's disease, a fairly wide range of MMSE scores did not discriminate capacity status well and there may still be approaches that enhance the practical utility of the MMSE in capacity assessment. The call for formal capacity assessments of potential research participants with impairments due to illnesses such as Alzheimer's disease is increasing. Because such an evaluation of every potential subject requires significant resources, clinicians and researchers may want to know the utility and the limits of a familiar cognitive screening test, the Mini Mental State Examination (MMSE), in capacity evaluations. In this study of 37 patients with mild to moderate Alzheimer's disease, a fairly wide range of MMSE scores (21 to 25, which includes an often used cutoff for \\\"normal\\\") did not discriminate capacity status well. Nevertheless, there may still be approaches that enhance the practical utility of the MMSE in capacity assessment.", "PublicationYear": "2002", "Authors": ["Scott Y. H. Kim", "Eric D. Caine"], "RelatedTopics": ["Medicine", "Psychology"], "References": [], "ReferenceCount": 0, "CitationCount": 138}, {"URL": "https://www.semanticscholar.org/paper/Evaluating-Progression-of-Alzheimer's-Disease-by-in-Alu%C3%ADsio-Cunha/d035391d54e9a8b2f0f3393886ae82349d4fffae", "ID": "d035391d54e9a8b2f0f3393886ae82349d4fffae", "Title": "Evaluating Progression of Alzheimer's Disease by Regression and Classification Methods in a Narrative Language Test in Portuguese", "Abstract": "Initial experiments in automatically diagnosing CTL, AD, and MCI patients from a narrative language test based on sequenced pictures and textual analysis of the resulting transcriptions are presented. Automated discourse analysis aiming at the diagnosis of language impairing dementias already exist for the English language, but no such work had been done for Portuguese. Here, we describe the results of creating a unified environment, entitled Coh-Metrix-Dementia, based on a previous tool to analyze discourse, named Coh-Metrix-Port. After adding 25 new metrics for measuring syntactical complexity, idea density, and text cohesion through latent semantics, Coh-Metrix-Dementia extracts 73 features from narratives of normal aging (CTL), Alzheimer\u2019s Disease (AD), and Mild Cognitive Impairment (MCI) patients. This paper presents initial experiments in automatically diagnosing CTL, AD, and MCI patients from a narrative language test based on sequenced pictures and textual analysis of the resulting transcriptions. In order to train regression and classification models, the large set of features in Coh-Metrix-Dementia must be reduced in size. Three feature selection methods are compared. In our experiments with classification, it was possible to separate CTL, AD, and MCI with 0.817 \\\\(F_1\\\\) score, and separate CTL and MCI with 0.900 \\\\(F_1\\\\) score. As for regression, the best results for MAE were 0.238 and 0.120 for scenarios with three and two classes, respectively.", "PublicationYear": "2016", "Authors": ["Sandra Maria Alu{\\'i}sio", "Andre Cunha", "Carolina Scarton"], "RelatedTopics": ["Computer Science", "Linguistics", "Medicine"], "References": ["6ca330477a1509b0a5b3d1848564b954bb5e29a4", "b28a7fdcd91e08f6411413409e12c32c9728b31b", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "5b8c44c31b79d10833a9d1ff6d4dbfa9a662ffa2", "56d3b485ef60c4d2631d2a25f01b9a3207a1e0ef", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "2e9253548a6f50b6d22d97bbc4be24fdd662ce8c", "7d50bfd726677efb91ee21a7fec90de18d273c5b", "e43a3c3c032cf3c70875c4193f8f8818531857b2", "a906fb5f751496ea43addf1fd00026683bb95412"], "ReferenceCount": 11, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/AUTOMATIC-DETECTION-OF-LINGUISTIC-INDICATORS-AS-A-A-Rentoumi-Paliouras/c756b90d1d87707895aa0870730b07743957e7f0", "ID": "c756b90d1d87707895aa0870730b07743957e7f0", "Title": "AUTOMATIC DETECTION OF LINGUISTIC INDICATORS AS A MEANS OF EARLY PREDICTION OF ALZHEIMER\u2019S AND OF RELATED DEMENTIAS: A CROSS-LINGUISTICS ANALYSIS", "Abstract": "Semantic Scholar extracted view of \\\"AUTOMATIC DETECTION OF LINGUISTIC INDICATORS AS A MEANS OF EARLY PREDICTION OF ALZHEIMER\u2019S AND OF RELATED DEMENTIAS: A CROSS-LINGUISTICS ANALYSIS\\\" by Vassiliki Rentoumi et al.", "PublicationYear": "2018", "Authors": ["Vassiliki Rentoumi", "George Paliouras", "Dimitra Arfani", "Katerina Fragkopoulou", "Spyridoula Varlokosta", "Peter Garrard"], "RelatedTopics": ["Linguistics", "Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 0}, {"URL": "https://www.semanticscholar.org/paper/Multilingual-word-embeddings-for-the-assessment-of-Fraser-Fors/dbcc61f2bfb5fd4edd48aa70e375a3d4b81a8d2a", "ID": "dbcc61f2bfb5fd4edd48aa70e375a3d4b81a8d2a", "Title": "Multilingual word embeddings for the assessment of narrative speech in mild cognitive impairment", "Abstract": "Semantic Scholar extracted view of \\\"Multilingual word embeddings for the assessment of narrative speech in mild cognitive impairment\\\" by Kathleen C. Fraser et al.", "PublicationYear": "2019", "Authors": ["Kathleen C. Fraser", "Kristina Lundholm Fors", "Dimitrios Kokkinakis"], "RelatedTopics": ["Medicine", "Computer Science", "Linguistics"], "References": ["bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "4dc3d29f66e887c780343226c8a4278df758a17e", "6ca330477a1509b0a5b3d1848564b954bb5e29a4", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "360806c34ea0dcb5faab9824dababc094bb05c07", "a9e967c091b500157aa2389965d2ecca90e7fb34", "647c4649b11a92d4797950d50a8294b1beaba22b", "4d4117e4e5214dcc887317e302db724df545729e", "cc435c9efd3a6454c150ab781dadc7f4fc5c8e9d", "8cd1d603498e65ae19baa59bdb31617f441d4296"], "ReferenceCount": 64, "CitationCount": 41}, {"URL": "https://www.semanticscholar.org/paper/Detecting-dementia-in-Mandarin-Chinese-using-from-a-Li-Hsu/1c5547142eaad896209d23af525c5d162d87d286", "ID": "1c5547142eaad896209d23af525c5d162d87d286", "Title": "Detecting dementia in Mandarin Chinese using transfer learning from a parallel corpus", "Abstract": "This appears to be the first study that transfers feature domains in detecting cognitive decline in dementia detection in Mandarin Chinese, and it is demonstrated that the method outperforms both unilingual and machine translation-based baselines. Machine learning has shown promise for automatic detection of Alzheimer\u2019s disease (AD) through speech; however, efforts are hampered by a scarcity of data, especially in languages other than English. We propose a method to learn a correspondence between independently engineered lexicosyntactic features in two languages, using a large parallel corpus of out-of-domain movie dialogue data. We apply it to dementia detection in Mandarin Chinese, and demonstrate that our method outperforms both unilingual and machine translation-based baselines. This appears to be the first study that transfers feature domains in detecting cognitive decline.", "PublicationYear": "2019", "Authors": ["Bai Li", "Yi-Te Hsu", "Frank Rudzicz"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["9e7b0384bc48c3ae6dc1c66d6ee674902380a2c8", "67caebd696086aa057bc9f451fdce47b44832860", "bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "f47e58797316ca268fa08b601bca33c0eefdc791", "2f6070f88ecca9a4d20167571a856d6884d6cb1a", "1cccdc99cdc44020cef5149ea788848696fa1369", "bc6bcc1752adfabae69a7f97c11234aaaede8fa1", "1115dda05b3cd28280a04cac31663e8c72e0f83f", "e11edb4201007530c3692814a155b22f78a0d659", "a600850ac0120cb09a0b7de7da80bb6a7a76de06"], "ReferenceCount": 23, "CitationCount": 10}, {"URL": "https://www.semanticscholar.org/paper/Speaking-in-Alzheimer%E2%80%99s-Disease%2C-is-That-an-Early-Szatl%C3%B3czki-Hoffmann/4dfd60a301f792311c7967f08b22d606091f9d12", "ID": "4dfd60a301f792311c7967f08b22d606091f9d12", "Title": "Speaking in Alzheimer\u2019s Disease, is That an Early Sign? Importance of Changes in Language Abilities in Alzheimer\u2019s Disease", "Abstract": "The purpose of this article is to summarize the relation between prodromal and manifest AD and language functions and language domains and claim that AD can be more sensitively detected with the help of a linguistic analysis than with other cognitive examinations. It is known that Alzheimer\u2019s disease (AD) influences the temporal characteristics of spontaneous speech. These phonetical changes are present even in mild AD. Based on this, the question arises whether an examination based on language analysis could help the early diagnosis of AD and if so, which language and speech characteristics can identify AD in its early stage. The purpose of this article is to summarize the relation between prodromal and manifest AD and language functions and language domains. Based on our research, we are inclined to claim that AD can be more sensitively detected with the help of a linguistic analysis than with other cognitive examinations. The temporal characteristics of spontaneous speech, such as speech tempo, number of pauses in speech, and their length are sensitive detectors of the early stage of the disease, which enables an early simple linguistic screening for AD. However, knowledge about the unique features of the language problems associated with different dementia variants still has to be improved and refined.", "PublicationYear": "2015", "Authors": ["Gr{\\'e}ta Szatl{\\'o}czki", "Ildik{\\'o} Hoffmann", "Veronika Vincze", "J{\\'a}nos K{\\'a}lm{\\'a}n", "Magdolna P{\\'a}k{\\'a}ski"], "RelatedTopics": ["Medicine", "Linguistics"], "References": ["4e037757379916f6bfa904a07c7eadfe71b67ce0", "ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "a3b6bc65831ca24a88b8ecf7277f170ecae086ee", "647c4649b11a92d4797950d50a8294b1beaba22b", "b82a869dcefa6ea9e523adf9a289f4a80e39ec1f", "79638b63586088a43d0fd49bd8c952ad258ee2ee", "4cc0cf8743909ee3484d87d5a214af104ae59574", "89fdc56356313988590709fbcce8c997055dae45", "cb42e0fc85b3d208120c8c69ca19520c8fc0a29e", "ecc10237040f1f867d9b304a4ba5878d49342900"], "ReferenceCount": 88, "CitationCount": 164}, {"URL": "https://www.semanticscholar.org/paper/Detecting-Japanese-Patients-with-Alzheimer%E2%80%99s-based-Shibata-Wakamiya/0b82ba2817418837d0e88259051de568c5ffc85e", "ID": "0b82ba2817418837d0e88259051de568c5ffc85e", "Title": "Detecting Japanese Patients with Alzheimer\u2019s Disease based on Word Category Frequencies", "Abstract": "Features of the words that AD patients use in their spoken language are investigated to demonstrate the basic feasibility of the proposed NLP-based detection approach. In recent years, detecting Alzheimer disease (AD) in early stages based on natural language processing (NLP) has drawn much attention. To date, vocabulary size, grammatical complexity, and fluency have been studied using NLP metrics. However, the content analysis of AD narratives is still unreachable for NLP. This study investigates features of the words that AD patients use in their spoken language. After recruiting 18 examinees of 53\u201390 years old (mean: 76.89), they were divided into two groups based on MMSE scores. The AD group comprised 9 examinees with scores of 21 or lower. The healthy control group comprised 9 examinees with a score of 22 or higher. Linguistic Inquiry and Word Count (LIWC) classified words were used to categorize the words that the examinees used. The word frequency was found from observation. Significant differences were confirmed for the usage of impersonal pronouns in the AD group. This result demonstrated the basic feasibility of the proposed NLP-based detection approach.", "PublicationYear": "2016", "Authors": ["Daisaku Shibata", "Shoko Wakamiya", "Ayae Kinoshita", "Eiji Aramaki"], "RelatedTopics": ["Medicine"], "References": ["4d4117e4e5214dcc887317e302db724df545729e", "9cb16c50e8069dbcdc600b71af0ba6be807d52c5", "79638b63586088a43d0fd49bd8c952ad258ee2ee", "4cc0cf8743909ee3484d87d5a214af104ae59574", "e7669ce4efce1c3917caaf5aca51953b58080c96", "d9b0e4e86d8b1841c270731f7fdc6028e43561a3", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "a214611baf46be5a21276218f892753177eed1f8", "651fd60a871cd7f06511da049427cd7702965884", "66535bbbabe9cb634ad23a5dc7f5fe9b2a2f055d"], "ReferenceCount": 22, "CitationCount": 25}, {"URL": "https://www.semanticscholar.org/paper/Domain-Adaptation-for-Detecting-Mild-Cognitive-Masrani-Murray/3838e92e4a20e230c697c107638d5fea542181f8", "ID": "3838e92e4a20e230c697c107638d5fea542181f8", "Title": "Domain Adaptation for Detecting Mild Cognitive Impairment", "Abstract": "This work uses domain adaptation to adapt Alzheimer\u2019s data to improve classification accuracy of MCI, and evaluates two simple domain adaptation algorithms,UGMENT and CORAL, and shows that AUGMENT improves upon all baselines. Lexical and acoustic markers in spoken language can be used to detect mild cognitive impairment (MCI), a condition which is often a precursor to dementia and frequently causes some degree of dysphasia. Research to develop such a diagnostic tool for clinicians has been hindered by the scarcity of available data. This work uses domain adaptation to adapt Alzheimer\u2019s data to improve classification accuracy of MCI. We evaluate two simple domain adaptation algorithms, AUGMENT and CORAL, and show that AUGMENT improves upon all baselines. Additionally we investigate the use of previously unconsidered discourse features and show they are not useful in distinguishing MCI from healthy controls.", "PublicationYear": "2017", "Authors": ["Vaden Masrani", "Gabriel Murray", "Thalia Shoshana Field", "Giuseppe Carenini"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "c1c33280fe9e00d8047ced66815e7232403e4ca2", "a7e7eab437ab096509a3bfeb57c00dfa32d306c5", "f94fc269db80b297556a2286befaed57b3184f59", "b6b5e13a5e03147fa970daf67e1c8e010c5ae80c", "935ab929a5db8cbbc0a07bd93e605a5545d6a801", "8cd1d603498e65ae19baa59bdb31617f441d4296", "d26ab10a601f0a35453af2de3ccac0fc900793bb", "c705c9be9e8debdc40a30d637a4b533b7e4fc390"], "ReferenceCount": 34, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Predicting-probable-Alzheimer%E2%80%99s-disease-using-and-Orimaye-Wong/bb83cccd9309861aeff98bfcba3653d4dde1dc87", "ID": "bb83cccd9309861aeff98bfcba3653d4dde1dc87", "Title": "Predicting probable Alzheimer\u2019s disease using linguistic deficits and biomarkers", "Abstract": "The best diagnostic model significantly distinguished the probable AD group from the healthy elderly group with a better Area Under the Receiving Operating Characteristics Curve (AUC) using the Support Vector Machines (SVM). The manual diagnosis of neurodegenerative disorders such as Alzheimer\u2019s disease (AD) and related Dementias has been a challenge. Currently, these disorders are diagnosed using specific clinical diagnostic criteria and neuropsychological examinations. The use of several Machine Learning algorithms to build automated diagnostic models using low-level linguistic features resulting from verbal utterances could aid diagnosis of patients with probable AD from a large population. For this purpose, we developed different Machine Learning models on the DementiaBank language transcript clinical dataset, consisting of 99 patients with probable AD and 99 healthy controls. Our models learned several syntactic, lexical, and n-gram linguistic biomarkers to distinguish the probable AD group from the healthy group. In contrast to the healthy group, we found that the probable AD patients had significantly less usage of syntactic components and significantly higher usage of lexical components in their language. Also, we observed a significant difference in the use of n-grams as the healthy group were able to identify and make sense of more objects in their n-grams than the probable AD group. As such, our best diagnostic model significantly distinguished the probable AD group from the healthy elderly group with a better Area Under the Receiving Operating Characteristics Curve (AUC) using the Support Vector Machines (SVM). Experimental and statistical evaluations suggest that using ML algorithms for learning linguistic biomarkers from the verbal utterances of elderly individuals could help the clinical diagnosis of probable AD. We emphasise that the best ML model for predicting the disease group combines significant syntactic, lexical and top n-gram features. However, there is a need to train the diagnostic models on larger datasets, which could lead to a better AUC and clinical diagnosis of probable AD.", "PublicationYear": "2017", "Authors": ["Sylvester Olubolu Orimaye", "Jojo Sze-Meng Wong", "Karen J. Golden", "Chee Piau Wong", "Ireneous N. Soyiri"], "RelatedTopics": ["Computer Science", "Linguistics", "Medicine"], "References": ["4d4117e4e5214dcc887317e302db724df545729e", "00b2b55669d446fdfde8e6d4b307da5fa8b400cf", "bca9453da6fbfd06ff9db5bbcb25fabaf9370e22", "deb71aca84609c4e659b804e4ff62ba839b8e5c2", "dc72a20d177f65b1919574e80b8d0502c9923650", "9f79b994b6bbb2da8002582200f6f0b8ba6daf91", "37d2d04f8c09da1f0cf8434a38a51841b5b703bf", "6eef856f1276c7f77c1d1c3aeb7e0bafcce512f1", "7f26f5e00cacea08c5f8a1149d35764b4b11bf8c", "ff2511b2d54017d6dd8c250dca05ec85b8ba5e26"], "ReferenceCount": 74, "CitationCount": 115}, {"URL": "https://www.semanticscholar.org/paper/Automatically-identifying-trouble-indicating-speech-Rudzicz-Currie/25176248277bd8ad6aaf7a472be9ad21bcbddd9c", "ID": "25176248277bd8ad6aaf7a472be9ad21bcbddd9c", "Title": "Automatically identifying trouble-indicating speech behaviors in alzheimer's disease", "Abstract": "This paper annotates two databases of dyad conversations, that include individuals with AD, with trouble indicating behaviors (TIBs), and extracts lexical/syntactic and acoustic features from all utterances to identify those that are most indicative of TIB. Alzheimer's disease (AD) deteriorates executive, linguistic, and functional capacity and is rapidly becoming more prevalent. In particular, AD leads to an inability to follow simple dialogues. In this paper, we annotate two databases of dyad conversations, that include individuals with AD, with trouble indicating behaviors (TIBs). We then extract lexical/syntactic and acoustic features from all utterances and identify those that are most indicative of TIB (which include speech rate and utterance likelihoods in a standard language model) and classify utterances as having TIB or not with up to 79.5% accuracy. This will allow us to build automated dialogue systems and assessment tools that are sensitive to confusion in people with AD.", "PublicationYear": "2014", "Authors": ["Frank Rudzicz", "Leila Chan Currie", "Andrew Danks", "Tejas Mehta", "Shunan Zhao"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["654ef8644667e3b47bbe236adc60d8ec147ec2ab", "c6b691f750c9ae8e254981864bf4911823139e7e", "eb42a490cf4f186d3383c92963817d100afd81e2", "40737e336eb476d224a305b87fefc6bac76c3573", "9e8c2878e15eab54a291e3d66d53d2415fd91247", "493c66214eb6ff66040538192bdad398e6cf1a50", "8cb0d8800bec7b8f6646bafd9ad352392e5bbdda", "9b4876f7313b111074e79a01f570e6e9e02c0dce", "14e53403a0055dbe5faaf9f1f3be96ca0e692a4d", "60ef0ce17b657cde1690571f28c90f325ec11074"], "ReferenceCount": 11, "CitationCount": 24}, {"URL": "https://www.semanticscholar.org/paper/Gender-comparisons-of-cognitive-performances-among-Buckwalter-Rizzo/c918ad033313ace6cb412063fc9f730ed348229c", "ID": "c918ad033313ace6cb412063fc9f730ed348229c", "Title": "Gender comparisons of cognitive performances among vascular dementia, Alzheimer disease, and older adults without dementia.", "Abstract": "Findings support the existence of a semantic memory deficit for women with AD and suggest that a similar deficit may exist among women with VD. BACKGROUND\\nWe hypothesized that women with Alzheimer disease (AD) would perform worse on a test of semantic memory but not on tests of other cognitive domains. We did not expect that women without dementia would perform more poorly than men without dementia on the same task.\\n\\n\\nOBJECTIVE\\nTo explore the specificity of a semantic memory deficit among women with AD by exploring gender differences among a group of subjects with vascular dementia (VD).\\n\\n\\nDESIGN\\nA case-control study in which differences between men and women were explored using regression models to control for the potentially confounding effects of age, education, duration of dementia, and severity of dementia.\\n\\n\\nSETTING\\nAlzheimer's Disease Research Center Consortium of Los Angeles and Orange Counties, California.\\n\\n\\nSUBJECTS\\nVolunteers, recruited from the community or clinic referrals, who met clinical criteria for AD (n = 159) or VD (n = 117) or met criteria for control status without dementia (n = 134).\\n\\n\\nMAIN OUTCOME MEASURES\\nFive neuropsychological measures, commonly used in the diagnosis and assessment of dementia.\\n\\n\\nRESULTS\\nWomen with VD scored lower than men with VD on 3 tests. However, when controlling for potential confounds, the gender difference was maintained only for the semantic memory task. Women with AD showed a strong trend to perform worse than men with AD on the test of semantic memory only. No gender differences were found among subjects without dementia.\\n\\n\\nCONCLUSIONS\\nFindings support the existence of a semantic memory deficit for women with AD and suggest that a similar deficit may exist among women with VD.", "PublicationYear": "1996", "Authors": ["J. Galen Buckwalter", "Alfonso A. Rizzo", "Richard McCleary", "Rodman Shankle", "Malcolm B. Dick", "V W Henderson"], "RelatedTopics": ["Medicine"], "References": ["1b3abeb45b1436eaf3bce77944fdd37ba7b0d389", "bc9bd1a8369fef3e5cd65d3f2f79caaf7f9dcefe", "bafaf0f55500b14df2dd8a8d2b288ea1ff1f618e", "38c3d3ef045ba7e2db43e0c611bcc80aedca1610", "09500e66e8674a54117221989767922be0cf673b", "8ddc984a46276aeccbc79ee9390ca22baaccdb57", "81d504509dcd55a208f2ed9a0f1bcc763bb7ee77", "ea71199043c4bde43088080e0ad21e965f942761", "351c8b44636cbb820944a0bb9a0455351a6910f1", "27b7554eecee001440c5c7e502faa97c3be47193"], "ReferenceCount": 33, "CitationCount": 64}, {"URL": "https://www.semanticscholar.org/paper/Clinical-diagnosis-of-Alzheimer's-disease%3A-Report-Mckhann-Drachman/074a31b5599a3deebb869a0ded54ddccf86c5655", "ID": "074a31b5599a3deebb869a0ded54ddccf86c5655", "Title": "Clinical diagnosis of Alzheimer's disease: Report of the NINCDS\u2014ADRDA Work Group under the auspices of Department of Health and Human Services Task Force on Alzheimer's Disease", "Abstract": "Semantic Scholar extracted view of \\\"Clinical diagnosis of Alzheimer's disease: Report of the NINCDS\u2014ADRDA Work Group under the auspices of Department of Health and Human Services Task Force on Alzheimer's Disease\\\" by G. Mckhann et al.", "PublicationYear": "2011", "Authors": ["Guy Mckhann", "David A. Drachman", "Marshal F. Folstein", "Robert Katzman", "Donald L. Price", "Emanuel M. Stadlan"], "RelatedTopics": ["Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 7858}, {"URL": "https://www.semanticscholar.org/paper/Clinical-diagnosis-of-Alzheimer's-disease-Mckhann-Drachman/1bb94d5f567071985b17cc117e6f59ad857aec55", "ID": "1bb94d5f567071985b17cc117e6f59ad857aec55", "Title": "Clinical diagnosis of Alzheimer's disease", "Abstract": "The criteria proposed are intended to serve as a guide for the diagnosis of probable, possible, and definite Alzheimer's disease; these criteria will be revised as more definitive information becomes available. Clinical criteria for the diagnosis of Alzheimer's disease include insidious onset and progressive impairment of memory and other cognitive functions. There are no motor, sensory, or coordination deficits early in the disease. The diagnosis cannot be determined by laboratory tests. These tests are important primarily in identifying other possible causes of dementia that must be excluded before the diagnosis of Alzheimer's disease may be made with confidence. Neuropsychological tests provide confirmatory evidence of the diagnosis of dementia and help to assess the course and response to therapy. The criteria proposed are intended to serve as a guide for the diagnosis of probable, possible, and definite Alzheimer's disease; these criteria will be revised as more definitive information becomes available.", "PublicationYear": "1984", "Authors": ["Guy Mckhann", "David A. Drachman", "Marshal F. Folstein", "Robert Katzman", "Donald L. Price", "Emanuel M. Stadlan"], "RelatedTopics": ["Medicine"], "References": ["c571decde97f4bacc2ee1190888a39cb3e1d84eb", "972606319946030708e8474e53ee4afee45b60b4", "9c8350d398465033f01b5947c6880ae2b9269900", "a130957ae1fbd23b09c8785da4349018ad310b90", "0541661d0036b961380b1bd425fc65b962101385", "aa9d3992a6e79f5435efdbea362b9c065a80163a", "d665895dc01a1630f4e4eebedc0de559aac775c3", "0a4426ee1a2374baa7ef4b9c3c05516e6b1e66cc", "bb0acdf516050a4df451f3fe6f4deec7a5f63d5f", "c73250b0658534a2b16b62f183a8a15c82319852"], "ReferenceCount": 36, "CitationCount": 20318}, {"URL": "https://www.semanticscholar.org/paper/Gender-differences-in-the-cognitive-impairment-in-Heun-Kockler/87812cc86532a63b0640ec909081ce081196f206", "ID": "87812cc86532a63b0640ec909081ce081196f206", "Title": "Gender differences in the cognitive impairment in Alzheimer's disease", "Abstract": "Women seem to have minor weaknesses in spatial thinking compared to men, which may explain the inferior test results of non-demented and demented women in visuoconstructive tasks, and give some evidence for additional domain specific gender differences of cognitive impairment of AD. SummaryIntroduction: There is evidence for gender differences in cognitive functioning. Men and women with Alzheimer's disease (AD) might also differ in the pattern of cognitive deficits. We hypothesised that gender differences in the cognitive deficits of Alzheimer's disease may be related to pre-existing gender differences in cognitive functioning.Method: The performances of 84 subjects with AD and 438 non-demented elderly, using the structured interview for the diagnosis of dementia of the Alzheimer type, multi-infarct dementia and dementias of other aetiology according to ICD-10 and DSM-III-R (SIDAM), were investigated. Subscores for different cognitive functions were compared between men and women. Confounding variables, i.e. age, degree of cognitive impairment, level of education, presence of lifetime diagnosis of major depression and of recent depressive symptoms, were accounted for by multiple regression analyses.Results: Non-demented elderly women had inferior visuoconstructive skills than men. In agreement, women with Alzheimer's disease also had inferior visuoconstructive skills, but in addition they tended to perform worse in items for intellectual abilities than men.Conclusion: Women seem to have minor weaknesses in spatial thinking compared to men. This may explain the inferior test results of non-demented and demented women in visuoconstructive tasks. However, our data also give some evidence for additional domain specific gender differences of cognitive impairment of AD that could not be observed in non-demented elderly, i.e. inferior test results in items for intellectual abilities in demented women compared with demented men. Gender differences in the neurodegenerative process of AD may add to gender differences in domain specific cognitive impairment. Further research on this topic is needed.", "PublicationYear": "2002", "Authors": ["Reinhard Heun", "Martin Kockler"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["bc9bd1a8369fef3e5cd65d3f2f79caaf7f9dcefe", "347c431613fd835ca25a2de277a71de84f4a46c4", "1b3abeb45b1436eaf3bce77944fdd37ba7b0d389", "682d2e4c63eb38f30dec851bede00fcfcf6dc3aa", "09500e66e8674a54117221989767922be0cf673b", "ade8617d2ac3c343459436e4e0acca3c22760155", "927b803dbab3ddbb22d6133a47f464a9104c29be", "f0115308f8a9b35af98b35c102a902401ac3fa4c", "620bf9f3c92e30d2d4a345018b4094d08e6c672b", "38c3d3ef045ba7e2db43e0c611bcc80aedca1610"], "ReferenceCount": 34, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Decline-of-language-among-women-and-men-with-Hebert-Wilson/347c431613fd835ca25a2de277a71de84f4a46c4", "ID": "347c431613fd835ca25a2de277a71de84f4a46c4", "Title": "Decline of language among women and men with Alzheimer's disease", "Abstract": "Semantic Scholar extracted view of \\\"Decline of language among women and men with Alzheimer's disease\\\" by L. Hebert et al.", "PublicationYear": "2000", "Authors": ["Liesi E. Hebert", "Robert S. Wilson", "David William Gilley", "Laurel A Beckett", "Paul A. Scherr", "David A. Bennett", "Denis A. Evans"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["83075765a2ecf09c32930afb66959693ab94ca91", "1b3abeb45b1436eaf3bce77944fdd37ba7b0d389", "c918ad033313ace6cb412063fc9f730ed348229c", "09500e66e8674a54117221989767922be0cf673b", "255871478ee06f4fc4f238cc38c4f80b72fdda1d", "a30e1d7809b3ce3fecc6dbdc1dd0ff8e39270406", "754bfedefcd2faf951660c069f7bb6aaff5085a9", "1a2f9ef54e65ed753e41d92a89171e3e7e7b8d60", "5b9ce664d7f8350f89faf508756b8bf47491feaa", "1d4df887bf845d17ef70f71432c4bf61c327ede0"], "ReferenceCount": 32, "CitationCount": 50}, {"URL": "https://www.semanticscholar.org/paper/Neuropsychological-evidence-for-multiple-implicit-a-Heindel-Salmon/543292e3965e681b322c86204a545e3ac915fef2", "ID": "543292e3965e681b322c86204a545e3ac915fef2", "Title": "Neuropsychological evidence for multiple implicit memory systems: a comparison of Alzheimer's, Huntington's, and Parkinson's disease patients", "Abstract": "The results for the PD patients suggest that the demented PD patients have endured damage to the neurologic systems subserving both motor learning and lexical priming. The performances of patients with dementia of the Alzheimer type (DAT), patients with Huntington's disease (HD), and demented and nondemented patients with Parkinson's disease (PD) were compared on 2 tests of implicit memory that do not require the conscious recollection of prior study episodes: (1) a pursuit-rotor motor learning task and (2) a lexical priming test. The HD patients were found to be impaired on the motor learning but not the lexical priming task, whereas the DAT patients evidenced the opposite relationship on these tasks. The demented, but not the nondemented, PD patients were found to be impaired on both tests of implicit memory. For both the HD and PD patients, deficits on the motor learning task correlated significantly with severity of dementia but not with level of primary motor dysfunction. The noted double dissociation between HD and DAT patients indicates that different forms of implicit memory, all of which are intact in amnesia, are dependent upon distinct neuroanatomic systems. Motor skill learning may be mediated by a corticostriatal system, whereas verbal priming may depend upon the integrity of the neocortical association areas involved in the storage of semantic knowledge. The results for the PD patients suggest that the demented PD patients have endured damage to the neurologic systems subserving both motor learning and lexical priming.", "PublicationYear": "1989", "Authors": ["W. Heindel", "DP Salmon", "CW Shults", "Patricia Ann Walicke", "Nelson M. Butters"], "RelatedTopics": ["Psychology", "Medicine"], "References": ["f58e383c36aaa7a519431c1e65664a94d6ec638a", "8c4aa1f000510f02fce9b13661b09d370fd9f3cf", "4a73956a23db9744a5c1244a4dc288833a086e96", "181b5552cdd586a39b4772aa9c9c86a6d1c30018", "7119a99bfda3d9b631e07fa87102d7970fb5dd2c", "19f2578e2b9bc8c5b810168cc7e460f980c6c594", "33bfcb05cbaf957d5ce8318a6f42fd03a5c1cfc7", "89e3af842e97f6442dc295bc75506bd481563e3e", "3bdb8e18ac87cc8bbcc6aaab231a5f89d615c48d", "7826941ac43f6effe9519791eea6bef2aa83f7f0"], "ReferenceCount": 35, "CitationCount": 612}, {"URL": "https://www.semanticscholar.org/paper/THIS-SPACE-MUST-BE-KEPT-BLANK)-Machine-Learning-for-Williams-Weakley/6eef856f1276c7f77c1d1c3aeb7e0bafcce512f1", "ID": "6eef856f1276c7f77c1d1c3aeb7e0bafcce512f1", "Title": "THIS SPACE MUST BE KEPT BLANK) Machine Learning Techniques for Diagnostic Differentiation of Mild Cognitive Impairment and Dementia", "Abstract": "Artificial intelligence techniques can be used to automate aspects of clinical diagnosis of individuals with cognitive impairment through the implementation of four machine learning algorithms and a feature selection method for reducing the number of neuropsychological and demographic data needed to make an accurate diagnosis. Detection of cognitive impairment, especially at the early stages, is critical. Such detection has traditionally been performed manually by one or more clinicians based on reports and test results. Machine learning algorithms offer an alternative method of detection that may provide an automated process and valuable insights into diagnosis and classification. In this paper, we explore the use of neuropsychological and demographic data to predict Clinical Dementia Rating (CDR) scores (no dementia, very mild dementia, dementia) and clinical diagnoses (cognitively healthy, mild cognitive impairment, dementia) through the implementation of four machine learning algorithms, naive Bayes (NB), C4.5 decision tree (DT), back-propagation neural network (NN), and support vector machine (SVM). Additionally, a feature selection method for reducing the number of neuropsychological and demographic data needed to make an accurate diagnosis was investigated. The NB classifier provided the best accuracies, while the SVM classifier proved to offer some of the lowest accuracies. We also illustrate that with the use of feature selection, accuracies can be improved. The experiments reported in this paper indicate that artificial intelligence techniques can be used to automate aspects of clinical diagnosis of individuals with cognitive impairment.", "PublicationYear": "2013", "Authors": ["Jennifer A. Williams", "Alyssa Weakley", "Diane Joyce Cook", "Maureen Schmitter-Edgecombe"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["28d7972832f52a5b39df9a5e4d26146e341fffe0", "6a52446c66bac33e0c34947b792c1a0a1dd31426", "6fcbf100eb09852c645ca20e04aafa37b1fe4536", "21c69136d138348e4ac9a6016a0222a53d457bb3", "f63f357a92d627b8b05ed783af8f2dd8c42d2006", "649a751380a2761a0d75ccac34d6461a2fed1f31", "8154596ec29309c701e7f8063ff61810cde22093", "52c2dee3d5ed4f28daa768991a21efef0f390e55", "0192d431781e3318e4f2f9f89dc73968dfadff21", "e44bcf15ba62d85334cad564d9eaf20c160e0fec"], "ReferenceCount": 30, "CitationCount": 24}, {"URL": "https://www.semanticscholar.org/paper/Machine-learning-approaches-to-diagnosis-and-in-Garrard-Rentoumi/cc435c9efd3a6454c150ab781dadc7f4fc5c8e9d", "ID": "cc435c9efd3a6454c150ab781dadc7f4fc5c8e9d", "Title": "Machine learning approaches to diagnosis and laterality effects in semantic dementia discourse", "Abstract": "Semantic Scholar extracted view of \\\"Machine learning approaches to diagnosis and laterality effects in semantic dementia discourse\\\" by P. Garrard et al.", "PublicationYear": "2014", "Authors": ["Peter Garrard", "Vassiliki Rentoumi", "Benno Gesierich", "Bruce L. Miller", "Maria Luisa Gorno-Tempini"], "RelatedTopics": ["Computer Science", "Medicine"], "References": ["c58a3a9900c783fc19043e270339c1769dfbd9bd", "3c24d224879361a1dacb277c5318e2c18af6962d", "2a1b1911329a5d036469b3f94f3f2f0bc764a1f3", "a636e2fae09f34821421c57a2aa2499ccf30f580", "6721962c1ff7d1925ef29d864a1e48014d0105ce", "6b20af22b0734757d9ead382b201a65f9dd637cc", "c11125f8ee935fdd2494c20e84ea80acece44c29", "544010adfd9a50394fb66ee08236fa5c22d2bcc8", "5c1a1c74216e0e8e08271a6857752177e1f507ad", "5940b3698b69bc7f78a5161db24cf39ceefc46d9"], "ReferenceCount": 37, "CitationCount": 86}, {"URL": "https://www.semanticscholar.org/paper/Computerized-assessment-of-syntactic-complexity-in-Pakhomov-Chac%C3%B3n/0959830b666ec7871b547a486076a706571c3e5a", "ID": "0959830b666ec7871b547a486076a706571c3e5a", "Title": "Computerized assessment of syntactic complexity in Alzheimer\u2019s disease: a case study of Iris Murdoch\u2019s writing", "Abstract": "Computerized Linguistic Analysis System (CLAS) is a fully automated system that may be used to derive objective and reproducible measures of syntactic complexity in language production and can be particularly useful in longitudinal studies with large volumes of language samples. Currently, the majority of investigations of linguistic manifestations of neurodegenerative disorders such as Alzheimer\u2019s disease are conducted based on manual linguistic analysis. Grammatical complexity is one of the language use characteristics sensitive to the effects of Alzheimer\u2019s disease and is difficult to operationalize and measure using manual approaches. In the current study, we demonstrate the application of computational linguistic methods to automate the analysis of grammatical complexity. We implemented the Computerized Linguistic Analysis System (CLAS) based on the Stanford syntactic parser (Klein and Manning, Pattern Recognition, 38(9), 1407\u20131419, 2005) for longitudinal analysis of changes in syntactic complexity in language affected by neurodegenerative disorders. We manually validated CLAS scoring and used it to analyze writings of Iris Murdoch, a renowned Irish author diagnosed with Alzheimer\u2019s disease. We found clear patterns of decline in grammatical complexity consistent with previous analyses of Murdoch\u2019s writing conducted by Garrard, Maloney, Hodges, and Patterson (Brain, 128(250\u2013260, 2005). CLAS is a fully automated system that may be used to derive objective and reproducible measures of syntactic complexity in language production and can be particularly useful in longitudinal studies with large volumes of language samples.", "PublicationYear": "2011", "Authors": ["Serguei V. S. Pakhomov", "Dustin Alfonso Chac{\\'o}n", "Mark Wicklund", "Jeanette K. Gundel"], "RelatedTopics": ["Computer Science", "Linguistics", "Medicine"], "References": ["d634adcb9d65f8636b0f37f90797cc354b2a5e91", "aff0b8b4c097520cb45e307c2f32f6235cabb1f2", "46f0853ef3c9de611493ce36b2fa24ff4b5a5aaf", "bb3f9849fe5350df576d7a6dfd3cb87c433d0c68", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "4a5314fa5f521e78b0ef360369e6c62d37d6dbb2", "62907d088f82abe73c5f9d663d35f24d56fc062d", "6fa90c9af69f66fe653fab1d983b23cec13d4acf", "7670373c12530269f790ac851c0e1d1716b2b84b", "7083a1e5f9459fab1c1ca810cf1280a4fb47ea40"], "ReferenceCount": 30, "CitationCount": 48}, {"URL": "https://www.semanticscholar.org/paper/Machine-learning-techniques-for-building-a-model-Chen-Herskovits/6fcbf100eb09852c645ca20e04aafa37b1fe4536", "ID": "6fcbf100eb09852c645ca20e04aafa37b1fe4536", "Title": "Machine-learning techniques for building a diagnostic model for very mild dementia", "Abstract": "Semantic Scholar extracted view of \\\"Machine-learning techniques for building a diagnostic model for very mild dementia\\\" by Rong Chen et al.", "PublicationYear": "2010", "Authors": ["Rong Chen", "Edward H. Herskovits"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["3d13d6f847e8f4c76c5a8d6f99fa49dbabe473c0", "5a05f55d60af3aa9fa60f684769d33edea78cb5c", "f9ce33d283a84db5eb837abcefbf7b5c7eedb4ae", "923a93fcee81dfc8aac93250abed126e87b2df32", "755d868d0db9ee34aada6e15b232089e42eb63e5", "52bb7c5d679b75b0e4cd980274c931c0ac65fb90", "823cbb5121e222c55452a765f2c9a8f921f3cddf", "dbe3574e25feb5691a1e904dda6cfb9c4dded610", "c59b33946813e99f48e8f17ed027735d4bd59a23", "08bf9959671ffc698491b66ef3ff0a3b6d685e85"], "ReferenceCount": 44, "CitationCount": 75}, {"URL": "https://www.semanticscholar.org/paper/Accuracy-of-dementia-diagnosis%E2%80%94a-direct-comparison-Kl%C3%B6ppel-Stonnington/e729730d5f69c9af97c4e3748297e37e057fd55f", "ID": "e729730d5f69c9af97c4e3748297e37e057fd55f", "Title": "Accuracy of dementia diagnosis\u2014a direct comparison between radiologists and a computerized method", "Abstract": "The results show that well-trained neuroradiologists classify typical Alzheimer's disease-associated scans comparable to SVMs, and indicate a role for computerized diagnostic methods in clinical practice. There has been recent interest in the application of machine learning techniques to neuroimaging-based diagnosis. These methods promise fully automated, standard PC-based clinical decisions, unbiased by variable radiological expertise. We recently used support vector machines (SVMs) to separate sporadic Alzheimer's disease from normal ageing and from fronto-temporal lobar degeneration (FTLD). In this study, we compare the results to those obtained by radiologists. A binary diagnostic classification was made by six radiologists with different levels of experience on the same scans and information that had been previously analysed with SVM. SVMs correctly classified 95% (sensitivity/specificity: 95/95) of sporadic Alzheimer's disease and controls into their respective groups. Radiologists correctly classified 65\u201395% (median 89%; sensitivity/specificity: 88/90) of scans. SVM correctly classified another set of sporadic Alzheimer's disease in 93% (sensitivity/specificity: 100/86) of cases, whereas radiologists ranged between 80% and 90% (median 83%; sensitivity/specificity: 80/85). SVMs were better at separating patients with sporadic Alzheimer's disease from those with FTLD (SVM 89%; sensitivity/specificity: 83/95; compared to radiological range from 63% to 83%; median 71%; sensitivity/specificity: 64/76). Radiologists were always accurate when they reported a high degree of diagnostic confidence. The results show that well-trained neuroradiologists classify typical Alzheimer's disease-associated scans comparable to SVMs. However, SVMs require no expert knowledge and trained SVMs can readily be exchanged between centres for use in diagnostic classification. These results are encouraging and indicate a role for computerized diagnostic methods in clinical practice.", "PublicationYear": "2008", "Authors": ["Stefan Kl{\\\"o}ppel", "Cynthia M. Stonnington", "Josephine Barnes", "F Chen", "Carlton Chu", "Catriona D. Good", "Irina Mader", "L. Anne Mitchell", "Ameet C Patel", "Catherine C. Roberts", "Nick C Fox", "Clifford R. Jack", "John Ashburner", "Richard S. J. Frackowiak"], "RelatedTopics": ["Medicine", "Computer Science"], "References": ["3d13d6f847e8f4c76c5a8d6f99fa49dbabe473c0", "4b84df3980b67ccf4090d1e32752af86ef308d86", "5a05f55d60af3aa9fa60f684769d33edea78cb5c", "01efbaff61bc915619f4c6f567efefb819fb38fc", "840071c12733df5408b2b5e304ddbb3092b273ef", "736229a589f477806668325d7d5d1ce13cb5e67e", "52bb7c5d679b75b0e4cd980274c931c0ac65fb90", "9e42d60bbb064521d08fa48b4a0775f1456fc595", "253eabc59a6440761cd5dbdebb05048eb91688ea", "e4c189b2b1ef5d4e3b2633d2fbfa28e200fa6e70"], "ReferenceCount": 29, "CitationCount": 255}, {"URL": "https://www.semanticscholar.org/paper/%5BAlzheimer's-disease-and-vascular-dementia%5D.-Nagata/8e361ca7c689d70c8ea16d42be37e333f051e25a", "ID": "8e361ca7c689d70c8ea16d42be37e333f051e25a", "Title": "[Alzheimer's disease and vascular dementia].", "Abstract": "The term \\\"AD with CVD\\\" has been used to classify patients fulfilling the clinical criteria for possible AD and who also present clinical or brain imaging evidence of relevant CVD. Alzheimer's disease (AD) and vascular dementia (VaD) are the two major forms of dementia in the elderly, and they had been separated categorically on the basis of pathogenetic mechanisms and clinical operationalized criteria. However, it was claimed that this strict separation might steered toward the overdiagnosis of vascular dementia, this dichotomy has been reevaluated in the light of recent epidemiological and neuropathological knowledge. Cerebrovascular disease (CVD) is now considered as one of the vascular risk factors to the onset and evolution of Alzheimer's disease. Futhermore, the term \\\"AD with CVD\\\" has been used to classify patients fulfilling the clinical criteria for possible AD and who also present clinical or brain imaging evidence of relevant CVD.", "PublicationYear": "2014", "Authors": ["Ken Nagata"], "RelatedTopics": ["Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 120}, {"URL": "https://www.semanticscholar.org/paper/Microlinguistic-aspects-of-the-oral-narrative-in-Lira-Ortiz/4def26f02218aff759e752870ee9d5f76d00e17c", "ID": "4def26f02218aff759e752870ee9d5f76d00e17c", "Title": "Microlinguistic aspects of the oral narrative in patients with Alzheimer's disease", "Abstract": "Performance in microlinguistics at the lexical and syntactic levels was lower than expected in participants with AD, indicating changes in the discourse of AD patients. ABSTRACT Background: Alzheimer's disease (AD) is characterized by memory loss and cognitive impairment. Phonological, syntactic, semantic and discursive aspects of language may also be affected. Analysis of micro- and macrolinguistic abilities of discourse may assist in diagnosing AD. The aim of this study was to identify changes in the discourse (lexical errors and syntactic index) of AD patients. Methods: 121 elderly subjects narrated a story based on a seven-figure picture description. Results: Patients with AD presented more word-finding difficulties, revisions and repetitions, and the syntactic index was lower than controls. Conclusion: Performance in microlinguistics at the lexical and syntactic levels was lower than expected in participants with AD.", "PublicationYear": "2010", "Authors": ["Juliana Onofre DE Lira", "Karin Zazo Ortiz", "Aline Carvalho Campanha", "Paulo Henrique Ferreira Bertolucci", "Tha{\\'i}s Minett"], "RelatedTopics": ["Medicine", "Linguistics"], "References": ["a5e043075186b750ce5c3f2c6de629c0e69b1f33", "8b4068bb9a4ac55eea6899fea9098e56f9064550", "c1ce0f32db5d096b583a8d5e0af6949cf44c928a", "b624573a0c572ca6e85f92991544aa9e1a518bcf", "97f1d23c912ba12aa117e9de4e5f1b02749b5aa8", "914e830bb7065964e14fab4bb98a4d86a5198fd9", "1e1c868e54592b3da0a05ed0d17d137cee4a662e", "bb3f9849fe5350df576d7a6dfd3cb87c433d0c68", "633bb493c206a268b09203d675478ef82faabddb", "fbcb81e3c1f8a13f4c047a3bb50fdc6c81bfc08c"], "ReferenceCount": 40, "CitationCount": 105}, {"URL": "https://www.semanticscholar.org/paper/Alzheimer's-disease-and-vascular-dementia-in-and-Kalaria-Maestre/94ff6ac108cc105c578f838df2f814c1dfac976c", "ID": "94ff6ac108cc105c578f838df2f814c1dfac976c", "Title": "Alzheimer's disease and vascular dementia in developing countries: prevalence, management, and risk factors", "Abstract": "Semantic Scholar extracted view of \\\"Alzheimer's disease and vascular dementia in developing countries: prevalence, management, and risk factors\\\" by R. Kalaria et al.", "PublicationYear": "2008", "Authors": ["Raj N. Kalaria", "Gladys E. Maestre", "Raul L Arizaga", "Robert P Friedland", "Douglas R. Galasko", "Kathleen Steele Hall", "Jos{\\'e} A. Luchsinger", "Adesola Ogunniyi", "Elaine K. Perry", "Felix Potocnik", "Martin James Prince", "Robert Stewart", "Anders Wimo", "Zhenxin Zhang", "Piero Antuono"], "RelatedTopics": ["Medicine"], "References": ["80636c276e94c189f7545b60b85aabd6ead6b90d", "a37d621b26fb1ffef2644699187fc5ee1de5505c", "8bee9d3f6dd1082f347b3fd4c8ea930d1436a437", "56425788a12221b24e7acf13adba92f5993a2352", "30e79c7c7dd6709abde9ae0b40a72bcbc57bbbd1", "e27b823e91fbe765a52c9cde3d098967c2c7f331", "1b5d7fed0dcfd9a100854536017f38ea27a97c69", "f9533ed4857c5ded623db8802247c0610d48120c", "e31a373bc94c4485f348ff98d71acb0db0ade3fc", "20c53bd2aa4b99e63556a4634f0999bc64c82e22"], "ReferenceCount": 220, "CitationCount": 1050}, {"URL": "https://www.semanticscholar.org/paper/Comparative-Study-of-Oral-and-Written-Picture-in-Croisile-Ska/97f1d23c912ba12aa117e9de4e5f1b02749b5aa8", "ID": "97f1d23c912ba12aa117e9de4e5f1b02749b5aa8", "Title": "Comparative Study of Oral and Written Picture Description in Patients with Alzheimer's Disease", "Abstract": "Oral and written picture descriptions were compared in 22 patients with Alzheimer's disease (AD) and 24 healthy elderly subjects. AD patients had a significant reduction of all word categories, which, similarly to controls, was more pronounced in written than in oral texts. They also reported fewer information units than controls, but without task difference. At the syntactic level, written descriptions of AD subjects were characterized by a diminution of subordinate clauses and a reduction of functors. More grammatical errors were present in written descriptions by AD and control subjects. AD and control groups produced an equivalent number of semantic errors in both tasks. However, in oral description, AD patients had more word-finding difficulties. In sum, AD descriptions were always shorter and less informative than control texts. Additionally, written descriptions of AD patients appeared shorter and more syntactically simplified than, but as informative as oral descriptions. Whereas no phonemic paraphasias were observed in either group, AD patients produced many more graphemic paragraphias than controls produced. Furthermore, written descriptions had more irrelevant semantic intrusions. Thus, as compared to oral descriptions, written texts appeared to be a more reliable test of semantic and linguistics difficulties in AD.", "PublicationYear": "1996", "Authors": ["Bernard Croisile", "Bernadette Ska", "Marie-Jos{\\'e}e Brabant", "Annick Duch{\\^e}ne", "Yves Lepage", "Gilbert Aimard", "Marc Trillet"], "RelatedTopics": ["Psychology", "Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 187}, {"URL": "https://www.semanticscholar.org/paper/Distinct-Patterns-of-Spontaneous-Speech-An-Early-of-Forbes-Venneri/ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "ID": "ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "Title": "Distinct Patterns of Spontaneous Speech Deterioration: An Early Predictor of Alzheimer's Disease", "Abstract": "Performance on the simple and complex picture description task indicated that minimal AD patients and healthy controls could be differentiated on several measures of semantic processing, which points to a breakdown in lexical semantic processing earlier in the disease process than previously reported. Although distinctive patterns of language impairment have been identified in Alzheimer's Disease (AD) patients, few studies have been conducted to identify the errors that consistently differentiate minimal and mild AD patients from healthy elderly individuals. Twenty-two AD patients (11 minimal and 11 mild) and 22 age- and education-matched healthy controls, were assessed on a simple and complex picture description task. The task assessed several aspects of spontaneous speech, including melodic line, articulation, grammatical form, phrase length, paraphasias, word-finding difficulties, error monitoring, information conveyed, and information content. Although both pictures could differentiate between the AD patients and the healthy controls, results suggested that the complex task was most sensitive. Performance on the latter task indicated that minimal AD patients and healthy controls could be differentiated on several measures of semantic processing. Errors point to a breakdown in lexical semantic processing, which occurs earlier in the disease process than previously reported.", "PublicationYear": "2002", "Authors": ["Katrina E. Forbes", "Annalena Venneri", "Michael Fraser Shanks"], "RelatedTopics": ["Medicine"], "References": [], "ReferenceCount": 0, "CitationCount": 81}, {"URL": "https://www.semanticscholar.org/paper/Abnormalities-of-connected-speech-in-semantic-vs-Sajjadi-Patterson/2a75030045c68f142e834e099e6e1c591d55c56b", "ID": "2a75030045c68f142e834e099e6e1c591d55c56b", "Title": "Abnormalities of connected speech in semantic dementia vs Alzheimer's disease", "Abstract": "The results suggest that the picture description task is more sensitive to abnormalities in the semantic measures, whereas the interviews are better at exposing morpho-syntactic deficits, which could help clinicians in syndromic classification of anomic speech. Background: Neurodegenerative syndromes are associated with varying degrees of language impairment. Connected speech analysis provides the most realistic measure of language function but its use has been restricted by operational constraints. Aims: In this prospective study we assessed the relative utility of a picture description task and a semi-structured interview in exposing the language decline in semantic dementia (SD) and typical mild Alzheimer's disease (AD), compared to each other and to healthy volunteers. Methods & Procedures: Our cohort comprised 16 patients with a clinical diagnosis of SD, 20 with mild typical AD, and 30 healthy participants. All speech samples were recorded during a face-to-face interview and were subjected to a well-controlled quantitative analysis. Outcomes & Results: Our results suggest that (a) the picture description task is more sensitive to abnormalities in the semantic measures, whereas the interviews are better at exposing morpho-syntactic deficits; (b) circumlocution is not, as has sometimes been claimed, a salient feature of speech in SD; (c) increases in the frequency of hesitation markers and of phonological and syntactic errors are prominent features of language decline in mild AD; and (d) a 150-word interview sample is adequate to provide a realistic reflection of language impairment. Conclusions: This study compared, for the first time, the two most commonly used methods of eliciting connected speech and documented many similarities in results from the two but also some salient differences in their sensitivity to specific aspects of language deficit. In addition, although replicating some aspects such as anomia, of what is already known about the language impairments in these two conditions, the study provides novel findings for both that could help clinicians in syndromic classification of anomic speech.", "PublicationYear": "2012", "Authors": ["Seyed Ahmad Sajjadi", "Karalyn E Patterson", "Michal Tomek", "Peter J. Nestor"], "RelatedTopics": ["Medicine"], "References": ["8c1b832e5182071f896be1f9e7ad724b7fd0e26b", "ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "647c4649b11a92d4797950d50a8294b1beaba22b", "d4e43a0e23bf13706b9691b772d1d79e203b1451", "216e373390e16cd474442dfcb9f1eecb3a4cdc99", "e86227915c939e9a68e98415ebebebd0c5726278", "8dc4a1a9bb4c52b1b3b161e825974051740da108", "a3b6bc65831ca24a88b8ecf7277f170ecae086ee", "be246d70706f72d22fa051a4cf48818d3d24533e", "e21c24239adda62938967a981f707f63bd224aa4"], "ReferenceCount": 62, "CitationCount": 94}, {"URL": "https://www.semanticscholar.org/paper/Speech-in-Alzheimer's-Disease%3A-Can-Temporal-and-Meil%C3%A1n-Mart%C3%ADnez-S%C3%A1nchez/3720bc93ed64a447b25a2be1efafa3b6b0f8fcd5", "ID": "3720bc93ed64a447b25a2be1efafa3b6b0f8fcd5", "Title": "Speech in Alzheimer's Disease: Can Temporal and Acoustic Parameters Discriminate Dementia?", "Abstract": "These measures offer a sensitive method of assessing spontaneous speech output in AD and they discriminate well between people with AD and healthy older adults, and it could be used as a dependent measure in clinical trials. Aims: The study explores how speech measures may be linked to language profiles in participants with Alzheimer's disease (AD) and how these profiles could distinguish AD from changes associated with normal aging. Methods: We analysed simple sentences spoken by older adults with and without AD. Spectrographic analysis of temporal and acoustic characteristics was carried out using the Praat software. Results: We found that measures of speech, such as variations in the percentage of voice breaks, number of periods of voice, number of voice breaks, shimmer (amplitude perturbation quotient), and noise-to-harmonics ratio, characterise people with AD with an accuracy of 84.8%. Discussion: These measures offer a sensitive method of assessing spontaneous speech output in AD, and they discriminate well between people with AD and healthy older adults. This method of evaluation is a promising tool for AD diagnosis and prognosis, and it could be used as a dependent measure in clinical trials.", "PublicationYear": "2014", "Authors": ["Juan Jos{\\'e} G. Meil{\\'a}n", "Francisco Mart{\\'i}nez-S{\\'a}nchez", "Juan Carro", "Dolores E L{\\'o}pez", "Lymarie Millian-Morell", "Jos{\\'e} M. Arana"], "RelatedTopics": ["Medicine"], "References": ["4e037757379916f6bfa904a07c7eadfe71b67ce0", "a3b6bc65831ca24a88b8ecf7277f170ecae086ee", "5bf00c6a2a3509ad017388a3b9f4bf4b2bd8a98e", "cb42e0fc85b3d208120c8c69ca19520c8fc0a29e", "2e2714f67021e9df2b5d89d5b1330e6e3457e53e", "ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "83a9ad2ef310f6633b313155744d3838b195337b", "647c4649b11a92d4797950d50a8294b1beaba22b", "343a5ab97e47368da0aa7b50256736297cbb9ce6", "7e75adf26035f8f3f77759ea5736d18c4d84b4b8"], "ReferenceCount": 40, "CitationCount": 108}, {"URL": "https://www.semanticscholar.org/paper/Connected-speech-as-a-marker-of-disease-progression-Ahmed-Haigh/c1c33280fe9e00d8047ced66815e7232403e4ca2", "ID": "c1c33280fe9e00d8047ced66815e7232403e4ca2", "Title": "Connected speech as a marker of disease progression in autopsy-proven Alzheimer\u2019s disease", "Abstract": "The findings suggest that there is a progressive disruption in language integrity, detectable from the prodromal stage in a subset of patients with Alzheimer\u2019s disease, and that measures of semantic and lexical content and syntactic complexity best capture the global progression of linguistic impairment through the successive clinical stages of disease. Although an insidious history of episodic memory difficulty is a typical presenting symptom of Alzheimer\u2019s disease, detailed neuropsychological profiling frequently demonstrates deficits in other cognitive domains, including language. Previous studies from our group have shown that language changes may be reflected in connected speech production in the earliest stages of typical Alzheimer\u2019s disease. The aim of the present study was to identify features of connected speech that could be used to examine longitudinal profiles of impairment in Alzheimer\u2019s disease. Samples of connected speech were obtained from 15 former participants in a longitudinal cohort study of ageing and dementia, in whom Alzheimer\u2019s disease was diagnosed during life and confirmed at post-mortem. All patients met clinical and neuropsychological criteria for mild cognitive impairment between 6 and 18 months before converting to a status of probable Alzheimer\u2019s disease. In a subset of these patients neuropsychological data were available, both at the point of conversion to Alzheimer\u2019s disease, and after disease severity had progressed from the mild to moderate stage. Connected speech samples from these patients were examined at later disease stages. Spoken language samples were obtained using the Cookie Theft picture description task. Samples were analysed using measures of syntactic complexity, lexical content, speech production, fluency and semantic content. Individual case analysis revealed that subtle changes in language were evident during the prodromal stages of Alzheimer\u2019s disease, with two-thirds of patients with mild cognitive impairment showing significant but heterogeneous changes in connected speech. However, impairments at the mild cognitive impairment stage did not necessarily entail deficits at mild or moderate stages of disease, suggesting non-language influences on some aspects of performance. Subsequent examination of these measures revealed significant linear trends over the three stages of disease in syntactic complexity, semantic and lexical content. The findings suggest, first, that there is a progressive disruption in language integrity, detectable from the prodromal stage in a subset of patients with Alzheimer\u2019s disease, and secondly that measures of semantic and lexical content and syntactic complexity best capture the global progression of linguistic impairment through the successive clinical stages of disease. The identification of disease-specific language impairment in prodromal Alzheimer\u2019s disease could enhance clinicians\u2019 ability to distinguish probable Alzheimer\u2019s disease from changes attributable to ageing, while longitudinal assessment could provide a simple approach to disease monitoring in therapeutic trials.", "PublicationYear": "2013", "Authors": ["Samrah Ahmed", "Anne-Marie Haigh", "Celeste A. de Jager", "Peter Garrard"], "RelatedTopics": ["Medicine"], "References": ["c11125f8ee935fdd2494c20e84ea80acece44c29", "e98de1db3a6159d0ada3312fc6e51116c3ad6873", "074a31b5599a3deebb869a0ded54ddccf86c5655", "1bb94d5f567071985b17cc117e6f59ad857aec55", "044a2b8c2f1bbf16b704f4a0b414ed23a3c975fe", "647c4649b11a92d4797950d50a8294b1beaba22b", "ccb63ef5e97479bbd003c6c6df3e7c1527bbc9da", "50bb1f61e17ca26ce64db8193b690e6f545e9c12", "216e373390e16cd474442dfcb9f1eecb3a4cdc99", "1cef879322a9717a7b9cccd1891465609bcbb98b"], "ReferenceCount": 46, "CitationCount": 241}, {"URL": "https://www.semanticscholar.org/paper/Analysis-of-spontaneous%2C-conversational-speech-in-Bucks-Singh/3d0bffdf62b34efbd2535a9c6b72289306d12511", "ID": "3d0bffdf62b34efbd2535a9c6b72289306d12511", "Title": "Analysis of spontaneous, conversational speech in dementia of Alzheimer type: Evaluation of an objective technique for analysing lexical performance", "Abstract": "Spontaneous, conversational speech in probable dementia of Alzheimer type participants and healthy older controls was analysed using eight linguistic measures and it is suggested that these measures offer a sensitive method of assessing spontaneous speech output in DAT. Spontaneous, conversational speech in probable dementia of Alzheimer type (DAT) participants and healthy older controls was analysed using eight linguistic measures. These were evaluated for their usefulness in discriminating between healthy and demented individuals. The measures were; noun rate, pronounrate, verb rate, adjective rate, clause-like semantic unit rate (all per 100 words), including three lexical richness measures; type token ratio (TTR), Brunet's Index (W) and Honore's statistic (R). Results suggest that these measures offer a sensitive method of assessing spontaneous speech output in DAT. Comparison between DAT and healthy older participants demonstrates that these measures discriminate well between these groups. This method shows promise as a diagnostic and prognostic tool, and as a measure for use in clinical trials. Further validation in a large sample of patient versus control \u2018norms\u2019 in addition to evaluation in other types of dementia is considered.", "PublicationYear": "2000", "Authors": ["Romola S. Bucks", "Sameer Singh", "Joanne M. Cuerden", "G. K. Wilcock"], "RelatedTopics": ["Medicine", "Linguistics"], "References": ["b624573a0c572ca6e85f92991544aa9e1a518bcf", "4a5314fa5f521e78b0ef360369e6c62d37d6dbb2", "a7e7eab437ab096509a3bfeb57c00dfa32d306c5", "e18ab9b0459de67aeec1f28c068bfbed9f1a5ddc", "e7669ce4efce1c3917caaf5aca51953b58080c96", "83a9ad2ef310f6633b313155744d3838b195337b", "6b4115a258857c16ae717f3e46cb8e47c5babcb8", "c1ce0f32db5d096b583a8d5e0af6949cf44c928a", "33192c6378b46f9e7c7f46eb365bf3a2679cf4aa", "2f110ef79582a12bcf360bd73fcc6a7bdc81e6fe"], "ReferenceCount": 97, "CitationCount": 208}, {"URL": "https://www.semanticscholar.org/paper/Detecting-subtle-spontaneous-language-decline-in-a-Forbes-McKay-Venneri/647c4649b11a92d4797950d50a8294b1beaba22b", "ID": "647c4649b11a92d4797950d50a8294b1beaba22b", "Title": "Detecting subtle spontaneous language decline in early Alzheimer\u2019s disease with a picture description task", "Abstract": "Prospective assessment of spontaneous language skills with a picture description task is useful to detect those subtle spontaneous language impairments caused by AD even at an early stage of the disease. The objective was to collect normative data for a simple and a complex version of a picture description task devised to assess spontaneous speech and writing skills in patients with Alzheimer\u2019s disease (AD), and to test whether some aspects of spontaneous language can discriminate between normal and pathological cognitive decline. Two hundred and forty English-speaking healthy volunteers were recruited to participate in this normative study. Thirty patients with a clinical diagnosis of minimal to moderate probable AD were also recruited. Age and education influenced some aspects of spontaneous oral and written language whereas sex had no influence on any of the variables assessed. A high proportion (&gt;70%) of AD patients performed below cut-off on those scales that measured semantic processing skills. Deficits were detected even amongst those in the very early stage of the disease when the complex version of the task was used. Prospective assessment of spontaneous language skills with a picture description task is useful to detect those subtle spontaneous language impairments caused by AD even at an early stage of the disease.", "PublicationYear": "2005", "Authors": ["Katrina E Forbes-McKay", "Annalena Venneri", "Annalena Venneri"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["ddf91e966b6309929d67ae6b08b12ef26b9eb00d", "216e373390e16cd474442dfcb9f1eecb3a4cdc99", "1347fe86c8d92cb76f475335aed0198a1d45a220", "a6274320c4e012a6bbde8f56a2dbc33c25255402", "c15bba8cfbe6a1ea7e23442cf4f8fab7d4e16951", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "6b4115a258857c16ae717f3e46cb8e47c5babcb8", "726be3231996cbe4fb35b3c9975a002aa0d1b2f1", "3f800154262d3e8d916abbf6fc0769c9b5885741", "97f1d23c912ba12aa117e9de4e5f1b02749b5aa8"], "ReferenceCount": 27, "CitationCount": 219}, {"URL": "https://www.semanticscholar.org/paper/Semantic-processing-in-connected-speech-at-a-early-Ahmed-Jager/bdd7750c5be25be75e39c7ff0c383ff50065acbf", "ID": "bdd7750c5be25be75e39c7ff0c383ff50065acbf", "Title": "Semantic processing in connected speech at a uniformly early stage of autopsy-confirmed Alzheimer's disease.", "Abstract": "The present study adds a lexico-semantic dimension to the linguistic profile based on discourse analysis in typical AD, recently described by the same authors. OBJECTIVE\\nThe aim of the present study was to quantify the semantic content of connected speech produced by patients at a uniformly early stage of pathologically proven Alzheimer's disease (AD). A secondary aim was to establish whether semantic units were reduced globally, or whether there was a disproportionate reduction of specific classes of information.\\n\\n\\nMETHOD\\nDiscourse samples were obtained from 18 AD patients and 18 matched controls, all pathologically confirmed. Semantic unit identification was scored overall and for four subclasses: subjects, locations, objects, and actions. Idea density and efficiency were calculated.\\n\\n\\nRESULTS\\nAD transcripts showed significantly reduced units overall, particularly actions and subjects, as well as reduced efficiency. Total semantic units and a combination of subject-, location-, and object-related units (\\\"noun\\\" units) correlated with the Expression subscore on the Cambridge Cognitive Examination (CAMCOG). Subject related units correlated with the CAMCOG Abstract Thinking scale. Logistic regression analyses confirmed that all measures that were lower in AD than controls were predictive of group membership. An exploratory comparison between units expressed mainly using nouns and those mainly using verbs showed that the latter was the stronger of these two predictors.\\n\\n\\nCONCLUSIONS\\nThe present study adds a lexico-semantic dimension to the linguistic profile based on discourse analysis in typical AD, recently described by the same authors. 2012, 83(11): 1056-1062). The suggestion of differential importance of verb and noun use in the present study may be related to the reduction in syntactic complexity that was reported, using the same set of discourse samples, in the earlier study.", "PublicationYear": "2013", "Authors": ["Samrah Ahmed", "Celeste A. de Jager", "Anne-Marie Haigh", "Peter Garrard"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["c11125f8ee935fdd2494c20e84ea80acece44c29", "27936d91df78a6b97aa868127d35003b3cb317f7", "1d01c8a50bdc7d97d8638fc1ff591966050b800a", "97f1d23c912ba12aa117e9de4e5f1b02749b5aa8", "6b4115a258857c16ae717f3e46cb8e47c5babcb8", "c705c9be9e8debdc40a30d637a4b533b7e4fc390", "216e373390e16cd474442dfcb9f1eecb3a4cdc99", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "f68911713ecc7e7b8c1e181585b912bdd27da209", "348a734692f7bfab54816fc882c13e489b6d25d0"], "ReferenceCount": 29, "CitationCount": 73}, {"URL": "https://www.semanticscholar.org/paper/Language-Analysis-of-Speakers-with-Dementia-of-the-Guinn-Habash/f402db195032286e8a715e531aca1357ac6f4b3a", "ID": "f402db195032286e8a715e531aca1357ac6f4b3a", "Title": "Language Analysis of Speakers with Dementia of the Alzheimer's Type", "Abstract": "Results from the analysis indicate that go-ahead utterances, certain fluency measures, and paraphrasing provide defensible means of differentiating the linguistic characteristics of spontaneous speech between healthy individuals and those with Alzheimer\u2019s disease. This research is a discriminative analysis of conversational dialogs involving individuals suffering from dementia of Alzheimer\u2019s type. Several metric analyses are applied to the transcripts of the Carolina Conversation Corpus (Pope and Davis 2011) in order to determine if there are significant statistical differences between individuals with and without Alzheimer\u2019s disease. Results from the analysis indicate that go-ahead utterances, certain fluency measures, and paraphrasing provide defensible means of differentiating the linguistic characteristics of spontaneous speech between healthy individuals and those with Alzheimer\u2019s disease. Several machine learning algorithms were used to classify the speech of individuals with and without dementia of the Alzheimer\u2019s type.", "PublicationYear": "2012", "Authors": ["Curry I. Guinn", "Anthony Habash"], "RelatedTopics": ["Medicine", "Computer Science", "Linguistics"], "References": ["3d0bffdf62b34efbd2535a9c6b72289306d12511", "d81a01eccef04be18e061fa515109713fa1ca42d", "577c752f3df4e6bb44f7f78f5950bc4247b9a11e", "9a2988387c721251866cf343360609a0f2c3a2ba", "a2da043fa9ef085386f56ee9869f44ce3809d0fc", "db3b1d08880fb33145f853932a6c80083a72b5c7", "491d4fd4feb96d5e79c7a7488050e7c3bcedd0b8", "73e2df755908a4ebd801339717e25bf5f737244e", "6ae18fd486195a992b9508a4392c5e8a880ba0a3", "493c66214eb6ff66040538192bdad398e6cf1a50"], "ReferenceCount": 35, "CitationCount": 67}, {"URL": "https://www.semanticscholar.org/paper/Pattern-of-language-impairment-is-different-in-and-Kontiola-Laaksonen/addce4c2a2b9a8fa7fe2851824b860aae919cc26", "ID": "addce4c2a2b9a8fa7fe2851824b860aae919cc26", "Title": "Pattern of language impairment is different in Alzheimer's disease and multi-infarct dementia", "Abstract": "Semantic Scholar extracted view of \\\"Pattern of language impairment is different in Alzheimer's disease and multi-infarct dementia\\\" by P\u00e4ivi Kontiola et al.", "PublicationYear": "1990", "Authors": ["P{\\\"a}ivi Kontiola", "Ritva K. Laaksonen", "Raimo O Sulkava", "Timo Erkinjuntti"], "RelatedTopics": ["Medicine"], "References": ["6e55c5bb30a0356ac8c853658c2c628e4fe0f7c8", "d8288a89916cc3685b8e25eb10e4cd6565206545", "e7669ce4efce1c3917caaf5aca51953b58080c96", "b50cdb9d179fb9905f3bd8efade58a8d0da2e8de", "e4208fb3ffc347e566789994b7e893b549f461a5", "6b4115a258857c16ae717f3e46cb8e47c5babcb8", "57be6981ef942a0f2505dbd2b092051c71668711", "bb1614d50c6535403b49617d412120fd3f723514", "1757d7d3f803c2c250121f070a9fd3f335c4b6fe", "8253a59999dbc65d72b532804bbfdc37628f0e4b"], "ReferenceCount": 32, "CitationCount": 85}, {"URL": "https://www.semanticscholar.org/paper/Logopenic-aphasia-in-Alzheimer's-disease%3A-Clinical-Ahmed-Jager/c11125f8ee935fdd2494c20e84ea80acece44c29", "ID": "c11125f8ee935fdd2494c20e84ea80acece44c29", "Title": "Logopenic aphasia in Alzheimer's disease: Clinical variant or clinical feature?", "Abstract": "Semantic Scholar extracted view of \\\"Logopenic aphasia in Alzheimer's disease: Clinical variant or clinical feature?\\\" by Samrah Ahmed et al.", "PublicationYear": "2012", "Authors": ["Samrah Ahmed", "Celeste de Jager", "Anne-Marie Haigh", "Peter Garrard"], "RelatedTopics": ["Medicine"], "References": ["6ee185718834a8757e68f8d96e8eee804d0cfc4d", "ad4dc43f0cf457f09bd90b30061d9f12e00b1979", "e98de1db3a6159d0ada3312fc6e51116c3ad6873", "74a7ea6726bc012eba8ff9d8566547b1476eaf8d", "60263cf072315ae94fc893b79675dc48dcf3b4a4", "00824afc1d6557949776849c48c5dd285587717d", "d67dc6d1be10878889e9d3c0e4b5cd04c1f27cc5", "074a31b5599a3deebb869a0ded54ddccf86c5655", "5c1a1c74216e0e8e08271a6857752177e1f507ad", "f6fa551a35f97a7672b5b101dd91ed3bdebc3f0d"], "ReferenceCount": 42, "CitationCount": 78}, {"URL": "https://www.semanticscholar.org/paper/Common-Pattern-of-Language-Impairment-in-Vascular-Vuorinen-Laine/216e373390e16cd474442dfcb9f1eecb3a4cdc99", "ID": "216e373390e16cd474442dfcb9f1eecb3a4cdc99", "Title": "Common Pattern of Language Impairment in Vascular Dementia and in Alzheimer Disease", "Abstract": "Language impairment in vascular dementia resembles that observed in Alzheimer disease, and semantically mediated functions are among the most sensitive language measures in differentiating early stages of both vascular dementia and Alzheimer disease from normal aging. The authors studied language performance patterns in early stages of vascular dementia and Alzheimer disease. The objective was to clarify to what extent dissolution of language in vascular dementia is similar to that in Alzheimer disease. Both structured language tests (comprehension, repetition, reading, and naming tasks) and nonstructured language tests (object and picture description) were employed. The structured tasks evidenced impairment on complex auditory comprehension and on picture naming for both dementia groups, whereas oral reading and single word repetition did not differentiate the patients from matched control subjects. On the unstructured narrative tasks, both patient groups showed normal fluency, but content analysis revealed that the patients with dementia produced fewer semantic units (themes) than the control subjects. In summary, both patient groups showed impairment, specifically on semantically mediated language tasks. According to the present results, language impairment in vascular dementia resembles that observed in Alzheimer disease. Semantically mediated functions are among the most sensitive language measures in differentiating early stages of both vascular dementia and Alzheimer disease from normal aging.", "PublicationYear": "2000", "Authors": ["Elina Vuorinen", "Matti Laine", "Juha O. Rinne"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["addce4c2a2b9a8fa7fe2851824b860aae919cc26", "b802b8e71375fa20db302d7c39ae5c48e61550ae", "6b4115a258857c16ae717f3e46cb8e47c5babcb8", "8c4aa1f000510f02fce9b13661b09d370fd9f3cf", "6e55c5bb30a0356ac8c853658c2c628e4fe0f7c8", "815b7476a58e451422da4a9a932468bf7341ac6a", "b50cdb9d179fb9905f3bd8efade58a8d0da2e8de", "650d53d24fc94aa12e8b11f957c922bcacb3b7bd", "935ab929a5db8cbbc0a07bd93e605a5545d6a801", "1361c8be38a4bdc85c2d7fc0a1786941de3a8f3f"], "ReferenceCount": 28, "CitationCount": 97}, {"URL": "https://www.semanticscholar.org/paper/Speech-and-language-alterations-in-multi%E2%80%90infarct-Powell-Cummings/b50cdb9d179fb9905f3bd8efade58a8d0da2e8de", "ID": "b50cdb9d179fb9905f3bd8efade58a8d0da2e8de", "Title": "Speech and language alterations in multi\u2010infarct dementia", "Abstract": "Speech and language functions were assessed in patients with multi-infarct dementia and patients with dementia of the Alzheimer type to demonstrate that speech and language differ in MID and DAT. Speech and language functions were assessed in 18 patients with multi-infarct dementia (MID) and 14 with dementia of the Alzheimer type (DAT). The age range and dementia severity of the two groups were comparable. We used a speech and language battery assessing 37 elements of verbal output to characterize alterations in the patients. MID patients had more abnormalities of motor aspects of speech, whereas DAT patients had empty speech, more marked anomia, and relative sparing of motor speech functions. The results demonstrate that speech and language differ in MID and DAT. In addition, MID patients exhibited common clinical features despite the heterogeneity of the syndrome.", "PublicationYear": "1988", "Authors": ["Artiss L. Powell", "Jeffrey L. Cummings", "Mary Ann Hill", "D. Frank Benson"], "RelatedTopics": ["Medicine"], "References": ["1757d7d3f803c2c250121f070a9fd3f335c4b6fe", "63668639aa8466e7468b90dc24863b53d9a2ebbb", "6b4115a258857c16ae717f3e46cb8e47c5babcb8", "e7669ce4efce1c3917caaf5aca51953b58080c96", "8253a59999dbc65d72b532804bbfdc37628f0e4b", "1bb94d5f567071985b17cc117e6f59ad857aec55", "2a91199a19745224e26b0f8466d8c144bd552a64", "c3f3d13af6db3859a6f51ccda3263c2cc6cc3850", "ce8e75a7f4fdfd732f9f252687d1b8ed14c28f36", "c571decde97f4bacc2ee1190888a39cb3e1d84eb"], "ReferenceCount": 21, "CitationCount": 64}, {"URL": "https://www.semanticscholar.org/paper/Detecting-semantic-changes-in-Alzheimer%E2%80%99s-disease-Fraser-Hirst/2da167f503f3eea7f591b672068e3ff941af53d8", "ID": "2da167f503f3eea7f591b672068e3ff941af53d8", "Title": "Detecting semantic changes in Alzheimer\u2019s disease with vector space models", "Abstract": "This work compares distributed word representations constructed from healthy controls and Alzheimer\u2019s patients, and investigates examples of words with different representations in the two spaces, to link the semantic and contextual differences to findings from the Alzheimer's disease. Numerous studies have shown that language impairments, particularly semantic deficits, are evident in the narrative speech of people with Alzheimer\u2019s disease from the earliest stages of the disease. Here, we present a novel technique for capturing those changes, by comparing distributed word representations constructed from healthy controls and Alzheimer\u2019s patients. We investigate examples of words with different representations in the two spaces, and link the semantic and contextual differences to findings from the Alzheimer\u2019s", "PublicationYear": "2016", "Authors": ["Kathleen C. Fraser", "Graeme Hirst"], "RelatedTopics": ["Medicine", "Computer Science", "Psychology"], "References": ["d25eb2bc2a3954d6d30eb0771588d723c87182fe", "bdd4aee4ea351e615eae0e4ab317bf974f1f731b", "7ee8995c0aa2829c55f2799dbf1f22a111ea2098", "c83b3a8f3460be4ab31108569c4a3334b48dd3a7", "bdd7750c5be25be75e39c7ff0c383ff50065acbf", "c1ce0f32db5d096b583a8d5e0af6949cf44c928a", "069674cfe6c8830cc101b9f5e21c9e169f81f5a7", "647c4649b11a92d4797950d50a8294b1beaba22b", "1eb8e96dcc853735fa3643d964123a364480e8ca", "4a5314fa5f521e78b0ef360369e6c62d37d6dbb2"], "ReferenceCount": 44, "CitationCount": 17}, {"URL": "https://www.semanticscholar.org/paper/Longitudinal-detection-of-dementia-through-lexical-Le-Lancashire/1e46a6d8d52c8d254706509a81748d766405dc85", "ID": "1e46a6d8d52c8d254706509a81748d766405dc85", "Title": "Longitudinal detection of dementia through lexical and syntactic changes in writing: a case study of three British novelists", "Abstract": "It is probable that Agatha Christie indeed suffered from the onset of Alzheimer's while writing her last novels, and that Iris Murdoch exhibited a 'trough' of relatively impoverished vocabulary and syntax in her writing in her late 40s and 50s that presaged her later dementia. We present a large-scale longitudinal study of lexical and syntactic changes in language in Alzheimer's disease using complete, fully parsed texts and a large number of measures, using as our subjects the British novelists Iris Murdoch (who died with Alzheimer's), Agatha Christie (who was suspected of it), and P.D. James (who has aged healthily). We avoid the limitations and deficiencies of Garrard et al.'s ((2005), The effects of very early Alzheimer's disease on the characteristics of writing by a renowned author. Brain, 128 (2): 250-60) earlier study of Iris Murdoch. Our results support the hypothesis that signs of dementia can be found in diachronic analyses of patients' writings, and in addition lead to new understanding of the work of the individual authors whom we studied. In particular, we show that it is probable that Agatha Christie indeed suffered from the onset of Alzheimer's while writing her last novels, and that Iris Murdoch exhibited a 'trough' of relatively impoverished vocabulary and syntax in her writing in her late 40s and 50s that presaged her later dementia.", "PublicationYear": "2011", "Authors": ["Xuan Le", "Ian Lancashire", "Graeme Hirst", "Regina Jokel"], "RelatedTopics": ["Medicine", "Linguistics", "Psychology"], "References": ["37d3d547cfb10f6827838dd4187c98c4140b81d6", "e0e0b6b28bb57ef022729861d07961de4051592c", "12b5dc2f3e3b3a5d486f40047d691fb7d1799bcd", "6ca330477a1509b0a5b3d1848564b954bb5e29a4", "01ad588fadddf12fe1a2f82e28c01a197b5a16e5", "bb3f9849fe5350df576d7a6dfd3cb87c433d0c68", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "6721962c1ff7d1925ef29d864a1e48014d0105ce", "650d53d24fc94aa12e8b11f957c922bcacb3b7bd", "6fa90c9af69f66fe653fab1d983b23cec13d4acf"], "ReferenceCount": 55, "CitationCount": 182}, {"URL": "https://www.semanticscholar.org/paper/Performance-on-the-Boston-Cookie-theft-picture-task-Giles-Patterson/c705c9be9e8debdc40a30d637a4b533b7e4fc390", "ID": "c705c9be9e8debdc40a30d637a4b533b7e4fc390", "Title": "Performance on the Boston Cookie theft picture description task in patients with early dementia of the Alzheimer's type: Missing information", "Abstract": "It was found that the total number of information-carrying units was the most salient variable which differentiated controls from even the minimal DAT subgroup. Abstract We report on the spoken language of 48 patients with dementia of the Alzheimer's type (DAT) who were divided into three approximately equal subgroups on the basis of the Mini-Mental State Examination (minimal 24\u201329, mild 17\u201323, and moderate 3\u201316) and 18 matched controls. The Cookie Theft picture description task from the Boston Diagnostic Aphasia Examination was chosen because it is considered an ecologically valid approximation to spontaneous discourse. All subjects were also assessed on a battery of semantic memory and non-verbal tests. Our analysis of the discourse sample focused on quantity versus information content over time, and included measures of the total number of syllables produced, the total number of information units produced, and the total time taken to describe the picture. We found that the total number of information-carrying units was the most salient variable which differentiated controls from even the minimal DAT subgroup. Moreover, information content correlated significan...", "PublicationYear": "1996", "Authors": ["Elaine Giles", "Karalyn E Patterson", "John R. Hodges"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["23df5b75a66a58476225546c63c5b53526e4e597", "5f1191ec1306c938534573f67d92aa438644d0ac", "33192c6378b46f9e7c7f46eb365bf3a2679cf4aa", "726be3231996cbe4fb35b3c9975a002aa0d1b2f1", "9208fe3a308483ffc4a4859ef01464bc0244282d", "27936d91df78a6b97aa868127d35003b3cb317f7", "1d01c8a50bdc7d97d8638fc1ff591966050b800a", "6b4115a258857c16ae717f3e46cb8e47c5babcb8", "5940b3698b69bc7f78a5161db24cf39ceefc46d9", "f6d741c533be179a7cc17479fcf1c65dd0e47948"], "ReferenceCount": 35, "CitationCount": 115}, {"URL": "https://www.semanticscholar.org/paper/GloVe%3A-Global-Vectors-for-Word-Representation-Pennington-Socher/f37e1b62a767a307c046404ca96bc140b3e68cb5", "ID": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "Title": "GloVe: Global Vectors for Word Representation", "Abstract": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure. Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.", "PublicationYear": "2014", "Authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["c4fd9c86b2b41df51a6fe212406dda81b1997fd4", "500d570ce02abf42bc1bc535620741d4c5665e6a", "53ab89807caead278d3deb7b6a4180b277d3cb77", "f6b51c8753a871dc94ff32152c00c01e94f90f09", "2b669398c4cf2ebe04375c8b1beae20f4ac802fa", "87f40e6f3022adbc1f1905e3e506abad05a9964f", "53ca064b9f1b92951c1997e90b776e95b0880e52", "dac72f2c509aee67524d3321f77e97e8eff51de6", "6c2b28f9354f667cd5bd07afc0471d8334430da7", "e89f679710507e239775a1e9c81988c3f928cbed"], "ReferenceCount": 32, "CitationCount": 28781}, {"URL": "https://www.semanticscholar.org/paper/To-be-semantically-impaired-or-to-be-Linguistic-in-Lai-Pai/f47e58797316ca268fa08b601bca33c0eefdc791", "ID": "f47e58797316ca268fa08b601bca33c0eefdc791", "Title": "To be semantically-impaired or to be syntactically-impaired: Linguistic patterns in Chinese-speaking persons with or without dementia", "Abstract": "Semantic Scholar extracted view of \\\"To be semantically-impaired or to be syntactically-impaired: Linguistic patterns in Chinese-speaking persons with or without dementia\\\" by Yi-hsiu Lai et al.", "PublicationYear": "2009", "Authors": ["Yi-hsiu Lai", "Hsiu\u2010hua Pai", "Yu-te Lin"], "RelatedTopics": ["Linguistics", "Medicine", "Psychology"], "References": ["1e1c868e54592b3da0a05ed0d17d137cee4a662e", "7083a1e5f9459fab1c1ca810cf1280a4fb47ea40", "bb3f9849fe5350df576d7a6dfd3cb87c433d0c68", "a15aab55296e636a4e84bc10d24fb83bbd1a204c", "97f1d23c912ba12aa117e9de4e5f1b02749b5aa8", "39c097c0ca32272bf31b577824f067156ceff39b", "3682d6266460f46ffd89140955e8832848c99739", "8f6d344b15438ce77febc86e6fd25055c17a9693", "c1ce0f32db5d096b583a8d5e0af6949cf44c928a", "a783400e390c97644ba1804f8e9669f14a630c1f"], "ReferenceCount": 24, "CitationCount": 27}, {"URL": "https://www.semanticscholar.org/paper/Natural-history-of-Alzheimer%E2%80%99s-disease-Honig-Mayeux/068a3d62f1d3eaaaba03df23912db89b5adeb41c", "ID": "068a3d62f1d3eaaaba03df23912db89b5adeb41c", "Title": "Natural history of Alzheimer\u2019s disease", "Abstract": "Understanding the natural history of AD will allow better targeting of the disease-modifying treatments that are on the horizon, and address factors that may influence disease course. Alzheimer\u2019s disease (AD) is the principal cause of dementia in the elderly, and affects about 15 million people worldwide. The earliest symptom is usually an insidious impairment of memory. As the disease progresses, there is increasing impairment of language and other cognitive functions. Problems occur with naming and word-finding, and later with verbal and written comprehension and expression. Visuospatial, analytic and abstract reasoning abilities, judgment, and insight become affected. Behavioral changes may include delusions, hallucinations, irritability, agitation, verbal or physical aggression, wandering, and disinhibition. Ultimately, there is loss of self-hygiene, eating, dressing, and ambulatory abilities, and incontinence and motor dysfunction. Before diagnosis of AD, individuals may have memory complaints, which represent a period of mild cognitive impairment (MCI). Before MCI, there is a prodromal, illdefined presymptomatic period of disease (\u201cpre- MCI\u201d). In this review, we particularly focus on these earliest stages. We also discuss the more advanced stages of AD, and address factors that may influence disease course. Understanding the natural history of AD will allow better targeting of the disease-modifying treatments that are on the horizon.", "PublicationYear": "2001", "Authors": ["Lawrence S. Honig", "Richard P Mayeux"], "RelatedTopics": ["Medicine"], "References": ["dc572d2cfd09b0b12951cf26e08aae45d5d7b345", "0fc1404ff233f2acd785e23951000d3885a69779", "fa127a2e184612b57b4ec1ea564d8cff85958547", "3fd4e184410101f3d905278018f0a8491152c3cf", "1a2f9ef54e65ed753e41d92a89171e3e7e7b8d60", "a7e7eab437ab096509a3bfeb57c00dfa32d306c5", "201d71912f169ae68b8987b9a7f268a92db19c04", "6211f41987ad191b9e2cf7b6de5e9aa32ab3a476", "be0e47550cb1d54a7153b08ce3104f9e7abd893d", "f63f357a92d627b8b05ed783af8f2dd8c42d2006"], "ReferenceCount": 138, "CitationCount": 129}, {"URL": "https://www.semanticscholar.org/paper/A-Rubric-for-Extracting-Idea-Density-from-Oral-Chand-Baynes/be9de6c52b9567d1306d1cc703d9cac698c15b7e", "ID": "be9de6c52b9567d1306d1cc703d9cac698c15b7e", "Title": "A Rubric for Extracting Idea Density from Oral Language Samples", "Abstract": "This unit outlines the history of ID research and findings, discusses issues with past rubrics, and presents an operationalized method for the systematic measurement of ID in language samples, with an extensive manual available as a supplement to this unit (Analysis of Idea Density, AID). While past research has demonstrated that low idea density (ID) scores from natural language samples correlate with late life risk for cognitive decline and Alzheimer's disease pathology, there are no published rubrics for collecting and analyzing language samples for idea density to verify or extend these findings into new settings. This unit outlines the history of ID research and findings, discusses issues with past rubrics, and then presents an operationalized method for the systematic measurement of ID in language samples, with an extensive manual available as a supplement to this unit (Analysis of Idea Density, AID). Finally, reliability statistics for this rubric in the context of dementia research on aging populations and verification that AID can replicate the significant association between ID and late\u2010life cognition are presented. Curr. Protoc. Neurosci. 58:10.5.1\u201010.5.15. \u00a9 2012 by John Wiley & Sons, Inc.", "PublicationYear": "2012", "Authors": ["Vineeta Chand", "Kathleen Baynes", "Lisa M. Bonnici", "Sarah T. Farias"], "RelatedTopics": ["Linguistics"], "References": ["fd46e4c4ad23ea006523b305a401de92e11f1f49", "6962ca77b741c47215971d0a83a7c44d76d2cf80", "348a734692f7bfab54816fc882c13e489b6d25d0", "a96fffdde62398a1461bdc3b3fbc59a20f36823f", "1e93b3eff5c7ad4dffac63bca3d9ad244f786f28", "926b402d5ecdf00853e9bdf2f5a6ff368f3c0a5e", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "8b4068bb9a4ac55eea6899fea9098e56f9064550", "601dc5a008cf11da1d312b5890b1456d56d45bb0", "4f1cb0b1f4120d08c2d0439dc6feb907c81f9361"], "ReferenceCount": 56, "CitationCount": 24}, {"URL": "https://www.semanticscholar.org/paper/Propositional-density-and-cognitive-function-in-the-Engelman-Agree/fd46e4c4ad23ea006523b305a401de92e11f1f49", "ID": "fd46e4c4ad23ea006523b305a401de92e11f1f49", "Title": "Propositional density and cognitive function in later life: findings from the Precursors Study.", "Abstract": "Test the hypothesis that written propositional density measured early in life is lower for people who develop dementia categorized as Alzheimer's disease by using longitudinal data from the Johns Hopkins Precursors Study to test this hypothesis. OBJECTIVES\\nWe used longitudinal data from the Johns Hopkins Precursors Study to test the hypothesis that written propositional density measured early in life is lower for people who develop dementia categorized as Alzheimer's disease (AD). This association was reported in 1996 for the Nun Study, and the Precursors Study offered an unprecedented chance to reexamine it among respondents with different gender, education, and occupation profiles.\\n\\n\\nMETHODS\\nEighteen individuals classified as AD patients (average age at diagnosis: 74) were assigned 2 sex-and-age matched controls, and propositional density in medical school admission essays (average age at writing: 22) was assessed via Computerized Propositional Idea Density Rater 3 linguistic analysis software. Adjusted odds ratios (ORs) for the matched case-control study were calculated using conditional (fixed-effects) logistic regression.\\n\\n\\nRESULTS\\nMean propositional density is lower for cases than for controls (4.70 vs. 4.99 propositions per 10 words, 1-sided p = .01). Higher propositional density substantially lowers the odds of AD (OR = 0.16, 95% confidence interval = 0.03-0.90, 1-sided p = .02).\\n\\n\\nDISCUSSION\\nPropositional density scores in writing samples from early adulthood appear to predict AD in later life for men as well as women. Studies of cognition across the life course might beneficially incorporate propositional density as a potential marker of cognitive reserve.", "PublicationYear": "2010", "Authors": ["Michal Engelman", "Emily M Agree", "Lucy A. Meoni", "Michael John Klag"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["6962ca77b741c47215971d0a83a7c44d76d2cf80", "a96fffdde62398a1461bdc3b3fbc59a20f36823f", "348a734692f7bfab54816fc882c13e489b6d25d0", "75d2e8ac75ed54338c2f6c50f232bbeae15bbd8f", "926b402d5ecdf00853e9bdf2f5a6ff368f3c0a5e", "d709977f951029c18c16df55e152bdd06145957e", "bb924b48e1ffee079373aba75605dac39a3738e4", "1422384ff9e9b19136dcd2f70f0206053d9a7f23", "0192d431781e3318e4f2f9f89dc73968dfadff21", "02bcf8bcb38023b7e92b2cd0126251025e19169e"], "ReferenceCount": 36, "CitationCount": 47}, {"URL": "https://www.semanticscholar.org/paper/Propositional-Idea-Density-in-aphasic-discourse-Bryant-Spencer/c35396244ee8028d3553ff1fd920248d534ae2ae", "ID": "c35396244ee8028d3553ff1fd920248d534ae2ae", "Title": "Propositional Idea Density in aphasic discourse", "Abstract": "PD has the potential to be used as a measure of discourse informativeness in aphasia and that further research into this approach to analysis is warranted, according to the findings. Background: Measuring and describing the effects of aphasia on the informativeness of language is a complex process. Due to technological advances in the recent years, the processes involved in the measurement of language can be automated through the use of computerised analyses. In the present research, the Computerized Propositional Idea Density Rater (CPIDR 3.2) provides an automated method for calculating Propositional Idea Density (PD), a measure which has been shown to be sensitive to the effects of ageing and dementia. The measure of PD quantifies the proportion of words within a text that are semantically intrinsic to its overall meaning. Aims: This research investigated the extent to which PD measures were different in aphasic and non-aphasic discourse, and the extent to which PD correlated with the severity of aphasia and with the established measures of other aspects of informativeness. Given the previously reported high levels of agreement between the computerised analysis and human raters, it was hypothesised that there would be high levels of agreement between the computerised analysis and human judgements for aphasic (as well as non-aphasic) discourse. Methods & Procedures: Data from the Goals in Aphasia Project were analysed for the purposes of the present research. De-identified transcriptions of 50 interviews with individuals with aphasia and 49 interviews with their family members were stripped of all interviewer data, leaving only conversational contributions made by the participants. These formatted transcripts were analysed using two automated, computerised language analysis tools: CPIDR 3.2) and Systematic Analysis of Language Transcripts (SALT Version 8) for a range of other discourse measures. Outcomes & Results: Results showed a significant difference in PD (p &lt; .001) between aphasic and non-aphasic discourse, and PD decreased significantly as aphasia increased in severity (p &lt; .001). The concurrent validity of these findings was supported by the findings of relationships with established discourse measures. The total percent agreement between the computerised analysis and human judgments for aphasic discourse was 99.57% and for non-aphasic discourse was 99.74%. Conclusions: The findings indicated that PD has the potential to be used as a measure of discourse informativeness in aphasia and that further research into this approach to analysis is warranted.", "PublicationYear": "2013", "Authors": ["Lucy Bryant", "Elizabeth Spencer", "Alison Ferguson", "Hugh Craig", "Kim Colyvas", "Linda Worrall"], "RelatedTopics": ["Linguistics", "Computer Science"], "References": ["2ef8980d969bc16d5832618715074b3383e81392", "1cccdc99cdc44020cef5149ea788848696fa1369", "a0ae37b155afed3120af1c540e4f368d0a580752", "c1812f4bb01835829258caf3118acad36a351344", "be9de6c52b9567d1306d1cc703d9cac698c15b7e", "13f494022b197bda10dc7f93ceef78baae2df319", "fd46e4c4ad23ea006523b305a401de92e11f1f49", "8abb6d846c38b6bc5c89456d0b21fd482780249f", "32c8bfb5e9f8efefef9721c2de42ba7531fb30c3", "4f7d65e2370b76ad95c7bb6ffb9362c10faf48fc"], "ReferenceCount": 46, "CitationCount": 22}, {"URL": "https://www.semanticscholar.org/paper/Automatic-measurement-of-propositional-idea-density-Brown-Snodgrass/7d50bfd726677efb91ee21a7fec90de18d273c5b", "ID": "7d50bfd726677efb91ee21a7fec90de18d273c5b", "Title": "Automatic measurement of propositional idea density from part-of-speech tagging", "Abstract": "The Computerized Propositional Idea Density Rater (CPIDR, pronounced \u201cspider\u201d) is a computer program that determines the propositional idea density (P-density) of an English text automatically on the basis of part of speech tags. The Computerized Propositional Idea Density Rater (CPIDR, pronounced \u201cspider\u201d) is a computer program that determines the propositional idea density (P-density) of an English text automatically on the basis of partof-speech tags. The key idea is that propositions correspond roughly to verbs, adjectives, adverbs, prepositions, and conjunctions. After tagging the parts of speech using MontyLingua (Liu, 2004), CPIDR applies numerous rules to adjust the count, such as combining auxiliary verbs with the main verb. A \u201cspeech mode\u201d is provided in which CPIDR rejects repetitions and a wider range of fillers. CPIDR is a user-friendly Windows .NET application distributed as open-source freeware under GPL. Tested against human raters, it agrees with the consensus of two human raters better than the team of five raters agree with each other [r(80) = .97 vs. r(10) = .82, respectively].", "PublicationYear": "2008", "Authors": ["Cati Brown", "Tony Snodgrass", "Susan Kemper", "Ruth E. Herman", "Michael A. Covington"], "RelatedTopics": ["Computer Science"], "References": ["a145854ede2f62098bf4e92de1584ab270b676c9", "3a529d4aeab47bd70b51fe276d8cf62a36edcb62", "a471110241ca904033ec0a7d1e85198b2ac54ec0", "c61a9a903c66b5f977ed3dfc17e35de80c82687c", "37e6cf1474d4296569e7d1d5534db28e093285a7", "43b27a765f0676bb4d469146e92a5b13500ba100", "ca831f023ff9eb7766c6b2c668f2540fa73741b2", "66b76e4453e0d544a1aa45e9ebd22f59967edeb0", "01bd08bad795ad314d8e14ef0481440acc697767", "d670da3eac38c102e0b69ebbff40f6892fc2b1b0"], "ReferenceCount": 34, "CitationCount": 195}, {"URL": "https://www.semanticscholar.org/paper/Word-production-and-comprehension-in-Alzheimer's-of-Martin-Fedio/33192c6378b46f9e7c7f46eb365bf3a2679cf4aa", "ID": "33192c6378b46f9e7c7f46eb365bf3a2679cf4aa", "Title": "Word production and comprehension in Alzheimer's dise\u00e1se: The breakdown of semantic knowledge", "Abstract": "Semantic Scholar extracted view of \\\"Word production and comprehension in Alzheimer's dise\u00e1se: The breakdown of semantic knowledge\\\" by Alex Martin et al.", "PublicationYear": "1983", "Authors": ["Alex Martin", "Paul Fedio"], "RelatedTopics": ["Psychology", "Medicine"], "References": ["e4755c674e5757d19b5b12d35f4ee312caab7d37", "5e4d2ae4941fbfb9bfaad1daf9b9326140d0c3b4", "f572161e4f294acdc1b8663adea6f9e29d8a2269", "397cc5c44ced1616b2a68c3c3711828a69a5ce26", "e39582b01f9dc0f7d5eebf311b5ed82414b6ecd7", "91e988ae867c04ef317cc4e0bf902fc907291706", "ce1c0d6ac3c2314451882398791432d3ac0682ac", "39c49523215d89a696d7e7b6f2136e5191da2939", "91bf065afb515dcacd916172fd13dc3abfb33a08", "003ce92cf70a376d7a91cf5d50936caf75fdfb17"], "ReferenceCount": 30, "CitationCount": 739}, {"URL": "https://www.semanticscholar.org/paper/The-nature-of-the-naming-deficit-in-Alzheimer's-and-Hodges-Salmon/9208fe3a308483ffc4a4859ef01464bc0244282d", "ID": "9208fe3a308483ffc4a4859ef01464bc0244282d", "Title": "The nature of the naming deficit in Alzheimer's and Huntington's disease.", "Abstract": "In HD, naming deficits initially involve disruption of perceptual analysis, whereas in DAT such impairments in the early stages reflect a breakdown in semantic processes, however, as DAT progresses, perceptual problems also begin to contribute to the patients' naming difficulties. A comparison of naming performance, on the Boston Naming Test, of 52 patients with dementia of Alzheimer's type (DAT), 16 patients with Huntington's disease (HD) and 52 normal control subjects was performed using a comprehensive classification of error types. Spontaneous and cued naming scores were significantly impaired both in the DAT and HD groups, but performance in the DAT patients was significantly worse than that of the HD patients. Normal controls made predominantly semantic-category and circumlocutory errors. The HD group differed from normal only in the proportion of visually based errors, which was greater in the patient group. By contrast, the DAT patients made a significantly greater proportion of semantic-superordinate and semantic-associative errors. The same pattern of naming errors was found when a group of DAT and HD patients matched for overall naming ability was compared. A subgroup of 22 DAT patients was followed longitudinally over 3 y. Their deterioration in overall naming performance was accompanied by a consistent change in the profile of naming errors: the proportion of semantic-associative errors increased significantly as did the proportion of visual errors. These results are considered in the light of current cognitive models of naming. They suggest that in HD, naming deficits initially involve disruption of perceptual analysis, whereas in DAT such impairments in the early stages reflect a breakdown in semantic processes. However, as DAT progresses, perceptual problems also begin to contribute to the patients' naming difficulties. Postlexical (phonemic) processes remain relatively intact throughout in both diseases.", "PublicationYear": "1991", "Authors": ["John R. Hodges", "David P. Salmon", "Nelson M. Butters"], "RelatedTopics": ["Medicine", "Psychology"], "References": [], "ReferenceCount": 0, "CitationCount": 303}, {"URL": "https://www.semanticscholar.org/paper/Fluency-deficits-in-patients-with-Alzheimer's-and-Phillips-Sala/d686a6d2a91f4aa73627608d44f2ed63762227d0", "ID": "d686a6d2a91f4aa73627608d44f2ed63762227d0", "Title": "Fluency deficits in patients with Alzheimer's disease and frontal lobe lesions", "Abstract": "In patients with Alzheimer's disease, fluency deficits were most closely associated with language and verbal memory deterioration, while in FL patients fluencies deficits were more strongly associated with executive measures of strategic planning and attention. Fluency tests are widely used in clinical settings to assess cognitive function. Fluency deficits In patients with Alzheimer's disease (AD) are generally attributed to deteriorated language storage. In contrast, patients with lesions to the frontal lobes (FL) of the brain are thought to have poor fluency due to executive deficits of retrieval. This study examined the relationships between fluency performance and cognitive measures of language and executive function in both AD and FL patients. In both groups, fluency performance related to measures of language comprehension and executive control of attention. However, in AD patients, fluency deficits were most closely associated with language and verbal memory deterioration, while in FL patients fluency deficits were more strongly associated with executive measures of strategic planning and attention. Qualitatively different patterns of functional deficits may influence fluency performance in different neuropsychological groups. Caution is therefore urged in the interpretation of poor fluency scores as indicative of either language or executive dysfunction, without additional information about the reasons for poor performance.", "PublicationYear": "1996", "Authors": ["Louise H. Phillips", "Sara Sala", "Cristina Trivelli"], "RelatedTopics": ["Medicine"], "References": ["485bfd900d8949bbef274f8fd0deca2e49d24133", "0b67bd18450dee65ef9e2e7c8218a7e300ec7831", "82ea050b13f095f54647efe529d36be1570f79ad", "61a9cbc6f30c7fcd1c47372934f2d94130c1107e", "976d1b65abe945cf0cc43971cf1d9bf0c7f8c5db", "6e694fa07947bc86b03f0dd56563b49726eb006d", "92fbb1a0feeff92fe249946c7e0c91c114f50bfd", "e8cd2551f41d130d7cfde84b60688d2e2697d217", "6745260d354b29310f856786b25bf49cb15cdae2", "332e0025a021446fe0e793b5b255fb31d6eb8364"], "ReferenceCount": 75, "CitationCount": 14}, {"URL": "https://www.semanticscholar.org/paper/Quality-of-Spelling-Breakdown-in-Alzheimer%E2%80%99s-is-of-Pestell-Shanks/52cabd4b2127899b191ecaebf00d295f9cc9f90c", "ID": "52cabd4b2127899b191ecaebf00d295f9cc9f90c", "Title": "Quality of Spelling Breakdown in Alzheimer\u2019s Disease is Independent of Disease Progression", "Abstract": "Although increasing in quantity with disease progression, analysis of quality of spelling errors reveal a multi-componential disruption of spelling ability, which is independent of disease progression. There is a convergence of evidence from recent studies that spelling is impaired in Alzheimer\u2019s Disease (AD) relative to normal aging. However, the literature is more divided over whether there is a logical pattern in spelling deterioration with disease progression. The present study reviewed performance of participants with mild AD, moderate AD, and control participants on a written and oral spelling task. Results suggest that spelling in individuals with AD is impaired relative to controls. Comparison between those with mild AD and moderate AD failed to find evidence of a logical pattern of deterioration. We further examined the effects of word characteristics on spelling performance. Although increasing in quantity with disease progression, analysis of quality of spelling errors reveal a multi-componential disruption of spelling ability, which is independent of disease progression.", "PublicationYear": "2000", "Authors": ["Simon J. Pestell", "Michael Fraser Shanks", "Jill Warrington", "Annalena Venneri"], "RelatedTopics": ["Medicine", "Psychology"], "References": ["3f800154262d3e8d916abbf6fc0769c9b5885741", "c9bf962a369704756182ea7ef67f8558e41c60ec", "210911f74c9349b114641d16b71637d36c3a9b9e", "f5e4dfb85b5e6a170138e6205dedc894e486e47c", "522dd18333d113cb7fb90c93cc9dfe9c2c05f41d", "6dec435a8429c5117c01846871930f1ca1e2b18d", "1757d7d3f803c2c250121f070a9fd3f335c4b6fe", "6bba349adcda26c0db78de6d0126bcf2eec037ed", "e2e95381a5dd782372ec2e6ac14ade96c5cf428c", "746bcdca6fb9c6b8e6852854dede74e1c1f91038"], "ReferenceCount": 38, "CitationCount": 26}, {"URL": "https://www.semanticscholar.org/paper/Aphasia-in-dementia-of-the-Alzheimer-type-Cummings-Benson/1757d7d3f803c2c250121f070a9fd3f335c4b6fe", "ID": "1757d7d3f803c2c250121f070a9fd3f335c4b6fe", "Title": "Aphasia in dementia of the Alzheimer type", "Abstract": "Speech and language assessment in 30 patients with dementia of the Alzheimer type and in 70 normal controls revealed that all Alzheimer patients were aphasic. Speech and language assessment in 30 patients with dementia of the Alzheimer type and in 70 normal controls revealed that all Alzheimer patients were aphasic. Throughout most of the course, the language disorder resembled transcortical sensory aphasia, and increasing language impairment correlated with increasing severity of dementia. Aphasia was present regardless of age of onset or family history of dementia. Aphasia is an important diagnostic criterion of dementia of the Alzheimer type.", "PublicationYear": "1985", "Authors": ["Jeffrey L. Cummings", "D. Frank Benson", "Mary Ann Hill", "Stephen L. Read"], "RelatedTopics": ["Medicine"], "References": ["269afec2b597e069278ddcbbc1ff6b1d69a3c4bb", "e7669ce4efce1c3917caaf5aca51953b58080c96", "a17aa0e70d0bc5323f6b0566bc571794d3b64914", "6a83ab7efcbb7db80094ca3f0b11d7eab8f6eb92", "2de959c949a55089565af42e4e60ad12aa8dd24a", "792615534f1f9f58b966294b43aecfe3ba7f375a", "7696b6254d6ed437e8243ccb7c76af7406a830d8", "c16ad4c147038b8a9c31bc68cd967c366668a6b8", "d0eecd1e3885dd49c23950f343b817bfe183e0ab", "942701c4fb12c44c64927d2ce72b98b2c12a1004"], "ReferenceCount": 20, "CitationCount": 322}, {"URL": "https://www.semanticscholar.org/paper/Assessing-functional-communication-in-aphasia%3A-and-Crockford-Lesser/59735a30545b145e7395cb889e1da586d2405270", "ID": "59735a30545b145e7395cb889e1da586d2405270", "Title": "Assessing functional communication in aphasia: clinical utility and time demands of three methods.", "Abstract": "The results suggested that, although more time-consuming, the partial conversational analysis was a more sensitive measure of stability or change of communicative effectiveness over time than the other two measures, and had the potential advantage for indirect intervention of revealing conversational strategies used by the partner as well as those usedby the aphasic individual. A variety of methods has recently been used to assess everyday communication abilities in aphasic adults. This study compares three such methods for their clinical utility and the amount of a therapist's time they use. The three methods employed a standard rating schedule completed by relatives, analysis of speech elicited through role-play and a partial analysis of everyday conversation samples. The utility of these assessments as a clinical tool was measured in terms of the therapist's time needed, and the assessment's ability to show stability or change of communicative effectiveness on test-re-test measures and to illuminate areas for therapeutic intervention. Eight aphasic adults (five acute and three chronic) were tested on all three assessments, then re-tested after a period of 3 months. The results suggested that, although more time-consuming, the partial conversational analysis was a more sensitive measure of stability or change of communicative effectiveness over time than the other two measures, and had the potential advantage for indirect intervention of revealing conversational strategies used by the partner as well as those used by the aphasic individual.", "PublicationYear": "1994", "Authors": ["Catherine Crockford", "Ruth Lesser"], "RelatedTopics": ["Medicine"], "References": ["acba13365d9022291c7a3e013606ce6ed5844eae", "0423edbf75fd4105827e05aae7b21a18e7ab3596", "1287cea44e7da49e665bd1e5999ece8a94ee4f00", "f83942e70bce19b7d27aa406157197d44812e449", "60ef0ce17b657cde1690571f28c90f325ec11074", "8f6c968b8f484276c70d4f04abac5ce70d68f61d", "284de75c6bc8a98db69486d5e6a29d115900bcab", "78b72adb3093410ea465301613275ac9dcf0d546", "a915a7ffe1a2d5efb641fb23fb67aa487b7e6106", "34d9803f1cc770e0a4300261d26e74bb609753ca"], "ReferenceCount": 13, "CitationCount": 59}, {"URL": "https://www.semanticscholar.org/paper/Text-Genre-Detection-Using-Common-Word-Frequencies-Stamatatos-Fakotakis/bc9edab1799a43f97bbeda92ec13681c486d6c67", "ID": "bc9edab1799a43f97bbeda92ec13681c486d6c67", "Title": "Text Genre Detection Using Common Word Frequencies", "Abstract": "It is shown that the most frequent words of the British National Corpus, representing the most Frequence of the written English language, are more reliable discriminators of text genre in comparison to the most frequently spoken words in a training corpus. In this paper we present a method for detecting the text genre quickly and easily following an approach originally proposed in authorship attribution studies which uses as style markers the frequencies of occurrence of the most frequent words in a training corpus (Burrows, 1992). In contrast to this approach we use the frequencies of occurrence of the most frequent words of the entire written language. Using as testing ground a part of the Wall Street Journal corpus, we show that the most frequent words of the British National Corpus, representing the most frequent words of the written English language, are more reliable discriminators of text genre in comparison to the most frequent words of the training corpus. Moreover, the frequencies of occurrence of the most common punctuation marks play an important role in terms of accurate text categorization as well as when dealing with training data of limited size.", "PublicationYear": "2000", "Authors": ["Efstathios Stamatatos", "Nikos Fakotakis", "George K. Kokkinakis"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["34d171f0870d4ea869bcbdf050086ed09b5950bf", "03dc0ddcacb60cc09b884dcfb3b8cd78bc2cf1a3", "ed97e813df6610c5a373a48aa439fddb54c84f6e", "0f91a81c6a760a22d2f6d20ede431fac757cca12", "79a0e0d47f80d9cfb3b50bf6aa6922a0026b93aa", "bbfbe12f4f16d02b987759d97cc8430f016569d2", "00742aafa1036e1ade29c89ae0840d5d6e681348", "f829fbe07e951cb18922225a4d8527db59afe6b9", "be96f54072f16c18be6d351914c114993849565d", "b1ba4bff0a7e5830dae0b03e9f99e5579eaf1986"], "ReferenceCount": 14, "CitationCount": 213}, {"URL": "https://www.semanticscholar.org/paper/Neural-Natural-Language-Inference-Models-Enhanced-Chen-Zhu/3b1d8eb163ffff598c2faa0d9d7cf933857a359f", "ID": "3b1d8eb163ffff598c2faa0d9d7cf933857a359f", "Title": "Neural Natural Language Inference Models Enhanced with External Knowledge", "Abstract": "This paper enrichs the state-of-the-art neural natural language inference models with external knowledge and demonstrates that the proposed models improve neural NLI models to achieve the state of theart performance on the SNLI and MultiNLI datasets. Modeling natural language inference is a very challenging task. With the availability of large annotated data, it has recently become feasible to train complex models such as neural-network-based inference models, which have shown to achieve the state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform natural language inference (NLI) from these data? If not, how can neural-network-based NLI models benefit from external knowledge and how to build NLI models to leverage it? In this paper, we enrich the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed models improve neural NLI models to achieve the state-of-the-art performance on the SNLI and MultiNLI datasets.", "PublicationYear": "2017", "Authors": ["Qian Chen", "Xiao-Dan Zhu", "Zhenhua Ling", "Diana Inkpen", "Si Wei"], "RelatedTopics": ["Computer Science"], "References": ["83e7654d545fbbaaf2328df365a781fb67b841b4", "596c882de006e4bb4a93f1fa08a5dd467bee060a", "1778e32c18bd611169e64c1805a51abff341ca53", "0fa5142f908afc94c923ca2adbe14a5673bc76eb", "ceb7dddbd0c51f511c4ba97d328b48fd10d2a7fc", "f04df4e20a18358ea2f689b4c129781628ef7fc1", "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "c48e5ae2cdeb2b0b52268ad5099d7c27a76c2e6b", "074ff9defa5f59739294e432d21e90dd56195a14", "cff79255a94b9b05a4ce893eb403a522e0923f04"], "ReferenceCount": 59, "CitationCount": 199}, {"URL": "https://www.semanticscholar.org/paper/Neural-Knowledge-Acquisition-via-Mutual-Attention-Han-Liu/083b9fd0f36528eb7ca35786ba5fb0149adc7727", "ID": "083b9fd0f36528eb7ca35786ba5fb0149adc7727", "Title": "Neural Knowledge Acquisition via Mutual Attention Between Knowledge Graph and Text", "Abstract": "A general joint representation learning framework for knowledge acquisition on two tasks, knowledge graph completion and relation extraction from text, where models trained under this joint framework are significantly improved in comparison with other baselines. \\n \\n We propose a general joint representation learning framework for knowledge acquisition (KA) on two tasks, knowledge graph completion (KGC) and relation extraction (RE) from text. In this framework, we learn representations of knowledge graphs (KGs) and text within a unified parameter sharing semantic space. To achieve better fusion, we propose an effective mutual attention between KGs and text. The reciprocal attention mechanism enables us to highlight important features and perform better KGC and RE. Different from conventional joint models, no complicated linguistic analysis or strict alignments between KGs and text are required to train our models. Experiments on relation extraction and entity link prediction show that models trained under our joint framework are significantly improved in comparison with other baselines. Most existing methods for KGC and RE can be easily integrated into our framework due to its flexible architectures. The source code of this paper can be obtained from https://github.com/thunlp/JointNRE.\\n \\n", "PublicationYear": "2018", "Authors": ["Xu Han", "Zhiyuan Liu", "Maosong Sun"], "RelatedTopics": ["Computer Science"], "References": ["cd5015209855b8db39c2dbf7e2b626cac3a4a6c4", "fe6f8a4bad6a51e2d50f70bb4c32541312a376dd", "345ef9a7d9af0ac0816d76803ddcf9b6d19404d7", "01a858189394940d94ee00ee4285f3e84bff6f29", "ea5907c9b0742baa2593d3abf99b7d0084a902a9", "9d2f9622509f91cd689fa9e4f6fd1a2af4129e6f", "96acb1c882ad655c6b8459c2cd331803801446ca", "3899f87a2031f3434f89beb68c11a1ca6428328a", "eda32bba3e4e8a42d63e1d6a2648b8f831b782a4", "955fe2ee26d888ae22749b0853981b8b581b133d"], "ReferenceCount": 37, "CitationCount": 133}, {"URL": "https://www.semanticscholar.org/paper/ERNIE%3A-Enhanced-Representation-through-Knowledge-Sun-Wang/031e4e43aaffd7a479738dcea69a2d5be7957aa3", "ID": "031e4e43aaffd7a479738dcea69a2d5be7957aa3", "Title": "ERNIE: Enhanced Representation through Knowledge Integration", "Abstract": "Experimental results show that ERNIE outperforms other baseline methods, achieving new state-of-the-art results on five Chinese natural language processing tasks including natural language inference, semantic similarity, named entity recognition, sentiment analysis and question answering. We present a novel language representation model enhanced by knowledge called ERNIE (Enhanced Representation through kNowledge IntEgration). Inspired by the masking strategy of BERT, ERNIE is designed to learn language representation enhanced by knowledge masking strategies, which includes entity-level masking and phrase-level masking. Entity-level strategy masks entities which are usually composed of multiple words.Phrase-level strategy masks the whole phrase which is composed of several words standing together as a conceptual unit.Experimental results show that ERNIE outperforms other baseline methods, achieving new state-of-the-art results on five Chinese natural language processing tasks including natural language inference, semantic similarity, named entity recognition, sentiment analysis and question answering. We also demonstrate that ERNIE has more powerful knowledge inference capacity on a cloze test.", "PublicationYear": "2019", "Authors": ["Yu Sun", "Shuohuan Wang", "Yukun Li", "Shikun Feng", "Xuyi Chen", "Han Zhang", "Xin Tian", "Danxiang Zhu", "Hao Tian", "Hua Wu"], "RelatedTopics": ["Computer Science"], "References": ["3febb2bed8865945e7fddc99efd791887bb7e14f", "245b03b60cb4bf0235109af4e48f958fbab03b34", "6e795c6e9916174ae12349f5dc3f516570c17ce8", "f37e1b62a767a307c046404ca96bc140b3e68cb5", "bc8fa64625d9189f5801837e7b133e7fe3c581f7", "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "6c2b28f9354f667cd5bd07afc0471d8334430da7", "1e077413b25c4d34945cc2707e17e46ed4fe784a", "9405cc0d6169988371b2755e573cc28650d14dfe", "df2b0e26d0599ce3e70df8a9da02e51594e0e992"], "ReferenceCount": 23, "CitationCount": 725}, {"URL": "https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "ID": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "Title": "Improving Language Understanding by Generative Pre-Training", "Abstract": "The general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, improving upon the state of the art in 9 out of the 12 tasks studied. Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).", "PublicationYear": "2018", "Authors": ["Alec Radford", "Karthik Narasimhan"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["afc2850945a871e72c245818f9bc141bd659b453", "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "1e077413b25c4d34945cc2707e17e46ed4fe784a", "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "3f1802d3f4f5f6d66875dac09112f978f12e1e1e", "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "85f94d8098322f8130512b4c6c4627548ce4a6cc", "2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45", "6e795c6e9916174ae12349f5dc3f516570c17ce8"], "ReferenceCount": 73, "CitationCount": 7464}, {"URL": "https://www.semanticscholar.org/paper/GLUE%3A-A-Multi-Task-Benchmark-and-Analysis-Platform-Wang-Singh/451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "ID": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "Title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding", "Abstract": "A benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models, which favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.", "PublicationYear": "2018", "Authors": ["Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["9784fbf77295860b2e412137b86356d70b25e3c0", "3febb2bed8865945e7fddc99efd791887bb7e14f", "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "6e795c6e9916174ae12349f5dc3f516570c17ce8", "687bac2d3320083eb4530bf18bb8f8f721477600", "7113bd87c3e6f727efae24ee52f20c81358da761", "afc2850945a871e72c245818f9bc141bd659b453", "e886d951ae997399ab65a0fbbccd1ee9f1935c44", "1778e32c18bd611169e64c1805a51abff341ca53", "ceb7dddbd0c51f511c4ba97d328b48fd10d2a7fc"], "ReferenceCount": 77, "CitationCount": 4964}, {"URL": "https://www.semanticscholar.org/paper/Semi-supervised-sequence-tagging-with-bidirectional-Peters-Ammar/0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "ID": "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "Title": "Semi-supervised sequence tagging with bidirectional language models", "Abstract": "A general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers. Pre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks. However, in most cases, the recurrent network that operates on word-level representations to produce context sensitive representations is trained on relatively little labeled data. In this paper, we demonstrate a general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks. We evaluate our model on two standard datasets for named entity recognition (NER) and chunking, and in both cases achieve state of the art results, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers.", "PublicationYear": "2017", "Authors": ["Matthew E. Peters", "Waleed Ammar", "Chandra Bhagavatula", "Russell Power"], "RelatedTopics": ["Computer Science"], "References": ["59761abc736397539bdd01ad7f9d91c8607c0457", "7ece4e8d31f872d928369ac2cf58a616a7182112", "b89926ec5f0046f3a5671d8e68c918ab9cac76fd", "bc1022b031dc6c7019696492e8116598097a8c12", "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "6e795c6e9916174ae12349f5dc3f516570c17ce8", "8dd6aae51e31a72752c4be5cddbdd76dfdc6cda4", "26e743d5bd465f49b9538deaf116c15e61b7951f", "ade0c116120b54b57a91da51235108b75c28375a", "189e6bb7523733c4e524214b9e6ae92d4ed50dac"], "ReferenceCount": 46, "CitationCount": 585}, {"URL": "https://www.semanticscholar.org/paper/Joint-Representation-Learning-of-Cross-lingual-and-Cao-Hou/5aadc803228b70c3cc6b31e332770d47d7fb1e6e", "ID": "5aadc803228b70c3cc6b31e332770d47d7fb1e6e", "Title": "Joint Representation Learning of Cross-lingual Words and Entities via Attentive Distant Supervision", "Abstract": "This paper proposes a novel method for joint representation learning of cross-lingual words and entities that captures mutually complementary knowledge, and enables cross-lingsual inferences among knowledge bases and texts. Jointly representation learning of words and entities benefits many NLP tasks, but has not been well explored in cross-lingual settings. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. It captures mutually complementary knowledge, and enables cross-lingual inferences among knowledge bases and texts. Our method does not require parallel corpus, and automatically generates comparable data via distant supervision using multi-lingual knowledge bases. We utilize two types of regularizers to align cross-lingual words and entities, and design knowledge attention and cross-lingual attention to further reduce noises. We conducted a series of experiments on three tasks: word translation, entity relatedness, and cross-lingual entity linking. The results, both qualitative and quantitative, demonstrate the significance of our method.", "PublicationYear": "2018", "Authors": ["Yixin Cao", "Lei Hou", "Juan-Zi Li", "Zhiyuan Liu", "Chengjiang Li", "Xu Chen", "Tiansi Dong"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["7039b7c97bd0e59693f2dc4ed7b40e8790bf2746", "c0fb4f62c39ad91ae6a884a6ad5ebe79517646a1", "4cc80844af0a9f72ef94283869504b995c122ab3", "e6180727be1760d0d9c9a3aaa20cf05bc6a54d27", "672c8bf27fd6c04d34496e359844f1f9d95ed1e4", "f7b0d94fd4a32c4c9be472b4e8d6c5bc308f0dfa", "46c112747fb44f82d3096c07c6d8a8faeee8b3d4", "d1f37d9cab68eb8cda669cc949394732f33264b4", "fc303b3b0be5b476ae5f3d8414b685e91d0378c6", "92c22d3743bcc080783b3deb1ed4889f967df286"], "ReferenceCount": 57, "CitationCount": 31}, {"URL": "https://www.semanticscholar.org/paper/Position-aware-Attention-and-Supervised-Data-Slot-Zhang-Zhong/400e746bc8027c4b5f915cae6123cd1775484b4d", "ID": "400e746bc8027c4b5f915cae6123cd1775484b4d", "Title": "Position-aware Attention and Supervised Data Improve Slot Filling", "Abstract": "An effective new model is proposed, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction that builds TACRED, a large supervised relation extraction dataset obtained via crowdsourcing and targeted towards TAC KBP relations. Organized relational knowledge in the form of \u201cknowledge graphs\u201d is important for many applications. However, the ability to populate knowledge bases with facts automatically extracted from documents has improved frustratingly slowly. This paper simultaneously addresses two issues that have held back prior work. We first propose an effective new model, which combines an LSTM sequence model with a form of entity position-aware attention that is better suited to relation extraction. Then we build TACRED, a large (119,474 examples) supervised relation extraction dataset obtained via crowdsourcing and targeted towards TAC KBP relations. The combination of better supervised data and a more appropriate high-capacity model enables much better relation extraction performance. When the model trained on this new dataset replaces the previous relation extraction component of the best TAC KBP 2015 slot filling system, its F1 score increases markedly from 22.2% to 26.7%.", "PublicationYear": "2017", "Authors": ["Yuhao Zhang", "Victor Zhong", "Danqi Chen", "Gabor Angeli", "Christopher D. Manning"], "RelatedTopics": ["Computer Science"], "References": ["e7e7b9a731678bf0494fe29cbebb42a822224cc6", "b7fb11ef06b0dcdc89ef0a5507c6c9ccea4206d8", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "d00c31df3c50cd57eba2ad39709e1cb14a208246", "41d32cb1ae6de0cc40b579eec7113a1fcaf0d3d3", "4521f5e30024dee07de088288aa5607bdeb38ad5", "3df46460149e4058abebc5274e09256dbefcc7bd", "d84b57362e2010f6f65357267df7e0157af30684", "eb9fb8385c5824b029633c0cb68a8fb8573380ad", "6b8b2075319accc23fef43e4cf76bc3682189d82"], "ReferenceCount": 42, "CitationCount": 686}, {"URL": "https://www.semanticscholar.org/paper/Neural-Relation-Extraction-with-Selective-Attention-Lin-Shen/345ef9a7d9af0ac0816d76803ddcf9b6d19404d7", "ID": "345ef9a7d9af0ac0816d76803ddcf9b6d19404d7", "Title": "Neural Relation Extraction with Selective Attention over Instances", "Abstract": "A sentence-level attention-based model for relation extraction that achieves signi\ufb01cant and consistent improvements on relation extraction as compared with baselines. Distant supervised relation extraction has been widely used to \ufb01nd novel relational facts from text. However, distant supervision inevitably accompanies with the wrong labelling problem, and these noisy data will substantially hurt the performance of relation extraction. To alleviate this issue, we propose a sentence-level attention-based model for relation extraction. In this model, we employ convolutional neural networks to embed the semantics of sentences. Afterwards, we build sentence-level attention over multiple instances, which is expected to dynamically reduce the weights of those noisy instances. Experimental results on real-world datasets show that, our model can make full use of all informative sentences and effectively reduce the in\ufb02uence of wrong labelled instances. Our model achieves signi\ufb01cant and consistent improvements on relation extraction as compared with baselines. The source code of this paper can be obtained from https: //github.com/thunlp/NRE .", "PublicationYear": "2016", "Authors": ["Yankai Lin", "Shiqi Shen", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun"], "RelatedTopics": ["Computer Science"], "References": ["faa5d6d1285eb5f39f28f275cdd2bd8dfbd53a8d", "e7e7b9a731678bf0494fe29cbebb42a822224cc6", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "c8434b04acfe1d300b56c0d369092038ec899a2b", "d84b57362e2010f6f65357267df7e0157af30684", "d48edf9e81653f4c3da716b037b0b50d54c5b034", "791b65c65f8ae7e16c1ee9203cdc3ee59ffeb99f", "96acb1c882ad655c6b8459c2cd331803801446ca", "8dff21517f7ac744089a260dbc3e2f48649e3119", "bc1022b031dc6c7019696492e8116598097a8c12"], "ReferenceCount": 25, "CitationCount": 925}, {"URL": "https://www.semanticscholar.org/paper/Attention-is-All-you-Need-Vaswani-Shazeer/204e3073870fae3d05bcbc2f6a8e263d9b72e776", "ID": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "Title": "Attention is All you Need", "Abstract": "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.", "PublicationYear": "2017", "Authors": ["Ashish Vaswani", "Noam M. Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"], "RelatedTopics": ["Computer Science"], "References": ["b60abe57bc195616063be10638c6437358c81d1e", "93499a7c7f699b6630a86fad964536f9423bb6d0", "cea967b59209c6be22829699f05b8b1ac4dc092d", "98445f4172659ec5e891e031d8202c102135c644", "032274e57f7d8b456bd255fe76b909b2c1d7458e", "735d547fc75e0772d2a78c46a1cc5fad7da1474c", "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "13d9323a8716131911bfda048a40e2cde1a76a46", "d76c07211479e233f7c6a6f32d5346c983c5598f", "43428880d75b3a14257c3ee9bda054e61eb869c0"], "ReferenceCount": 42, "CitationCount": 80337}, {"URL": "https://www.semanticscholar.org/paper/Dissecting-Contextual-Word-Embeddings%3A-Architecture-Peters-Neumann/ac11062f1f368d97f4c826c317bf50dcc13fdb59", "ID": "ac11062f1f368d97f4c826c317bf50dcc13fdb59", "Title": "Dissecting Contextual Word Embeddings: Architecture and Representation", "Abstract": "There is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks, suggesting that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated. Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) influences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated.", "PublicationYear": "2018", "Authors": ["Matthew E. Peters", "Mark Neumann", "Luke Zettlemoyer", "Wen-tau Yih"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["3febb2bed8865945e7fddc99efd791887bb7e14f", "fb29af99e4ef690bcde788442b087fbac087f533", "efef34c1caef102ad5cc052642d75beaaf5adcaf", "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "bc8fa64625d9189f5801837e7b133e7fe3c581f7", "fd5794fc63d5f19bf83cf7baa36e0aa62cbf6299", "263210f256603e3b62476ffb5b9bbbbc6403b646", "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7", "3aa52436575cf6768a0a1a476601825f6a62e58f"], "ReferenceCount": 56, "CitationCount": 344}, {"URL": "https://www.semanticscholar.org/paper/Semi-Supervised-Sequence-Modeling-with-Cross-View-Clark-Luong/0c47cad9729c38d9db1f75491b1ee4bd883a5d4e", "ID": "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e", "Title": "Semi-Supervised Sequence Modeling with Cross-View Training", "Abstract": "Cross-View Training (CVT), a semi-supervised learning algorithm that improves the representations of a Bi-LSTM sentence encoder using a mix of labeled and unlabeled data, is proposed and evaluated, achieving state-of-the-art results. Unsupervised representation learning algorithms such as word2vec and ELMo improve the accuracy of many supervised NLP models, mainly because they can take advantage of large amounts of unlabeled text. However, the supervised models only learn from task-specific labeled data during the main training phase. We therefore propose Cross-View Training (CVT), a semi-supervised learning algorithm that improves the representations of a Bi-LSTM sentence encoder using a mix of labeled and unlabeled data. On labeled examples, standard supervised learning is used. On unlabeled examples, CVT teaches auxiliary prediction modules that see restricted views of the input (e.g., only part of a sentence) to match the predictions of the full model seeing the whole input. Since the auxiliary modules and the full model share intermediate representations, this in turn improves the full model. Moreover, we show that CVT is particularly effective when combined with multi-task learning. We evaluate CVT on five sequence tagging tasks, machine translation, and dependency parsing, achieving state-of-the-art results.", "PublicationYear": "2018", "Authors": ["Kevin Clark", "Minh-Thang Luong", "Christopher D. Manning", "Quoc V. Le"], "RelatedTopics": ["Computer Science"], "References": ["7647a06965d868a4f6451bef0818994100a142e8", "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "85f94d8098322f8130512b4c6c4627548ce4a6cc", "afc2850945a871e72c245818f9bc141bd659b453", "ac17cfa150d802750b46220084d850cfdb64d1c1", "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "cea967b59209c6be22829699f05b8b1ac4dc092d", "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "d76c07211479e233f7c6a6f32d5346c983c5598f"], "ReferenceCount": 90, "CitationCount": 310}, {"URL": "https://www.semanticscholar.org/paper/Character-Level-Language-Modeling-with-Deeper-Al-Rfou-Choe/b9de9599d7241459db9213b5cdd7059696f5ef8d", "ID": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "Title": "Character-Level Language Modeling with Deeper Self-Attention", "Abstract": "This paper shows that a deep (64-layer) transformer model with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. LSTMs and other RNN variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model (Vaswani et al. 2017) with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.", "PublicationYear": "2018", "Authors": ["Rami Al-Rfou", "Dokook Choe", "Noah Constant", "Mandy Guo", "Llion Jones"], "RelatedTopics": ["Computer Science"], "References": ["88caa4a0253a8b0076176745ebc072864eab66e1", "58c6f890a1ae372958b7decf56132fe258152722", "55cf59bfbb25d6363cab87cb747648ebe8a096e5", "1fd7fc06653723b05abe5f3d1de393ddcf6bdddb", "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "2f2d8f8072e5cc9b296fad551f65f183bdbff7aa", "f9a1b3850dfd837793743565a8af95973d395a4e", "4db8cd9117254d21c9c828b8ba2aea58e57ee2c4", "27981998aaef92952eabef2c1490b926f9150c4f", "9f0687bcd0a7d7fc91b8c5d36c003a38b8853105"], "ReferenceCount": 54, "CitationCount": 309}, {"URL": "https://www.semanticscholar.org/paper/QANet%3A-Combining-Local-Convolution-with-Global-for-Yu-Dohan/8c1b00128e74f1cd92aede3959690615695d5101", "ID": "8c1b00128e74f1cd92aede3959690615695d5101", "Title": "QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension", "Abstract": "A new Q\\\\&A architecture called QANet is proposed, which does not require recurrent networks, and its encoder consists exclusively of convolution and self-attention, where convolution models local interactions andSelf-att attention models global interactions. Current end-to-end machine reading and question answering (Q\\\\&A) models are primarily based on recurrent neural networks (RNNs) with attention. Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs. We propose a new Q\\\\&A architecture called QANet, which does not require recurrent networks: Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions. On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference, while achieving equivalent accuracy to recurrent models. The speed-up gain allows us to train the model with much more data. We hence combine our model with data generated by backtranslation from a neural machine translation model. On the SQuAD dataset, our single model, trained with augmented data, achieves 84.6 F1 score on the test set, which is significantly better than the best published F1 score of 81.8.", "PublicationYear": "2018", "Authors": ["Adams Wei Yu", "David Dohan", "Minh-Thang Luong", "Rui Zhao", "Kai Chen", "Mohammad Norouzi", "Quoc V. Le"], "RelatedTopics": ["Computer Science"], "References": ["204e3073870fae3d05bcbc2f6a8e263d9b72e776", "e94697b98b707f557436e025bdc8498fa261d3bc", "93499a7c7f699b6630a86fad964536f9423bb6d0", "97e6ed1f7e5de0034f71c370c01f59c87aaf9a72", "adc276e6eae7051a027a4c269fb21dae43cadfed", "b798cfd967e1a9ca5e7bc995d33a907bf65d1c7f", "de0c30321b22c56d637e7c29cb59180f157272a8", "ff1861b71eaedba46cb679bbe2c585dbe18f9b19", "12e20e4ea572dbe476fd894c5c9a9930cf250dd2", "c25a67ad7e8629a9d12b9e2fc356cd73af99a060"], "ReferenceCount": 50, "CitationCount": 1005}, {"URL": "https://www.semanticscholar.org/paper/Skip-Thought-Vectors-Kiros-Zhu/6e795c6e9916174ae12349f5dc3f516570c17ce8", "ID": "6e795c6e9916174ae12349f5dc3f516570c17ce8", "Title": "Skip-Thought Vectors", "Abstract": "The approach for unsupervised learning of a generic, distributed sentence encoder is described, using the continuity of text from books to train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice.", "PublicationYear": "2015", "Authors": ["Ryan Kiros", "Yukun Zhu", "Ruslan Salakhutdinov", "Richard S. Zemel", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler"], "RelatedTopics": ["Computer Science"], "References": ["27725a2d2a8cee9bf9fffc6c2167017103aba0fa", "0ca7d208ff8d81377e0eaa9723820aeae7a7322d", "f3de86aeb442216a8391befcacb49e58b478f512", "cea967b59209c6be22829699f05b8b1ac4dc092d", "687bac2d3320083eb4530bf18bb8f8f721477600", "d41cfe9b2ada4e09d53262bc75c473d8043936fc", "0b544dfe355a5070b60986319a3f51fb45d1348e", "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88", "ae5e6c6f5513613a161b2c85563f9708bf2e9178", "944a1cfd79dbfb6fef460360a0765ba790f4027a"], "ReferenceCount": 43, "CitationCount": 2231}, {"URL": "https://www.semanticscholar.org/paper/MaskGAN%3A-Better-Text-Generation-via-Filling-in-the-Fedus-Goodfellow/7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d", "ID": "7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d", "Title": "MaskGAN: Better Text Generation via Filling in the ______", "Abstract": "This work introduces an actor-critic conditional GAN that fills in missing text conditioned on the surrounding context and shows qualitatively and quantitatively, evidence that this produces more realistic conditional and unconditional text samples compared to a maximum likelihood trained model. Neural text generation models are often autoregressive language models or seq2seq models. These models generate text by sampling words sequentially, with each word conditioned on the previous word, and are state-of-the-art for several machine translation and summarization benchmarks. These benchmarks are often defined by validation perplexity even though this is not a direct measure of the quality of the generated text. Additionally, these models are typically trained via maxi- mum likelihood and teacher forcing. These methods are well-suited to optimizing perplexity but can result in poor sample quality since generating text requires conditioning on sequences of words that may have never been observed at training time. We propose to improve sample quality using Generative Adversarial Networks (GANs), which explicitly train the generator to produce high quality samples and have shown a lot of success in image generation. GANs were originally designed to output differentiable values, so discrete language generation is challenging for them. We claim that validation perplexity alone is not indicative of the quality of text generated by a model. We introduce an actor-critic conditional GAN that fills in missing text conditioned on the surrounding context. We show qualitatively and quantitatively, evidence that this produces more realistic conditional and unconditional text samples compared to a maximum likelihood trained model.", "PublicationYear": "2018", "Authors": ["William Fedus", "Ian J. Goodfellow", "Andrew M. Dai"], "RelatedTopics": ["Computer Science"], "References": ["a8176a160777bfe82b1c67506835c60073e6fbe8", "bad429f1fff54bff3d20cde79651fec2eb805a7c", "b7aee9dfb027d6061c6a653684c0fa9a9bba750d", "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "32c4e19f4a757f6c6984416b97d69e287d1d0ecd", "0d16298285eb347bf951b302e6f2c8e4dc472253", "cea967b59209c6be22829699f05b8b1ac4dc092d", "2fe874a1c85ecc9e848bf9defd76535e19d51f39", "424aef7340ee618132cc3314669400e23ad910ba", "67d968c7450878190e45ac7886746de867bf673d"], "ReferenceCount": 38, "CitationCount": 438}, {"URL": "https://www.semanticscholar.org/paper/Contextual-String-Embeddings-for-Sequence-Labeling-Akbik-Blythe/421fc2556836a6b441de806d7b393a35b6eaea58", "ID": "421fc2556836a6b441de806d7b393a35b6eaea58", "Title": "Contextual String Embeddings for Sequence Labeling", "Abstract": "This paper proposes to leverage the internal states of a trained character language model to produce a novel type of word embedding which they refer to as contextual string embeddings, which are fundamentally model words as sequences of characters and are contextualized by their surrounding text. Recent advances in language modeling using recurrent neural networks have made it viable to model language as distributions over characters. By learning to predict the next character on the basis of previous characters, such models have been shown to automatically internalize linguistic concepts such as words, sentences, subclauses and even sentiment. In this paper, we propose to leverage the internal states of a trained character language model to produce a novel type of word embedding which we refer to as contextual string embeddings. Our proposed embeddings have the distinct properties that they (a) are trained without any explicit notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use. We conduct a comparative evaluation against previous embeddings and find that our embeddings are highly useful for downstream tasks: across four classic sequence labeling tasks we consistently outperform the previous state-of-the-art. In particular, we significantly outperform previous work on English and German named entity recognition (NER), allowing us to report new state-of-the-art F1-scores on the CoNLL03 shared task. We release all code and pre-trained language models in a simple-to-use framework to the research community, to enable reproduction of these experiments and application of our proposed embeddings to other tasks: https://github.com/zalandoresearch/flair", "PublicationYear": "2018", "Authors": ["A. Akbik", "Duncan A. J. Blythe", "Roland Vollgraf"], "RelatedTopics": ["Computer Science"], "References": ["3febb2bed8865945e7fddc99efd791887bb7e14f", "32ece3fe025b43d44086ebf4141e09786ceecb7e", "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38", "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7", "7647a06965d868a4f6451bef0818994100a142e8", "0fe73c19513dfd17372d8ef58da0d0149725832c", "f37e1b62a767a307c046404ca96bc140b3e68cb5", "cea967b59209c6be22829699f05b8b1ac4dc092d", "664ec878de4b7170712baae4a7821fc2602bba25", "2f2d8f8072e5cc9b296fad551f65f183bdbff7aa"], "ReferenceCount": 40, "CitationCount": 1171}, {"URL": "https://www.semanticscholar.org/paper/Representation-Learning-of-Knowledge-Graphs-with-Xie-Liu/96acb1c882ad655c6b8459c2cd331803801446ca", "ID": "96acb1c882ad655c6b8459c2cd331803801446ca", "Title": "Representation Learning of Knowledge Graphs with Entity Descriptions", "Abstract": "Experimental results on real-world datasets show that, the proposed novel RL method for knowledge graphs outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that the method is capable of building representations for novel entities according to their descriptions. \\n \\n Representation learning (RL) of knowledge graphs aims to project both entities and relations into a continuous low-dimensional space. Most methods concentrate on learning representations with knowledge triples indicating relations between entities. In fact, in most knowledge graphs there are usually concise descriptions for entities, which cannot be well utilized by existing methods. In this paper, we propose a novel RL method for knowledge graphs taking advantages of entity descriptions. More specifically, we explore two encoders, including continuous bag-of-words and deep convolutional neural models to encode semantics of entity descriptions. We further learn knowledge representations with both triples and descriptions. We evaluate our method on two tasks, including knowledge graph completion and entity classification. Experimental results on real-world datasets show that, our method outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that our method is capable of building representations for novel entities according to their descriptions. The source code of this paper can be obtained from https://github.com/xrb92/DKRL.\\n \\n", "PublicationYear": "2016", "Authors": ["Ruobing Xie", "Zhiyuan Liu", "Jia Jia", "Huanbo Luan", "Maosong Sun"], "RelatedTopics": ["Computer Science"], "References": ["994afdf0db0cb0456f4f76468380822c2f532726", "86412306b777ee35aba71d4795b02915cb8a04c3", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "085e4ab0164e13464b183d3430021f74a9df673a", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "af2e6165b68e75c911dfdb8f81f9ab6627722ab7", "318b558717ff9a4a996e45368b26a1233f03d1d7", "4e278a0fe9fbfeceb29acde435706aa790aeda56"], "ReferenceCount": 18, "CitationCount": 595}, {"URL": "https://www.semanticscholar.org/paper/DOLORES%3A-Deep-Contextualized-Knowledge-Graph-Wang-Kulkarni/cab46caf83a9e0390c6ca4d8603187969c9a53ad", "ID": "cab46caf83a9e0390c6ca4d8603187969c9a53ad", "Title": "DOLORES: Deep Contextualized Knowledge Graph Embeddings", "Abstract": "This work introduces a new method DOLORES for learning knowledge graph embeddings that effectively captures contextual cues and dependencies among entities and relations and shows that these representations can very easily be incorporated into existing models to significantly advance the state of the art on several knowledge graph prediction tasks. We introduce a new method DOLORES for learning knowledge graph embeddings that effectively captures contextual cues and dependencies among entities and relations. First, we note that short paths on knowledge graphs comprising of chains of entities and relations can encode valuable information regarding their contextual usage. We operationalize this notion by representing knowledge graphs not as a collection of triples but as a collection of entity-relation chains, and learn embeddings for entities and relations using deep neural models that capture such contextual usage. In particular, our model is based on Bi-Directional LSTMs and learn deep representations of entities and relations from constructed entity-relation chains. We show that these representations can very easily be incorporated into existing models to significantly advance the state of the art on several knowledge graph prediction tasks like link prediction, triple classification, and missing relation type prediction (in some cases by at least 9.5%).", "PublicationYear": "2018", "Authors": ["Haoyu Wang", "Vivek Kulkarni", "William Yang Wang"], "RelatedTopics": ["Computer Science"], "References": ["994afdf0db0cb0456f4f76468380822c2f532726", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "2b828ff9ab979bfd3b5558d15b95d1c56a70012c", "ae64d2b8deec906a8ae4138a696388032efa9e3b", "af2e6165b68e75c911dfdb8f81f9ab6627722ab7", "e379f7c85441df5d8ddc1565cabf4b4290c22f1f", "86412306b777ee35aba71d4795b02915cb8a04c3", "9697d32ed0a16da167f2bdba05ef96d0da066eb5", "1522df73ddd64a308ac2a900b29c6e3dd1c16941", "2e61ddfa317a197e27ed90d4eab3a19882fe3e8e"], "ReferenceCount": 40, "CitationCount": 25}, {"URL": "https://www.semanticscholar.org/paper/Knowledge-Graph-Representation-with-Jointly-and-Xu-Qiu/bd345877856dc83c2c10c125dbf0f41e2bde38b1", "ID": "bd345877856dc83c2c10c125dbf0f41e2bde38b1", "Title": "Knowledge Graph Representation with Jointly Structural and Textual Encoding", "Abstract": "This paper introduces three neural models to encode the valuable information from text description of entity, among which an attentive model can select related information as needed, and proposes a novel deep architecture to utilize both structural and textual information of entities. The objective of knowledge graph embedding is to encode both entities and relations of knowledge graphs into continuous low-dimensional vector spaces. Previously, most works focused on symbolic representation of knowledge graph with structure information, which can not handle new entities or entities with few facts well. In this paper, we propose a novel deep architecture to utilize both structural and textual information of entities. Specifically, we introduce three neural models to encode the valuable information from text description of entity, among which an attentive model can select related information as needed. Then, a gating mechanism is applied to integrate representations of structure and text into a unified architecture. Experiments show that our models outperform baseline and obtain state-of-the-art results on link prediction and triplet classification tasks.", "PublicationYear": "2016", "Authors": ["Jiacheng Xu", "Xipeng Qiu", "Kan Chen", "Xuanjing Huang"], "RelatedTopics": ["Computer Science"], "References": ["6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8", "96acb1c882ad655c6b8459c2cd331803801446ca", "c0fb4f62c39ad91ae6a884a6ad5ebe79517646a1", "7e928ef936c2815d7522c5176163d6ab7309a8b7", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "d6e5c0cabb07081e750d6426b649978584918216", "085e4ab0164e13464b183d3430021f74a9df673a", "318b558717ff9a4a996e45368b26a1233f03d1d7", "994afdf0db0cb0456f4f76468380822c2f532726", "18bd7cd489874ed9976b4f87a6a558f9533316e0"], "ReferenceCount": 48, "CitationCount": 114}, {"URL": "https://www.semanticscholar.org/paper/SSP%3A-Semantic-Space-Projection-for-Knowledge-Graph-Xiao-Huang/e379f7c85441df5d8ddc1565cabf4b4290c22f1f", "ID": "e379f7c85441df5d8ddc1565cabf4b4290c22f1f", "Title": "SSP: Semantic Space Projection for Knowledge Graph Embedding with Text Descriptions", "Abstract": "This paper proposes the semantic space projection (SSP) model, a model which jointly learns from the symbolic triples and textual descriptions to discover semantic relevance and offer precise semantic embedding. \\n \\n Knowledge graph embedding represents entities and relations in knowledge graph as low-dimensional, continuous vectors, and thus enables knowledge graph compatible with machine learning models. Though there have been a variety of models for knowledge graph embedding, most methods merely concentrate on the fact triples, while supplementary textual descriptions of entities and relations have not been fully employed. To this end, this paper proposes the semantic space projection (SSP) model which jointly learns from the symbolic triples and textual descriptions. Our model builds interaction between the two information sources, and employs textual descriptions to discover semantic relevance and offer precise semantic embedding. Extensive experiments show that our method achieves substantial improvements against baselines on the tasks of knowledge graph completion and entity classification.\\n \\n", "PublicationYear": "2016", "Authors": ["Han Xiao", "Minlie Huang", "Lian Meng", "Xiaoyan Zhu"], "RelatedTopics": ["Computer Science"], "References": ["67cab3bafc8fa9e1ae3ff89791ad43c81441d271", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "d42d2a4112e0a751424624ac0b78980fa9fe9d96", "96acb1c882ad655c6b8459c2cd331803801446ca", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "994afdf0db0cb0456f4f76468380822c2f532726", "318b558717ff9a4a996e45368b26a1233f03d1d7", "d1a525c16a53b94200029df1037f2c9c7c244d7b", "0dddf37145689e5f2899f8081d9971882e6ff1e9", "69418ff5d4eac106c72130e152b807004e2b979c"], "ReferenceCount": 32, "CitationCount": 176}, {"URL": "https://www.semanticscholar.org/paper/Representation-Learning-of-Knowledge-Graphs-with-Xie-Liu/17a1e5d78bffb17979ac55aa792698727fe25a21", "ID": "17a1e5d78bffb17979ac55aa792698727fe25a21", "Title": "Representation Learning of Knowledge Graphs with Hierarchical Types", "Abstract": "Experimental results show that the proposed Type-embodied Knowledge Representation Learning models significantly outperform all baselines on both tasks, especially with long-tail distribution, and indicates that the models are capable of capturing hierarchical type information which is significant when constructing representations of knowledge graphs. Representation learning of knowledge graphs aims to encode both entities and relations into a continuous low-dimensional vector space. Most existing methods only concentrate on learning representations with structured information located in triples, regardless of the rich information located in hierarchical types of entities, which could be collected in most knowledge graphs. In this paper, we propose a novel method named Type-embodied Knowledge Representation Learning (TKRL) to take advantages of hierarchical entity types. We suggest that entities should have multiple representations in different types. More specifically, we consider hierarchical types as projection matrices for entities, with two type encoders designed to model hierarchical structures. Meanwhile, type information is also utilized as relation-specific type constraints. We evaluate our models on two tasks including knowledge graph completion and triple classification, and further explore the performances on long-tail dataset. Experimental results show that our models significantly outperform all baselines on both tasks, especially with long-tail distribution. It indicates that our models are capable of capturing hierarchical type information which is significant when constructing representations of knowledge graphs. The source code of this paper can be obtained from https://github.com/thunlp/TKRL.", "PublicationYear": "2016", "Authors": ["Ruobing Xie", "Zhiyuan Liu", "Maosong Sun"], "RelatedTopics": ["Computer Science"], "References": ["96acb1c882ad655c6b8459c2cd331803801446ca", "f86e65797301b7e35aec66672a320a1697018924", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "86412306b777ee35aba71d4795b02915cb8a04c3", "994afdf0db0cb0456f4f76468380822c2f532726", "18bd7cd489874ed9976b4f87a6a558f9533316e0", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "62754e946c454af793085e8b761e21c4fc68827b", "e745b0506f4133263633eb05e5006a8cff4129f0", "04cc04457e09e17897f9256c86b45b92d70a401f"], "ReferenceCount": 25, "CitationCount": 270}, {"URL": "https://www.semanticscholar.org/paper/Accurate-Text-Enhanced-Knowledge-Graph-Learning-An-Chen/3ce14b7a3c1b89c717eba10229d9d80d80bd0e04", "ID": "3ce14b7a3c1b89c717eba10229d9d80d80bd0e04", "Title": "Accurate Text-Enhanced Knowledge Graph Representation Learning", "Abstract": "This work proposes an accurate text-enhanced knowledge graph representation learning method, which can represent a relation/entity with different representations in different triples by exploiting additional textual information. Previous representation learning techniques for knowledge graph representation usually represent the same entity or relation in different triples with the same representation, without considering the ambiguity of relations and entities. To appropriately handle the semantic variety of entities/relations in distinct triples, we propose an accurate text-enhanced knowledge graph representation learning method, which can represent a relation/entity with different representations in different triples by exploiting additional textual information. Specifically, our method enhances representations by exploiting the entity descriptions and triple-specific relation mention. And a mutual attention mechanism between relation mention and entity description is proposed to learn more accurate textual representations for further improving knowledge graph representation. Experimental results show that our method achieves the state-of-the-art performance on both link prediction and triple classification tasks, and significantly outperforms previous text-enhanced knowledge representation models.", "PublicationYear": "2018", "Authors": ["Bo An", "Bo Chen", "Xianpei Han", "Le Sun"], "RelatedTopics": ["Computer Science"], "References": ["bd345877856dc83c2c10c125dbf0f41e2bde38b1", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "ea5907c9b0742baa2593d3abf99b7d0084a902a9", "96acb1c882ad655c6b8459c2cd331803801446ca", "7e928ef936c2815d7522c5176163d6ab7309a8b7", "994afdf0db0cb0456f4f76468380822c2f532726", "67cab3bafc8fa9e1ae3ff89791ad43c81441d271", "0dddf37145689e5f2899f8081d9971882e6ff1e9", "d2072e4bc03c82697be667c265d728045712bc46", "318b558717ff9a4a996e45368b26a1233f03d1d7"], "ReferenceCount": 35, "CitationCount": 63}, {"URL": "https://www.semanticscholar.org/paper/Modeling-Relation-Paths-for-Representation-Learning-Lin-Liu/aa1b05e8449eb5ee93b114453d9c946ae00459b1", "ID": "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "Title": "Modeling Relation Paths for Representation Learning of Knowledge Bases", "Abstract": "This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, it design a path-constraint resource allocation algorithm to measure the reliability of relation paths and (2) represents relation paths via semantic composition of relation embeddings. Representation learning of knowledge bases aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text. The source code of this paper can be obtained from https://github.com/mrlyk423/ relation_extraction.", "PublicationYear": "2015", "Authors": ["Yankai Lin", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun", "Siwei Rao", "Song Liu"], "RelatedTopics": ["Computer Science"], "References": ["8c68094a59dd2f24415082c53464abf45387f0bb", "994afdf0db0cb0456f4f76468380822c2f532726", "834cb8e1e738b8d2c6d24e652ac966d6e7089a46", "e7e7b9a731678bf0494fe29cbebb42a822224cc6", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "d48edf9e81653f4c3da716b037b0b50d54c5b034", "8007fc25a1f5c03f7c8ac95ccf5cf8aa3d989092", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "974d1048fa45227a3ef9f71efe5501f79683dfdf"], "ReferenceCount": 33, "CitationCount": 571}, {"URL": "https://www.semanticscholar.org/paper/TransG-%3A-A-Generative-Model-for-Knowledge-Graph-Xiao-Huang/67cab3bafc8fa9e1ae3ff89791ad43c81441d271", "ID": "67cab3bafc8fa9e1ae3ff89791ad43c81441d271", "Title": "TransG : A Generative Model for Knowledge Graph Embedding", "Abstract": "This paper addresses a new issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples, and proposes a novel Gaussian mixture model for embedding, TransG, which can discover latent semantics for a relation and leverage a mixture of relation component vectors for embeddedding a fact triple. Recently, knowledge graph embedding, which projects symbolic entities and relations into continuous vector space, has become a new, hot topic in artificial intelligence. This paper addresses a new issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples, and proposes a novel Gaussian mixture model for embedding, TransG. The new model can discover latent semantics for a relation and leverage a mixture of relation component vectors for embedding a fact triple. To the best of our knowledge, this is the first generative model for knowledge graph embedding, which is able to deal with multiple relation semantics. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines.", "PublicationYear": "2015", "Authors": ["Han Xiao", "Minlie Huang", "Xiaoyan Zhu"], "RelatedTopics": ["Computer Science"], "References": ["994afdf0db0cb0456f4f76468380822c2f532726", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "0dddf37145689e5f2899f8081d9971882e6ff1e9", "991b64748dfeecf026a27030c16fe1743aa20167", "02e2059c328bd9fad4e676266435199663bed804", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "2a3f862199883ceff5e3c74126f0c80770653e05", "69418ff5d4eac106c72130e152b807004e2b979c", "1bb60eff4965b9dca7917808395769b952806017", "04cc04457e09e17897f9256c86b45b92d70a401f"], "ReferenceCount": 39, "CitationCount": 257}, {"URL": "https://www.semanticscholar.org/paper/Regularizing-and-Optimizing-LSTM-Language-Models-Merity-Keskar/58c6f890a1ae372958b7decf56132fe258152722", "ID": "58c6f890a1ae372958b7decf56132fe258152722", "Title": "Regularizing and Optimizing LSTM Language Models", "Abstract": "This paper proposes the weight-dropped LSTM which uses DropConnect on hidden-to-hidden weights as a form of recurrent regularization and introduces NT-ASGD, a variant of the averaged stochastic gradient method, wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. Recurrent neural networks (RNNs), such as long short-term memory networks (LSTMs), serve as a fundamental building block for many sequence learning tasks, including machine translation, language modeling, and question answering. In this paper, we consider the specific problem of word-level language modeling and investigate strategies for regularizing and optimizing LSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on hidden-to-hidden weights as a form of recurrent regularization. Further, we introduce NT-ASGD, a variant of the averaged stochastic gradient method, wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. Using these and other regularization strategies, we achieve state-of-the-art word level perplexities on two data sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the effectiveness of a neural cache in conjunction with our proposed model, we achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and 52.0 on WikiText-2.", "PublicationYear": "2017", "Authors": ["Stephen Merity", "Nitish Shirish Keskar", "Richard Socher"], "RelatedTopics": ["Computer Science"], "References": ["d1275b2a2ab53013310e759e5c6878b96df643d4", "424aef7340ee618132cc3314669400e23ad910ba", "737fee76a437be2346bee4261e05707bf6a74be1", "7dba53e72c182e25e98e8f73a99d75ff69dda0c2", "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7", "2397ce306e5d7f3d0492276e357fb1833536b5d8", "67d968c7450878190e45ac7886746de867bf673d", "efbd381493bb9636f489b965a2034d529cd56bcd", "2d876ed1dd2c58058d7197b734a8e4d349b8f231", "63e39cdf1ad884da6bc69096bb3413b5b1100559"], "ReferenceCount": 47, "CitationCount": 1020}, {"URL": "https://www.semanticscholar.org/paper/Dynamic-Entity-Representations-in-Neural-Language-Ji-Tan/9c81f16df774c772dbefc947fe0e467b72500844", "ID": "9c81f16df774c772dbefc947fe0e467b72500844", "Title": "Dynamic Entity Representations in Neural Language Models", "Abstract": "A new type of language model is presented that can explicitly model entities, dynamically update their representations, and contextually generate their mentions and can model an arbitrary number of entities in context while generating each entity mention at an arbitrary length. Understanding a long document requires tracking how entities are introduced and evolve over time. We present a new type of language model, EntityNLM, that can explicitly model entities, dynamically update their representations, and contextually generate their mentions. Our model is generative and flexible; it can model an arbitrary number of entities in context while generating each entity mention at an arbitrary length. In addition, it can be used for several different tasks such as language modeling, coreference resolution, and entity prediction. Experimental results with all these tasks demonstrate that our model consistently outperforms strong baselines and prior work.", "PublicationYear": "2017", "Authors": ["Yangfeng Ji", "Chenhao Tan", "Sebastian Martschat", "Yejin Choi", "Noah A. Smith"], "RelatedTopics": ["Computer Science"], "References": ["26e9eb44ed8065122d37b0c429a8d341bfeea9a5", "7719679e6255c51d157116fcfbc858b7e7dfdb59", "77770099cd73e6da90f046ac92fa2f9d32e469f6", "e9ff2d0274bcb76bdea4ab8ae1d2c972f6e83c74", "033dd6cf61a6017e9aa9b46068d3c89082849cf3", "e8e76b1062918624e9904e0073e11794d7594593", "7df76272e3cf0e8c26177bd6f29c320620f728da", "f8cdf754fb7c08caf6e2f82b176819230910be5b", "b8e1143268c524ad81af27cea3026851d4825fe1", "889e57259a1d6017701fb2c2ceece82f9f4eff4c"], "ReferenceCount": 40, "CitationCount": 88}, {"URL": "https://www.semanticscholar.org/paper/A-Neural-Knowledge-Language-Model-Ahn-Choi/0fa5142f908afc94c923ca2adbe14a5673bc76eb", "ID": "0fa5142f908afc94c923ca2adbe14a5673bc76eb", "Title": "A Neural Knowledge Language Model", "Abstract": "A Neural Knowledge Language Model (NKLM) which combines symbolic knowledge provided by a knowledge graph with the RNN language model, and shows that the NKLM significantly improves the perplexity while generating a much smaller number of unknown words. Current language models have significant limitations in their ability to encode and decode knowledge. This is mainly because they acquire knowledge based on statistical co-occurrences, even if most of the knowledge words are rarely observed named entities. In this paper, we propose a Neural Knowledge Language Model (NKLM) which combines symbolic knowledge provided by a knowledge graph with the RNN language model. At each time step, the model predicts a fact on which the observed word is to be based. Then, a word is either generated from the vocabulary or copied from the knowledge graph. We train and test the model on a new dataset, WikiFacts. In experiments, we show that the NKLM significantly improves the perplexity while generating a much smaller number of unknown words. In addition, we demonstrate that the sampled descriptions include named entities which were used to be the unknown words in RNN language models.", "PublicationYear": "2016", "Authors": ["Sungjin Ahn", "Heeyoul Choi", "Tanel P{\\\"a}rnamaa", "Yoshua Bengio"], "RelatedTopics": ["Computer Science"], "References": ["aa5b35dcf8b024f5352db73cc3944e8fad4f3793", "6c2b28f9354f667cd5bd07afc0471d8334430da7", "1f4a4769e4d2fb846e59c2f185e0377190739f18", "5b0d644f5c4b9880cbaf79932c0a4fa98996f068", "a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb", "c19fbefdeead6a4154a22a9c8551a18b1530033a", "efbd381493bb9636f489b965a2034d529cd56bcd", "2f2d8f8072e5cc9b296fad551f65f183bdbff7aa", "71ae756c75ac89e2d731c9c79649562b5768ff39", "50d53cc562225549457cbc782546bfbe1ac6f0cf"], "ReferenceCount": 51, "CitationCount": 121}, {"URL": "https://www.semanticscholar.org/paper/Wikidata%3A-a-free-collaborative-knowledgebase-Vrande%C4%8Di%C4%87-Kr%C3%B6tzsch/dab7e605237ad4f4fe56dcba2861b8f0a57112be", "ID": "dab7e605237ad4f4fe56dcba2861b8f0a57112be", "Title": "Wikidata: a free collaborative knowledgebase", "Abstract": "This collaboratively edited knowledgebase provides a common source of data for Wikipedia, and everyone else, to help improve the quality of the encyclopedia. This collaboratively edited knowledgebase provides a common source of data for Wikipedia, and everyone else.", "PublicationYear": "2014", "Authors": ["Denny Vrande{\\vc}i{\\'c}", "Markus Kr{\\\"o}tzsch"], "RelatedTopics": ["Computer Science"], "References": ["667bd9008d499dfcf47c8cc09acbe109ceb060ed", "0d759be6f5cfa6ac28d6cd9f54f3fd7d7e039b23", "1976c9eeccc7115d18a04f1e7fb5145db6b96002", "54e8820e676fa597718e14a4f39c5040d022a6a7", "4dfe43ddfcfbe00dd663a4d70b0df9dcc8c92184", "58f72b53d576c6e4a42b4d8812e5542ffa2c03cc", "c9c17279a2a6e564219cf573a74c6675cebb62e6", "9f54a0057d0694bc7d1dcf69d186e313ca92775c", "d40f82c46ec4d789bd1ad652aca63c8017d0781d", "1f4081abc0c973ff5d7830655ac3341ad28ecdc2"], "ReferenceCount": 35, "CitationCount": 2715}, {"URL": "https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe", "ID": "9405cc0d6169988371b2755e573cc28650d14dfe", "Title": "Language Models are Unsupervised Multitask Learners", "Abstract": "It is demonstrated that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText, suggesting a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations. Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.", "PublicationYear": "2019", "Authors": ["Alec Radford", "Jeff Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "3bbf2ee642ed311e500017def1f54df453a935c1", "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "afc2850945a871e72c245818f9bc141bd659b453", "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "19281b9ecdb5c07a93423a506627ab9d9b0cf039", "cea967b59209c6be22829699f05b8b1ac4dc092d", "86311b182786bfde19446f6ded0854de973d4060", "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "85f94d8098322f8130512b4c6c4627548ce4a6cc"], "ReferenceCount": 75, "CitationCount": 13965}, {"URL": "https://www.semanticscholar.org/paper/Challenges-in-Data-to-Document-Generation-Wiseman-Shieber/13395213d47f78672ab4e81573f2b0fa0cfc8c6d", "ID": "13395213d47f78672ab4e81573f2b0fa0cfc8c6d", "Title": "Challenges in Data-to-Document Generation", "Abstract": "A new, large-scale corpus of data records paired with descriptive documents is introduced, a series of extractive evaluation methods for analyzing performance are proposed, and baseline results are obtained using current neural generation methods. Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difficult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce fluent text, but fail to convincingly approximate human-generated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copy- and reconstruction-based extensions lead to noticeable improvements.", "PublicationYear": "2017", "Authors": ["Sam Wiseman", "Stuart M. Shieber", "Alexander M. Rush"], "RelatedTopics": ["Computer Science"], "References": ["604764133befe7a0aaa692919545846197e6e065", "f273adbfe0e6ba39a583b9669d94cc8d828d8c25", "41de65f718207cc5f98b561a62b16d5e818cb98c", "cea967b59209c6be22829699f05b8b1ac4dc092d", "cb62f427698c4d4cb8e2f48057069af974ae8c7c", "d82b55c35c8673774a708353838918346f6c006f", "efbd381493bb9636f489b965a2034d529cd56bcd", "b7eac64a8410976759445cce235469163d23ee65", "aa5b35dcf8b024f5352db73cc3944e8fad4f3793", "31fc1b0fd5ec43863f1a502f6fc3df2cc71b6e6f"], "ReferenceCount": 55, "CitationCount": 497}, {"URL": "https://www.semanticscholar.org/paper/Pointer-Sentinel-Mixture-Models-Merity-Xiong/efbd381493bb9636f489b965a2034d529cd56bcd", "ID": "efbd381493bb9636f489b965a2034d529cd56bcd", "Title": "Pointer Sentinel Mixture Models", "Abstract": "The pointer sentinel-LSTM model achieves state of the art language modeling performance on the Penn Treebank while using far fewer parameters than a standard softmax LSTM and the freely available WikiText corpus is introduced. Recent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies. Even then they struggle to predict rare or unseen words even if the context makes the prediction unambiguous. We introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier. Our pointer sentinel-LSTM model achieves state of the art language modeling performance on the Penn Treebank (70.9 perplexity) while using far fewer parameters than a standard softmax LSTM. In order to evaluate how well language models can exploit longer contexts and deal with more realistic vocabularies and larger corpora we also introduce the freely available WikiText corpus.", "PublicationYear": "2016", "Authors": ["Stephen Merity", "Caiming Xiong", "James Bradbury", "Richard Socher"], "RelatedTopics": ["Computer Science"], "References": ["d1275b2a2ab53013310e759e5c6878b96df643d4", "5d833331b0e22ff359db05c62a8bca18c4f04b68", "0fa5142f908afc94c923ca2adbe14a5673bc76eb", "aa5b35dcf8b024f5352db73cc3944e8fad4f3793", "e44da7d8c71edcc6e575fa7faadd5e75785a7901", "7dba53e72c182e25e98e8f73a99d75ff69dda0c2", "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7", "e957747f4f8600940be4c5bb001aa70c84e53a53", "452059171226626718eb677358836328f884298e", "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e"], "ReferenceCount": 30, "CitationCount": 1705}, {"URL": "https://www.semanticscholar.org/paper/Neural-Text-Generation-from-Structured-Data-with-to-Lebret-Grangier/604764133befe7a0aaa692919545846197e6e065", "ID": "604764133befe7a0aaa692919545846197e6e065", "Title": "Neural Text Generation from Structured Data with Application to the Biography Domain", "Abstract": "A neural model for concept-to-text generation that scales to large, rich domains and significantly out-performs a classical Kneser-Ney language model adapted to this task by nearly 15 BLEU is introduced. This paper introduces a neural model for concept-to-text generation that scales to large, rich domains. We experiment with a new dataset of biographies from Wikipedia that is an order of magnitude larger than existing resources with over 700k samples. The dataset is also vastly more diverse with a 400k vocabulary, compared to a few hundred words for Weathergov or Robocup. Our model builds upon recent work on conditional neural language model for text generation. To deal with the large vocabulary, we extend these models to mix a fixed vocabulary with copy actions that transfer sample-specific words from the input database to the generated output sentence. Our neural model significantly out-performs a classical Kneser-Ney language model adapted to this task by nearly 15 BLEU.", "PublicationYear": "2016", "Authors": ["R{\\'e}mi Lebret", "David Grangier", "Michael Auli"], "RelatedTopics": ["Computer Science"], "References": ["41de65f718207cc5f98b561a62b16d5e818cb98c", "f273adbfe0e6ba39a583b9669d94cc8d828d8c25", "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0", "1956c239b3552e030db1b78951f64781101125ed", "ba49d3823d43515e447296ca4e1e55d3f1fd8c4d", "15f102c3c9f4d4fe6ba105e221df48c6e8902b3b", "1a6b7cf5e1a3e069338498d1c17aa7d46c1ac7e9", "3b977cab4abd0a5ed9a0f9ffbf498db9941b5c5d", "2e36ea91a3c8fbff92be2989325531b4002e2afc", "03bf35097e9bf47b57eb594093803b8c00f59ebb"], "ReferenceCount": 43, "CitationCount": 449}, {"URL": "https://www.semanticscholar.org/paper/Enriching-the-WebNLG-corpus-Ferreira-Moussallem/dec8fe49a9336149e1268a332ce4ab9ecea7841b", "ID": "dec8fe49a9336149e1268a332ce4ab9ecea7841b", "Title": "Enriching the WebNLG corpus", "Abstract": "The enrichment of WebNLG corpus is described with the aim to further extend its usefulness as a resource for evaluating common NLG tasks, including Discourse Ordering, Lexicalization and Referring Expression Generation. This paper describes the enrichment of WebNLG corpus (Gardent et al., 2017a,b), with the aim to further extend its usefulness as a resource for evaluating common NLG tasks, including Discourse Ordering, Lexicalization and Referring Expression Generation. We also produce a silver-standard German translation of the corpus to enable the exploitation of NLG approaches to other languages than English. The enriched corpus is publicly available.", "PublicationYear": "2018", "Authors": ["Thiago Castro Ferreira", "Diego Moussallem", "Emiel J. Krahmer", "Sander Wubben"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["a4c40532e68728fbeab5d9415f6ad8e9530db360", "531a7f2c659787165df4fd5b4580590b953448e4", "85099e075880a4844f3de77006a80c73daf99a4c", "671fa06bda74f847fba21327bfee5603230929ed", "19a632b17b2ee5f64df41bdd23755316a02fb939", "79ee3b9254dc59e0be2750fe3f2017bd9e544ed6", "dc9a05bdfc7e83a9b682fb3c1a7259d76f8fa818", "e1e8ec02bfca20ebe030f61dd94ca340ac5b0c67", "60e6cf2f76da04dc71e3174079972da070a3722e", "d7ec2f43258ff2032c8dd13f8777f221221340b1"], "ReferenceCount": 21, "CitationCount": 46}, {"URL": "https://www.semanticscholar.org/paper/ProjE%3A-Embedding-Projection-for-Knowledge-Graph-Shi-Weninger/e3274206b36a603abc4a335af91273ecba5e73cc", "ID": "e3274206b36a603abc4a335af91273ecba5e73cc", "Title": "ProjE: Embedding Projection for Knowledge Graph Completion", "Abstract": "This work presents a shared variable neural network model called ProjE that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph\u2019s entities and edges, and through subtle, but important, changes to the standard loss function. \\n \\n With the large volume of new information created every day, determining the validity of information in a knowledge graph and filling in its missing parts are crucial tasks for many researchers and practitioners. To address this challenge, a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings. Although researchers continue to improve these models using an increasingly complex feature space, we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering. In this work, we present a shared variable neural network model called ProjE that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph\u2019s entities and edges, and through subtle, but important, changes to the standard loss function. In doing so, ProjE has a parameter size that is smaller than 11 out of 15 existing methods while performing 37% better than the current-best method on standard datasets. We also show, via a new fact checking task, that ProjE is capable of accurately determining the veracity of many declarative statements.\\n \\n", "PublicationYear": "2016", "Authors": ["Baoxu Shi", "Tim Weninger"], "RelatedTopics": ["Computer Science"], "References": ["abea782b5d0bdb4cd90ec42f672711613e71e43e", "2a3f862199883ceff5e3c74126f0c80770653e05", "96acb1c882ad655c6b8459c2cd331803801446ca", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "994afdf0db0cb0456f4f76468380822c2f532726", "955fe2ee26d888ae22749b0853981b8b581b133d", "033f25ad905ef2ed32a8331cf38b83953ff15922", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "1f4a4769e4d2fb846e59c2f185e0377190739f18", "054ba27fe5cc6085d20ea2707de886db6865dbed"], "ReferenceCount": 38, "CitationCount": 242}, {"URL": "https://www.semanticscholar.org/paper/Machine-Learning-with-World-Knowledge%3A-The-Position-Song-Roth/6fba4968f1b39d490bf95fe4030e3d385f167074", "ID": "6fba4968f1b39d490bf95fe4030e3d385f167074", "Title": "Machine Learning with World Knowledge: The Position and Survey", "Abstract": "This paper starts from the comparison of world knowledge with domain-specific knowledge, and introduces three key problems in using world knowledge in learning processes, i.e., explicit and implicit feature representation, inference for knowledge linking and disambiguation, and learning with direct or indirect supervision. Machine learning has become pervasive in multiple domains, impacting a wide variety of applications, such as knowledge discovery and data mining, natural language processing, information retrieval, computer vision, social and health informatics, ubiquitous computing, etc. Two essential problems of machine learning are how to generate features and how to acquire labels for machines to learn. Particularly, labeling large amount of data for each domain-specific problem can be very time consuming and costly. It has become a key obstacle in making learning protocols realistic in applications. In this paper, we will discuss how to use the existing general-purpose world knowledge to enhance machine learning processes, by enriching the features or reducing the labeling work. We start from the comparison of world knowledge with domain-specific knowledge, and then introduce three key problems in using world knowledge in learning processes, i.e., explicit and implicit feature representation, inference for knowledge linking and disambiguation, and learning with direct or indirect supervision. Finally we discuss the future directions of this research topic.", "PublicationYear": "2017", "Authors": ["Yangqiu Song", "Dan Roth"], "RelatedTopics": ["Computer Science"], "References": ["d1cbb4331d4983a23ad19943405fe087d488823c", "d48edf9e81653f4c3da716b037b0b50d54c5b034", "2e396850373bb03e409b5686b956b2590bbc20fe", "cf5ea582bccc7cb21a2ebeb7a0987f79652bde8d", "c54f38857d25315ad1ca4024010cfd985d361e9b", "6df8cd4c69e75b286b1ba27417fd41a21d4982e1", "a25fbcbbae1e8f79c4360d26aa11a3abf1a11972", "31b4c03d721dc10b87c178277c1d369f91db8f0e", "fb8f6c5670755a7d282fb9322bc8439492ea052a", "07abd02f02774d178f26ca99937e5f94001a9ec9"], "ReferenceCount": 248, "CitationCount": 9}, {"URL": "https://www.semanticscholar.org/paper/A-Review-of-Relational-Machine-Learning-for-Graphs-Nickel-Murphy/033f25ad905ef2ed32a8331cf38b83953ff15922", "ID": "033f25ad905ef2ed32a8331cf38b83953ff15922", "Title": "A Review of Relational Machine Learning for Knowledge Graphs", "Abstract": "This paper provides a review of how statistical models can be \u201ctrained\u201d on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph) and how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be \u201ctrained\u201d on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's knowledge vault project as an example of such combination.", "PublicationYear": "2015", "Authors": ["Maximilian Nickel", "Kevin P. Murphy", "Volker Tresp", "Evgeniy Gabrilovich"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["5f8aaefa3c07563cb11884f3f227bd94431544ff", "6c71c34eb649c28288bf05d445d544aa15a5f82c", "81bbe42e3ec09c28b8864956148e58f4cb5aa860", "bafcfdb587decd9f1ccdc1ccc793a8035ef292d7", "c3cdd505ac569baf21e736aa4ca59b99174b15a2", "80416b542f4dab56e61999c62dacfc66e877706f", "04cc04457e09e17897f9256c86b45b92d70a401f", "46225772ac4f68a003a26f053bb248d77c7dbf87", "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "32b12924aa35e0da4367d821f25e466b14f3189a"], "ReferenceCount": 160, "CitationCount": 1416}, {"URL": "https://www.semanticscholar.org/paper/Reasoning-With-Neural-Tensor-Networks-for-Knowledge-Socher-Chen/50d53cc562225549457cbc782546bfbe1ac6f0cf", "ID": "50d53cc562225549457cbc782546bfbe1ac6f0cf", "Title": "Reasoning With Neural Tensor Networks for Knowledge Base Completion", "Abstract": "An expressive neural tensor network suitable for reasoning over relationships between two entities given a subset of the knowledge base is introduced and performance can be improved when entities are represented as an average of their constituting word vectors. Knowledge bases are an important resource for question answering and other tasks but often suffer from incompleteness and lack of ability to reason over their discrete entities and relationships. In this paper we introduce an expressive neural tensor network suitable for reasoning over relationships between two entities. Previous work represented entities as either discrete atomic units or with a single entity vector representation. We show that performance can be improved when entities are represented as an average of their constituting word vectors. This allows sharing of statistical strength between, for instance, facts involving the \\\"Sumatran tiger\\\" and \\\"Bengal tiger.\\\" Lastly, we demonstrate that all models improve when these word vectors are initialized with vectors learned from unsupervised large corpora. We assess the model by considering the problem of predicting additional true relations between entities given a subset of the knowledge base. Our model outperforms previous models and can classify unseen relationships in WordNet and FreeBase with an accuracy of 86.2% and 90.0%, respectively.", "PublicationYear": "2013", "Authors": ["Richard Socher", "Danqi Chen", "Christopher D. Manning", "A. Ng"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["1f4a4769e4d2fb846e59c2f185e0377190739f18", "687bac2d3320083eb4530bf18bb8f8f721477600", "27e38351e48fe4b7da2775bf94341738bc4da07e", "00a3f6924f90fcd77e6e7e6534b957a75d0ced07", "f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433", "04cc04457e09e17897f9256c86b45b92d70a401f", "e703e928bc07900527c368db2428d0d5c57148c2", "796918285116a29537489bb7dc1778f2b1f3e4e8", "57458bc1cffe5caa45a885af986d70f723f406b4", "81bbe42e3ec09c28b8864956148e58f4cb5aa860"], "ReferenceCount": 25, "CitationCount": 1841}, {"URL": "https://www.semanticscholar.org/paper/The-More-You-Know%3A-Using-Knowledge-Graphs-for-Image-Marino-Salakhutdinov/79baf8cf6be6510f69be8c515516136138678cf5", "ID": "79baf8cf6be6510f69be8c515516136138678cf5", "Title": "The More You Know: Using Knowledge Graphs for Image Classification", "Abstract": "This paper investigates the use of structured prior knowledge in the form of knowledge graphs and shows that using this knowledge improves performance on image classification, and introduces the Graph Search Neural Network as a way of efficiently incorporating large knowledge graphs into a vision classification pipeline. One characteristic that sets humans apart from modern learning-based computer vision algorithms is the ability to acquire knowledge about the world and use that knowledge to reason about the visual world. Humans can learn about the characteristics of objects and the relationships that occur between them to learn a large variety of visual concepts, often with few examples. This paper investigates the use of structured prior knowledge in the form of knowledge graphs and shows that using this knowledge improves performance on image classification. We build on recent work on end-to-end learning on graphs, introducing the Graph Search Neural Network as a way of efficiently incorporating large knowledge graphs into a vision classification pipeline. We show in a number of experiments that our method outperforms standard neural network baselines for multi-label classification.", "PublicationYear": "2016", "Authors": ["Kenneth Marino", "Ruslan Salakhutdinov", "Abhinav Kumar Gupta"], "RelatedTopics": ["Computer Science"], "References": ["b7d3fca013d5bb578c341383c219669fd2bf52a5", "3fd90098551bf88c7509521adf1c0ba9b5dfeb57", "53e4ab9730e983242a3409c7bf1af945041a6563", "4deb435bd9ddd9db30909abe9a20e85c4eced5f1", "ea8fe33cc1596b2e493ddd87f22cd21f563664e8", "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "7c6de5a9e02a779e24504619050c6118f4eac181", "e49ff72d420c8d72e62a9353e3abc053445e59bd", "5e925a9f1e20df61d1e860a7aa71894b35a1c186", "eb42cf88027de515750f230b23b1a057dc782108"], "ReferenceCount": 45, "CitationCount": 316}, {"URL": "https://www.semanticscholar.org/paper/TransG-%3A-A-Generative-Mixture-Model-for-Knowledge-Xiao-Huang/d77de3a4ddfa62f8105c0591fd41e549edcfd95f", "ID": "d77de3a4ddfa62f8105c0591fd41e549edcfd95f", "Title": "TransG : A Generative Mixture Model for Knowledge Graph Embedding", "Abstract": "This paper addresses a new issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples, and proposes a novel Gaussian mixture model for embedding, TransG, which can discover latent semantics for a relation and leverage a mixture of relation component vectors for embeddedding a fact triple. Recently, knowledge graph embedding, which projects symbolic entities and relations into continuous vector space, has become a new, hot topic in artificial intelligence. This paper addresses a new issue of multiple relation semantics that a relation may have multiple meanings revealed by the entity pairs associated with the corresponding triples, and proposes a novel Gaussian mixture model for embedding, TransG. The new model can discover latent semantics for a relation and leverage a mixture of relation component vectors for embedding a fact triple. To the best of our knowledge, this is the first generative model for knowledge graph embedding, which is able to deal with multiple relation semantics. Extensive experiments show that the proposed model achieves substantial improvements against the state-of-the-art baselines.", "PublicationYear": "2015", "Authors": ["Han Xiao", "Minlie Huang", "Yu Hao", "Xiaoyan Zhu"], "RelatedTopics": ["Computer Science"], "References": ["994afdf0db0cb0456f4f76468380822c2f532726", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "02e2059c328bd9fad4e676266435199663bed804", "0dddf37145689e5f2899f8081d9971882e6ff1e9", "aa1b05e8449eb5ee93b114453d9c946ae00459b1", "04cc04457e09e17897f9256c86b45b92d70a401f", "69418ff5d4eac106c72130e152b807004e2b979c", "2a3f862199883ceff5e3c74126f0c80770653e05", "9f7cbae1e5c23687b1197d273851048f4bd6fbfd", "f6764d853a14b0c34df1d2283e76277aead40fde"], "ReferenceCount": 29, "CitationCount": 99}, {"URL": "https://www.semanticscholar.org/paper/Knowledge-Graph-Embedding-via-Dynamic-Mapping-Ji-He/18bd7cd489874ed9976b4f87a6a558f9533316e0", "ID": "18bd7cd489874ed9976b4f87a6a558f9533316e0", "Title": "Knowledge Graph Embedding via Dynamic Mapping Matrix", "Abstract": "A more fine-grained model named TransD, which is an improvement of TransR/CTransR, which not only considers the diversity of relations, but also entities, which makes it can be applied on large scale graphs. Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR/CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-the-art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR/CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms state-of-the-art methods.", "PublicationYear": "2015", "Authors": ["Guoliang Ji", "Shizhu He", "Liheng Xu", "Kang Liu", "Jun Zhao"], "RelatedTopics": ["Computer Science"], "References": ["994afdf0db0cb0456f4f76468380822c2f532726", "2a3f862199883ceff5e3c74126f0c80770653e05", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "1f4a4769e4d2fb846e59c2f185e0377190739f18", "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "04cc04457e09e17897f9256c86b45b92d70a401f", "033f25ad905ef2ed32a8331cf38b83953ff15922", "00a3f6924f90fcd77e6e7e6534b957a75d0ced07", "f6764d853a14b0c34df1d2283e76277aead40fde"], "ReferenceCount": 20, "CitationCount": 1283}, {"URL": "https://www.semanticscholar.org/paper/Holographic-Embeddings-of-Knowledge-Graphs-Nickel-Rosasco/955fe2ee26d888ae22749b0853981b8b581b133d", "ID": "955fe2ee26d888ae22749b0853981b8b581b133d", "Title": "Holographic Embeddings of Knowledge Graphs", "Abstract": "Holographic embeddings (HolE) are proposed to learn compositional vector space representations of entire knowledge graphs to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets. \\n \\n Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.\\n \\n", "PublicationYear": "2015", "Authors": ["Maximilian Nickel", "Lorenzo Rosasco", "Tomaso A. Poggio"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["2582ab7c70c9e7fcb84545944eba8f3a7f253248", "86412306b777ee35aba71d4795b02915cb8a04c3", "e745b0506f4133263633eb05e5006a8cff4129f0", "033f25ad905ef2ed32a8331cf38b83953ff15922", "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "2a3f862199883ceff5e3c74126f0c80770653e05", "994afdf0db0cb0456f4f76468380822c2f532726", "f6764d853a14b0c34df1d2283e76277aead40fde", "03dfada96b88c741bb26bd4ce7b5ae4232157d37", "927610c4031ed6d011380dadbb02d7688fe0cc15"], "ReferenceCount": 35, "CitationCount": 1027}, {"URL": "https://www.semanticscholar.org/paper/K-BERT%3A-Enabling-Language-Representation-with-Graph-Liu-Zhou/06a73ad09664435f8b3cd90293f4e05a047cf375", "ID": "06a73ad09664435f8b3cd90293f4e05a047cf375", "Title": "K-BERT: Enabling Language Representation with Knowledge Graph", "Abstract": "This work proposes a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge, which significantly outperforms BERT and reveals promising results in twelve NLP tasks. Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by being equipped with a KG without pre-training by itself because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.", "PublicationYear": "2019", "Authors": ["Weijie Liu", "Peng Zhou", "Zhe Zhao", "Zhiruo Wang", "Qi Ju", "Haotang Deng", "Ping Wang"], "RelatedTopics": ["Computer Science"], "References": ["5f994dc8cae24ca9d1ed629e517fcc652660ddde", "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "f48ae425e2567be2d993efcaaf74c2274fc9d7c5", "6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8", "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "2c69bbb3b7ba3f324276924bab6f41de467c928a", "7e928ef936c2815d7522c5176163d6ab7309a8b7"], "ReferenceCount": 25, "CitationCount": 572}, {"URL": "https://www.semanticscholar.org/paper/Knowledge-Enhanced-Contextual-Word-Representations-Peters-Neumann/bfeb827d06c1a3583b5cc6d25241203a81f6af09", "ID": "bfeb827d06c1a3583b5cc6d25241203a81f6af09", "Title": "Knowledge Enhanced Contextual Word Representations", "Abstract": "After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the entity linkers and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating WordNet and a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and word sense disambiguation. KnowBert\u2019s runtime is comparable to BERT\u2019s and it scales to large KBs.", "PublicationYear": "2019", "Authors": ["Matthew E. Peters", "Mark Neumann", "IV RobertL.Logan", "Roy Schwartz", "Vidur Joshi", "Sameer Singh", "Noah A. Smith"], "RelatedTopics": ["Computer Science"], "References": ["2927dfc481446568fc9108795570eb4d416be021", "f0462312d9e985f13fd20d65178f9565d967f07e", "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "26aa6fe2028b5eefbaa40ab54ef725bbbe7d9810", "59761abc736397539bdd01ad7f9d91c8607c0457", "28f3a20ebd5e2f3afa871b1784076cf7004415b8", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "96901acc92d68350443774596fa2b38bc522a0ce", "d95738f38d97a030d98508357e4d5c78a4a208ba", "4af09143735210777281b66997ec12994dbb43d4"], "ReferenceCount": 70, "CitationCount": 546}, {"URL": "https://www.semanticscholar.org/paper/Knowledge-Graph-and-Text-Jointly-Embedding-Wang-Zhang/f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "ID": "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "Title": "Knowledge Graph and Text Jointly Embedding", "Abstract": "Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts, compared to separately embedding knowledge graphs and text. We examine the embedding approach to reason new relational facts from a largescale knowledge graph and a text corpus. We propose a novel method of jointly embedding entities and words into the same continuous vector space. The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus. Entity names and Wikipedia anchors are utilized to align the embeddings of entities and words in the same space. Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts, compared to separately embedding knowledge graphs and text. Particularly, jointly embedding enables the prediction of facts containing entities out of the knowledge graph, which cannot be handled by previous embedding methods. At the same time, concerning the quality of the word embeddings, experiments on the analogical reasoning task show that jointly embedding is comparable to or slightly better than word2vec (Skip-Gram).", "PublicationYear": "2014", "Authors": ["Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "RelatedTopics": ["Computer Science"], "References": ["834cb8e1e738b8d2c6d24e652ac966d6e7089a46", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "e7e7b9a731678bf0494fe29cbebb42a822224cc6", "2a3f862199883ceff5e3c74126f0c80770653e05", "1f4a4769e4d2fb846e59c2f185e0377190739f18", "d48edf9e81653f4c3da716b037b0b50d54c5b034", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "d84b57362e2010f6f65357267df7e0157af30684", "c2908deec5b09ea4bdfce7ad5e827606ef425ee4"], "ReferenceCount": 19, "CitationCount": 370}, {"URL": "https://www.semanticscholar.org/paper/SimplE-Embedding-for-Link-Prediction-in-Knowledge-Kazemi-Poole/70af3ee98c53441d9090119f7b76efb1b6d03edd", "ID": "70af3ee98c53441d9090119f7b76efb1b6d03edd", "Title": "SimplE Embedding for Link Prediction in Knowledge Graphs", "Abstract": "It is proved SimplE is fully expressive and derive a bound on the size of its embeddings for full expressivity and shown empirically that, despite its simplicity, SimplE outperforms several state-of-the-art tensor factorization techniques. Knowledge graphs contain knowledge about the world and provide a structured representation of this knowledge. Current knowledge graphs contain only a small subset of what is true in the world. Link prediction approaches aim at predicting new links for a knowledge graph given the existing links among the entities. Tensor factorization approaches have proved promising for such link prediction problems. Proposed in 1927, Canonical Polyadic (CP) decomposition is among the first tensor factorization approaches. CP generally performs poorly for link prediction as it learns two independent embedding vectors for each entity, whereas they are really tied. We present a simple enhancement of CP (which we call SimplE) to allow the two embeddings of each entity to be learned dependently. The complexity of SimplE grows linearly with the size of embeddings. The embeddings learned through SimplE are interpretable, and certain types of background knowledge can be incorporated into these embeddings through weight tying. We prove SimplE is fully expressive and derive a bound on the size of its embeddings for full expressivity. We show empirically that, despite its simplicity, SimplE outperforms several state-of-the-art tensor factorization techniques. SimplE's code is available on GitHub at this https URL.", "PublicationYear": "2018", "Authors": ["Seyed Mehran Kazemi", "David L. Poole"], "RelatedTopics": ["Computer Science"], "References": ["ae64d2b8deec906a8ae4138a696388032efa9e3b", "322aa32b2a409d2e135dbb14736d9aeb497f1c52", "9697d32ed0a16da167f2bdba05ef96d0da066eb5", "a4dfb121275a6408d290b803baf8c9caeb23dc5b", "994afdf0db0cb0456f4f76468380822c2f532726", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "cd8a9914d50b0ac63315872530274d158d6aff09", "2218e2e1df2c3adfb70e0def2e326a39928aacfc", "86412306b777ee35aba71d4795b02915cb8a04c3", "a1fb4e2029af4a118a045cf9dc7c00d65047f8df"], "ReferenceCount": 70, "CitationCount": 570}, {"URL": "https://www.semanticscholar.org/paper/Joint-Representation-Learning-of-Text-and-Knowledge-Han-Liu/6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8", "ID": "6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8", "Title": "Joint Representation Learning of Text and Knowledge for Knowledge Graph Completion", "Abstract": "This work proposes a novel framework to embed words, entities and relations into the same continuous vector space and shows that the model can significantly and consistently improve the performance on the three tasks as compared with other baselines. Joint representation learning of text and knowledge within a unified semantic space enables us to perform knowledge graph completion more accurately. In this work, we propose a novel framework to embed words, entities and relations into the same continuous vector space. In this model, both entity and relation embeddings are learned by taking knowledge graph and plain text into consideration. In experiments, we evaluate the joint learning model on three tasks including entity prediction, relation prediction and relation classification from text. The experiment results show that our model can significantly and consistently improve the performance on the three tasks as compared with other baselines.", "PublicationYear": "2016", "Authors": ["Xu Han", "Zhiyuan Liu", "Maosong Sun"], "RelatedTopics": ["Computer Science"], "References": ["7e928ef936c2815d7522c5176163d6ab7309a8b7", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "834cb8e1e738b8d2c6d24e652ac966d6e7089a46", "994afdf0db0cb0456f4f76468380822c2f532726", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "e7e7b9a731678bf0494fe29cbebb42a822224cc6", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "d48edf9e81653f4c3da716b037b0b50d54c5b034", "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "054ba27fe5cc6085d20ea2707de886db6865dbed"], "ReferenceCount": 26, "CitationCount": 40}, {"URL": "https://www.semanticscholar.org/paper/Learning-Entity-and-Relation-Embeddings-for-Graph-Lin-Liu/994afdf0db0cb0456f4f76468380822c2f532726", "ID": "994afdf0db0cb0456f4f76468380822c2f532726", "Title": "Learning Entity and Relation Embeddings for Knowledge Graph Completion", "Abstract": "TransR is proposed to build entity and relation embeddings in separate entity space and relation spaces by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. \\n \\n Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH.\\n \\n", "PublicationYear": "2015", "Authors": ["Yankai Lin", "Zhiyuan Liu", "Maosong Sun", "Yang Liu", "Xuan Zhu"], "RelatedTopics": ["Computer Science"], "References": ["e7e7b9a731678bf0494fe29cbebb42a822224cc6", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "2a3f862199883ceff5e3c74126f0c80770653e05", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "834cb8e1e738b8d2c6d24e652ac966d6e7089a46", "d84b57362e2010f6f65357267df7e0157af30684", "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "d48edf9e81653f4c3da716b037b0b50d54c5b034", "04cc04457e09e17897f9256c86b45b92d70a401f"], "ReferenceCount": 22, "CitationCount": 2834}, {"URL": "https://www.semanticscholar.org/paper/Bridge-Text-and-Knowledge-by-Learning-Entity-Cao-Huang/f7b0d94fd4a32c4c9be472b4e8d6c5bc308f0dfa", "ID": "f7b0d94fd4a32c4c9be472b4e8d6c5bc308f0dfa", "Title": "Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding", "Abstract": "A novel Multi-Prototype Mention Embedding model is proposed, which learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a knowledge base, and an efficient language model based approach to disambiguate each mention to a specific sense. Integrating text and knowledge into a unified semantic space has attracted significant research interests recently. However, the ambiguity in the common space remains a challenge, namely that the same mention phrase usually refers to various entities. In this paper, to deal with the ambiguity of entity mentions, we propose a novel Multi-Prototype Mention Embedding model, which learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a knowledge base. In addition, we further design an efficient language model based approach to disambiguate each mention to a specific sense. In experiments, both qualitative and quantitative analysis demonstrate the high quality of the word, entity and multi-prototype mention embeddings. Using entity linking as a study case, we apply our disambiguation method as well as the multi-prototype mention embeddings on the benchmark dataset, and achieve state-of-the-art performance.", "PublicationYear": "2017", "Authors": ["Yixin Cao", "Lifu Huang", "Heng Ji", "Xu Chen", "Juan-Zi Li"], "RelatedTopics": ["Computer Science"], "References": ["9a501e501a60b431b6031f81dc2c19b390b0aff3", "43b239a996358af9463689c3dbb080104e28f337", "d95738f38d97a030d98508357e4d5c78a4a208ba", "a9aa7531b35811348c1f8a174da9045b120a8af4", "f0efb4f8e1e5957bb252d9d530202b1cef9b0494", "ea5907c9b0742baa2593d3abf99b7d0084a902a9", "96c697be387566a0637941fc7492fcfc25ad56bb", "3b294fb99aa967558befd9b0e2d6f925915080ae", "12f7b71324ee8e1796a9ef07af05b66674fe6af0", "306fad753dc178a9d8168bec3500d89d80320317"], "ReferenceCount": 40, "CitationCount": 86}, {"URL": "https://www.semanticscholar.org/paper/Convolutional-2D-Knowledge-Graph-Embeddings-Dettmers-Minervini/9697d32ed0a16da167f2bdba05ef96d0da066eb5", "ID": "9697d32ed0a16da167f2bdba05ef96d0da066eb5", "Title": "Convolutional 2D Knowledge Graph Embeddings", "Abstract": "ConvE, a multi-layer convolutional network model for link prediction, is introduced, and it is found that ConvE achieves state-of-the-art Mean Reciprocal Rank across all datasets. \\n \\n Link prediction for knowledge graphs is the task of predicting missing relationships between entities. Previous work on link prediction has focused on shallow, fast models which can scale to large knowledge graphs. However, these models learn less expressive features than deep, multi-layer models \u2014 which potentially limits performance. In this work we introduce ConvE, a multi-layer convolutional network model for link prediction, and report state-of-the-art results for several established datasets. We also show that the model is highly parameter efficient, yielding the same performance as DistMult and R-GCN with 8x and 17x fewer parameters. Analysis of our model suggests that it is particularly effective at modelling nodes with high indegree \u2014 which are common in highly-connected, complex knowledge graphs such as Freebase and YAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer from test set leakage, due to inverse relations from the training set being present in the test set \u2014 however, the extent of this issue has so far not been quantified. We find this problem to be severe: a simple rule-based model can achieve state-of-the-art results on both WN18 and FB15k. To ensure that models are evaluated on datasets where simply exploiting inverse relations cannot yield competitive results, we investigate and validate several commonly used datasets \u2014 deriving robust variants where necessary. We then perform experiments on these robust datasets for our own and several previously proposed models, and find that ConvE achieves state-of-the-art Mean Reciprocal Rank across all datasets.\\n \\n", "PublicationYear": "2017", "Authors": ["Tim Dettmers", "Pasquale Minervini", "Pontus Stenetorp", "Sebastian Riedel"], "RelatedTopics": ["Computer Science"], "References": ["cd8a9914d50b0ac63315872530274d158d6aff09", "f86e65797301b7e35aec66672a320a1697018924", "86412306b777ee35aba71d4795b02915cb8a04c3", "2218e2e1df2c3adfb70e0def2e326a39928aacfc", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "033f25ad905ef2ed32a8331cf38b83953ff15922", "955fe2ee26d888ae22749b0853981b8b581b133d", "50de83b8a00f448b3e344701a60dfdcfd84881f4", "e15d062ef07abab8fae65244f64ccd2aac8d2b94", "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82"], "ReferenceCount": 46, "CitationCount": 1859}, {"URL": "https://www.semanticscholar.org/paper/Injecting-Logical-Background-Knowledge-into-for-Rockt%C3%A4schel-Singh/822f1ed9a76a57cc19d8fda7745365b97130b97a", "ID": "822f1ed9a76a57cc19d8fda7745365b97130b97a", "Title": "Injecting Logical Background Knowledge into Embeddings for Relation Extraction", "Abstract": "This paper introduces a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with first-order logic domain knowledge, and shows that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae. Matrix factorization approaches to relation extraction provide several attractive features: they support distant supervision, handle open schemas, and leverage unlabeled data. Unfortunately, these methods share a shortcoming with all other distantly supervised approaches: they cannot learn to extract target relations without existing data in the knowledge base, and likewise, these models are inaccurate for relations with sparse data. Rule-based extractors, on the other hand, can be easily extended to novel relations and improved for existing but inaccurate relations, through first-order formulae that capture auxiliary domain knowledge. However, usually a large set of such formulae is necessary to achieve generalization. In this paper, we introduce a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with first-order logic domain knowledge. We introduce simple approaches for estimating such embeddings, as well as a novel training algorithm to jointly optimize over factual and first-order logic information. Our results show that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae.", "PublicationYear": "2015", "Authors": ["Tim Rockt{\\\"a}schel", "Sameer Singh", "Sebastian Riedel"], "RelatedTopics": ["Computer Science"], "References": ["5fac0ca1b3ea3b6f234dd0821e1f3678f0b6096d", "311eb232e4bd3ed53b1ef3381d75b65615d4e29c", "7c2e6497fcc9a7052655ef747f58ed4ebf80f260", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "d48edf9e81653f4c3da716b037b0b50d54c5b034", "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "1f4a4769e4d2fb846e59c2f185e0377190739f18", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "d84b57362e2010f6f65357267df7e0157af30684", "4a6de89efc5da79c4aabccdb4737ebeedbea7ab2"], "ReferenceCount": 50, "CitationCount": 253}, {"URL": "https://www.semanticscholar.org/paper/Compositional-Vector-Space-Models-for-Knowledge-Neelakantan-Roth/af2e6165b68e75c911dfdb8f81f9ab6627722ab7", "ID": "af2e6165b68e75c911dfdb8f81f9ab6627722ab7", "Title": "Compositional Vector Space Models for Knowledge Base Completion", "Abstract": "This paper presents an approach that reasons about conjunctions of multi-hop relations non-atomically, composing the implications of a path using a recurrent neural network (RNN) that takes as inputs vector embeddings of the binary relation in the path. Knowledge base (KB) completion adds new facts to a KB by making inferences from existing facts, for example by inferring with high likelihood nationality(X,Y) from bornIn(X,Y). Most previous methods infer simple one-hop relational synonyms like this, or use as evidence a multi-hop relational path treated as an atomic feature, like bornIn(X,Z)\u2192 containedIn(Z,Y). This paper presents an approach that reasons about conjunctions of multi-hop relations non-atomically, composing the implications of a path using a recurrent neural network (RNN) that takes as inputs vector embeddings of the binary relation in the path. Not only does this allow us to generalize to paths unseen at training time, but also, with a single high-capacity RNN, to predict new relation types not seen when the compositional model was trained (zero-shot learning). We assemble a new dataset of over 52M relational triples, and show that our method improves over a traditional classifier by 11%, and a method leveraging pre-trained embeddings by 7%.", "PublicationYear": "2015", "Authors": ["Arvind Neelakantan", "Benjamin Roth", "Andrew McCallum"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["50d53cc562225549457cbc782546bfbe1ac6f0cf", "86412306b777ee35aba71d4795b02915cb8a04c3", "5346525f5022b3d60e7a954b50772ea75d967e7d", "2aea6cc6c42101b2615753c2933a33e57dd665f2", "974d1048fa45227a3ef9f71efe5501f79683dfdf", "5fac0ca1b3ea3b6f234dd0821e1f3678f0b6096d", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "687bac2d3320083eb4530bf18bb8f8f721477600", "4ea80c206b8ad73a6d320c9d8ed0321d84fe6d85", "921da70f380e9f9082e5594b128369cfd0fdf120"], "ReferenceCount": 50, "CitationCount": 257}, {"URL": "https://www.semanticscholar.org/paper/Embedding-Entities-and-Relations-for-Learning-and-Yang-Yih/86412306b777ee35aba71d4795b02915cb8a04c3", "ID": "86412306b777ee35aba71d4795b02915cb8a04c3", "Title": "Embedding Entities and Relations for Learning and Inference in Knowledge Bases", "Abstract": "It is found that embeddings learned from the bilinear objective are particularly good at capturing relational semantics and that the composition of relations is characterized by matrix multiplication. Abstract: We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and/or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as \\\"BornInCity(a,b) and CityInCountry(b,c) =&gt; Nationality(a,c)\\\". We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-of-the-art confidence-based rule mining approach in mining Horn rules that involve compositional reasoning.", "PublicationYear": "2014", "Authors": ["Bishan Yang", "Wen-tau Yih", "Xiaodong He", "Jianfeng Gao", "Li Deng"], "RelatedTopics": ["Computer Science"], "References": ["2582ab7c70c9e7fcb84545944eba8f3a7f253248", "1f4a4769e4d2fb846e59c2f185e0377190739f18", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "04cc04457e09e17897f9256c86b45b92d70a401f", "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "311eb232e4bd3ed53b1ef3381d75b65615d4e29c", "f6764d853a14b0c34df1d2283e76277aead40fde", "1e7cf9047604f39e517951d129b2b3eecf9e1cfb", "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "fdb813d8b927bdd21ae1858cafa6c34b66a36268"], "ReferenceCount": 39, "CitationCount": 2480}, {"URL": "https://www.semanticscholar.org/paper/Question-Answering-over-Freebase-with-Multi-Column-Dong-Wei/1ef01e7bfab2041bc0c0a56a57906964df9fc985", "ID": "1ef01e7bfab2041bc0c0a56a57906964df9fc985", "Title": "Question Answering over Freebase with Multi-Column Convolutional Neural Networks", "Abstract": "This paper introduces multi-column convolutional neural networks (MCCNNs) to understand questions from three different aspects and learn their distributed representations and develops a method to compute the salience scores of question words in different column networks. Answering natural language questions over a knowledge base is an important and challenging task. Most of existing systems typically rely on hand-crafted features and rules to conduct question understanding and/or answer ranking. In this paper, we introduce multi-column convolutional neural networks (MCCNNs) to understand questions from three different aspects (namely, answer path, answer context, and answer type) and learn their distributed representations. Meanwhile, we jointly learn low-dimensional embeddings of entities and relations in the knowledge base. Question-answer pairs are used to train the model to rank candidate answers. We also leverage question paraphrases to train the column networks in a multi-task learning manner. We use FREEBASE as the knowledge base and conduct extensive experiments on the WEBQUESTIONS dataset. Experimental results show that our method achieves better or comparable performance compared with baseline systems. In addition, we develop a method to compute the salience scores of question words in different column networks. The results help us intuitively understand what MCCNNs learn.", "PublicationYear": "2015", "Authors": ["Li Dong", "Furu Wei", "M. Zhou", "Ke Xu"], "RelatedTopics": ["Computer Science"], "References": ["921da70f380e9f9082e5594b128369cfd0fdf120", "4cfad7889dc12825309325cd4b4f3febed424e36", "a584211768d49f80192f13b8ed2fda9c058dec34", "33261d252218007147a71e40f8367ed152fa2fe0", "c0be2ac2f45681f1852fc1d298af5dceb85834f4", "bbc860159dea10df35c54d1271bcc0a6b9e2df22", "b29447ba499507a259ae9d8f685d60cc1597d7d3", "a129f612a9eff903d9133244a6f0914ef3cbda72", "2c8ac3e1f0edeed1fbd76813e61efdc384c319c7", "3d1d42c9435b419ac928ebf7bcf4c86a460d6ef4"], "ReferenceCount": 30, "CitationCount": 409}, {"URL": "https://www.semanticscholar.org/paper/Traversing-Knowledge-Graphs-in-Vector-Space-Guu-Miller/e745b0506f4133263633eb05e5006a8cff4129f0", "ID": "e745b0506f4133263633eb05e5006a8cff4129f0", "Title": "Traversing Knowledge Graphs in Vector Space", "Abstract": "It is demonstrated that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results. Path queries on a knowledge graph can be used to answer compositional questions such as \\\"What languages are spoken by people living in Lisbon?\\\". However, knowledge graphs often have missing facts (edges) which disrupts path queries. Recent models for knowledge base completion impute missing facts by embedding knowledge graphs in vector spaces. We show that these models can be recursively applied to answer path queries, but that they suffer from cascading errors. This motivates a new \\\"compositional\\\" training objective, which dramatically improves all models' ability to answer path queries, in some cases more than doubling accuracy. On a standard knowledge base completion task, we also demonstrate that compositional training acts as a novel form of structural regularization, reliably improving performance across all base models (reducing errors by up to 43%) and achieving new state-of-the-art results.", "PublicationYear": "2015", "Authors": ["Kelvin Guu", "John Miller", "Percy Liang"], "RelatedTopics": ["Computer Science"], "References": ["af2e6165b68e75c911dfdb8f81f9ab6627722ab7", "2aea6cc6c42101b2615753c2933a33e57dd665f2", "5346525f5022b3d60e7a954b50772ea75d967e7d", "50d53cc562225549457cbc782546bfbe1ac6f0cf", "054ba27fe5cc6085d20ea2707de886db6865dbed", "cf5ea582bccc7cb21a2ebeb7a0987f79652bde8d", "86412306b777ee35aba71d4795b02915cb8a04c3", "7c05a4ffee7e159e34b2efea7e44d994333ec628", "33261d252218007147a71e40f8367ed152fa2fe0", "2582ab7c70c9e7fcb84545944eba8f3a7f253248"], "ReferenceCount": 29, "CitationCount": 338}, {"URL": "https://www.semanticscholar.org/paper/Inductive-Representation-Learning-on-Large-Graphs-Hamilton-Ying/6b7d6e6416343b2a122f8416e69059ce919026ef", "ID": "6b7d6e6416343b2a122f8416e69059ce919026ef", "Title": "Inductive Representation Learning on Large Graphs", "Abstract": "GraphSAGE is presented, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data and outperforms strong baselines on three inductive node-classification benchmarks. Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.", "PublicationYear": "2017", "Authors": ["William L. Hamilton", "Zhitao Ying", "Jure Leskovec"], "RelatedTopics": ["Computer Science"], "References": ["36ee2c8bd605afd48035d15fdc6b8c8842363376", "3d846cb01f6a975554035d2210b578ca61344b22", "0834e74304b547c9354b6d7da6fa78ef47a48fa8", "c2fd72cb2a77941e655b5d949d0d59b01e173c3b", "36eff562f65125511b5dfab68ce7f7a943c27478", "7e1874986cf6433fabf96fff93ef42b60bdc49f8", "322cf9bcde458a45eaeca989a1eec92f7c6db984", "492f57ee9ceb61fb5a47ad7aebfec1121887a175", "fff114cbba4f3ba900f33da574283e3de7f26c83", "9ca9f28676ad788d04ba24a51141a9a0a0df4d67"], "ReferenceCount": 42, "CitationCount": 10561}, {"URL": "https://www.semanticscholar.org/paper/Column-Networks-for-Collective-Classification-Pham-Tran/97f7ef7a5332218e0e9ce75ad5cf77048466ca83", "ID": "97f7ef7a5332218e0e9ce75ad5cf77048466ca83", "Title": "Column Networks for Collective Classification", "Abstract": "\\n \\n Relational learning deals with data that are characterized by relational structures. An important task is collective classification, which is to jointly classify networked objects. While it holds a great promise to produce a better accuracy than non-collective classifiers, collective classification is computationally challenging and has not leveraged on the recent breakthroughs of deep learning. We present Column Network (CLN), a novel deep learning model for collective classification in multi-relational domains. CLN has many desirable theoretical properties: (i) it encodes multi-relations between any two instances; (ii) it is deep and compact, allowing complex functions to be approximated at the network level with a small set of free parameters; (iii) local and relational features are learned simultaneously; (iv) long-range, higher-order dependencies between instances are supported naturally; and (v) crucially, learning and inference are efficient with linear complexity in the size of the network and the number of relations. We evaluate CLN on multiple real-world applications: (a) delay prediction in software projects, (b) PubMed Diabetes publication classification and (c) film genre classification. In all of these applications, CLN demonstrates a higher accuracy than state-of-the-art rivals.\\n \\n", "PublicationYear": "2016", "Authors": ["Trang Pham", "T. Tran", "Dinh Q. Phung", "Svetha Venkatesh"], "RelatedTopics": ["Computer Science"], "References": ["676564a5654663f0b2569503cfd64b02b4810b74", "9cc36397e1fef5c922d64e88211a7e08ecc64759", "d582539ba974385a1b08c000b63fe9869a63c1ed", "5f8aaefa3c07563cb11884f3f227bd94431544ff", "5e27712db641bc8f16c510292f7fd5440acd563d", "43d2ed5c3c55c1100450cd74dc1031afa24d37b2", "bc82b4f9f202062857958f0336fc28327a75563b", "c8af456dedb2dfe664641f801d5e3060fbd4e293", "b6b26564df790262abbe48fa18079d9610189b29", "ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a"], "ReferenceCount": 34, "CitationCount": 141}, {"URL": "https://www.semanticscholar.org/paper/A-latent-factor-model-for-highly-multi-relational-Jenatton-Roux/04cc04457e09e17897f9256c86b45b92d70a401f", "ID": "04cc04457e09e17897f9256c86b45b92d70a401f", "Title": "A latent factor model for highly multi-relational data", "Abstract": "This paper proposes a method for modeling large multi-relational datasets, with possibly thousands of relations, based on a bilinear structure, which captures various orders of interaction of the data and also shares sparse latent factors across different relations. Many data such as social networks, movie preferences or knowledge bases are multi-relational, in that they describe multiple relations between entities. While there is a large body of work focused on modeling these data, modeling these multiple types of relations jointly remains challenging. Further, existing approaches tend to breakdown when the number of these types grows. In this paper, we propose a method for modeling large multi-relational datasets, with possibly thousands of relations. Our model is based on a bilinear structure, which captures various orders of interaction of the data, and also shares sparse latent factors across different relations. We illustrate the performance of our approach on standard tensor-factorization datasets where we attain, or outperform, state-of-the-art results. Finally, a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations.", "PublicationYear": "2012", "Authors": ["Rodolphe Jenatton", "Nicolas Le Roux", "Antoine Bordes", "Guillaume Obozinski"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["f6764d853a14b0c34df1d2283e76277aead40fde", "fec691d09b564986ad27162ce15344604c840ff9", "81bbe42e3ec09c28b8864956148e58f4cb5aa860", "4e07791ee0872401215f12aefde342bd843240cc", "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "1a27b23a56b42cd52249ed3767f3b320acd07c91", "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "8b27153da18537bd7ec7fd8205d24a34d1c64883", "5c12193fc84ed7973fe4515ae893625d8af4ce4f", "b6ce4ec0d28c050b99ec647a16e47116c939473c"], "ReferenceCount": 29, "CitationCount": 406}, {"URL": "https://www.semanticscholar.org/paper/A-Three-Way-Model-for-Collective-Learning-on-Data-Nickel-Tresp/f6764d853a14b0c34df1d2283e76277aead40fde", "ID": "f6764d853a14b0c34df1d2283e76277aead40fde", "Title": "A Three-Way Model for Collective Learning on Multi-Relational Data", "Abstract": "This work presents a novel approach to relational learning based on the factorization of a three-way tensor that is able to perform collective learning via the latent components of the model and provide an efficient algorithm to compute the factorizations. Relational learning is becoming increasingly important in many areas of application. Here, we present a novel approach to relational learning based on the factorization of a three-way tensor. We show that unlike other tensor approaches, our method is able to perform collective learning via the latent components of the model and provide an efficient algorithm to compute the factorization. We substantiate our theoretical considerations regarding the collective learning capabilities of our model by the means of experiments on both a new dataset and a dataset commonly used in entity resolution. Furthermore, we show on common benchmark datasets that our approach achieves better or on-par results, if compared to current state-of-the-art relational learning solutions, while it is significantly faster to compute.", "PublicationYear": "2011", "Authors": ["Maximilian Nickel", "Volker Tresp", "Hans-Peter Kriegel"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["fec691d09b564986ad27162ce15344604c840ff9", "81bbe42e3ec09c28b8864956148e58f4cb5aa860", "19680a17240eb1eab6cfec04e3faa2bd5be61ab9", "c8967a8d3d132673d2e3ff5c785b83b5402bf440", "611dac316bf03112c778cf7365d08e4a9d171876", "a32aa4d00a4038e721f0736b9b01b58d09681c15", "43d2ed5c3c55c1100450cd74dc1031afa24d37b2", "16840a46b3980eb39382814adfe2270bd5bbdbc7", "39d61c55cdf80bcb473a320492ddb64a308e54c0", "b6ce4ec0d28c050b99ec647a16e47116c939473c"], "ReferenceCount": 22, "CitationCount": 1936}, {"URL": "https://www.semanticscholar.org/paper/A-semantic-matching-energy-function-for-learning-Glorot-Bordes/eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "ID": "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82", "Title": "A semantic matching energy function for learning with multi-relational data", "Abstract": "A new neural network architecture designed to embed multi-relational graphs into a flexible continuous vector space in which the original data is kept and enhanced, demonstrating that it can scale up to tens of thousands of nodes and thousands of types of relation. Large-scale relational learning becomes crucial for handling the huge amounts of structured data generated daily in many application domains ranging from computational biology or information retrieval, to natural language processing. In this paper, we present a new neural network architecture designed to embed multi-relational graphs into a flexible continuous vector space in which the original data is kept and enhanced. The network is trained to encode the semantics of these graphs in order to assign high probabilities to plausible components. We empirically show that it reaches competitive performance in link prediction on standard datasets from the literature as well as on data from a real-world knowledge base (WordNet). In addition, we present how our method can be applied to perform word-sense disambiguation in a context of open-text semantic parsing, where the goal is to learn to assign a structured meaning representation to almost any sentence of free text, demonstrating that it can scale up to tens of thousands of nodes and thousands of types of relation.", "PublicationYear": "2013", "Authors": ["Xavier Glorot", "Antoine Bordes", "Jason Weston", "Yoshua Bengio"], "RelatedTopics": ["Computer Science"], "References": ["1f4a4769e4d2fb846e59c2f185e0377190739f18", "f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433", "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "27e38351e48fe4b7da2775bf94341738bc4da07e", "233d861338cfcd479b1d21897453fcc66418d5e1", "93bb6228776eafa606965e21f229d548de1998eb", "db328685d00ec35fe35f9350f884c7b4b8db3f4c", "12f17c64eb20f051552295d2c928f036f5b8163b", "aea0f946e8dcddb65cc2e907456c42453f246a50", "16840a46b3980eb39382814adfe2270bd5bbdbc7"], "ReferenceCount": 72, "CitationCount": 628}, {"URL": "https://www.semanticscholar.org/paper/Connecting-Language-and-Knowledge-Bases-with-Models-Weston-Bordes/834cb8e1e738b8d2c6d24e652ac966d6e7089a46", "ID": "834cb8e1e738b8d2c6d24e652ac966d6e7089a46", "Title": "Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction", "Abstract": "This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge, based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.", "PublicationYear": "2013", "Authors": ["Jason Weston", "Antoine Bordes", "Oksana Yakhnenko", "Nicolas Usunier"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["d48edf9e81653f4c3da716b037b0b50d54c5b034", "233d861338cfcd479b1d21897453fcc66418d5e1", "9c7f4412b8f0310a91334aed79b8553b2ad70908", "e7e7b9a731678bf0494fe29cbebb42a822224cc6", "2a2d03a1534b365c5b048c824c0886e16ccf7dfa", "d84b57362e2010f6f65357267df7e0157af30684", "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "796918285116a29537489bb7dc1778f2b1f3e4e8", "fbe358ce706371b93c10c4395cab9a78ad3aef67", "f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433"], "ReferenceCount": 27, "CitationCount": 236}, {"URL": "https://www.semanticscholar.org/paper/Learning-New-Facts-From-Knowledge-Bases-With-Neural-Chen-Socher/8007fc25a1f5c03f7c8ac95ccf5cf8aa3d989092", "ID": "8007fc25a1f5c03f7c8ac95ccf5cf8aa3d989092", "Title": "Learning New Facts From Knowledge Bases With Neural Tensor Networks and Semantic Word Vectors", "Abstract": "A neural tensor network (NTN) model is introduced which predicts new relationship entries that can be added to the database and can classify unseen relationships in WordNet with an accuracy of 75.8%. Knowledge bases provide applications with the benefit of easily accessible, systematic relational knowledge but often suffer in practice from their incompleteness and lack of knowledge of new entities and relations. Much work has focused on building or extending them by finding patterns in large unannotated text corpora. In contrast, here we mainly aim to complete a knowledge base by predicting additional true relationships between entities, based on generalizations that can be discerned in the given knowledgebase. We introduce a neural tensor network (NTN) model which predicts new relationship entries that can be added to the database. This model can be improved by initializing entity representations with word vectors learned in an unsupervised fashion from text, and when doing this, existing relations can even be queried for entities that were not present in the database. Our model generalizes and outperforms existing models for this problem, and can classify unseen relationships in WordNet with an accuracy of 75.8%.", "PublicationYear": "2013", "Authors": ["Danqi Chen", "Richard Socher", "Christopher D. Manning", "A. Ng"], "RelatedTopics": ["Computer Science"], "References": ["1f4a4769e4d2fb846e59c2f185e0377190739f18", "e703e928bc07900527c368db2428d0d5c57148c2", "f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433", "00a3f6924f90fcd77e6e7e6534b957a75d0ced07", "27e38351e48fe4b7da2775bf94341738bc4da07e", "2b669398c4cf2ebe04375c8b1beae20f4ac802fa", "dac72f2c509aee67524d3321f77e97e8eff51de6", "81bbe42e3ec09c28b8864956148e58f4cb5aa860", "57458bc1cffe5caa45a885af986d70f723f406b4", "d4b651d6a904f69f8fa1dcad4ebe972296af3a9a"], "ReferenceCount": 15, "CitationCount": 64}, {"URL": "https://www.semanticscholar.org/paper/Factorizing-YAGO%3A-scalable-machine-learning-for-Nickel-Tresp/498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "ID": "498ca0a1f8c980586408addf7ab2919ecdb7dd3d", "Title": "Factorizing YAGO: scalable machine learning for linked data", "Abstract": "This work presents an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts, and shows how ontological knowledge can be incorporated in the factorizations to improve learning results and how computation can be distributed across multiple nodes. Vast amounts of structured information have been published in the Semantic Web's Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD's size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD's data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize non-deterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts. Furthermore, we show how ontological knowledge can be incorporated in the factorization to improve learning results and how computation can be distributed across multiple nodes. We demonstrate that our approach is able to factorize the YAGO~2 core ontology and globally predict statements for this large knowledge base using a single dual-core desktop computer. Furthermore, we show experimentally that our approach achieves good results in several relational learning tasks that are relevant to Linked Data. Once a factorization has been computed, our model is able to predict efficiently, and without any additional training, the likelihood of any of the 4.3 \u22c5 1014 possible triples in the YAGO~2 core ontology.", "PublicationYear": "2012", "Authors": ["Maximilian Nickel", "Volker Tresp", "Hans-Peter Kriegel"], "RelatedTopics": ["Computer Science"], "References": ["477244deb1116aa0681a404c77ca2f466876bf0b", "a32aa4d00a4038e721f0736b9b01b58d09681c15", "f6764d853a14b0c34df1d2283e76277aead40fde", "19680a17240eb1eab6cfec04e3faa2bd5be61ab9", "9d8825281ef9cb55e2b4d518da1a92691257f985", "16840a46b3980eb39382814adfe2270bd5bbdbc7", "81bbe42e3ec09c28b8864956148e58f4cb5aa860", "b7d2ff895947e8730d788b6240de2807c9c1f4be", "de7a42ed958cb152e50bbda0816184e45c6a7788", "cd366ddeb824f2b26213e9040ba3ff8a4497cec4"], "ReferenceCount": 38, "CitationCount": 414}, {"URL": "https://www.semanticscholar.org/paper/Learning-Structured-Embeddings-of-Knowledge-Bases-Bordes-Weston/1f4a4769e4d2fb846e59c2f185e0377190739f18", "ID": "1f4a4769e4d2fb846e59c2f185e0377190739f18", "Title": "Learning Structured Embeddings of Knowledge Bases", "Abstract": "A learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced would allow data from any KB to be easily used in recent machine learning meth- ods for prediction and information retrieval. \\n \\n Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigorous symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like nat- ural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning meth- ods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text.\\n \\n", "PublicationYear": "2011", "Authors": ["Antoine Bordes", "Jason Weston", "Ronan Collobert", "Yoshua Bengio"], "RelatedTopics": ["Computer Science"], "References": ["a88966cdaeddd15d0a3de365a8f0a5931aebd756", "2b776119a1347e1455dc498ff5078b3a94029ed9", "d04d6db5f0df11d0cff57ec7e15134990ac07a4f", "57458bc1cffe5caa45a885af986d70f723f406b4", "364fc5142fcad8ed0f9aaee6044276eb269fb017", "aea0f946e8dcddb65cc2e907456c42453f246a50", "2d03baec8ac1568e6813aa43d625d552524f977e", "6c2b28f9354f667cd5bd07afc0471d8334430da7", "8df1e4d7a7c2f288b7ca4645b444b128b076a572", "08c81389b3ac4b8253d718a7cebe04a5536efa78"], "ReferenceCount": 26, "CitationCount": 851}, {"URL": "https://www.semanticscholar.org/paper/Relational-learning-via-collective-matrix-Singh-Gordon/fec691d09b564986ad27162ce15344604c840ff9", "ID": "fec691d09b564986ad27162ce15344604c840ff9", "Title": "Relational learning via collective matrix factorization", "Abstract": "This model generalizes several existing matrix factorization methods, and therefore yields new large-scale optimization algorithms for these problems, which can handle any pairwise relational schema and a wide variety of error models. Relational learning is concerned with predicting unknown values of a relation, given a database of entities and observed relations among entities. An example of relational learning is movie rating prediction, where entities could include users, movies, genres, and actors. Relations encode users' ratings of movies, movies' genres, and actors' roles in movies. A common prediction technique given one pairwise relation, for example a #users x #movies ratings matrix, is low-rank matrix factorization. In domains with multiple relations, represented as multiple matrices, we may improve predictive accuracy by exploiting information from one relation while predicting another. To this end, we propose a collective matrix factorization model: we simultaneously factor several matrices, sharing parameters among factors when an entity participates in multiple relations. Each relation can have a different value type and error distribution; so, we allow nonlinear relationships between the parameters and outputs, using Bregman divergences to measure error. We extend standard alternating projection algorithms to our model, and derive an efficient Newton update for the projection. Furthermore, we propose stochastic optimization methods to deal with large, sparse matrices. Our model generalizes several existing matrix factorization methods, and therefore yields new large-scale optimization algorithms for these problems. Our model can handle any pairwise relational schema and a wide variety of error models. We demonstrate its efficiency, as well as the benefit of sharing parameters among relations.", "PublicationYear": "2008", "Authors": ["Ajit Paul Singh", "Geoffrey J. Gordon"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["2549520c25c4f3fcc80cc9c99157e760a9548f14", "f273e19d9f5c8a01bb0626a923db2a381d527363", "5c58ad9a6c09782814a7d048bebd6ef1609c0fb4", "6ac17e450f35b5b4d8e8f1345a2912edfc4ca187", "6a221e1c54217a2f9e6a38c79e2f2d82d339797c", "6cd49dd5d26d1e8e33891f8e64ad3b5012e90ba6", "348b65c8dcabb6f1028f120e36eee7b4d8ae32a6", "1cb5c5cd4ccafe870e4ac8a0f040e88554ec6fc6", "6fb07b90b7fd2785ffec0da1069e75c53f7313c2", "5020ba7489d8453952c61f863af6dda91ad10bb9"], "ReferenceCount": 40, "CitationCount": 1182}, {"URL": "https://www.semanticscholar.org/paper/Modelling-Relational-Data-using-Bayesian-Clustered-Sutskever-Salakhutdinov/81bbe42e3ec09c28b8864956148e58f4cb5aa860", "ID": "81bbe42e3ec09c28b8864956148e58f4cb5aa860", "Title": "Modelling Relational Data using Bayesian Clustered Tensor Factorization", "Abstract": "The Bayesian Clustered Tensor Factorization (BCTF) model is introduced, which embeds a factorized representation of relations in a nonparametric Bayesian clustering framework that is fully Bayesian but scales well to large data sets. We consider the problem of learning probabilistic models for complex relational structures between various types of objects. A model can help us \\\"understand\\\" a dataset of relational facts in at least two ways, by finding interpretable structure in the data, and by supporting predictions, or inferences about whether particular unobserved relations are likely to be true. Often there is a tradeoff between these two aims: cluster-based models yield more easily interpretable representations, while factorization-based approaches have given better predictive performance on large data sets. We introduce the Bayesian Clustered Tensor Factorization (BCTF) model, which embeds a factorized representation of relations in a nonparametric Bayesian clustering framework. Inference is fully Bayesian but scales well to large data sets. The model simultaneously discovers interpretable clusters and yields predictive performance that matches or beats previous probabilistic models for relational data.", "PublicationYear": "2009", "Authors": ["Ilya Sutskever", "Ruslan Salakhutdinov", "Joshua B. Tenenbaum"], "RelatedTopics": ["Computer Science", "Mathematics"], "References": ["ce97e12004784109965febf3abf06fabed91c6a1", "5262fe8369992259be27165ccd09d1d31c7a4def", "1a27b23a56b42cd52249ed3767f3b320acd07c91", "d9b9fb207013bf8afb064f23f3dffc7edd005f73", "e19971e7d100386b9b4cf4ea1a0782b62fe036e5", "b6ce4ec0d28c050b99ec647a16e47116c939473c", "87ca5a0f345533c30217f6359bc4325a2442a0b9", "be860525cb9c5d99722a5f3535bbbbbd605a7ea5", "91e62d27c08db29cf011a0326a61509e574cf772", "6305dcc03c8378e371e73b0a68ff29f1167a65f0"], "ReferenceCount": 41, "CitationCount": 272}, {"URL": "https://www.semanticscholar.org/paper/Nonparametric-Latent-Feature-Models-for-Link-Miller-Griffiths/4e07791ee0872401215f12aefde342bd843240cc", "ID": "4e07791ee0872401215f12aefde342bd843240cc", "Title": "Nonparametric Latent Feature Models for Link Prediction", "Abstract": "This work pursues a similar approach with a richer kind of latent variable\u2014latent features\u2014using a Bayesian nonparametric approach to simultaneously infer the number of features at the same time the authors learn which entities have each feature, and combines these inferred features with known covariates in order to perform link prediction. As the availability and importance of relational data\u2014such as the friendships summarized on a social networking website\u2014increases, it becomes increasingly important to have good models for such data. The kinds of latent structure that have been considered for use in predicting links in such networks have been relatively limited. In particular, the machine learning community has focused on latent class models, adapting Bayesian nonparametric methods to jointly infer how many latent classes there are while learning which entities belong to each class. We pursue a similar approach with a richer kind of latent variable\u2014latent features\u2014using a Bayesian nonparametric approach to simultaneously infer the number of features at the same time we learn which entities have each feature. Our model combines these inferred features with known covariates in order to perform link prediction. We demonstrate that the greater expressiveness of this approach allows us to improve performance on three datasets.", "PublicationYear": "2009", "Authors": ["Kurt T. Miller", "Thomas L. Griffiths", "Michael I. Jordan"], "RelatedTopics": ["Computer Science"], "References": ["4d63618acc0bc6ecb1b3e88d5050b1cef06c3bed", "c8967a8d3d132673d2e3ff5c785b83b5402bf440", "15a1779b2029787a0d683f072ba9ae2a87b660a9", "d9b9fb207013bf8afb064f23f3dffc7edd005f73", "82e4390c043754d5af22d48964a42a891f81e8b3", "dbe30a96b7db2df4e8f6c3492e2092c68feedcd6", "769139f6cc8e50b1ad426c1bf48a3332c86819fc", "bce1b1140472a45ca4864c1cade951ccc9893291", "ab30b9de25048c15df0ebc353c64f4f3cf6ed52b", "630bab4b708bc6621f97789b14f790153f115d15"], "ReferenceCount": 26, "CitationCount": 420}, {"URL": "https://www.semanticscholar.org/paper/DocBERT%3A-BERT-for-Document-Classification-Adhikari-Ram/1a9954d86466a7e4de6f98ddee452ceb50e15d86", "ID": "1a9954d86466a7e4de6f98ddee452ceb50e15d86", "Title": "DocBERT: BERT for Document Classification", "Abstract": "It is shown that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets, and distill knowledge from BERT-large to small bidirectional LSTMs, reaching Bert-base parity on multiple datasets using 30x fewer parameters. We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.", "PublicationYear": "2019", "Authors": ["Ashutosh Adhikari", "Achyudh Ram", "Raphael Tang", "Jimmy J. Lin"], "RelatedTopics": ["Computer Science"], "References": ["b7bdf98ef84909d4ec0b2ebd5157ee3cb38522b8", "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89", "9d32a5f33826471e5dc895bc6da654c0ddb66ebc", "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "0c908739fbff75f03469d13d4a1a07de3414ee19", "ace92710c6090131d9b28fcfee0038c3ceb18438", "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "455afd748e8834ef521e4b67c7c056d3c33429e2", "9257779eed46107bcdce9f4dc86298572ff466ce"], "ReferenceCount": 24, "CitationCount": 254}, {"URL": "https://www.semanticscholar.org/paper/Hierarchical-Multi-label-Classification-of-Text-Aly-Remus/58203813610b866483ffc2bd1181f616ae38107c", "ID": "58203813610b866483ffc2bd1181f616ae38107c", "Title": "Hierarchical Multi-label Classification of Text with Capsule Networks", "Abstract": "This paper applies and compares simple shallow capsule networks for hierarchical multi-label text classification and shows that they can perform superior to other neural networks, and non-neural network architectures such as SVMs. Capsule networks have been shown to demonstrate good performance on structured data in the area of visual inference. In this paper we apply and compare simple shallow capsule networks for hierarchical multi-label text classification and show that they can perform superior to other neural networks, such as CNNs and LSTMs, and non-neural network architectures such as SVMs. For our experiments, we use the established Web of Science (WOS) dataset and introduce a new real-world scenario dataset, the BlurbGenreCollection (BGC). Our results confirm the hypothesis that capsule networks are especially advantageous for rare events and structurally diverse categories, which we attribute to their ability to combine latent encoded information.", "PublicationYear": "2019", "Authors": ["Rami Aly", "Steffen Remus", "Chris Biemann"], "RelatedTopics": ["Computer Science"], "References": ["4bb858f1cb3d02aaf526046ce0b42be34a2d403b", "6a377115d0026bca3f67ed34ea03543880f6a2e3", "ba98f3e910160e2b699d6db34af5bf52778c983c", "67e69f21270400d285e2c5d5e7d91305ae458399", "ff7eb443d708674a257ebf84f605daff578a9c99", "a5cbdb78ef74aafa5b5610ba3390ae319d28aff8", "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "9dfacffdae4527d01563814c804e410e4ca885e1", "76394c65ae506fcbfc582d0ed917042f8c7bbe22", "6a597d84842c5c89c56014135646f9a4078b0b3b"], "ReferenceCount": 25, "CitationCount": 64}, {"URL": "https://www.semanticscholar.org/paper/Multi-Task-Learning-of-Pairwise-Sequence-Tasks-over-Augenstein-Ruder/64c5f7055b2e6982b6b95e069b22230d13a134bb", "ID": "64c5f7055b2e6982b6b95e069b22230d13a134bb", "Title": "Multi-Task Learning of Pairwise Sequence Classification Tasks over Disparate Label Spaces", "Abstract": "This work combines multi-task learning and semi-supervised learning by inducing a joint embedding space between disparate label spaces and learning transfer functions between label embeddings, enabling them to jointly leverage unlabelled data and auxiliary, annotated datasets. We combine multi-task learning and semi-supervised learning by inducing a joint embedding space between disparate label spaces and learning transfer functions between label embeddings, enabling us to jointly leverage unlabelled data and auxiliary, annotated datasets. We evaluate our approach on a variety of tasks with disparate label spaces. We outperform strong single and multi-task baselines and achieve a new state of the art for aspect-based and topic-based sentiment analysis.", "PublicationYear": "2018", "Authors": ["Isabelle Augenstein", "Sebastian Ruder", "Anders S{\\o}gaard"], "RelatedTopics": ["Computer Science"], "References": ["ac17cfa150d802750b46220084d850cfdb64d1c1", "80342ff87a7bda2168f57a601577ae39e8f4e9b6", "ad945987071d3c5b4b915b85e09ae3488b2212c0", "1b02204b210f822dabf8d68b7e3ea7ac14ee1268", "9151f229e7b4e318b0b12afe99993da0ee5e0e34", "03ad06583c9721855ccd82c3d969a01360218d86", "83b83ee4f27388445bdebb199cd75e5bf546dd85", "d23f3b85ec5595df8115407aaf7d769abce1fe20", "d3c04a424fff21d3d12ff8b0543734cf244d5f67", "bfca0b9a3198685eaa403e89e1da7c55d0393499"], "ReferenceCount": 49, "CitationCount": 73}, {"URL": "https://www.semanticscholar.org/paper/Using-Wikipedia-knowledge-to-improve-text-Wang-Hu/fc1d23d2f9167d13ef1bce098ef55d1b40894dd4", "ID": "fc1d23d2f9167d13ef1bce098ef55d1b40894dd4", "Title": "Using Wikipedia knowledge to improve text classification", "Abstract": "Experimental results on several data sets show that the proposed approach, integrated with the thesaurus built from Wikipedia, can achieve significant improvements with respect to the baseline algorithm. Text classification has been widely used to assist users with the discovery of useful information from the Internet. However, traditional classification methods are based on the \u201cBag of Words\u201d (BOW) representation, which only accounts for term frequency in the documents, and ignores important semantic relationships between key terms. To overcome this problem, previous work attempted to enrich text representation by means of manual intervention or automatic document expansion. The achieved improvement is unfortunately very limited, due to the poor coverage capability of the dictionary, and to the ineffectiveness of term expansion. In this paper, we automatically construct a thesaurus of concepts from Wikipedia. We then introduce a unified framework to expand the BOW representation with semantic relations (synonymy, hyponymy, and associative relations), and demonstrate its efficacy in enhancing previous approaches for text classification. Experimental results on several data sets show that the proposed approach, integrated with the thesaurus built from Wikipedia, can achieve significant improvements with respect to the baseline algorithm.", "PublicationYear": "2009", "Authors": ["Pu Wang", "Jian Hu", "Hua-Jun Zeng", "Zheng Chen"], "RelatedTopics": ["Computer Science"], "References": ["c54f38857d25315ad1ca4024010cfd985d361e9b", "7a24be92f23e7d2b07c7a1396d401a058870bb5f", "fb8f6c5670755a7d282fb9322bc8439492ea052a", "b5faf0d29a3abc83b69d3339800ad2c1c0fdcd65", "3b27c7eae282b938a6ab768dc00ca212c1ed625a", "7c56100bd4b89735bf9332b79c12e54d9368e9ac", "338a891907dce447da9a0fa2f27221bd35164163", "38b3a4447a47a6a6ed1869f3da03352c487f8fe3", "6e55023e67ee4681736b0ca5ef516b8abaca0ca0", "56951f7d540d2fe3bf845be0111a49177d3ad956"], "ReferenceCount": 19, "CitationCount": 178}, {"URL": "https://www.semanticscholar.org/paper/Hierarchical-Attention-Networks-for-Document-Yang-Yang/455afd748e8834ef521e4b67c7c056d3c33429e2", "ID": "455afd748e8834ef521e4b67c7c056d3c33429e2", "Title": "Hierarchical Attention Networks for Document Classification", "Abstract": "Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. We propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences.", "PublicationYear": "2016", "Authors": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard H. Hovy"], "RelatedTopics": ["Computer Science"], "References": ["f895cbc2d4a2cd00b4a81cccabc6d9c94b8ddfe4", "2c1890864c1c2b750f48316dc8b650ba4772adc5", "7e8d5a108c28cdfb92f419ce919fbf7993dfebfc", "1e7cf9047604f39e517951d129b2b3eecf9e1cfb", "eba36ac75bf22edf9a1bfd33244d459c75b98305", "27725a2d2a8cee9bf9fffc6c2167017103aba0fa", "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "ecb5336bf7b54a62109f325e7152bb74c4c7f527", "b21c78a62fbb945a19ae9a8935933711647e7d70", "32de44f01a96d4473d21099d15e25bc2b9f08e2f"], "ReferenceCount": 34, "CitationCount": 4098}, {"URL": "https://www.semanticscholar.org/paper/Massively-Multilingual-Sentence-Embeddings-for-and-Artetxe-Schwenk/160563abbd75265b19afc8b4169bab9e1eb33d97", "ID": "160563abbd75265b19afc8b4169bab9e1eb33d97", "Title": "Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond", "Abstract": "An architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts using a single BiLSTM encoder with a shared byte-pair encoding vocabulary for all languages, coupled with an auxiliary decoder and trained on publicly available parallel corpora. Abstract We introduce an architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts. Our system uses a single BiLSTM encoder with a shared byte-pair encoding vocabulary for all languages, which is coupled with an auxiliary decoder and trained on publicly available parallel corpora. This enables us to learn a classifier on top of the resulting embeddings using English annotated data only, and transfer it to any of the 93 languages without any modification. Our experiments in cross-lingual natural language inference (XNLI data set), cross-lingual document classification (MLDoc data set), and parallel corpus mining (BUCC data set) show the effectiveness of our approach. We also introduce a new test set of aligned sentences in 112 languages, and show that our sentence embeddings obtain strong results in multilingual similarity search even for low- resource languages. Our implementation, the pre-trained encoder, and the multilingual test set are available at https://github.com/facebookresearch/LASER.", "PublicationYear": "2018", "Authors": ["Mikel Artetxe", "Holger Schwenk"], "RelatedTopics": ["Computer Science", "Linguistics"], "References": ["1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "d1c16b82e04f36614f218d0dd1f8af0c0b60df3a", "800c56dba246d3b3cee9ae9cbb456e17dcb72682", "562c09c112df56c5696c010d90a815d6018a86c8", "a486e2839291111bb44fa1f07731ada123539f75", "8f204d94cb75d7b704e2e7be6174051db169d0db", "48925fef94500cf19ee220ed74217816f1ab5e60", "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc", "f3b96ef2dc1fc5e14982f1b963db8db6a54183bb", "1a1b75176575634f509b65401914fe8ad9967a88"], "ReferenceCount": 67, "CitationCount": 789}, {"URL": "https://www.semanticscholar.org/paper/PyTorch-BigGraph%3A-A-Large-scale-Graph-Embedding-Lerer-Wu/7ac58400e5063bed9b7c35f87e44ddb917ccf357", "ID": "7ac58400e5063bed9b7c35f87e44ddb917ccf357", "Title": "PyTorch-BigGraph: A Large-scale Graph Embedding System", "Abstract": "PyTorch-BigGraph (PBG), an embedding system that incorporates several modifications to traditional multi-relation embedding systems that allow it to scale to graphs with billions of nodes and trillions of edges, is presented. Graph embedding methods produce unsupervised node features from graphs that can then be used for a variety of machine learning tasks. Modern graphs, particularly in industrial applications, contain billions of nodes and trillions of edges, which exceeds the capability of existing embedding systems. We present PyTorch-BigGraph (PBG), an embedding system that incorporates several modifications to traditional multi-relation embedding systems that allow it to scale to graphs with billions of nodes and trillions of edges. PBG uses graph partitioning to train arbitrarily large embeddings on either a single machine or in a distributed environment. We demonstrate comparable performance with existing embedding systems on common benchmarks, while allowing for scaling to arbitrarily large graphs and parallelization on multiple machines. We train and evaluate embeddings on several large social network graphs as well as the full Freebase dataset, which contains over 100 million nodes and 2 billion edges.", "PublicationYear": "2019", "Authors": ["Adam Lerer", "Ledell Yu Wu", "Jiajun Shen", "Timoth{\\'e}e Lacroix", "Luca Wehrstedt", "Abhijit Bose", "Alexander Peysakhovich"], "RelatedTopics": ["Computer Science"], "References": ["6b7d6e6416343b2a122f8416e69059ce919026ef", "984caf9e6f3e912b33356be2e1fba9ab2676fd79", "ecf6c42d84351f34e1625a6a2e4cc6526da45c74", "420a0e5fc398f197bca3dfe40291a82b2c65655a", "df67349bc22e251ddd586e16091d881321578b9a", "6c96c2d4a3fbd572fef2d59cb856521ee1746789", "e41956966fbbde4a25b420ab0cf32b62ab6e2589", "a1959624b143dc067898a1cda20b80307a963ac4", "cd8a9914d50b0ac63315872530274d158d6aff09", "033f25ad905ef2ed32a8331cf38b83953ff15922"], "ReferenceCount": 45, "CitationCount": 319}, {"URL": "https://www.semanticscholar.org/paper/A-Simple-Method-for-Commonsense-Reasoning-Trinh-Le/d7b6753a2d4a2b286c396854063bde3a91b75535", "ID": "d7b6753a2d4a2b286c396854063bde3a91b75535", "Title": "A Simple Method for Commonsense Reasoning", "Abstract": "Key to this method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests, which outperform previous state-of-the-art methods by a large margin. Commonsense reasoning is a long-standing challenge for deep learning. For example, it is difficult to use neural networks to tackle the Winograd Schema dataset (Levesque et al., 2011). In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.", "PublicationYear": "2018", "Authors": ["Trieu H. Trinh", "Quoc V. Le"], "RelatedTopics": ["Computer Science"], "References": ["bb770a84b9c93514e579a18a7acff528eb0677b4", "10ce5528d372765d5eeac312beacac35106660a8", "cea967b59209c6be22829699f05b8b1ac4dc092d", "85f94d8098322f8130512b4c6c4627548ce4a6cc", "e86e81ad3fa4ab0b736f7fef721689e293ee788e", "05dd7254b632376973f3a1b4d39485da17814df5", "1e077413b25c4d34945cc2707e17e46ed4fe784a", "c319af92127378e7ee64ec6a3e2e8752fe1421c7", "3febb2bed8865945e7fddc99efd791887bb7e14f", "ebe84feeed3cf6a297f5a2fa504647e3eeba05b5"], "ReferenceCount": 40, "CitationCount": 375}]